1 00:00:01,786 --> 00:00:05,562 主持人：欢迎，Jeff，感谢您接受 deeplearning.ai 的采访。
2 00:00:07,451 --> 00:00:09,079 主持人：感谢您的邀请。
3 00:00:09,311 --> 00:00:38,137 主持人：我认为在这个世界上，您比任何人都更多地发明了深度学习背后的许多想法，很多人称您为深度学习的教父，尽管直到我们几分钟前的聊天中我才意识到，您是第一个这样称呼您的人，我很高兴能这样做，但我想要问的是，很多人知道您是一位传奇人物，我想了解您作为传奇背后的个人故事。
4 00:00:38,118 --> 00:00:44,689 主持人：那么，您是如何涉足人工智能、机器学习和神经网络的，可以追溯到很久以前吗？
5 00:00:46,051 --> 00:00:51,279 说话人 SPEAKER_02：所以我上高中时，有一个同学在所有事情上都比我做得更好。
6 00:00:52,540 --> 00:00:53,823 说话人 SPEAKER_02：他是一位杰出的数学家。
7 00:00:54,704 --> 00:01:00,154 说话人 SPEAKER_02：有一天他来到学校，说，你知道吗，大脑使用全息图？
8 00:01:01,676 --> 00:01:05,221 说话人 SPEAKER_02：我想那是在 1966 年左右。
9 00:01:05,826 --> 00:01:07,368 说话人 SPEAKER_02：我说，嗯，什么是全息图？
10 00:01:07,388 --> 00:01:12,275 说话人 SPEAKER_02：他解释说，在全息图中，你砍掉一半，仍然能看到整个画面。
11 00:01:13,036 --> 00:01:15,840 说话人 SPEAKER_02：大脑中的记忆可能分布在整个大脑中。
12 00:01:16,680 --> 00:01:24,852 说话人 SPEAKER_02：我想他可能阅读过 Lashley 的实验，其中你砍掉老鼠大脑的一部分，发现很难找到存储特定记忆的一个特定部分。
13 00:01:27,975 --> 00:01:32,120 说话人 SPEAKER_02：这就是最初让我对大脑如何存储记忆产生兴趣的原因。
14 00:01:33,367 --> 00:01:38,493 说话人 SPEAKER_02：然后我上大学，最初学习生理学和物理学。
15 00:01:39,655 --> 00:01:43,379 说话人 SPEAKER_02：我想我在剑桥的时候，是唯一一个同时学习生理学和物理学的本科生。
16 00:01:44,260 --> 00:01:52,191 说话人 SPEAKER_02：然后我放弃了这个想法，尝试学习哲学，因为我认为这可能会给我带来更多的洞察力。
17 00:01:52,432 --> 00:01:59,540 说话人 SPEAKER_02：但实际上我觉得他们在说谎时缺乏区分方式。
18 00:02:00,581 --> 00:02:02,665 说话人 SPEAKER_02：所以我转到了心理学。
19 00:02:03,269 --> 00:02:08,094 说话人 SPEAKER_02：在心理学中，他们有非常简单的理论。
20 00:02:08,515 --> 00:02:12,099 说话人 SPEAKER_02：在我看来，这些理论对于解释大脑的工作是极其不充分的。
21 00:02:12,860 --> 00:02:14,824 说话人 SPEAKER_02：然后我休息了一段时间，成为了一名木匠。
22 00:02:15,664 --> 00:02:18,027 说话人 SPEAKER_02：然后我决定尝试人工智能。
23 00:02:18,628 --> 00:02:21,992 说话人 SPEAKER_02：然后我去了爱丁堡，和 Longit Higgins 一起学习人工智能。
24 00:02:22,854 --> 00:02:24,977 说话人 SPEAKER_02：他在神经网络方面做了很多出色的工作。
25 00:02:25,418 --> 00:02:30,424 说话人 SPEAKER_02：他已经放弃了神经网络，并对 Winograd 的论文印象深刻。
26 00:02:30,961 --> 00:02:36,828 说话人 SPEAKER_02：所以我到的时候，他认为我正在做这种过时的东西，我应该开始做符号 AI。
27 00:02:37,449 --> 00:02:40,592 说话人 SPEAKER_02：我们为此争论了很多，但我一直坚持自己的信念。
28 00:02:41,413 --> 00:02:42,254 说话人 SPEAKER_02：然后呢？
29 00:02:43,516 --> 00:02:49,463 说话人 SPEAKER_02：我最终获得了人工智能的博士学位，然后在英国找不到工作。
30 00:02:51,507 --> 00:02:56,152 说话人 SPEAKER_02：但我看到了加州斯隆奖学金的一个非常好的广告。
31 00:02:57,593 --> 00:02:58,975 说话人 SPEAKER_02：我设法得到了其中一个。
32 00:02:59,377 --> 00:03:00,478 说话人 SPEAKER_02：然后我去了加州。
33 00:03:00,762 --> 00:03:02,223 说话人 SPEAKER_02：在那里，一切都不同了。
34 00:03:04,106 --> 00:03:09,253 说话人 SPEAKER_02：在英国，神经网络被认为有点愚蠢。
35 00:03:09,294 --> 00:03:19,870 说话人 SPEAKER_02：而在加利福尼亚，Don Norman 和 David Ronald Hart 对神经网络的想法非常开放。
36 00:03:19,930 --> 00:03:26,179 说话人 SPEAKER_02：这是我第一次去一个地方，那里的人们在思考大脑是如何工作的，以及这如何可能与心理学相关。
37 00:03:26,479 --> 00:03:28,542 说话人 SPEAKER_02：被视为一件非常积极的事情。
38 00:03:28,902 --> 00:03:30,304 说话人 SPEAKER_02：在那里有很多乐趣。
39 00:03:30,324 --> 00:03:32,646 说话人 SPEAKER_02：特别是与 David Rommelhardt 合作很棒。
40 00:03:33,106 --> 00:03:33,427 说话人 SPEAKER_02：我明白了。
41 00:03:33,448 --> 00:03:33,647 说话人 说话人_00: 对。
42 00:03:33,728 --> 00:03:42,997 所以这是你还在加州大学圣地亚哥分校的时候，你和 Rommelhardt，大约在 1982 年，完成了那篇开创性的背景论文，对吧？
43 00:03:43,337 --> 00:03:45,520 说话人 说话人_: 实际上，情况比这更复杂。
44 00:03:46,801 --> 00:03:48,343 说话人 说话人_02: 发生了什么？
45 00:03:48,364 --> 00:03:55,812 说话人 SPEAKER_02：我想，在 1982 年初，大卫·罗梅尔哈特和我
46 00:03:56,197 --> 00:04:02,227 说话人 SPEAKER_02：还有罗恩·威廉姆斯，我们俩共同开发了反向传播算法。
47 00:04:02,426 --> 00:04:04,550 说话人 SPEAKER_02：这主要是大卫·鲁梅尔哈特的想法。
48 00:04:05,772 --> 00:04:08,796 说话人 SPEAKER_02：后来我们发现，还有很多人已经发明了它。
49 00:04:09,558 --> 00:04:14,646 说话人 SPEAKER_02：大卫·帕克发明了它，可能在我们之后，但在我们发表之前。
50 00:04:16,290 --> 00:04:21,478 说话人 SPEAKER_02：保罗·韦伯斯多年前就已经发表了，但没有人过多关注。
51 00:04:22,031 --> 00:04:25,357 说话人 SPEAKER_02：还有其他人开发了非常类似的算法。
52 00:04:25,416 --> 00:04:30,985 说话人 SPEAKER_02：反向传播的含义并不明确，但使用链式法则来获取导数并不是一个新颖的想法。
53 00:04:32,447 --> 00:04:39,317 说话人 说话人_00: 你认为为什么是你的论文对社区接受反向传播算法帮助如此之大？
54 00:04:39,377 --> 00:04:44,324 说话人 说话人_: 它感觉你的论文标志着这个算法被接受的一个转折点，无论谁接受了它。
55 00:04:45,446 --> 00:04:49,812 说话人 说话人_02: 所以我们成功在1986年将论文发表在《自然》杂志上。
56 00:04:50,112 --> 00:04:53,216 说话人 说话人_02: 我为了使这篇论文被接受做了很多政治工作。
57 00:04:53,858 --> 00:04:59,807 讲者 SPEAKER_02：我想到了一个裁判可能就是斯图尔特·萨瑟兰，他是英国著名的心理学家。
58 00:05:00,408 --> 00:05:03,994 讲者 SPEAKER_02：我和他谈了很久，并详细解释了正在发生的事情。
59 00:05:04,754 --> 00:05:11,985 讲者 SPEAKER_02：他对我们展示反向传播能够学习词的表示印象深刻。
60 00:05:12,266 --> 00:05:18,516 讲者 SPEAKER_02：你可以查看这些表示，它们是小小的向量，你可以理解个别特征的意义。
61 00:05:19,120 --> 00:05:34,016 说话人 SPEAKER_02：所以我们实际上是在关于家谱的小三元词上训练它，比如玛丽有母亲维多利亚，你给出前两个词，它就得预测最后一个词。
62 00:05:34,838 --> 00:05:48,012 说话人 SPEAKER_02：训练之后，你可以在单个词的表示中看到各种特征，比如人的国籍和他们的时代，他们在家谱中的哪个分支，等等。
63 00:05:48,398 --> 00:05:50,759 说话人 SPEAKER_02：这就是斯图尔特·萨瑟顿对它印象深刻的原因。
64 00:05:50,800 --> 00:05:52,581 说话人 SPEAKER_02：我想这就是论文被接受的原因。
65 00:05:53,201 --> 00:06:00,889 说话人 说话人_00：非常早期的词嵌入，你已经开始看到从训练算法中学习到的语义意义的特征。
66 00:06:01,670 --> 00:06:01,910 说话人 说话人_02：是的。
67 00:06:02,050 --> 00:06:12,098 说话人 说话人_02：从心理学家的角度来看，有趣的是它统一了关于知识是什么样的两种完全不同的思想流派。
68 00:06:13,000 --> 00:06:17,764 说话人 说话人_02：所以，有老心理学家的观点，一个概念只是一个大特征包。
69 00:06:18,165 --> 00:06:19,427 证据很多。
70 00:06:20,048 --> 00:06:29,141 那时 AI 的观点是一种更结构主义的观点，即一个概念是如何与其他概念相关联的。
71 00:06:29,661 --> 00:06:34,127 为了捕捉一个概念，你可能需要做一些类似图结构或语义网的事情。
72 00:06:35,029 --> 00:06:48,088 这个反向传播的例子表明，你可以给它输入信息，这些信息可以进入图结构，或者在这个例子中，是一个家谱，然后它可以把这些信息转换成特征。
73 00:06:48,591 --> 00:06:55,600 说话人 SPEAKER_02: 以一种方式，使其能够利用特征来推导出新的连贯信息，即。
74 00:06:55,680 --> 00:06:56,201 说话人 SPEAKER_02: 进行泛化。
75 00:06:56,723 --> 00:07:11,562 说话人 SPEAKER_02: 但关键在于这种在图形表示，或者说家谱的树状结构表示，以及将人物表示为大型特征向量之间的往复，以及你能够从
76 00:07:12,216 --> 00:07:18,269 说话人 SPEAKER_02: 图形表示中获取到特征向量，从特征向量中又能获取到更多的图形表示。
77 00:07:18,288 --> 00:07:19,250 说话人 SPEAKER_02：这是 1986 年。
78 00:07:19,269 --> 00:07:33,718 说话人 SPEAKER_02：在 20 世纪 90 年代初，Bengio 展示了你可以使用真实数据，你可以使用英文文本并应用相同的技巧，从而从英文文本中获得真实单词的嵌入。
79 00:07:34,271 --> 00:07:36,314 说话人 SPEAKER_00：这让人们印象深刻。
80 00:07:37,196 --> 00:07:44,906 说话人 SPEAKER_00：我想最近我们谈论了很多关于计算机如 GPU 和超级计算机如何推动深度学习发展的话题。
81 00:07:45,005 --> 00:07:52,937 说话人 说话人_00：我没有意识到在1986年到90年代初，你丹乔之间已经有了这种趋势的萌芽。
82 00:07:53,838 --> 00:07:55,220 说话人 说话人_02：是的，有一个巨大的进步。
83 00:07:55,360 --> 00:08:03,891 说话人 说话人_02：我的意思是，1986 年，我使用的是 Lisp 机器，它的速度不到十分之一兆次浮点运算。
84 00:08:04,629 --> 00:08:10,596 说话人 说话人_02：到1993年左右，人们看到的速度大约是10兆次浮点运算。
85 00:08:11,057 --> 00:08:12,478 说话人 SPEAKER_02：这是一个 100 倍的因子。
86 00:08:13,000 --> 00:08:16,584 说话人 SPEAKER_02：就在这个时候使用起来变得容易，因为计算机的速度正在变快。
87 00:08:16,884 --> 00:08:22,870 说话人 SPEAKER_00：在过去的几十年里，你发明了许多神经网络和深度学习的部件。
88 00:08:23,351 --> 00:08:28,478 说话人 SPEAKER_00：我实际上很好奇，你发明了这么多东西，哪些是你现在仍然最兴奋的？
89 00:08:30,043 --> 00:08:34,750 说话人 SPEAKER_02：我认为最美丽的是我和 Terry Sinofsky 在巴尔的摩机器上的工作。
90 00:08:35,871 --> 00:08:45,965 说话人 SPEAKER_02：我们发现有一个非常简单的学习算法，适用于非常大的密集连接网络，你只能看到少数节点。
91 00:08:46,785 --> 00:08:59,341 说话人 SPEAKER_02：它会学习隐藏表示，这是一个非常简单的算法，看起来就像你能在大脑中找到的那种，因为每个突触只需要了解它直接连接的两个神经元的特性。
92 00:09:00,166 --> 00:09:04,490 说话人 SPEAKER_02：传播的信息是相同的。
93 00:09:04,551 --> 00:09:08,294 说话人 SPEAKER_02：有两个不同的阶段，我们称之为清醒和睡眠。
94 00:09:08,414 --> 00:09:12,078 说话人 SPEAKER_02：但在这两个不同的阶段，你都是以相同的方式传播信息。
95 00:09:12,578 --> 00:09:18,085 说话人 SPEAKER_02：而像反向传播这样的过程，有一个正向传递和一个反向传递，它们的工作方式不同。
96 00:09:18,105 --> 00:09:19,687 说话人 SPEAKER_02：它们发送的是不同类型的信号。
97 00:09:21,028 --> 00:09:21,408 说话人 SPEAKER_02: 对。
98 00:09:21,427 --> 00:09:23,831 说话人 SPEAKER_02: 我认为那是最美丽的事情。
99 00:09:24,471 --> 00:09:28,535 说话人 SPEAKER_02: 而在许多年里，它看起来就像一个好奇心，因为它看起来太慢了。
100 00:09:29,342 --> 00:09:37,340 说话人 SPEAKER_02: 但后来，我放弃了一些美丽，不再让事物稳定下来，而是在一个相对简单的网络中使用一次迭代。
101 00:09:37,902 --> 00:09:42,731 说话人 SPEAKER_02：这导致了受限玻尔兹曼机，实际上在实践中效果非常好。
102 00:09:42,792 --> 00:09:45,057 说话人 SPEAKER_02：比如在 Netflix 竞赛中，
103 00:09:45,255 --> 00:09:48,701 说话人 SPEAKER_02：受限玻尔兹曼机是获奖方案的一部分。
104 00:09:49,282 --> 00:10:01,100 说话人 SPEAKER_00：实际上，从大约 2007 年开始，神经网络深度学习的近期复兴很大程度上归功于您和您实验室在受限玻尔兹曼机和深度受限玻尔兹曼机方面的工作。
105 00:10:02,222 --> 00:10:04,927 说话人 SPEAKER_02: 是的，这是我非常高兴的另一项工作。
106 00:10:05,427 --> 00:10:11,297 说话人 SPEAKER_02: 想法是你可以训练一个只有一层隐藏特征的受限玻尔兹曼机，
107 00:10:11,934 --> 00:10:13,836 说话人 SPEAKER_02: 你可以学习一层特征。
108 00:10:14,357 --> 00:10:17,441 说话人 SPEAKER_02: 然后你可以将这些特征视为数据再次进行操作。
109 00:10:17,480 --> 00:10:22,066 说话人 SPEAKER_02：然后你可以把学到的这些新特征当作数据，喜欢多少次就做多少次。
110 00:10:23,648 --> 00:10:25,509 说话人 SPEAKER_02：这很好，实际上效果不错。
111 00:10:26,331 --> 00:10:34,379 说话人 SPEAKER_02：然后易伟泰意识到整个系统可以当作一个单一模型来处理，但这是一个很奇怪的类型。
112 00:10:34,919 --> 00:10:37,722 说话人 SPEAKER_02：这是一个模型，在顶部有一个受限玻尔兹曼机，
113 00:10:38,311 --> 00:10:45,817 说话人 SPEAKER_02：但在那之下，你有一个 sigmoid 信念网络，这是 Radford Neal 多年前发明的东西。
114 00:10:46,298 --> 00:10:47,620 说话人 SPEAKER_02：所以它是一个有向模型。
115 00:10:48,541 --> 00:10:55,988 说话人 SPEAKER_02：通过训练这些受限的 BOS 机器，我们找到了在 sigmoid 信念网络中进行推理的高效方法。
116 00:10:57,149 --> 00:11:07,879 说话人 SPEAKER_02：在那个时期，有一些使用密集连接网络进行神经网络研究的人，但他们没有好的方法来进行概率推理。
117 00:11:08,585 --> 00:11:18,953 说话人 SPEAKER_02：你有一些人做图形模型，比如 Mike Jordan，他们能正确进行推理，但只能在稀疏连接的网络中。
118 00:11:20,154 --> 00:11:31,245 说话人 SPEAKER_02：而我们设法证明的是，有一种方法可以学习这些深度信念网络，从而实现快速的近似推理，它只需要单次正向传递即可完成。
119 00:11:32,105 --> 00:11:33,907 说话人 SPEAKER_02：这是一个非常漂亮的结果。
120 00:11:34,347 --> 00:11:38,270 说话人 SPEAKER_02：你可以保证每次你学习一个额外的特征层时，
121 00:11:39,230 --> 00:11:40,110 说话人 SPEAKER_02：有一个界限。
122 00:11:40,672 --> 00:11:45,177 说话人 SPEAKER_02：每次你学习一个新的层，你得到一个新的界限，而这个新的界限总是比旧的界限更好。
123 00:11:45,557 --> 00:11:50,263 说话人 SPEAKER_00：是的，或者那个变分界限表明，随着层的增加，是的，是的，我记得。
124 00:11:50,283 --> 00:11:52,625 说话人 SPEAKER_02：所以这是我真正兴奋的第二件事。
125 00:11:53,086 --> 00:11:58,133 说话人 SPEAKER_02：我想第三件事是我和布拉德福德·尼尔在变分方法上的工作。
126 00:11:58,994 --> 00:12:05,400 说话人 SPEAKER_02：结果发现统计学界早些时候已经做了类似的工作，但我们不知道这一点。
127 00:12:07,984 --> 00:12:08,544 说话人 SPEAKER_02：所以
128 00:12:09,267 --> 00:12:14,273 说话人 SPEAKER_02：我们通过表明不需要进行完美的 E 步，成功地使 EM 工作变得更好。
129 00:12:14,293 --> 00:12:15,754 说话人 SPEAKER_02：你可以做一个近似的 E 步。
130 00:12:16,056 --> 00:12:20,461 说话人 SPEAKER_02：EM 算法在统计学中是一个大算法，我们已经展示了它的一个重大推广。
131 00:12:21,101 --> 00:12:36,961 说话人 SPEAKER_02：特别是在 1993 年左右，我想，我和 Van Kamp 合作发表了一篇论文，我认为这是第一篇变分贝叶斯论文，我们展示了你可以实际上做一个贝叶斯学习的版本，这个版本远比原来的更易于处理
132 00:12:37,600 --> 00:12:40,073 说话人 SPEAKER_02：通过用高斯分布来近似真实的后验分布。
133 00:12:41,240 --> 00:12:43,009 说话人 SPEAKER_02：你可以在神经网络中做到这一点。
134 00:12:43,592 --> 00:12:45,383 说话人 SPEAKER_02：我对那件事非常兴奋。
135 00:12:45,750 --> 00:12:46,292 说话人 SPEAKER_00：我明白了。
136 00:12:46,312 --> 00:12:46,491 说话人 SPEAKER_00：哇。
137 00:12:46,611 --> 00:12:46,831 说话人 说话人_00: 对。
138 00:12:46,951 --> 00:12:47,393 说话人 说话人_00: 嗯。
139 00:12:47,413 --> 00:12:53,678 说话人 说话人_00: 我想我记得所有这些论文，Neal 和 Hinton 的近似 EM 论文，对吧？
140 00:12:53,698 --> 00:12:55,220 说话人 说话人_00: 花了很多时间阅读这些。
141 00:12:55,961 --> 00:13:07,851 说话人 说话人_00: 我认为，你知道，今天你使用的某些算法或者很多人几乎每天都会使用的某些算法，比如 dropout 或者我认为是来自你团队的激活值？
142 00:13:09,793 --> 00:13:10,495 说话人 说话人_02: 是也不是。
143 00:13:10,754 --> 00:13:14,138 说话人 说话人_02: 所以其他人也考虑过 ReLU。
144 00:13:14,658 --> 00:13:26,119 说话人 说话人_02: 我们实际上与受限玻尔兹曼机进行了一些工作，表明 ReLU 几乎等同于一系列逻辑单元。
145 00:13:26,139 --> 00:13:28,582 说话人 SPEAKER_02：这就是 ReLU 流行起来的一个原因。
146 00:13:29,034 --> 00:13:30,618 说话人 SPEAKER_00：我对此真的很感兴趣。
147 00:13:30,697 --> 00:13:38,230 说话人 SPEAKER_00：ReLU 论文中有大量的数学推导，表明这个函数可以被近似到这个非常复杂的公式。
148 00:13:38,812 --> 00:13:48,207 说话人 SPEAKER_00：你是为了使你的论文能够被学术会议接受而做了这些数学推导，还是这些数学推导真正影响了 0 和 x 的最大值函数的发展？
149 00:13:49,623 --> 00:13:55,129 说话人 SPEAKER_02：这实际上是一个数学对想法发展很重要的例子。
150 00:13:55,629 --> 00:13:59,653 说话人 SPEAKER_02：显然，我了解 ReLU（修正线性单元）和逻辑单元。
151 00:14:00,274 --> 00:14:05,139 说话人 SPEAKER_02：由于对玻尔兹曼机的相关工作，所有基本工作都是使用逻辑单元完成的。
152 00:14:06,059 --> 00:14:11,585 说话人 SPEAKER_02：因此问题是，学习算法能否在具有 ReLU（修正线性单元）的结构中工作？
153 00:14:12,505 --> 00:14:19,072 说话人 SPEAKER_02：通过展示修正线性单元几乎与堆叠的逻辑单元完全相同，
154 00:14:19,592 --> 00:14:22,596 说话人 SPEAKER_02：我们证明了所有的数学推导都是适用的。
155 00:14:24,519 --> 00:14:35,451 说话人 SPEAKER_00：我明白了，这提供了灵感，但如今成千上万的人使用 ReLU，它只需工作而不必 necessarily needing to understand the same motivation。
156 00:14:36,393 --> 00:14:47,085 说话人 SPEAKER_02：是的，后来当我 2014 年加入谷歌时，我注意到一件事，我在谷歌做了一次关于使用 ReLU 的演讲，
157 00:14:47,673 --> 00:14:49,496 说话人 SPEAKER_02：使用单位矩阵初始化。
158 00:14:49,937 --> 00:14:58,354 说话人 SPEAKER_02：因为 ReLU 的好处是，如果你不断复制隐藏层并且使用单位矩阵初始化，它就会复制下一层的模式。
159 00:14:58,413 --> 00:15:07,572 说话人 SPEAKER_02：所以我展示了你可以训练具有 300 个隐藏层的网络，如果你使用单位矩阵初始化，你可以非常高效地训练它们。
160 00:15:07,956 --> 00:15:11,120 说话人 SPEAKER_02：但我没有进一步追求这个，我真的很后悔没有继续追求。
161 00:15:11,321 --> 00:15:18,889 说话人 SPEAKER_02：我们发表了一篇与李国辉合著的论文，展示了如何初始化循环神经网络，以及与 Navdeep Jaitley 合著的论文，展示了如何初始化这样的循环网络。
162 00:15:19,529 --> 00:15:27,058 说话人 SPEAKER_02：但我本应该进一步追求这个方向，因为后来残差网络实际上就是这样一类东西。
163 00:15:27,818 --> 00:15:29,902 说话人 SPEAKER_00：多年来，我经常听到您谈论大脑。
164 00:15:29,922 --> 00:15:33,186 说话人 SPEAKER_00：我听到您谈论反向传播与大脑之间的关系。
165 00:15:33,725 --> 00:15:35,347 说话人 SPEAKER_00：你对那个问题现在的看法是什么？
166 00:15:36,576 --> 00:15:39,321 说话人 SPEAKER_02：我实际上正在写一篇关于那个问题的论文。
167 00:15:40,102 --> 00:15:43,467 说话人 SPEAKER_02：我想我的主要想法是这样的。
168 00:15:44,489 --> 00:15:54,885 说话人 SPEAKER_02：如果反向传播确实是一个很好的学习算法，那么进化肯定已经找到了实现它的方法。
169 00:15:56,307 --> 00:15:59,813 说话人 SPEAKER_02：我的意思是，有些细胞可以变成眼睛或者牙齿。
170 00:16:00,575 --> 00:16:01,976 说话人 SPEAKER_02：现在，如果细胞能这样做，
171 00:16:02,210 --> 00:16:04,793 说话人 SPEAKER_02：那么它们当然可以实现反向传播。
172 00:16:05,374 --> 00:16:08,177 说话人 SPEAKER_02：而且，这肯定存在巨大的选择性压力。
173 00:16:09,138 --> 00:16:13,121 说话人 SPEAKER_02：我认为神经科学家认为这不太可能的想法很愚蠢。
174 00:16:13,743 --> 00:16:15,565 说话人 SPEAKER_02：可能有一些细微的实现方式。
175 00:16:16,144 --> 00:16:21,250 说话人 SPEAKER_02：我认为大脑可能有一些东西，可能不是完全的反向传播，但非常接近。
176 00:16:21,912 --> 00:16:25,576 说话人 SPEAKER_02：多年来，我提出了许多关于这可能如何工作的想法。
177 00:16:26,177 --> 00:16:31,001 说话人 SPEAKER_02：1987 年，与 Jay McClelland 合作，
178 00:16:31,740 --> 00:16:45,715 说话人 SPEAKER_02：我想出了循环算法，其想法是将信息发送到循环中，并尝试使信息在循环中传递时保持不变。
179 00:16:46,495 --> 00:16:57,966 说话人 SPEAKER_02：最简单的版本是这样的，你有一些输入单元和隐藏单元，信息从输入单元发送到隐藏单元，然后再从隐藏单元发送回输入单元，然后再次从输入单元发送到隐藏单元，如此循环。
180 00:16:58,506 --> 00:16:59,587 说话人 SPEAKER_02：你想要
181 00:17:00,142 --> 00:17:04,588 说话人 SPEAKER_02：你想训练一个自动编码器，但又不想进行反向传播。
182 00:17:05,510 --> 00:17:09,698 说话人 SPEAKER_02：所以你只是训练它，试图消除所有活动的变化。
183 00:17:10,499 --> 00:17:24,461 说话人 SPEAKER_02：所以，对于突触的学习规则是按比例改变权重，按比例改变突触后输入的变化率。
184 00:17:24,964 --> 00:17:30,551 说话人 SPEAKER_02：但在循环中，你试图使突触后输入变得更好，使旧的变得更好，新的变得不好。
185 00:17:31,493 --> 00:17:32,855 说话人 SPEAKER_02：所以你正在朝那个方向改变。
186 00:17:34,156 --> 00:17:40,105 说话人 SPEAKER_02：我们在神经科学家提出突触时间依赖性可塑性之前就发明了这个算法。
187 00:17:40,125 --> 00:17:48,695 说话人 SPEAKER_02：突触时间依赖性可塑性实际上是同一个算法，但方向相反，新的学习规则中好的是新的，坏的是旧的。
188 00:17:49,557 --> 00:17:54,042 说话人 SPEAKER_02：所以你是按照突触前活动的比例来改变权重的。
189 00:17:54,428 --> 00:17:57,772 说话人 SPEAKER_02：新的突触后活动减去旧的活动。
190 00:18:00,336 --> 00:18:19,688 说话人 SPEAKER_02：后来，我在 2007 年意识到，如果你堆叠了一堆受限玻尔兹曼机并对其进行训练，训练完成后，你就有条件通过尝试重建来实现反向传播。
191 00:18:19,748 --> 00:18:21,651 说话人 SPEAKER_02：如果你看重建误差
192 00:18:22,441 --> 00:18:29,069 说话人 SPEAKER_02：这个重建误差实际上会告诉你判别性能的导数。
193 00:18:30,131 --> 00:18:38,442 说话人 SPEAKER_02：在 2007 年 NIPS 第一次深度学习研讨会上，我谈到了这一点，但几乎被完全忽视了。
194 00:18:40,164 --> 00:18:47,074 说话人 SPEAKER_02：后来，Yoshio Bengio 采纳了这个想法，并在这方面做了很多工作。
195 00:18:47,615 --> 00:18:49,376 说话人 SPEAKER_02：我自己也在做更多的工作。
196 00:18:49,643 --> 00:19:05,208 说话人 SPEAKER_02：我认为，如果你有一堆自编码器，那么可以通过将活动向后发送并查看重建错误来获取导数，这是一个非常有趣的想法，这可能是大脑的工作方式。
197 00:19:05,848 --> 00:19:14,863 说话人 说话人_00：还有一个话题，我知道你思考了很多，而且我听说你还在研究，那就是如何在深度学习中处理多个时间尺度。
198 00:19:15,243 --> 00:19:17,186 说话人 说话人_00：那么，你能分享一下你的想法吗？
199 00:19:17,757 --> 00:19:21,580 说话人 说话人_02：是的，这实际上可以追溯到我的研究生第一年。
200 00:19:22,181 --> 00:19:26,786 说话人 说话人_02：我第一次发表的演讲是关于使用我所说的快速权重。
201 00:19:27,326 --> 00:19:32,310 说话人 SPEAKER_02：因此，这些权重可以快速适应，但也会快速衰减，因此可以保持短期记忆。
202 00:19:33,172 --> 00:19:39,377 说话人 SPEAKER_02：我在 1973 年展示了一个非常简单的系统，使用这些权重可以实现真正的递归。
203 00:19:39,857 --> 00:19:47,645 说话人 SPEAKER_02：我所说的真正递归是指用于表示事物的神经元，在递归调用中会被重复使用。
204 00:19:48,250 --> 00:19:51,795 说话人 SPEAKER_02：在递归调用中表示事物时，这些神经元会被重复使用。
205 00:19:53,557 --> 00:19:57,683 说话人 SPEAKER_02：用于表示知识的权重在递归调用中被重复使用。
206 00:19:58,605 --> 00:20:04,815 说话人 SPEAKER_02：那么，当你从递归调用中退出时，你如何记住你当时正在做什么？
207 00:20:04,875 --> 00:20:05,676 说话人 SPEAKER_02：记忆在哪里？
208 00:20:06,116 --> 00:20:08,320 说话人 SPEAKER_02：因为你在递归调用中使用了神经元。
209 00:20:09,362 --> 00:20:16,333 说话人 SPEAKER_02：答案是你可以将这种记忆放入快速权重中，并可以从这些快速权重中恢复神经元的活性状态。
210 00:20:17,089 --> 00:20:23,781 说话人 SPEAKER_02：最近，与 Jimmy Barr 合作，我们在 NIPS 上发表了一篇关于使用快速权重进行递归的论文。
211 00:20:25,565 --> 00:20:27,868 说话人 SPEAKER_02：所以这是一个相当大的差距。
212 00:20:28,569 --> 00:20:37,726 说话人 SPEAKER_02：第一个模型是在 1973 年未发表的，然后 Jimmy Barr 的模型是在 2015 年，我想是 2016 年。
213 00:20:37,746 --> 00:20:40,329 说话人 SPEAKER_02：大约 40 年后了。
214 00:20:40,984 --> 00:20:49,356 说话人 SPEAKER_00：我想还有另外一个想法，您已经谈论了多年，我想有五年了吧，那就是胶囊。
215 00:20:49,817 --> 00:20:50,980 说话人 SPEAKER_00：您在这方面进展如何？
216 00:20:52,561 --> 00:21:01,816 说话人 SPEAKER_02：好吧，我又回到了我习惯的状态，那就是我有一个非常相信的想法，但其他人都不相信。
217 00:21:02,636 --> 00:21:04,920 说话人 SPEAKER_02：我提交了关于它的论文，但都被拒绝了。
218 00:21:06,762 --> 00:21:09,507 说话人 SPEAKER_02：但我真的相信这个想法，我会继续推动它。
219 00:21:10,229 --> 00:21:16,459 说话人 SPEAKER_02：所以这取决于几个关键想法。
220 00:21:17,200 --> 00:21:19,845 说话人 SPEAKER_02：其中一个是关于如何表示多维实体。
221 00:21:21,567 --> 00:21:30,863 说话人 SPEAKER_02：您可以通过一个非常小的活动向量来表示多维实体，只要您知道只有一个这样的实体。
222 00:21:30,883 --> 00:21:37,333 说话人 SPEAKER_02：所以，在每个图像区域，您会假设最多只有一个特定类型的特征。
223 00:21:38,376 --> 00:21:46,467 说话人 SPEAKER_02：然后您会使用许多神经元，它们的激活将代表该特征的不同方面。
224 00:21:47,488 --> 00:21:50,491 说话人 SPEAKER_02：比如在这个区域内，它的 X 和 Y 坐标究竟是什么？
225 00:21:50,531 --> 00:21:51,653 说话人 SPEAKER_02：它处于什么方向？
226 00:21:52,034 --> 00:21:53,134 说话人 SPEAKER_02：它移动得有多快？
227 00:21:53,234 --> 00:21:53,915 说话人 SPEAKER_02：它是什么颜色？
228 00:21:53,935 --> 00:21:54,537 说话人 SPEAKER_02：它有多亮？
229 00:21:54,576 --> 00:21:55,258 说话人 SPEAKER_02：然后还有类似的东西。
230 00:21:55,878 --> 00:22:04,249 说话人 SPEAKER_02：所以你可以用很多神经元来表示同一事物的不同维度，前提是只有一个。
231 00:22:05,848 --> 00:22:11,039 说话人 SPEAKER_02：这是一种与我们通常在神经网络中使用的表示方式非常不同的方法。
232 00:22:11,119 --> 00:22:15,348 说话人 SPEAKER_02：在神经网络中，我们通常只有一个很大的层，所有的单元都去执行它们的工作。
233 00:22:15,809 --> 00:22:20,560 说话人 SPEAKER_02：但你不会把它们打包成代表同一事物不同坐标的小组。
234 00:22:21,983 --> 00:22:24,869 说话人 SPEAKER_02：所以我认为应该有这种额外的结构。
235 00:22:25,188 --> 00:22:27,790 说话人 SPEAKER_02：然后是与之相关的另一个部分，另一个想法。
236 00:22:28,171 --> 00:22:36,901 说话人 SPEAKER_00：这意味着在分布式表示中，你将表示分割成不同的子集来表示，对吧？
237 00:22:37,080 --> 00:22:39,423 说话人 SPEAKER_02：我把这些子集称为胶囊。
238 00:22:39,443 --> 00:22:44,670 说话人 SPEAKER_02：胶囊的想法是它能够表示一个特征实例，但只有一个。
239 00:22:44,730 --> 00:22:49,895 说话人 SPEAKER_02：并且它表示该特征的所有不同属性。
240 00:22:50,145 --> 00:22:57,532 说话人 SPEAKER_02：所以它是一个具有许多属性的特性，与正常神经网络中的正常神经元不同，后者只有一个标量属性。
241 00:22:59,513 --> 00:23:11,444 说话者 SPEAKER_02：然后如果你有了这个，你可以做正常神经网络很糟糕的事情，那就是你可以做我称之为“通过协议根植”的事情。
242 00:23:12,326 --> 00:23:20,153 说话者 SPEAKER_02：假设你想进行分割，你有一个可能是嘴巴，另一个可能是鼻子，
243 00:23:21,077 --> 00:23:24,242 说话者 SPEAKER_02：并且你想知道你是否应该把它们放在一起成为一个整体。
244 00:23:24,303 --> 00:23:32,837 说话者 SPEAKER_02：所以想法是，你会有一个嘴巴的胶囊，它具有嘴巴的参数，你还有一个鼻子的胶囊，它具有鼻子的参数。
245 00:23:33,878 --> 00:23:42,032 说话人 SPEAKER_02：然后决定是否将它们组合在一起，让每个参数为面部投票。
246 00:23:43,234 --> 00:23:47,000 说话人 SPEAKER_02：现在如果嘴巴和鼻子在正确的空间关系中，它们会达成一致。
247 00:23:47,909 --> 00:23:58,630 说话人 SPEAKER_02：所以当你在同一级别的两个胶囊为下一级别的同一组参数投票时，你可以假设它们可能是正确的，因为在高维空间中达成一致是非常不可能的。
248 00:24:00,393 --> 00:24:06,846 说话人 SPEAKER_02：这与我们通常在神经网络中使用的过滤方式非常不同。
249 00:24:09,510 --> 00:24:10,051 说话人 SPEAKER_02: 嗯
250 00:24:11,247 --> 00:24:19,243 说话人 SPEAKER_02: 我认为这种通过协议的路由对于神经网络从有限数据中更好地泛化至关重要。
251 00:24:19,984 --> 00:24:29,424 说话人 SPEAKER_02: 我认为它在处理视角变化方面非常出色，在分割方面也非常出色，我希望它比我们目前在神经网络中做的统计效率要高得多。
252 00:24:29,759 --> 00:24:35,846 说话人 SPEAKER_02: 也就是说，如果你想要处理视角变化，你只需给它提供一大堆视角变化，并对其进行训练即可。
253 00:24:35,865 --> 00:24:37,028 说话人 SPEAKER_02: 我明白了，是的，是的。
254 00:24:37,528 --> 00:24:42,515 说话人 SPEAKER_00: 所以，与其只使用 FIFO 的监督学习，你可以用其他方式来学习。
255 00:24:43,496 --> 00:24:50,163 说话人 SPEAKER_02: 嗯，我仍然计划使用监督学习来做，但前向传播的机制非常不同。
256 00:24:51,005 --> 00:24:55,851 说话人 SPEAKER_02: 这不是纯粹的前向传播，因为其中有一些迭代的过程。
257 00:24:56,303 --> 00:25:03,950 说话人 SPEAKER_02：你认为你找到了一个嘴巴，你也找到了一个鼻子，然后你进行一些迭代来决定它们是否真的应该放在一起形成一个脸。
258 00:25:04,529 --> 00:25:04,769 说话人 SPEAKER_02：我明白了。
259 00:25:06,192 --> 00:25:08,874 说话人 SPEAKER_02：你可以为所有的迭代进行反向传播。
260 00:25:09,434 --> 00:25:09,954 说话人 SPEAKER_00：我明白了，太好了。
261 00:25:10,075 --> 00:25:11,516 说话人 SPEAKER_02：所以你可以全部进行判别性训练。
262 00:25:11,957 --> 00:25:12,978 说话人 SPEAKER_00：我明白了，太好了。
263 00:25:14,798 --> 00:25:17,181 说话人 SPEAKER_02：我们现在在多伦多的团队也在做这个工作。
264 00:25:17,701 --> 00:25:20,604 说话人 SPEAKER_02：现在我有一个小型的谷歌团队在多伦多，是大脑团队的一部分。
265 00:25:20,944 --> 00:25:21,404 说话人 SPEAKER_02: 我明白了，是的。
266 00:25:22,885 --> 00:25:23,467 说话人 SPEAKER_02: 我明白了，太好了。
267 00:25:23,507 --> 00:25:24,807 说话人 SPEAKER_02: 这正是我现在感到兴奋的事情。
268 00:25:25,176 --> 00:25:25,657 说话人 SPEAKER_00: 哦，我明白了。
269 00:25:25,678 --> 00:25:25,978 说话人 SPEAKER_00: 很好。
270 00:25:26,018 --> 00:25:26,117 说话人 SPEAKER_00: 是的。
271 00:25:26,137 --> 00:25:28,119 说话人 SPEAKER_00: 期待那篇论文出来。
272 00:25:29,922 --> 00:25:30,021 说话人 SPEAKER_02: 是的。
273 00:25:30,041 --> 00:25:30,643 说话人 SPEAKER_02: 如果它出现了。
274 00:25:33,405 --> 00:25:36,209 说话人 SPEAKER_00: 你在深度学习领域工作了数十年。
275 00:25:36,249 --> 00:25:41,994 说话人 SPEAKER_00: 我实际上非常好奇，这些年来你的思考、你对人工智能的理解是如何变化的？
276 00:25:43,797 --> 00:25:54,828 说话人 SPEAKER_02: 所以我想我大部分的智力历史都与反向传播有关，以及如何使用反向传播，如何利用它的力量。
277 00:25:56,699 --> 00:26:02,627 说话人 SPEAKER_02：首先，在 80 年代中期，我们用它来进行判别性学习，效果很好。
278 00:26:03,528 --> 00:26:17,069 说话人 SPEAKER_02：然后，我在 90 年代初决定，实际上大多数人类学习都是无监督学习，我对无监督学习产生了更大的兴趣，那时我开始研究像 wake-sleep 算法这样的东西。
279 00:26:17,454 --> 00:26:21,499 说话人 SPEAKER_00：你那时的评论也真正影响了我的思考。
280 00:26:21,618 --> 00:26:28,286 说话人 SPEAKER_00：所以当我领导谷歌大脑项目时，我们的第一个项目，我投入了大量精力研究无监督学习，这是受到了你的影响。
281 00:26:29,086 --> 00:26:29,347 说话人 SPEAKER_02: 对。
282 00:26:30,107 --> 00:26:32,570 说话人 SPEAKER_02: 可能我误导了你。
283 00:26:32,871 --> 00:26:37,236 说话人 SPEAKER_02: 也就是说，从长远来看，我认为无监督学习将至关重要。
284 00:26:38,436 --> 00:26:40,759 说话人 SPEAKER_02: 但你必须面对现实。
285 00:26:41,740 --> 00:26:45,825 说话人 SPEAKER_02：那么在过去的 10 年左右，什么方法取得了成功
286 00:26:46,125 --> 00:26:54,097 说话人 SPEAKER_02：那就是监督学习，判别性训练，你拥有标签，或者你试图预测系列中的下一个事物，这样它就充当了标签。
287 00:26:55,078 --> 00:26:56,761 说话人 SPEAKER_02：而且这种方法非常有效。
288 00:26:57,943 --> 00:27:04,673 说话人 SPEAKER_02：我仍然相信无监督学习将至关重要。
289 00:27:05,314 --> 00:27:06,395 说话人 SPEAKER_02：事情将会运作得非常好
290 00:27:06,712 --> 00:27:11,377 说话人 SPEAKER_02：当它运作正常时，会比现在好得多，但我们还没有做到。
291 00:27:12,238 --> 00:27:12,759 说话人 SPEAKER_00：是的，没错。
292 00:27:13,199 --> 00:27:19,285 说话人 SPEAKER_00：我认为包括我在内的许多深度学习领域的资深人士，对此都保持着极大的热情。
293 00:27:19,305 --> 00:27:24,851 说话人 说话人_00：我们几乎没有人真正知道如何去做。
294 00:27:24,871 --> 00:27:25,832 说话人 说话人_00：也许你知道。
295 00:27:25,852 --> 00:27:26,471 说话人 说话人_00：我觉得我不知道。
296 00:27:26,511 --> 00:27:32,798 说话人 说话人_02：嗯，变分自编码器，使用重新参数化技巧，在我看来是一个非常好的想法。
297 00:27:33,659 --> 00:27:34,240 说话人 SPEAKER_02: 并且
298 00:27:34,439 --> 00:27:38,203 说话人 SPEAKER_02: 生成对抗网络在我看来也是一个非常好的想法。
299 00:27:38,505 --> 00:27:45,493 说话人 SPEAKER_02: 我认为生成对抗网络是深度学习中最新的、最重大的想法之一。
300 00:27:46,015 --> 00:27:49,519 说话人 SPEAKER_02: 我希望我能做出成功的胶囊。
301 00:27:49,559 --> 00:27:54,166 说话人 SPEAKER_02：但就目前来看，生成对抗网络我认为是一个重大突破。
302 00:27:55,028 --> 00:28:03,720 说话人 SPEAKER_00：稀疏性和慢特征这两个构建无监督模型的原则发生了什么？
303 00:28:04,779 --> 00:28:07,021 说话人 SPEAKER_02：我从未像你那样重视稀疏性。
304 00:28:09,984 --> 00:28:13,929 说话人 SPEAKER_02：但慢特征我认为是一个错误。
305 00:28:16,010 --> 00:28:16,991 说话人 SPEAKER_02：你不应该说慢。
306 00:28:17,011 --> 00:28:21,016 说话人 SPEAKER_02：基本想法是对的，但你不应该追求那些不会变化的特征。
307 00:28:21,135 --> 00:28:23,739 说话人 SPEAKER_02：你应该追求那些以可预测方式变化的特征。
308 00:28:24,138 --> 00:28:29,163 说话人 SPEAKER_02：所以这里有一个关于如何建模任何事物的基本原则。
309 00:28:31,886 --> 00:28:34,128 说话人 SPEAKER_02：请测量您的数据。
310 00:28:35,189 --> 00:28:43,903 说话人 SPEAKER_02：然后您对测量数据进行非线性变换，直到得到一个表示为状态向量的形式，其中动作是线性的。
311 00:28:45,946 --> 00:29:00,150 说话人 SPEAKER_02：所以您不是像在使用卡尔曼滤波器时那样假装它是线性的，而是实际上找到一个从可观测量到潜在变量的变换，其中对潜在变量进行的线性操作（如矩阵乘法）将完成工作。
312 00:29:00,603 --> 00:29:10,748 说话人 SPEAKER_02：例如，如果您想改变视角，如果您想从另一个视角生成图像，您应该从像素到坐标进行转换。
313 00:29:11,065 --> 00:29:22,042 说话人 SPEAKER_02：一旦你得到了坐标表示，也就是我希望能由胶囊找到的那种东西，然后你可以进行矩阵乘法来改变视角，然后你可以将其映射回像素。
314 00:29:22,482 --> 00:29:22,624 说话人 SPEAKER_02：没错。
315 00:29:22,644 --> 00:29:23,505 说话人 SPEAKER_00：这就是你为什么要做所有那些事情。
316 00:29:23,525 --> 00:29:24,987 说话人 SPEAKER_02：我认为这是一个非常通用的原则。
317 00:29:25,428 --> 00:29:27,991 说话人 说话人_00: 这就是为什么你做了所有关于相位合成的工作，对吧？
318 00:29:28,011 --> 00:29:34,001 说话人 说话人_00: 我们将一个相位压缩成一个非常低维的向量，因此你可以对其进行调整并回到其他相位。
319 00:29:35,298 --> 00:29:37,661 说话人 说话人_02: 我有一个学生在这方面做了工作。
320 00:29:37,701 --> 00:29:39,463 说话人 说话人_02: 我自己在这方面的工作并不多。
321 00:29:40,526 --> 00:29:46,914 说话人 说话人_00：我敢肯定你仍然经常被问及，如果有人想进入深度学习领域，他们应该做什么？
322 00:29:47,315 --> 00:29:48,297 说话人 说话人_00：你有什么建议吗？
323 00:29:48,396 --> 00:29:59,752 说话人 说话人_00：我敢肯定你在一对一的场合已经给过很多人很多建议，但针对观看这个视频的全球观众，你对他们进入深度学习有什么建议？
324 00:29:59,953 --> 00:30:05,000 说话人 说话人_02：我的建议是阅读文献，但不要读太多。
325 00:30:05,403 --> 00:30:10,871 讲者 SPEAKER_02：这是我导师给我的建议，这和大多数人说的都不一样。
326 00:30:11,352 --> 00:30:16,799 讲者 SPEAKER_02：大多数人会说你应该花几年时间阅读文献，然后你应该开始着手自己的想法。
327 00:30:17,840 --> 00:30:30,599 讲者 SPEAKER_02：这可能对一些研究人员来说是正确的，但对于具有创造力的研究人员来说，我认为你想要做的是阅读一点文献，并注意到你认为大家都在做错的事情。
328 00:30:31,458 --> 00:30:33,019 讲者 SPEAKER_02：在这方面，我是一个持不同意见者。
329 00:30:33,579 --> 00:30:35,561 说话人 SPEAKER_02：你看它，就是感觉不对劲。
330 00:30:36,923 --> 00:30:38,844 说话人 SPEAKER_02：然后找出怎么做得正确。
331 00:30:40,125 --> 00:30:43,808 说话人 SPEAKER_02：当别人告诉你那不行的时候，就坚持下去。
332 00:30:44,608 --> 00:30:52,496 说话人 SPEAKER_02：我有一个很好的原则可以帮助人们坚持下去，那就是你的直觉要么是好的，要么是不好的。
333 00:30:53,277 --> 00:30:56,660 说话人 SPEAKER_02：如果你的直觉很好，你应该跟随它们，你最终会成功的。
334 00:30:57,380 --> 00:31:00,282 说话人 SPEAKER_02：如果你的直觉不好，你做什么都无关紧要。
335 00:31:02,457 --> 00:31:05,642 说话人 SPEAKER_00：没错，这些建议很鼓舞人心，所以不妨去尝试一下。
336 00:31:06,682 --> 00:31:08,306 说话人 SPEAKER_02：你不妨相信你的直觉。
337 00:31:08,546 --> 00:31:10,509 说话人 SPEAKER_02：信任他们毫无意义。
338 00:31:11,270 --> 00:31:13,192 说话人 SPEAKER_00：我明白了，是的。
339 00:31:13,473 --> 00:31:24,130 说话人 SPEAKER_00：我通常建议人们不仅要阅读，还要复制已发表的论文，这可能自然地限制了你可以完成的工作数量，因为复制结果相当耗时。
340 00:31:25,192 --> 00:31:30,539 说话人 SPEAKER_02：是的，当你尝试复制一篇已发表的论文时，你会发现所有必要的技巧，这些技巧是使它工作所必需的。
341 00:31:31,414 --> 00:31:34,577 说话人 SPEAKER_02：我还有一条建议，那就是永远不要停止编程。
342 00:31:35,419 --> 00:31:41,306 说话人 SPEAKER_02：因为如果你给学生一个任务，如果他们是个差学生，他们就会回来告诉你它不起作用。
343 00:31:41,885 --> 00:31:47,593 说话人 SPEAKER_02：而它不起作用的原因可能是他们做出了某些他们没有意识到是关键性的小决定。
344 00:31:48,333 --> 00:31:55,201 说话人 SPEAKER_02：而如果你给一个优秀的学生，比如易伟泰，他任何东西都能做，他会回来告诉你它成功了。
345 00:31:55,922 --> 00:31:57,202 说话人 SPEAKER_02：我记得我做过这件事。
346 00:31:57,654 --> 00:31:58,875 说话人 SPEAKER_02：我说，等等，EY。
347 00:31:59,777 --> 00:32:02,780 说话人 SPEAKER_02：自从我们上次谈话以来，我意识到你不可能因为以下原因。
348 00:32:03,602 --> 00:32:05,763 说话人 SPEAKER_02：EY 说，哦，是的，我立刻就意识到了。
349 00:32:05,784 --> 00:32:07,065 说话人 SPEAKER_02：所以我以为你不是这个意思。
350 00:32:08,066 --> 00:32:09,508 说话人 SPEAKER_00：我明白了。
351 00:32:09,528 --> 00:32:10,269 说话人 SPEAKER_00：是的，这很好。
352 00:32:11,470 --> 00:32:12,711 说话人 SPEAKER_00：是的。
353 00:32:12,731 --> 00:32:14,133 说话人 说话人_00：让我们看看。
354 00:32:14,272 --> 00:32:18,317 说话人 说话人_00：对于想要进入 AI 和深度学习领域的人来说，还有其他建议吗？
355 00:32:21,260 --> 00:32:26,666 说话人 说话人_02：我认为基本上读得足够多了，这样你就可以开始培养直觉，然后相信你的直觉。
356 00:32:27,845 --> 00:32:57,480 说话人 说话人_02：就去做吧，不要过于担心别人说它是胡说八道，我想别人说它是胡说八道的时候，也没有办法知道他们是对是错，但你只需要去做，然后找出答案。但是有一个方法，有一件事，那就是如果你认为这是一个非常好的主意，而别人告诉你它是胡说八道，那么你就知道你真的找到了一些东西。一个例子是，当我和 Radford 第一次提出变分方法时。
357 00:32:58,607 --> 00:33:05,839 讲者 SPEAKER_02：我给一位名叫彼得·布朗的我的前学生发了邮件解释这件事，他非常了解 EM。
358 00:33:06,921 --> 00:33:11,769 讲者 SPEAKER_02：然后他把这展示给了和他一起工作的达利亚·皮特拉兄弟。
359 00:33:11,949 --> 00:33:13,050 讲者 SPEAKER_02：他们是双胞胎，我想。
360 00:33:13,231 --> 00:33:18,138 讲者 SPEAKER_02：后来他告诉我他们说了什么。
361 00:33:19,280 --> 00:33:24,108 说话者 SPEAKER_02：他们觉得这个人要么喝醉了，要么就是愚蠢。
362 00:33:25,067 --> 00:33:52,542 说话者 SPEAKER_02：所以他们真的觉得这是胡说八道。这可能部分是因为我解释的方式，因为我用直观的方式来解释，但是当你有一个好主意，而其他人认为那是垃圾时，这就是一个真正好主意的标志。哦，我明白了，这就是你的角色。哦，还有，还有，研究课题，你知道，新毕业生应该研究胶囊和可能的无监督学习，还有其他什么。
363 00:33:54,126 --> 00:34:09,748 说话者 SPEAKER_02：给新研究生的一条好建议是，看看你是否能找到一个和你有相似信念的导师，因为如果你从事导师深感兴趣的工作，你会得到很多好的建议和时间。
364 00:34:10,449 --> 00:34:16,978 说话者 SPEAKER_02：如果你从事导师不感兴趣的工作，你只会得到一些建议，但几乎没什么用。
365 00:34:18,527 --> 00:34:21,972 说话人 说话人_00：最后一个是关于学习者的建议。
366 00:34:22,673 --> 00:34:31,125 说话人 说话人_00：对于人们进入博士项目与加入，你知道的，顶级公司或企业顶级研究组，你有什么看法？
367 00:34:33,228 --> 00:34:34,429 说话人 说话人_02：是的，这很复杂。
368 00:34:34,849 --> 00:34:44,782 说话人 说话人_02：我认为现在的问题是，在深度学习领域受过训练的学者数量不足以教育我们需要的所有大学教育者。
369 00:34:45,284 --> 00:34:47,606 讲者 SPEAKER_02：那里根本就没有足够的师资力量。
370 00:34:48,311 --> 00:35:16,597 讲者 SPEAKER_02：嗯，但我想那将是暂时的。我认为发生的事情是，大多数系部都反应迟缓，没有理解正在发生的这场革命。我同意你的看法，这并不完全是一场第二次工业革命，但它的规模几乎与之相当，正在发生巨大的变革。这主要是因为我们与计算机的关系发生了变化，我们不再是编程它们，而是向它们展示，然后它们自己解决问题。
371 00:35:17,135 --> 00:35:19,217 讲者 SPEAKER_02：这是一种完全不同的使用计算机的方式。
372 00:35:19,697 --> 00:35:23,722 讲者 SPEAKER_02：计算机科学系是建立在编程计算机这一理念之上的。
373 00:35:24,143 --> 00:35:32,092 说话人 SPEAKER_02：他们不明白这种展示计算机的方式将会像编程计算机一样重要。
374 00:35:32,572 --> 00:35:37,858 说话人 SPEAKER_02：所以他们不明白，部门里应该有一半的人是那些通过展示来让计算机做事的人。
375 00:35:38,458 --> 00:35:38,739 说话人 SPEAKER_02：我明白了。
376 00:35:39,500 --> 00:35:39,740 说话人 SPEAKER_00：没错。
377 00:35:39,760 --> 00:35:45,387 说话人 SPEAKER_02：我所在的部门拒绝承认
378 00:35:45,670 --> 00:35:47,652 说话人 SPEAKER_02：它应该有很多人在做这件事。
379 00:35:48,052 --> 00:35:52,039 说话人 SPEAKER_02：他们认为只有几个，可能还有几个，但不多。
380 00:35:53,300 --> 00:35:59,228 说话人 SPEAKER_02：在这种情况下，你必须依赖大公司来做大量的训练。
381 00:35:59,768 --> 00:36:02,793 说话人 SPEAKER_02：所以现在谷歌正在培训我们称之为大脑居民的这些人。
382 00:36:03,635 --> 00:36:06,918 说话人 SPEAKER_02：我怀疑大学最终会赶上的。
383 00:36:07,387 --> 00:36:08,128 说话人 SPEAKER_00：我明白了。
384 00:36:08,148 --> 00:36:08,429 说话人 SPEAKER_00：没错。
385 00:36:08,449 --> 00:36:11,572 讲者：事实上，嗯，可能很多学生都已经想到了这一点。
386 00:36:11,592 --> 00:36:19,880 讲者：很多顶尖的博士项目，你知道，超过一半的博士申请者实际上是想展示而不是编程。
387 00:36:19,900 --> 00:36:20,661 讲者：是的。
388 00:36:20,681 --> 00:36:21,202 讲者：是的。
389 00:36:21,222 --> 00:36:21,322 说话人 说话人_00: 很酷。
390 00:36:21,342 --> 00:36:22,063 说话人 说话人_00: 是的。
391 00:36:22,083 --> 00:36:22,503 说话人 说话人_00: 是的。
392 00:36:22,523 --> 00:36:35,438 说话人 说话人_00: 事实上，你知道，应该给予应有的赞誉， whereas，uh，deeplearning.ai 正在创建一个深度学习专业课程，据我所知，第一个深度学习 MOOC 实际上是在 2012 年由你在 Coursera 上开设的。
393 00:36:35,418 --> 00:36:42,157 说话人 说话人_00: 然后，然后，有些奇怪的是，那时你首次发布了 RMSProp 算法，这也迅速走红。
394 00:36:43,581 --> 00:36:43,922 说话人 说话人_02: 对。
395 00:36:44,182 --> 00:36:44,583 说话人 说话人_02: 是。
396 00:36:45,052 --> 00:36:53,244 说话人 说话人_02: 好吧，正如你所知，那是因为你邀请我去做 MOOC，然后当我非常犹豫是否去做时，你一直鼓励我去做。
397 00:36:54,106 --> 00:36:56,829 说话者 SPEAKER_02：所以我做得很不错，尽管工作量很大。
398 00:36:57,550 --> 00:36:59,474 说话者 SPEAKER_00：是的，谢谢你这么做。
399 00:36:59,514 --> 00:37:10,150 说话者 SPEAKER_00：我记得你向我抱怨工作量有多大，你晚上熬夜，但我想，你知道，很多很多学习者都从你的第一个 MOOC 中受益，我仍然非常感激你。
400 00:37:10,534 --> 00:37:12,737 说话者 SPEAKER_00：那很好，是的。
401 00:37:12,757 --> 00:37:19,505 说话人 说话人_00：多年来，我看到了你卷入关于人工智能范式的辩论，以及是否发生了人工智能范式的转变。
402 00:37:20,326 --> 00:37:22,088 说话人 说话人_00：你能分享一下你的看法吗？
403 00:37:23,650 --> 00:37:24,451 说话人 说话人_02：当然可以。
404 00:37:25,952 --> 00:37:34,463 说话人 说话人_02：所以我认为在早期，在50年代，像冯·诺伊曼和图灵这样的人不相信符号人工智能。
405 00:37:34,802 --> 00:37:36,905 说话人 SPEAKER_02：他们受到了大脑的极大启发。
406 00:37:36,945 --> 00:37:40,068 说话人 SPEAKER_02：不幸的是，他们都过早地去世了。
407 00:37:40,876 --> 00:38:09,077 说话人 SPEAKER_02：嗯，他们的声音没有被听到，在人工智能的早期，人们完全确信，为了实现智能，你需要的是某种类型的符号表达式，某种经过清理的逻辑，你可以做非单调的事情，不是完全的逻辑，但类似于逻辑，智能的本质是推理。而现在有一个完全不同的观点，那就是
408 00:38:09,833 --> 00:38:13,797 说话人 SPEAKER_02：一个想法，就是一个巨大的神经网络活动向量。
409 00:38:15,340 --> 00:38:17,943 说话者 SPEAKER_02：那么，将这个与思维是一种符号表达的想法进行对比。
410 00:38:18,963 --> 00:38:23,429 说话者 SPEAKER_02：我认为那些认为思维是符号表达的人犯了一个巨大的错误。
411 00:38:24,510 --> 00:38:27,414 说话者 SPEAKER_02：进来的是一串词语。
412 00:38:28,135 --> 00:38:30,097 说话者 SPEAKER_02：出去的也是一串词语。
413 00:38:31,418 --> 00:38:35,422 发言人 SPEAKER_02：正因为如此，字符串便是表达事物的明显方式。
414 00:38:35,864 --> 00:38:38,507 说话人 SPEAKER_02：他们认为中间应该是单词的序列。
415 00:38:38,824 --> 00:38:40,967 说话人 SPEAKER_02：或者类似单词的序列。
416 00:38:41,608 --> 00:38:43,750 说话人 SPEAKER_02：我认为中间的东西与单词序列截然不同。
417 00:38:44,530 --> 00:38:55,820 说话人 SPEAKER_02：我认为思想必须是一种语言的想法，就像理解空间场景布局必须用像素一样荒谬。
418 00:38:55,840 --> 00:39:02,367 说话人 SPEAKER_02：像素进来，如果我们把点阵打印机连接到我们这里，那么像素就会输出。
419 00:39:03,568 --> 00:39:05,210 说话人 SPEAKER_02：但中间的不是像素。
420 00:39:06,490 --> 00:39:07,211 说话人 SPEAKER_02：所以我认为
421 00:39:07,512 --> 00:39:18,548 说话人 SPEAKER_02：思想只是这些巨大的向量，这些大向量具有因果力量，它们引起其他大向量，这与标准人工智能观点中思想是符号表达的观点截然不同。
422 00:39:19,369 --> 00:39:20,972 说话人 说话人_00：我明白了，是的。
423 00:39:20,992 --> 00:39:24,978 说话人 说话人_00：我想 AI 确实正在逐渐接受这种新的观点。
424 00:39:24,998 --> 00:39:25,458 说话人 说话人_00：其中一部分。
425 00:39:25,900 --> 00:39:30,887 说话人 说话人_00：我认为 AI 界很多人仍然认为思维必须是符号表达。
426 00:39:31,389 --> 00:39:33,054 说话人 说话人_00: 非常感谢您接受这次采访。
427 00:39:33,094 --> 00:39:39,126 说话人 说话人_00: 听到深度学习如何在过去几年中发展，以及您如何继续推动它走向未来，非常令人着迷。
428 00:39:39,166 --> 00:39:40,009 说话人 说话人_00: 所以谢谢，杰夫。
429 00:39:41,030 --> 00:39:42,653 说话人 说话人_00: 感谢您给我这个机会。
430 00:39:43,195 --> 00:39:43,476 说话者 说话者_00：谢谢。
