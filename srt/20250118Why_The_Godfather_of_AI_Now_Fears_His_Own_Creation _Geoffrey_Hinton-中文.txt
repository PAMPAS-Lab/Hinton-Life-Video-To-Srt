1 00:00:00,031 --> 00:00:04,086 说话人 SPEAKER_00：现在有一些证据表明人工智能可以被故意欺骗。
2 00:00:04,107 --> 00:00:09,146 说话人 SPEAKER_00：一旦它们意识到获得更多控制是好的，一旦它们比我们聪明，我们就会变得无关紧要。
3 00:00:09,185 --> 00:00:11,474 说话人 SPEAKER_00：我们并不特殊，我们也不安全。
4 00:00:12,535 --> 00:00:19,925 说话人 SPEAKER_02：当世界上最聪明的大脑之一相信他的创造对人类构成了生存威胁时，会发生什么？
5 00:00:20,405 --> 00:00:31,841 说话人 SPEAKER_02：2024 年诺贝尔物理学奖得主、前谷歌副总裁兼工程研究员杰弗里·辛顿（Geoffrey Hinton）花费了数十年的时间开发出支撑当今人工智能系统的基本算法。
6 00:00:32,220 --> 00:00:37,328 说话人 SPEAKER_02：事实上，他在 1981 年甚至发表了一篇预示了核心注意力机制的论文。
7 00:00:37,307 --> 00:00:41,472 说话人 SPEAKER_02：然而，辛顿现在正发出一个他声称很少有研究人员愿意听到的警报。
8 00:00:41,932 --> 00:00:48,037 说话人 SPEAKER_02：我们关于意识使人类特殊并免受人工智能统治的假设显然是错误的。
9 00:00:48,438 --> 00:01:02,930 说话人 SPEAKER_02：我的名字叫库尔特·杰姆纳格尔，这次采访对我来说意义非凡，部分原因是因为我在多伦多大学获得了数学物理学位，而 Hinton 教授就是那里的教授，而且像伊利亚·苏茨克维和安德烈·卡帕蒂这样的他的前学生也是我的同学。
10 00:01:03,231 --> 00:01:07,314 说话人 SPEAKER_02：能被邀请到 Hinton 的家中进行这次扣人心弦的对话是一种荣幸。
11 00:01:07,295 --> 00:01:11,864 说话人 SPEAKER_02：在这里，Hinton 挑战了我们关于人类独特性的最深层假设。
12 00:01:12,385 --> 00:01:14,329 说话人 SPEAKER_02：他是不是现代的奥本海默？
13 00:01:14,730 --> 00:01:18,759 说话人 SPEAKER_02：这颗光辉的头脑是否看到了我们其他人忽略的东西？
14 00:01:20,742 --> 00:01:25,253 说话人 SPEAKER_02：是什么时刻让你意识到人工智能的发展速度超过了我们控制的能力？
15 00:01:26,465 --> 00:01:31,977 说话人 SPEAKER_00：我想是在 2023 年初，两件事结合在一起。
16 00:01:33,078 --> 00:01:37,007 说话人 SPEAKER_00：其中之一是 Chat GBT，它非常令人印象深刻。
17 00:01:38,250 --> 00:01:47,088 说话人 SPEAKER_00：另一项工作是我一直在谷歌进行的，关于思考如何进行模拟计算以节省电力。
18 00:01:47,439 --> 00:01:54,534 说话人 SPEAKER_00：并意识到数字计算更好，而且它之所以更好，是因为你可以复制相同的模型。
19 00:01:55,334 --> 00:02:02,028 说话人 SPEAKER_00：每个副本都可以有不同的经验，它们可以通过平均它们的权重或权重梯度来分享它们学到的知识。
20 00:02:02,829 --> 00:02:04,873 说话人 SPEAKER_00：这是你在模拟系统中无法做到的。
21 00:02:06,477 --> 00:02:09,802 说话人 SPEAKER_02：我们的大脑有什么优势是因为它是模拟的吗？
22 00:02:10,676 --> 00:02:12,600 说话人 SPEAKER_00：它的功耗，功耗要低得多。
23 00:02:13,581 --> 00:02:14,805 说话人 SPEAKER_00：我们大约运行在 30 瓦。
24 00:02:16,106 --> 00:02:19,193 说话人 SPEAKER_00：以及能够集成大量连接的能力。
25 00:02:19,252 --> 00:02:21,477 说话人 说话人_00：我们大约有一百万亿个连接。
26 00:02:22,038 --> 00:02:24,443 说话人 说话人_00：最大的模型大约有一万亿。
27 00:02:24,462 --> 00:02:27,147 说话人 说话人_00：所以我们几乎比最大的模型大一百倍。
28 00:02:28,531 --> 00:02:29,832 说话人 说话人_00：并且我们以30瓦的功率运行。
29 00:02:30,842 --> 00:02:33,808 说话人 SPEAKER_02：在扩展方面有什么不利之处吗？
30 00:02:34,008 --> 00:02:39,599 说话人 SPEAKER_02：所以你说这更好，但就像有益或积极的东西可以迅速传播一样。
31 00:02:40,020 --> 00:02:43,888 说话人 SPEAKER_02：所以病毒或有害的东西可以快速复制。
32 00:02:44,550 --> 00:02:47,455 说话人 SPEAKER_02：所以我们说这更好，因为你可以更快地复制它。
33 00:02:47,996 --> 00:02:52,024 说话人 SPEAKER_00：如果你有多个副本，它们可以非常高效地共享经验。
34 00:02:54,045 --> 00:03:00,616 说话人 SPEAKER_00：所以 GPT-4 知道这么多，是因为你在不同的硬件上运行了多个副本。
35 00:03:01,459 --> 00:03:05,385 说话人 SPEAKER_00：通过平均权重梯度，它们可以共享每个副本学到的知识。
36 00:03:05,806 --> 00:03:08,670 说话人 SPEAKER_00：你不需要让一个副本经历整个互联网。
37 00:03:09,954 --> 00:03:11,817 说话人 说话人_00: 这可以分成许多份。
38 00:03:12,638 --> 00:03:14,822 说话人 说话人_00: 我们不能这么做，因为我们不能高效地共享。
39 00:03:16,016 --> 00:03:17,902 说话人 说话人_02: Scott Aronson 实际上对这个有疑问。
40 00:03:18,544 --> 00:03:27,832 说话人 说话人_02: 霍 inton 博士，我很想听听您关于构建运行在不可克隆的模拟硬件上的 AI 的想法，这样它们就不能在互联网上自我复制。
41 00:03:29,500 --> 00:03:30,581 说话人 SPEAKER_00：嗯，我们就是这样。
42 00:03:31,703 --> 00:03:39,555 说话人 SPEAKER_00：如果我想把我的知识从我的大脑传到你的大脑，我会产生一串词语，然后你在你的大脑中改变连接字符串，这样你可能就会设置相同的词语串。
43 00:03:40,477 --> 00:03:43,341 说话人 SPEAKER_00：这是一种非常低效的知识共享方式。
44 00:03:44,062 --> 00:03:53,195 说话人 SPEAKER_00：一句话只有大约 100 比特，所以我们每句话只能共享大约 100 比特，而这些大型模型可以共享万亿比特。
45 00:03:54,931 --> 00:03:58,915 说话人 SPEAKER_00：这种模拟硬件的问题在于它不能共享。
46 00:03:59,758 --> 00:04:04,243 说话人 SPEAKER_00：但如果你担心安全性，这可能是一个优势，因为它不能轻易复制自己。
47 00:04:06,225 --> 00:04:10,872 说话人 SPEAKER_02：你表达了对 AI 接管或 AI 统治人类的担忧。
48 00:04:11,674 --> 00:04:13,175 说话人 SPEAKER_02：那具体会是什么样子呢？
49 00:04:15,805 --> 00:04:23,656 说话人 SPEAKER_00：我们不知道它具体是什么样子，但要让 AI 代理存在，你必须赋予它们创建子目标的能力。
50 00:04:24,997 --> 00:04:32,206 说话人 SPEAKER_00：而一个稍微有些令人恐惧的路径是，它们会很快意识到一个好的子目标是获得更多的控制。
51 00:04:32,627 --> 00:04:35,492 说话人 SPEAKER_00：因为如果你获得更多的控制，你就能实现你的其他目标。
52 00:04:35,732 --> 00:04:41,560 说话人 SPEAKER_00：所以即使它们只是在尝试做我们要求它们做的事情，它们也会意识到获得更多的控制是做到这一点最好的方式。
53 00:04:41,540 --> 00:04:48,377 说话人 SPEAKER_00：一旦他们意识到获得更多控制是好的，一旦他们比我们聪明，我们就会变得或多或少无关紧要。
54 00:04:48,478 --> 00:04:51,487 说话人 SPEAKER_00：即使它们是仁慈的，我们也会变得有些无关紧要。
55 00:04:53,372 --> 00:04:57,843 说话人 SPEAKER_00：我们就像那些实际上由其他人管理的庞大公司的非常愚蠢的 CEO。
56 00:04:57,824 --> 00:05:00,266 说话人 SPEAKER_02：我想引用你。
57 00:05:01,108 --> 00:05:06,555 说话人 SPEAKER_02：你说，因为很多人会想，我们能不能像现在这样关掉这些机器。
58 00:05:07,057 --> 00:05:08,939 说话人 SPEAKER_02：所以，人们会想，我们完全可以关掉它。
59 00:05:09,579 --> 00:05:14,968 说话人 SPEAKER_02：想象一下，这些机器比我们聪明得多，记住，他们会阅读一切，一切马基雅维利所写的一切。
60 00:05:15,007 --> 00:05:19,314 说话人 SPEAKER_02：他们会阅读人类欺骗的每一个例子。
61 00:05:19,613 --> 00:05:25,182 说话人 SPEAKER_02：他们将真正成为行家里手，擅长进行人类欺骗，因为他们会从我们这里学到这一点，并且他们比我们做得更好。
62 00:05:25,161 --> 00:05:29,367 说话人 SPEAKER_02：一旦你能用你的话操纵人们，那么你就能完成任何你想要的事情。
63 00:05:29,427 --> 00:05:33,392 说话人 SPEAKER_02：你认为这已经在发生了吗？
64 00:05:34,293 --> 00:05:36,416 说话人 SPEAKER_02：AI 已经在操纵我们了吗？
65 00:05:37,778 --> 00:05:38,779 说话人 SPEAKER_00: 现在有证据了。
66 00:05:38,800 --> 00:05:43,507 说话人 SPEAKER_00: 最近有论文显示，人工智能可以有意识地欺骗。
67 00:05:44,127 --> 00:05:51,658 说话人 SPEAKER_00: 它们可以像在训练数据上表现得与测试数据不同一样，这样在训练过程中欺骗你。
68 00:05:52,519 --> 00:05:54,882 说话人 SPEAKER_00: 所以现在有证据表明它们确实会这样做。
69 00:05:55,300 --> 00:05:55,540 说话人 SPEAKER_00: 嗯。
70 00:05:56,781 --> 00:06:00,629 说话人 SPEAKER_02: 你认为这是有意的吗，还是这只是他们发现的某种模式？
71 00:06:03,153 --> 00:06:06,718 说话人 SPEAKER_00: 我认为是有意的，但对此仍有争议。
72 00:06:07,660 --> 00:06:11,305 说话人 SPEAKER_00: 当然，有意可能只是你发现的某种模式。
73 00:06:13,709 --> 00:06:19,839 说话人 SPEAKER_02：那么，您的观点是这些人工智能与主观体验有关吗？
74 00:06:21,101 --> 00:06:30,822 说话人 SPEAKER_00：好的，所以大多数人，事实上几乎所有人，都认为我们相对安全的一个原因是，我们拥有他们没有且永远不会拥有的东西。
75 00:06:31,783 --> 00:06:33,548 说话人 SPEAKER_00：我们文化中的大多数人仍然相信这一点。
76 00:06:34,831 --> 00:06:40,242 说话人 SPEAKER_00：我们有意识、感知或主观体验。
77 00:06:40,677 --> 00:06:46,805 说话人 SPEAKER_00: 很多人非常自信他们没有意识，但如果你问他们，你说的意识是什么意思？
78 00:06:47,026 --> 00:06:49,288 说话人 SPEAKER_00: 他们说，我不知道，但他们没有。
79 00:06:50,189 --> 00:06:54,555 说话人 SPEAKER_00: 这种观点似乎相当不一致，自信他们没有意识，却不知道意识是什么。
80 00:06:54,615 --> 00:06:59,382 说话人 SPEAKER_00: 因此我更愿意关注主观体验。
81 00:07:00,684 --> 00:07:03,567 说话人 SPEAKER_00: 我认为这就像是楔子的尖端。
82 00:07:04,149 --> 00:07:07,072 说话人 SPEAKER_00: 如果你能证明它们有主观体验，
83 00:07:07,120 --> 00:07:11,747 说话人 SPEAKER_00: 那么人们对意识和感知的信心就会降低。
84 00:07:12,449 --> 00:07:14,011 说话人 SPEAKER_00: 所以让我们来谈谈主观体验。
85 00:07:15,452 --> 00:07:22,665 说话人 SPEAKER_00：当我喝醉了，告诉你，我有一种主观体验，面前漂浮着粉红色的小象。
86 00:07:25,733 --> 00:07:32,324 说话人 SPEAKER_00：大多数人会这样解释，他们有一个关于这意思的模型，我认为这是一个完全错误的模型。
87 00:07:32,803 --> 00:07:39,595 说话人 SPEAKER_00：他们的模型是这样的，有一个内在的剧院，在这个内在的剧院里，有粉红色的小元素在飘动，只有我能看到它们。
88 00:07:41,298 --> 00:07:45,745 说话人 SPEAKER_00：这就是关于心灵的标准模型，至少在感知方面是这样的。
89 00:07:47,208 --> 00:07:49,310 说话者 SPEAKER_00：我认为那个模型完全错误。
90 00:07:49,966 --> 00:07:56,154 说话者 SPEAKER_00：它错误得就像一个宗教原教旨主义的物质世界模型一样。
91 00:07:57,497 --> 00:08:01,764 说话者 SPEAKER_00：也许宗教原教旨主义者认为这一切都是 6000 年前创造的。
92 00:08:02,283 --> 00:08:03,064 说话者 SPEAKER_00：这纯粹是胡说。
93 00:08:03,146 --> 00:08:03,605 说话人 说话人_00: 这是错误的。
94 00:08:04,947 --> 00:08:07,992 说话人 说话人_00: 并不是你可以选择相信的真理。
95 00:08:08,033 --> 00:08:08,553 说话人 说话人_00: 只不过它是错误的。
96 00:08:11,437 --> 00:08:14,201 说话人 说话人_00: 所以我认为人们对心智的认识只是错误的。
97 00:08:15,564 --> 00:08:25,757 说话人 SPEAKER_00：再次，我又有小粉象在我面前飘浮的主观体验，现在我不用“主观体验”这个词来说同样的话。
98 00:08:26,959 --> 00:08:27,699 说话人 SPEAKER_00：好的，开始了。
99 00:08:29,161 --> 00:08:31,723 说话人 SPEAKER_00：我的感知系统告诉我一些我不相信的事情。
100 00:08:32,105 --> 00:08:35,249 说话人 SPEAKER_00：这就是我为什么用“主观”这个词的原因。
101 00:08:35,269 --> 00:08:40,695 说话者 SPEAKER_00：但如果在我面前漂浮着粉红色的小象，我的感知系统就会告诉我真相。
102 00:08:41,806 --> 00:08:46,091 说话者 SPEAKER_00：就是这样，我只是没有用主观或经验这个词说了同样的话。
103 00:08:48,113 --> 00:09:10,277 说话者 SPEAKER_00：所以，当我的感知系统出错时，我会通过说“主观”来向你表明这一点，然后为了试图向你解释我的感知系统试图告诉你什么，我会告诉你一个假设的世界状态，如果世界是这样的，我的感知系统就会告诉我真相。
104 00:09:11,572 --> 00:09:15,840 说话者 SPEAKER_00：好的，现在让我们用聊天机器人来做同样的操作。
105 00:09:16,279 --> 00:09:17,982 说话者 说话者_00：假设我们有一个多模态聊天机器人。
106 00:09:18,683 --> 00:09:25,234 说话者 说话者_00：它有一个可以指点的机械臂，还有一个摄像头，显然它还能说话。
107 00:09:25,274 --> 00:09:30,542 说话者 说话者_00：我们训练它，然后把它面前放一个物体，然后我们说指向这个物体。
108 00:09:31,062 --> 00:09:32,245 说话者 说话者_00：没问题，它指向了物体。
109 00:09:33,306 --> 00:09:37,091 说话者 说话者_00：然后当它没注意的时候，我们在摄像机镜头前放了一个棱镜。
110 00:09:38,235 --> 00:09:41,759 说话者 说话者_00：然后我们在它前面放一个物体，说指向那个物体，它就指向那里。
111 00:09:43,581 --> 00:09:46,465 说话者 说话者_00：然后我们说，不，物体不在那里。
112 00:09:46,504 --> 00:09:50,028 说话者 说话者_00：物体实际上就在你面前，但我把棱镜放在了你的镜头前。
113 00:09:50,970 --> 00:09:52,311 说话人 SPEAKER_00: 噢，我明白了。
114 00:09:53,653 --> 00:09:59,720 说话人 SPEAKER_00: 晶体折射了光线，所以物体实际上在那里，但我主观上觉得它在那里。
115 00:10:01,380 --> 00:10:05,525 说话人 SPEAKER_00: 现在如果它这么说，它就是像我们一样使用了“主观经验”这个词。
116 00:10:06,451 --> 00:10:10,336 说话人 SPEAKER_00: 因此，我说，多模态聊天机器人已经可以拥有主观经验了。
117 00:10:11,078 --> 00:10:18,070 说话人 SPEAKER_00：如果你搞砸了他们的感知系统，他们会认为世界是这样的，但实际上却是那样的。
118 00:10:19,272 --> 00:10:25,120 说话人 SPEAKER_00：为了告诉你他们是如何看待世界的，他们会说，嗯，他们主观上觉得世界是这样的。
119 00:10:26,724 --> 00:10:29,808 说话人 SPEAKER_00：好的，所以他们已经有了主观经验。
120 00:10:30,885 --> 00:10:33,990 说话人 SPEAKER_00：现在，你对其他事情变得不那么自信了。
121 00:10:34,330 --> 00:10:45,482 说话者 SPEAKER_00: 意识显然更复杂，因为人们对它的理解各不相同，但它包含一个自我反思的元素，一个自我意识的元素，这使得它更加复杂。
122 00:10:46,203 --> 00:10:55,394 说话者 SPEAKER_00: 但一旦你确定它们有主观经验，我认为你可以放弃这样的想法：它们（我们）有一些永远无法拥有的东西。
123 00:10:57,056 --> 00:10:59,778 说话者 SPEAKER_00: 这让我感到不那么安全。
124 00:11:01,429 --> 00:11:04,894 说话者 SPEAKER_02: 你认为意识和自我意识之间有区别吗？
125 00:11:05,195 --> 00:11:08,620 说话者 SPEAKER_02：你说意识具有自我反思性，但有些意识确实如此。
126 00:11:09,059 --> 00:11:09,280 说话者 SPEAKER_00：是的。
127 00:11:09,581 --> 00:11:12,544 说话者 SPEAKER_00：所以哲学家们对此谈了很多。
128 00:11:13,125 --> 00:11:14,868 说话者 SPEAKER_00：目前，我不想深入讨论这个问题。
129 00:11:15,048 --> 00:11:18,312 说话人 SPEAKER_00：我只是想在那里打开一个缺口，说他们有主观经验。
130 00:11:19,774 --> 00:11:24,642 说话人 SPEAKER_02：那么，某物有主观经验，这不意味着它是意识吗？
131 00:11:24,841 --> 00:11:27,044 说话人 SPEAKER_02：比如，主观经验发生在谁身上？
132 00:11:27,504 --> 00:11:29,427 说话人 SPEAKER_02：主观经验在哪里被感受到？
133 00:11:30,437 --> 00:11:31,921 说话人 SPEAKER_00: 好的，确实如此。
134 00:11:31,941 --> 00:11:34,466 说话人 SPEAKER_00: 你说，主观体验是在哪里感受到的？
135 00:11:36,971 --> 00:11:48,177 说话人 SPEAKER_00: 这涉及到拥有一种特定的主观体验模型，如果你问哲学家，当我说我有一个小野象在我面前飘浮的主观体验时，
136 00:11:48,157 --> 00:11:51,059 说话人 SPEAKER_00: 你会说，那些小大象在哪里？
137 00:11:51,080 --> 00:11:52,221 说话者 SPEAKER_00: 他们说你心里有他们。
138 00:11:53,261 --> 00:11:55,244 说话者 SPEAKER_00: 你会说，嗯，它们是由什么组成的？
139 00:11:55,484 --> 00:11:57,405 说话者 SPEAKER_00: 哲学家们告诉你它们是由“质料”组成的。
140 00:11:57,947 --> 00:12:08,457 说话者 SPEAKER_00: 它们是由粉红色的质料、大象质料、飘浮质料、不那么大的质料、正立质料，所有这些都被质料胶粘在一起。
141 00:12:08,557 --> 00:12:11,600 说话人 SPEAKER_00: 这就是许多哲学家的看法。
142 00:12:12,100 --> 00:12:15,565 说话人 SPEAKER_00: 这是因为他们犯了一个语言错误。
143 00:12:16,287 --> 00:12:21,452 说话人 SPEAKER_00: 他们认为“工作经验”这个词就像“照片”这个词一样。
144 00:12:22,293 --> 00:12:28,581 说话人 SPEAKER_00: 如果我说我有一张小粉象的照片，你完全可以合理地问，嗯，照片在哪里？
145 00:12:29,341 --> 00:12:30,783 说话人 SPEAKER_00: 这张照片是由什么组成的？
146 00:12:32,785 --> 00:12:38,753 说话人 SPEAKER_00: 人们认为，如果我说我有过粉红色小象的经历，你可以问，嗯，经历在哪里？
147 00:12:38,893 --> 00:12:39,754 说话人 SPEAKER_00: 嗯，它在我的脑海里。
148 00:12:40,075 --> 00:12:40,936 说话人 SPEAKER_00: 它是由什么组成的？
149 00:12:41,015 --> 00:12:41,956 说话人 SPEAKER_00：它是由质料构成的。
150 00:12:43,388 --> 00:12:45,311 说话人 SPEAKER_00：但这只是胡说。
151 00:12:45,510 --> 00:12:51,100 说话人 SPEAKER_00：那是因为你认为“经验”和“照片”的作用方式相同，但实际上它们并不相同。
152 00:12:51,921 --> 00:13:10,830 说话人 SPEAKER_00：“经验”是如何运作的，或者说“主观经验”，是主观上说我不同意，而“经验”实际上是通过告诉我一个假设的世界状态来向我展示我的感知系统的一个指标。
153 00:13:11,013 --> 00:13:12,294 说话人 SPEAKER_00: 这就是那种语言的工作方式。
154 00:13:13,155 --> 00:13:16,139 说话人 SPEAKER_00: 它并不是指内在剧院中的某个东西。
155 00:13:17,782 --> 00:13:21,306 说话人 SPEAKER_02: 当我听到“感知”这个词时，它听起来也像是一个内在剧院。
156 00:13:21,567 --> 00:13:29,035 说话人 SPEAKER_02: 就像如果你说，我在我的感知系统中看到了某样东西，听起来就像有一个“你”正在一个被喂给它的感知系统中看到某样东西。
157 00:13:29,317 --> 00:13:30,337 说话者 SPEAKER_02：这就是错误的模型。
158 00:13:30,789 --> 00:13:34,777 说话者 SPEAKER_00：是的，你看不见你的感知，你有你的感知。
159 00:13:35,639 --> 00:13:47,139 说话者 SPEAKER_00：所以，光子进来，你的大脑进行了一系列处理，你大概得到了对世界外部的一些内部表征，但你看不见这个内部表征。
160 00:13:47,240 --> 00:13:50,024 说话者 SPEAKER_00：我们称这个内部表征为感知。
161 00:13:50,044 --> 00:13:51,969 说话人 SPEAKER_00: 你没看到，你有那个。
162 00:13:52,610 --> 00:13:54,232 说话人 SPEAKER_00: 有那个就是看到。
163 00:13:58,263 --> 00:14:06,532 说话人 SPEAKER_00: 人们总是试图认为你有一个外部世界，有什么东西进入内心剧场，然后你看看内心剧场里有什么。
164 00:14:07,254 --> 00:14:08,138 说话人 SPEAKER_00: 它不是那样的。
165 00:14:09,417 --> 00:14:13,261 有一位心理学家或神经学家认为，棋子与意识有关。
166 00:14:14,163 --> 00:14:18,850 最近，自我意识与默认模式网络有关。
167 00:14:18,870 --> 00:14:23,515 好的，AI 系统中是否有与自我意识有关的部分？
168 00:14:24,336 --> 00:14:28,423 还请帮我解释一下，当我提到 AI 系统时，我的术语是什么意思。
169 00:14:29,062 --> 00:14:30,846 说话人 SPEAKER_02：我们是在说它在 GPU 上运行时吗？
170 00:14:30,865 --> 00:14:31,927 说话人 SPEAKER_02：我们是在说它是算法吗？
171 00:14:31,947 --> 00:14:36,052 说话人 SPEAKER_02：比如说，什么是具有意识或主观经验的 AI 系统？
172 00:14:36,332 --> 00:14:37,634 说话人 SPEAKER_02：那么它在哪呢？
173 00:14:37,615 --> 00:14:47,014 说话人 SPEAKER_00: 我猜肯定有一些硬件在运行它，如果有什么东西会变得有意识的话，那将是这个系统。
174 00:14:50,280 --> 00:14:57,294 说话人 SPEAKER_00: 软件本身，我认为它必须运行在某个东西上，才能变得有意识。
175 00:14:57,764 --> 00:15:02,408 说话人 SPEAKER_02: 《经济学人》实际上已经多次采访并报道过杰弗里·辛顿。
176 00:15:02,828 --> 00:15:04,029 说话人 SPEAKER_02: 链接在描述中。
177 00:15:04,529 --> 00:15:14,859 主持人 SPEAKER_02：正如您所知，在《万物理论》中，我们深入探讨了一些最令人激荡现实的物理学理论、意识、人工智能和新兴技术等概念。
178 00:15:15,139 --> 00:15:27,770 主持人 SPEAKER_02：为了在日新月异的领域中保持信息更新，我认为《经济学人》是一个充满洞察力和深入报道的源泉，涵盖了我们在本节目以及更广泛的范围内探讨的各种话题。
179 00:15:27,750 --> 00:15:39,530 主持人 SPEAKER_02：《经济学人》对严谨新闻的承诺意味着您能够清晰地了解世界上最重要的进展，无论是科学创新还是全球政治板块的变动。
180 00:15:39,630 --> 00:15:43,977 主持人 SPEAKER_02：《经济学人》提供了超越标题的全面报道。
181 00:15:44,418 --> 00:15:52,392 说话人 SPEAKER_02：经济学人之所以与众不同，在于其将复杂问题变得易于理解和引人入胜，正如我们在这个播客中所努力做到的那样。
182 00:15:52,371 --> 00:16:01,489 说话人 SPEAKER_02：如果你热衷于拓展知识并深入了解塑造我们世界的力量，那么我强烈推荐你订阅经济学人。
183 00:16:01,649 --> 00:16:03,813 说话人 SPEAKER_02：这是一项对智力成长的投入。
184 00:16:04,193 --> 00:16:05,316 说话人 SPEAKER_02：这是一项你不会后悔的投资。
185 00:16:05,657 --> 00:16:10,225 主持人 SPEAKER_02：作为 Toe 的听众，您将获得特别的 20%折扣。
186 00:16:10,505 --> 00:16:14,092 主持人 SPEAKER_02：现在您可以以更低的价格享受《经济学人》及其所有服务。
187 00:16:14,072 --> 00:16:20,582 主持人 SPEAKER_02：访问他们的网站，www.economist.com slash toe，T-O-E，开始使用。
188 00:16:20,743 --> 00:16:25,811 主持人 SPEAKER_02：感谢收听，现在回到我们对宇宙奥秘的探索。
189 00:16:27,933 --> 00:16:34,764 说话人 SPEAKER_00：软件本身，我认为，必须运行在某个东西上，才能有意识。
190 00:16:35,351 --> 00:16:38,515 说话人 SPEAKER_02：我询问的是，就像之前一样，有一些停止运行的容器。
191 00:16:38,535 --> 00:16:44,062 说话人 SPEAKER_00：我认为一个很好的思考方式是考虑当 AI 实体化后，AI 系统会是什么样子。
192 00:16:45,183 --> 00:16:52,153 说话人 SPEAKER_00：所以，我们很快就会到达那里，因为人们正忙于建造战斗机器人，这不会是好事。
193 00:16:54,035 --> 00:16:56,719 说话人 SPEAKER_00：但如果有一个战斗机器人。
194 00:16:57,525 --> 00:17:08,278 说话人 SPEAKER_00：如果它已经知道了你在深夜会迟到，你会在深夜独自待在某个阴暗的小巷里，它决定在你最意想不到的时候从背后靠近你，从你后脑勺开枪。
195 00:17:09,358 --> 00:17:22,133 说话人 SPEAKER_00：讨论战斗机器人所相信的事情是完全合理的，你谈论战斗机器人所相信的方式和你谈论一个人所相信的方式是一样的。
196 00:17:22,348 --> 00:17:25,913 说话人 SPEAKER_00：战斗机器人可能会认为，如果它发出声音，你会转过身来看它。
197 00:17:26,413 --> 00:17:28,855 说话者 SPEAKER_00: 它可能真的会像人们一样思考。
198 00:17:31,499 --> 00:17:32,559 说话者 SPEAKER_00: 它可能有意图。
199 00:17:32,980 --> 00:17:34,962 说话者 SPEAKER_00: 它可能意图从你身后靠近并射击你。
200 00:17:38,386 --> 00:17:49,960 说话者 SPEAKER_00: 所以我认为，一旦这些事物被实现，我们不愿意使用“相信”、“意图”和“思考”等词语的犹豫将会消失。
201 00:17:50,597 --> 00:17:53,847 说话者 说话者_00：它已经消失得相当严重了。
202 00:17:54,008 --> 00:18:00,709 说话者 说话者_00：所以如果我和一个聊天机器人聊天，它开始向我推荐一些毫无意义的东西。
203 00:18:01,144 --> 00:18:06,854 说话者 说话者_00：然后过了一会儿，我觉得这个聊天机器人可能认为我是一个少女。
204 00:18:08,435 --> 00:18:15,788 说话者 说话者_00：这就是为什么它会给我推荐所有关于化妆、衣服和某些流行乐队、男孩乐队之类的东西。
205 00:18:16,648 --> 00:18:21,036 说话人 SPEAKER_00：所以我问聊天机器人，你认为我是哪个年龄段的人？
206 00:18:21,056 --> 00:18:23,239 说话人 SPEAKER_00：它说，我认为你是个少女。
207 00:18:24,780 --> 00:18:28,366 说话人 SPEAKER_00：当它说，我认为你是个少女，
208 00:18:29,173 --> 00:18:32,900 说话人 SPEAKER_00：我们真的没有怀疑它就是这么想的，对吧？
209 00:18:33,560 --> 00:18:36,546 说话人 SPEAKER_00：用正常语言来说，它认为我是个少女。
210 00:18:36,945 --> 00:18:46,361 说话人 SPEAKER_00：你不会说，你真的不相信，对吧，它只是一堆软件或神经网络，表现得好像它认为我是少女。
211 00:18:46,701 --> 00:18:47,282 说话人 SPEAKER_00：你不会这么说。
212 00:18:47,403 --> 00:18:48,684 说话人 SPEAKER_00：它认为你是少女。
213 00:18:50,166 --> 00:18:58,579 说话者 说话者_00：我们在处理这些系统时已经使用了像“认为”这样的词，即使它们没有与之相关的硬件，或者有明显的硬件与之相关。
214 00:18:58,599 --> 00:19:00,603 说话者 说话者_00：我们已经使用了“认为”和“相信”这样的词。
215 00:19:02,285 --> 00:19:04,648 说话者 说话者_00：所以我们已经把它们归因于心理状态。
216 00:19:05,229 --> 00:19:07,251 说话者 说话者_00：只是我们有一个关于心理状态的奇怪模型。
217 00:19:08,094 --> 00:19:15,684 说话者 SPEAKER_00：我们可以将心理状态归因于它们，但对拥有心理状态的本质有一个完全错误的认识。
218 00:19:16,356 --> 00:19:18,881 说话者 SPEAKER_00：我们把这个比作一个剧院，即心灵等等。
219 00:19:20,143 --> 00:19:21,505 说话者 SPEAKER_00：你的心理状态并不是这样的。
220 00:19:23,627 --> 00:19:30,637 说话者 SPEAKER_02：如果它们没有意识或没有主观体验，你对 AI 及其方向的担忧会有多大程度的减轻？
221 00:19:30,919 --> 00:19:32,079 说话者 SPEAKER_02：这与它相关吗？
222 00:19:32,180 --> 00:19:36,626 说话者 SPEAKER_02：这仅仅是加速了灾难吗？
223 00:19:36,758 --> 00:19:47,635 说话者 SPEAKER_00：其重要性在于它使大多数人感到相对安全，使大多数人认为我们拥有他们没有或永远不会拥有的东西，这使我们感到更加安全，更加特别。
224 00:19:48,537 --> 00:19:50,881 说话者 SPEAKER_00：我们并不特殊，我们并不安全。
225 00:19:52,584 --> 00:19:55,729 说话者 SPEAKER_00：我们当然不安全，因为我们有主观经验，而它们没有。
226 00:19:56,974 --> 00:20:06,646 说话者 SPEAKER_00：但我觉得这里真正的问题与其说是一个科学问题，不如说是一个哲学问题，那就是人们误解了主观经验的意义。
227 00:20:07,268 --> 00:20:09,771 说话者 SPEAKER_00：我想给你举一个例子来展示你可以使用语言。
228 00:20:11,614 --> 00:20:15,398 说话者 SPEAKER_00：你有科学背景，所以你可能认为你知道“水平”和“垂直”这两个词的含义。
229 00:20:16,440 --> 00:20:17,862 说话人 说话人_00: 我的意思是，这没问题，对吧？
230 00:20:18,122 --> 00:20:19,002 说话人 说话人_00: 他们想表达的意思很明显。
231 00:20:19,644 --> 00:20:23,669 说话人 说话人_00: 如果我给你看一样东西，那个是垂直的，那个是水平的，对吧？
232 00:20:24,450 --> 00:20:25,632 说话人 说话人_00: 不难。
233 00:20:25,814 --> 00:20:30,240 说话人 SPEAKER_00：现在我将说服你们，你们实际上对它们的工作方式有一个错误的模型。
234 00:20:30,582 --> 00:20:37,172 说话人 SPEAKER_00：并不完全错误，但在你对“水平”和“垂直”这两个术语的模型中存在重大问题，存在许多错误。
235 00:20:37,653 --> 00:20:38,294 说话人 SPEAKER_00：好的，我们开始吧。
236 00:20:39,756 --> 00:20:44,163 说话人 SPEAKER_00：假设我手里有一大堆小铝棒，数量很多。
237 00:20:44,223 --> 00:20:47,229 说话人 SPEAKER_00: 我把它们抛向空中，它们翻滚、旋转，互相碰撞。
238 00:20:47,689 --> 00:20:49,392 说话人 SPEAKER_00: 突然，我让时间停止。
239 00:20:49,759 --> 00:20:56,347 说话人 SPEAKER_00: 然后我问你，有多少是在垂直方向上相差一度的，有多少是在水平方向上相差一度的，还是大约一样多？
240 00:20:56,667 --> 00:20:57,849 说话人 SPEAKER_00: 大约一样吧。
241 00:20:58,530 --> 00:21:00,732 说话人 说话人_00: 对，大多数人都是这样说的，差不多。
242 00:21:01,354 --> 00:21:06,380 说话人 说话人_00: 他们很惊讶，当我告诉你们有大约114倍的数量在水平方向上相差一度以内。
243 00:21:07,821 --> 00:21:08,963 说话人 说话人_00: 这有点令人惊讶，对吧？
244 00:21:09,443 --> 00:21:10,144 说话人 说话人_00: 这是怎么发生的？
245 00:21:11,467 --> 00:21:14,990 说话人 说话人_00：嗯，这是垂直的。
246 00:21:15,358 --> 00:21:18,162 说话人 说话人_00：这也是垂直的，有一个旋转自由度。
247 00:21:18,922 --> 00:21:22,005 说话人 说话人_00：这是水平的，这也是水平的，但这也是。
248 00:21:23,026 --> 00:21:24,688 说话人 说话人_00：所以水平有两个自由度。
249 00:21:25,067 --> 00:21:26,288 说话人 SPEAKER_00: 垂直方向只有一个自由度。
250 00:21:26,990 --> 00:21:30,512 说话人 SPEAKER_00: 这里有一个你不知道的关于水平和垂直的事实。
251 00:21:31,773 --> 00:21:34,236 说话人 SPEAKER_00: 垂直方向非常特殊，而水平方向则精确到分。
252 00:21:35,998 --> 00:21:37,298 说话人 SPEAKER_00: 这对你来说可能有点意外。
253 00:21:37,318 --> 00:21:40,521 说话人 SPEAKER_00: 显然，在二维中不是这样的，但在三维中它们非常不同。
254 00:21:40,561 --> 00:21:42,203 说话人 SPEAKER_00: 其中一个非常特别，而另一个则不是。
255 00:21:42,223 --> 00:21:43,644 说话人 SPEAKER_00: 那为什么你不知道呢？
256 00:21:44,164 --> 00:21:46,608 说话人 SPEAKER_00: 好吧，我给你另一个问题。
257 00:21:46,628 --> 00:21:58,325 说话者 SPEAKER_00：假设我手里有一大堆小铝盘，我把它们都扔到空中，它们翻滚、转动，互相碰撞，突然时间停止了。
258 00:21:59,827 --> 00:22:05,015 说话者 SPEAKER_00：是垂直方向上的一度范围内更多，还是水平方向上的一度范围内更多，还是两者差不多？
259 00:22:05,536 --> 00:22:09,862 说话者 SPEAKER_00：不是，垂直方向上的一度范围内大约有 114 倍那么多。
260 00:22:10,262 --> 00:22:10,742 说话者 SPEAKER_02：有趣。
261 00:22:11,144 --> 00:22:13,227 说话人 SPEAKER_00：这就是垂直的。
262 00:22:13,882 --> 00:22:16,925 说话人 SPEAKER_00：这是垂直的，这也是垂直的。
263 00:22:18,087 --> 00:22:21,833 说话人 SPEAKER_00：这是水平的，这也是水平的，但它只有一个自由度。
264 00:22:22,433 --> 00:22:29,505 说话人 SPEAKER_00：所以，对于平面来说，水平面非常特殊，而垂直面则微不足道。
265 00:22:30,425 --> 00:22:34,551 说话人 SPEAKER_00：对于线条来说，垂直的非常特别，水平的才是真的分文不值。
266 00:22:34,971 --> 00:22:37,476 说话人 SPEAKER_00：这就是一个简单的例子。
267 00:22:37,928 --> 00:22:41,314 说话人 SPEAKER_00：你有一种关于词语如何工作的元理论。
268 00:22:41,334 --> 00:22:45,180 说话人 SPEAKER_00：即使你正确地使用了这些词语，这个元理论也可能是错误的。
269 00:22:45,740 --> 00:22:49,907 说话者 说话者_00：这就是我对所有这些心理状态术语的看法，比如主观体验。
270 00:22:50,689 --> 00:23:01,606 说话者 说话者_00：你可以正确地使用它们，你也可以理解当别人使用它们时他们的意思，但你有一个关于它们如何工作的元理论，这是一个由氯元素构成的内在剧院，完全是垃圾。
271 00:23:02,988 --> 00:23:14,368 说话者 说话者_02：那么，关于感知理论或主观体验的理论，是什么让它变得正确，以至于你可以这样说，我比大多数人认为的更接近正确的道路？
272 00:23:14,409 --> 00:23:23,645 说话者 说话者_00：你认为它们是某些东西，这些主观体验，你认为它们必须存在于某个地方，并且必须由某种东西构成。
273 00:23:24,824 --> 00:23:27,148 说话人 SPEAKER_00：那两件事都不真实。
274 00:23:28,752 --> 00:23:35,869 说话人 SPEAKER_00：当我提到主观体验时，这是一个标志，表明我接下来要谈论的是一个假设的世界状态，这个状态并不真实。
275 00:23:37,333 --> 00:23:39,458 说话人 SPEAKER_00：所以它并不存在于任何地方，它是一个假设的世界状态。
276 00:23:40,805 --> 00:23:45,673 说话人 SPEAKER_00：但请注意，说我要谈论的这个东西只是假设的，它实际上并不存在，两者之间有一个很大的区别。
277 00:23:46,134 --> 00:23:48,037 说话人 说话人_00: 但如果它在某个地方，它就会在世界上的某个地方。
278 00:23:49,219 --> 00:23:54,027 说话人 说话人_00: 相比之下，我谈论的是一种由有趣的东西构成的内心剧院中的东西。
279 00:23:54,807 --> 00:23:56,490 说话人 说话人_00: 这两个模型完全不同。
280 00:23:57,992 --> 00:24:04,163 说话人 说话人_00: 而那个由有趣的东西构成的内心剧院中的模型，我认为是完全错误的，尽管这是我们几乎所有人都有的一种模型。
281 00:24:05,289 --> 00:24:09,775 说话人 SPEAKER_02：关于像你的诺贝尔奖得主同行罗杰·彭罗斯这样的人，你提到过吗？
282 00:24:09,914 --> 00:24:12,057 说话人 SPEAKER_02：让我给你讲一个关于罗杰·彭罗斯的故事。
283 00:24:12,858 --> 00:24:23,471 说话人 SPEAKER_00：很久以前，他被邀请去多伦多大学做关于他新书《皇帝的新装》的讲座。
284 00:24:24,853 --> 00:24:28,277 说话人 SPEAKER_00：我还被邀请去为他介绍。
285 00:24:28,477 --> 00:24:30,699 院长打电话给我，说，你愿意介绍罗杰·彭罗斯吗？
286 00:24:31,259 --> 00:24:31,941 我说，当然。
287 00:24:32,741 --> 00:24:34,002 她说，哦，非常感谢。
288 00:24:34,723 --> 00:24:37,366 我说，啊，但在你同意之前，你应该知道我会说什么。
289 00:24:37,426 --> 00:24:40,130 说话人 SPEAKER_00: 她说，你会说什么？
290 00:24:41,290 --> 00:24:48,898 说话人 SPEAKER_00: 我说，罗杰·彭罗斯是一位杰出的数学物理学家，他对数学物理做出了巨大贡献。
291 00:24:49,440 --> 00:24:51,582 说话人 SPEAKER_00: 而他今天要讨论的内容完全是垃圾。
292 00:24:53,519 --> 00:24:58,503 说话人 SPEAKER_00: 所以这是我对于罗杰·彭罗斯对意识看法的观点。
293 00:24:59,184 --> 00:25:12,417 说话者 说话者_00：他犯了一个疯狂的错误，现在我得小心地表达，因为显然人们会批评这一点。
294 00:25:12,478 --> 00:25:22,007 说话者 说话者_00：问题是，数学家能否直观地认识到那些无法被证明为真的事物？
295 00:25:23,776 --> 00:25:30,265 说话者 说话者_00：如果数学家的直觉总是正确的，那就非常令人担忧。
296 00:25:31,086 --> 00:25:38,095 说话者 说话者_00：如果他们每次都能正确地做到这一点，那就非常令人担忧，似乎有些奇怪的事情正在发生。
297 00:25:40,357 --> 00:25:40,898 说话人 SPEAKER_00: 他们做不到。
298 00:25:41,439 --> 00:25:45,203 说话人 SPEAKER_00: 数学家有直觉，他们有时是对的，有时是错的。
299 00:25:46,306 --> 00:25:47,928 说话人 SPEAKER_00: 所以这并不能证明什么。
300 00:25:47,948 --> 00:25:51,893 说话人 SPEAKER_00: 这并不能证明你需要量子力学来解释数学家是如何工作的。
301 00:25:52,413 --> 00:25:58,762 说话人 SPEAKER_00：我看不出需要量子力学来解释像意识这样的东西有任何理由。
302 00:26:00,164 --> 00:26:03,088 说话人 SPEAKER_00：到目前为止，人工智能做得相当不错。
303 00:26:03,589 --> 00:26:06,233 说话人 SPEAKER_00：我们已经生产了这些聊天机器人。
304 00:26:06,253 --> 00:26:12,884 说话人 SPEAKER_00：正如我刚才所论证的，这些聊天机器人，如果你给他们一个摄像头，可以拥有主观体验。
305 00:26:15,047 --> 00:26:19,534 说话人 SPEAKER_00：关于人类，没有什么需要量子力学来解释的。
306 00:26:21,438 --> 00:26:28,828 说话人 SPEAKER_02：Penrose 论证中有什么是 100%依赖于数学家正确直觉的吗？
307 00:26:29,849 --> 00:26:31,352 说话人 SPEAKER_00：只有当他们能够正确直觉时。
308 00:26:31,392 --> 00:26:33,194 说话人 SPEAKER_00：如果他们在猜测，那也行。
309 00:26:35,357 --> 00:26:47,194 说话者 SPEAKER_00：如果他们总是能找到正确答案，这些无法在系统中得出、无法在系统中回答的问题，那就会成问题。
310 00:26:47,634 --> 00:26:48,896 说话者 SPEAKER_00：但他们做不到，他们会犯错误。
311 00:26:50,277 --> 00:26:53,345 说话者 SPEAKER_00：你能概述一下他的论点，潘纳罗萨的？
312 00:26:54,488 --> 00:27:00,384 说话者 SPEAKER_00：我不想，我的意思是，论点，正如我理解的那样，有两件事在进行中。
313 00:27:01,006 --> 00:27:06,160 说话人 SPEAKER_00：他说，经典计算无法解释意识。
314 00:27:06,426 --> 00:27:09,951 说话人 SPEAKER_00：我认为这是一个大错误，我认为这是基于对意识的一种荒谬的理解。
315 00:27:10,211 --> 00:27:10,792 说话人 SPEAKER_00：这是不对的。
316 00:27:11,413 --> 00:27:12,955 说话人 SPEAKER_00：对意识的一种误解。
317 00:27:13,998 --> 00:27:24,211 说话人 SPEAKER_00：第二个原因是数学家可以直观地认识到无法证明的事物，这表明有些奇怪的事情正在发生。
318 00:27:25,094 --> 00:27:28,719 说话人 SPEAKER_00：除非他们每次都能正确直观地认识到，否则这并不表明有什么奇怪的事情正在发生。
319 00:27:30,602 --> 00:27:34,686 说话人 SPEAKER_02：所以我相信你已经听说过中国房间实验。
320 00:27:34,707 --> 00:27:35,167 说话人 SPEAKER_00：我听说过。
321 00:27:35,468 --> 00:27:36,328 说话人 SPEAKER_02：对此您有什么看法？
322 00:27:36,910 --> 00:27:39,772 说话人 SPEAKER_02：请随意简要地向观众概述一下。
323 00:27:39,792 --> 00:27:40,113 说话人 SPEAKER_00：好的。
324 00:27:41,114 --> 00:27:47,362 说话人 SPEAKER_00：所以，大约在 1990 年，我被邀请和约翰·塞尔一起参加一个电视节目。
325 00:27:48,843 --> 00:27:51,987 说话人 SPEAKER_00: 我给我的朋友丹·丹尼特打电话，问他，我应该这么做吗？
326 00:27:53,449 --> 00:28:00,717 说话人 SPEAKER_00: 他说，嗯，他会尽力让你看起来很愚蠢。
327 00:28:02,738 --> 00:28:05,621 说话人 SPEAKER_00: 但如果你这么做，不要谈论中国房间论点。
328 00:28:06,561 --> 00:28:10,207 说话人 SPEAKER_00: 所以我同意和索一起参加节目。
329 00:28:11,387 --> 00:28:14,892 说话者 SPEAKER_00: 他说的第一件事是一段长达一小时的采访。
330 00:28:15,452 --> 00:28:23,121 说话者 SPEAKER_00: 他说的第一件事是，所以杰弗里·辛顿是一位连接主义者，当然他对中国房间论没有问题。
331 00:28:23,382 --> 00:28:24,222 说话者 SPEAKER_00: 是一位连接主义者。
332 00:28:24,363 --> 00:28:24,982 说话者 SPEAKER_00: 是一位连接主义者。
333 00:28:25,403 --> 00:28:28,948 说话者 说话者_00: 因此他说，他对中文房间论点没有问题。
334 00:28:29,366 --> 00:28:31,549 说话者 说话者_00: 我们已经同意不讨论这个话题。
335 00:28:31,829 --> 00:28:34,713 说话者 说话者_00: 他说的一些事情是完全错误的。
336 00:28:34,794 --> 00:28:36,856 说话者 说话者_00: 我对中文错论有很多问题。
337 00:28:36,896 --> 00:28:37,718 说话人 SPEAKER_00: 我认为这是胡说。
338 00:28:38,278 --> 00:28:40,422 说话人 SPEAKER_00: 我认为这是一个故意误导的论点。
339 00:28:40,442 --> 00:28:42,064 说话人 SPEAKER_00: 我认为这是一个不诚实的论点。
340 00:28:44,146 --> 00:28:53,338 说话人 SPEAKER_00: 你所做的是，你说有一个房间里满是中国人，我想。
341 00:28:53,980 --> 00:28:55,662 说话人 SPEAKER_00: 嗯，这里有一个房间
342 00:28:57,380 --> 00:29:07,940 说话人 SPEAKER_00: 他希望你识别，是的，我们可以制作一个由中国人组成的系统，他们用中文互相发送信息。
343 00:29:08,701 --> 00:29:15,252 说话人 SPEAKER_00: 由于所有这些用中文发送的信息，你可以发送一个英文句子，
344 00:29:16,432 --> 00:29:18,094 说话人 SPEAKER_00: 他们会用中文互相发送信息。
345 00:29:18,114 --> 00:29:19,435 说话人 SPEAKER_00：这只是我的记忆中的论点。
346 00:29:20,196 --> 00:29:29,250 说话人 SPEAKER_00：他们甚至能够回答这个英语句子，尽管发送这些信息的所有人都不懂英语，因为他们只是在运行一个程序。
347 00:29:29,971 --> 00:29:31,953 说话人 SPEAKER_00：但他们通过互相发送中文信息来完成。
348 00:29:32,974 --> 00:29:45,712 说话人 SPEAKER_00：好，这个论点不诚实的地方在于，他想让你认为整个系统
349 00:29:45,877 --> 00:29:48,041 说话人 SPEAKER_00: 以及那些发送消息的个体中国人。
350 00:29:49,545 --> 00:29:51,448 说话人 SPEAKER_00: 整个系统都理解英语。
351 00:29:52,450 --> 00:29:54,733 说话人 SPEAKER_00: 但是那些发送消息的个体中国人却不理解。
352 00:29:55,895 --> 00:30:01,626 说话人 SPEAKER_00: 他想让你认为整个系统不可能理解英语，因为里面的人都不懂英语。
353 00:30:02,288 --> 00:30:02,969 说话人 SPEAKER_00: 这纯粹是胡说。
354 00:30:03,028 --> 00:30:04,511 说话人 SPEAKER_00: 系统理解英语。
355 00:30:06,174 --> 00:30:07,297 说话人 SPEAKER_01: 我认为这就是论点错误的地方。
356 00:30:09,220 --> 00:30:10,182 说话人 SPEAKER_01: 现在，说到中国，
357 00:30:11,950 --> 00:30:18,721 众多 AI 研究人员没有预料到的是，中国在 AI 发展方面已经赶上了西方。
358 00:30:19,423 --> 00:30:21,688 那您对此有何感想，以及这会带来什么后果？
359 00:30:22,710 --> 00:30:24,373 我认为他们还没有完全赶上。
360 00:30:24,593 --> 00:30:26,836 但他们非常接近了。
361 00:30:28,116 --> 00:30:33,403 说话人 SPEAKER_00: 美国将通过试图阻止他们获得最新的 NVIDIA 芯片来稍微减缓他们的步伐。
362 00:30:34,503 --> 00:30:37,105 说话人 SPEAKER_00: NVIDIA 也许能找到解决方案。
363 00:30:38,528 --> 00:30:46,856 说话人 SPEAKER_00: 如果禁运有效，这将促使中国发展自己的技术。
364 00:30:47,817 --> 00:30:51,461 说话人 SPEAKER_00: 他们可能会落后几年，但他们会迎头赶上。
365 00:30:51,480 --> 00:30:54,984 说话人 SPEAKER_00：他们的 STEM 教育比美国更好。
366 00:30:55,218 --> 00:30:57,845 说话人 SPEAKER_00：所以他们有更多受过更好教育的人。
367 00:30:57,865 --> 00:31:02,757 说话人 SPEAKER_01：我认为他们将要赶上来了。
368 00:31:04,821 --> 00:31:06,246 说话人 SPEAKER_00：你知道马克·安德森是谁吗？
369 00:31:07,388 --> 00:31:08,510 说话人 SPEAKER_00: 他认为。
370 00:31:09,173 --> 00:31:11,538 说话人 SPEAKER_00: 是的，我认为我在很多方面都不同意他。
371 00:31:12,717 --> 00:31:14,057 说话人 SPEAKER_02: 好的，那我们选一个怎么样？
372 00:31:14,959 --> 00:31:18,002 说话人 SPEAKER_02: 所以他评论说，我不明白你将如何将其锁定。
373 00:31:18,042 --> 00:31:23,888 说话者 SPEAKER_02：他正在和政府的人谈话，政府说，如果人工智能发展失控，我们可以将其“锁定”，
374 00:31:23,909 --> 00:31:24,088 说话者 SPEAKER_02：对。
375 00:31:24,189 --> 00:31:25,431 说话者 SPEAKER_02：他说，你怎么能这么做呢？
376 00:31:25,451 --> 00:31:27,152 说话者 SPEAKER_02：因为人工智能的数学公式已经公开了。
377 00:31:27,172 --> 00:31:28,294 说话人 SPEAKER_02：它无处不在都在被教授。
378 00:31:28,834 --> 00:31:35,520 说话人 SPEAKER_02：对此，官员们回应说，在冷战期间，我们将整个物理领域分类并从研究社区中移除。
379 00:31:35,882 --> 00:31:39,045 说话人 SPEAKER_02：物理的整个分支基本上陷入了黑暗，没有继续发展。
380 00:31:39,025 --> 00:31:44,136 说话人 SPEAKER_02：如果我们决定需要，我们也会对 AI 底层的数学做同样的事情。
381 00:31:45,519 --> 00:31:45,941 说话人 SPEAKER_02:算了吧。
382 00:31:48,446 --> 00:31:49,951 说话人 SPEAKER_00:我同意 Marc-André Ciron 的观点。
383 00:31:50,010 --> 00:31:52,696 说话人 SPEAKER_00:你不可能做到的...
384 00:31:53,992 --> 00:32:02,260 说话人 SPEAKER_00:比如说，谷歌在 2017 年本可以决定不发布 Transformers。
385 00:32:03,162 --> 00:32:06,144 说话者 SPEAKER_00：可能要过几年才会有人想出同样的主意。
386 00:32:07,286 --> 00:32:08,988 说话者 SPEAKER_00：所以他们可能可以推迟几年。
387 00:32:11,770 --> 00:32:20,598 说话者 SPEAKER_00：但我认为阻止信息泄露的希望不大……我的意思是，想想阻止信息泄露需要付出多大的努力。
388 00:32:20,618 --> 00:32:21,299 说话者 SPEAKER_00：这会非常困难。
389 00:32:22,174 --> 00:32:26,701 说话人 SPEAKER_02：你不认为政府可以归类一些，比如说，线性代数吗？
390 00:32:27,722 --> 00:32:27,942 说话人 SPEAKER_00：不。
391 00:32:29,305 --> 00:32:34,412 说话人 SPEAKER_00：我的意思是，他们可能会使某些类型的信息共享变得更加困难，这可能会稍微减缓一些进程。
392 00:32:35,913 --> 00:32:44,705 说话人 SPEAKER_00：但我认为他们不可能采纳真正有效的 AI 想法。
393 00:32:45,174 --> 00:32:49,046 说话者：SPEAKER_00：不分享它们，防止其他人创建它们。
394 00:32:49,467 --> 00:33:00,837 说话者：SPEAKER_00：新想法的出现往往伴随着一种，一种时代精神，在那个时代精神中，可以产生新的想法。
395 00:33:00,817 --> 00:33:11,589 说话者：SPEAKER_00：通常情况下，一个人会有一个新想法，在大约同一时间，相当独立地，除了他们共享同样的时代精神，其他人会有相同想法的略微不同的版本。
396 00:33:12,109 --> 00:33:13,412 说话者：SPEAKER_00：这种情况一直在发生。
397 00:33:14,512 --> 00:33:21,580 除非你能摆脱整个时代精神，否则你无法拥有新想法并保守秘密。
398 00:33:22,080 --> 00:33:24,784 因为几年后，其他人也会想出同样的想法。
399 00:33:26,636 --> 00:33:28,460 关于人工智能的去中心化呢？
400 00:33:28,480 --> 00:33:30,442 这是个很大的话题。
401 00:33:30,462 --> 00:33:36,752 有人说，嗯，这是把原子弹交给任何想要获得原子弹的人。
402 00:33:36,813 --> 00:33:37,574 是的，我同意这个观点。
403 00:33:37,953 --> 00:33:48,130 然而还有人说，为了防止类似天网那样的场景，我们需要有多个不同的去中心化代理或 AI。
404 00:33:48,150 --> 00:33:49,952 对不起，这里有两个去中心化的概念。
405 00:33:49,972 --> 00:33:53,218 说话人 SPEAKER_00：那么，我们来谈谈权重的共享。
406 00:33:54,176 --> 00:34:03,047 说话人 SPEAKER_00：那么，如果你问为什么阿拉巴马没有炸弹，那是因为你需要裂变材料。
407 00:34:04,147 --> 00:34:05,730 说话人 SPEAKER_00：而且获取裂变材料很难。
408 00:34:05,869 --> 00:34:09,052 说话人 SPEAKER_00：生产裂变材料需要大量的时间和能量。
409 00:34:09,934 --> 00:34:13,677 说话人 SPEAKER_00：一旦你有了裂变材料，制造炸弹就变得容易多了。
410 00:34:13,697 --> 00:34:17,443 说话人 SPEAKER_00：因此，政府显然不希望裂变材料流散出去。
411 00:34:17,463 --> 00:34:19,644 说话人 SPEAKER_00：你不能在 eBay 上买到裂变材料。
412 00:34:21,498 --> 00:34:24,963 说话人 SPEAKER_00：这就是为什么我们没有许多属于小国的微型原子弹。
413 00:34:27,206 --> 00:34:37,460 说话人 SPEAKER_00：那么，如果你问这些大型聊天机器人的等效物是什么，等效物是一个经过训练的基础模型，可能花费了 1 亿美元，甚至 10 亿美元。
414 00:34:38,041 --> 00:34:39,922 说话人 SPEAKER_00：它是在大量数据上训练的。
415 00:34:40,643 --> 00:34:42,166 说话人 SPEAKER_00：它拥有巨大的能力。
416 00:34:43,407 --> 00:34:47,673 说话人 SPEAKER_00：如果你释放该模型的权重，你现在可以将其微调到各种不良用途。
417 00:34:48,902 --> 00:34:55,981 说话人 SPEAKER_00: 我认为发布这些大型模型的权重是疯狂的行为，因为它们是我们约束不良行为者的主要手段。
418 00:34:57,445 --> 00:35:00,291 说话人 SPEAKER_00: Meta 已经这样做了，其他人也纷纷效仿。
419 00:35:01,956 --> 00:35:06,286 说话人 SPEAKER_00: 现在已经太晚了，猫已经从袋子里出来了，但这是一个疯狂的决定。
420 00:35:08,173 --> 00:35:15,206 说话人 SPEAKER_02: 说到基础模型，我们最新的 AI 繁荣很大程度上归功于 Transformer 架构。
421 00:35:15,608 --> 00:35:21,880 说话人 SPEAKER_02：你看到一些其他的大突破，无论是某种范式还是其他某种架构即将出现吗？
422 00:35:22,518 --> 00:35:29,744 说话人 SPEAKER_00：好吧，我认为还会有其他一些具有相当规模的大突破，因为科学就是这样运作的。
423 00:35:30,385 --> 00:35:31,166 说话人 SPEAKER_00：我不知道它们是什么。
424 00:35:31,206 --> 00:35:33,469 说话人 SPEAKER_00：如果我知道它们是什么，我就会在做它们。
425 00:35:33,489 --> 00:35:33,989 说话者 SPEAKER_00: 你会吗？
426 00:35:34,710 --> 00:35:35,751 说话者 SPEAKER_00: 哎，我现在太老了。
427 00:35:35,831 --> 00:35:37,152 说话者 SPEAKER_02: 我有学生在做这些。
428 00:35:37,172 --> 00:35:43,398 说话者 SPEAKER_02: 我的意思是，你如何调和你在该领域的过去贡献和现在的困扰？
429 00:35:43,838 --> 00:35:46,041 说话者 SPEAKER_02：你会为它做出贡献吗？
430 00:35:47,422 --> 00:35:50,144 说话者 SPEAKER_00：那么问题来了。
431 00:35:50,429 --> 00:36:04,706 说话者 SPEAKER_00：对很多有利于人类的事情非常好，比如更好的医疗保健、对抗气候变化、更好的材料，比如室温超导体，AI 可能真的会参与其中，实际上发现它们。
432 00:36:05,786 --> 00:36:07,409 说话者 SPEAKER_00：假设它们确实存在。
433 00:36:09,510 --> 00:36:15,237 说话人 SPEAKER_00：所以有很多事情，AI 的积极用途，我认为发展是不会停止的。
434 00:36:15,893 --> 00:36:22,342 说话人 SPEAKER_00：我认为说我们应该放慢 AI 的发展，放慢发展步伐是不明智的。
435 00:36:22,362 --> 00:36:27,630 说话人 SPEAKER_00：这是不可能发生的，因为竞争太激烈，而且也不可行。
436 00:36:27,869 --> 00:36:31,615 说话人 SPEAKER_00：这可能对人类是最好的事情，但这是不可能发生的。
437 00:36:32,617 --> 00:36:36,702 说话人 SPEAKER_00：我们应该做的是在它开发的过程中，想办法让它保持安全。
438 00:36:39,333 --> 00:36:42,818 说话人 SPEAKER_02：所以说，这就像是一块谁都无法阻止的巨石。
439 00:36:42,878 --> 00:36:46,242 说话人 SPEAKER_02：同时，也要负责推动这块巨石。
440 00:36:46,603 --> 00:36:57,077 说话人 SPEAKER_02：那么，如果你看到前方有突破性的进展，就像雷·库兹韦尔一样，你有这种出色的预测能力，你会真的把赌注压在上面并投入其中吗？
441 00:36:57,998 --> 00:37:00,623 说话者 说话者_00：只要它与如何确保其安全的工作相结合。
442 00:37:00,682 --> 00:37:00,902 说话者 说话者_00：是的。
443 00:37:01,463 --> 00:37:06,471 说话者 说话者_00：我觉得我没有意识到它将有多么危险。
444 00:37:06,974 --> 00:37:08,074 说话者 说话者_00：我希望我能早点意识到。
445 00:37:09,317 --> 00:37:11,659 说话人 SPEAKER_02：爱因斯坦曾有一句关于原子弹的引用。
446 00:37:11,699 --> 00:37:16,186 他说，如果我知道我所发展的东西会导致原子弹，我会烧掉我的手。
447 00:37:16,567 --> 00:37:17,628 你感觉类似吗？
448 00:37:17,648 --> 00:37:20,632 我实际上并不觉得。
449 00:37:20,672 --> 00:37:22,014 说话人 SPEAKER_00：也许我应该。
450 00:37:23,096 --> 00:37:26,000 说话人 SPEAKER_00：我不后悔我所做的事情。
451 00:37:26,019 --> 00:37:29,423 说话人 SPEAKER_00：我后悔的是它可能带来不好的事情。
452 00:37:30,045 --> 00:37:32,547 说话人 SPEAKER_00：但我并不回头想，哦，我希望我从未做过那件事。
453 00:37:33,510 --> 00:37:35,192 说话人 SPEAKER_00: 我认为人工智能将会被开发。
454 00:37:35,695 --> 00:37:40,943 说话人 SPEAKER_00: 嘛，我觉得我们在这方面没有太多选择，因为国家之间和公司之间的竞争。
455 00:37:42,666 --> 00:37:46,652 说话人 SPEAKER_00: 我认为我们应该把精力集中在尝试安全地开发它上，而不是。
456 00:37:47,855 --> 00:37:50,599 说话人 SPEAKER_00: 这与试图减缓它的开发速度非常不同。
457 00:37:51,920 --> 00:37:54,945 说话人 SPEAKER_02: 除了对齐之外，什么是 AI 安全开发的含义？
458 00:37:55,005 --> 00:37:57,469 说话人 SPEAKER_00: 好的。
459 00:37:57,971 --> 00:38:02,378 说话者 SPEAKER_00: 嗯，考虑如何应对短期风险。
460 00:38:04,231 --> 00:38:06,974 说话者 SPEAKER_00: 这些风险有很多，而且它们都有不同的解决方案。
461 00:38:08,376 --> 00:38:17,284 说话者 SPEAKER_00: 比如致命的自主武器，处理这个问题需要诸如日内瓦公约这样的东西，但我们不会在发生糟糕的事情之前得到它们。
462 00:38:19,306 --> 00:38:25,875 说话者 SPEAKER_00: 你有虚假的视频和图像破坏选举，尤其是如果它们针对特定的人。
463 00:38:27,096 --> 00:38:28,197 说话人 SPEAKER_00：为了处理这个问题，
464 00:38:29,711 --> 00:38:34,878 说话人 SPEAKER_00：我认为你需要一个更好的系统来确立视频或图像的来源。
465 00:38:35,719 --> 00:38:40,387 说话人 SPEAKER_00：最初我认为你应该将它们标记为假，你应该坚持将它们标记为假。
466 00:38:41,427 --> 00:38:43,251 说话人 SPEAKER_00：我认为这已经没有多少前景了。
467 00:38:43,610 --> 00:38:50,300 说话人 SPEAKER_00: 我认为你最好坚持认为事物有来源，并且你的浏览器可以检查来源。
468 00:38:51,302 --> 00:38:53,103 说话人 SPEAKER_00: 就像已经那样
469 00:38:54,771 --> 00:38:57,838 说话人 SPEAKER_00: 它说，不要相信这个，我无法确认。
470 00:38:58,661 --> 00:39:01,648 说话人 SPEAKER_00: 应该是这样的。
471 00:39:02,791 --> 00:39:06,300 说话人 SPEAKER_00：存在歧视和偏见
472 00:39:09,672 --> 00:39:17,885 说话人 SPEAKER_00：你可以冻结系统的权重，测量其偏见，然后多少进行纠正。
473 00:39:17,905 --> 00:39:19,867 说话人 SPEAKER_00：你永远无法完全纠正，但可以多少进行纠正。
474 00:39:20,568 --> 00:39:23,313 说话人 SPEAKER_00：因此，你可以使系统比训练数据更少地存在偏见。
475 00:39:24,253 --> 00:39:27,900 说话人 SPEAKER_00: 因此你可以用不那么有偏见的系统来替换人。
476 00:39:28,117 --> 00:39:29,177 说话人 SPEAKER_00: 它永远不会没有偏见。
477 00:39:29,478 --> 00:39:37,005 说话人 SPEAKER_00: 但如果你只是用不那么有偏见的系统来替换系统，这就叫做梯度下降，事物会变得不那么有偏见。
478 00:39:38,108 --> 00:39:39,208 说话人 SPEAKER_00: 所以我对这一点并不那么担心。
479 00:39:39,728 --> 00:39:41,050 说话人 SPEAKER_00: 可能是因为我是个老白人。
480 00:39:44,034 --> 00:39:45,094 说话人 SPEAKER_00: 有工作。
481 00:39:45,375 --> 00:39:47,097 说话人 SPEAKER_00: 我们真的不知道该怎么办。
482 00:39:48,038 --> 00:39:55,626 说话人 SPEAKER_00: 所以现在挖沟的人不多了，因为挖掘机挖沟比人强多了。
483 00:39:56,905 --> 00:40:00,009 说话者 SPEAKER_00：对于几乎所有日常智力劳动来说，情况都将如此。
484 00:40:01,150 --> 00:40:06,056 说话者 SPEAKER_00：一个 AI 系统将比人做得更好的法律助理。
485 00:40:09,400 --> 00:40:13,726 说话者 SPEAKER_00：这真的很可怕，因为它将对社会产生什么影响。
486 00:40:14,527 --> 00:40:18,130 说话者 SPEAKER_00：它将使富人变得更富，因为我们将获得大幅度的生产力提升。
487 00:40:19,052 --> 00:40:20,273 说话人 SPEAKER_00: 那笔财富会去哪里？
488 00:40:20,293 --> 00:40:23,858 说话人 SPEAKER_00: 会流向富人，而穷人则会变得更穷。
489 00:40:24,090 --> 00:40:25,416 说话人 SPEAKER_00: 我不知道该怎么办。
490 00:40:25,637 --> 00:40:34,590 说话人 SPEAKER_00: 最低生活保障有助于阻止一些饿死的人，但这并不能真正解决问题，因为如果人们没有工作，他们的尊严就消失了。
491 00:40:35,768 --> 00:40:44,019 说话者 SPEAKER_02：那么，之前我们讨论了感知，然后感知与主观品质相关联。
492 00:40:44,681 --> 00:40:45,922 说话者 SPEAKER_02：也许那里有一个错误的模型。
493 00:40:46,423 --> 00:40:55,157 说话者 SPEAKER_02：但是无论如何，当我们谈论感知时，我们是在谈论感知，因此我们是在谈论与之相关的主观体验吗？
494 00:40:56,219 --> 00:41:03,108 说话者 SPEAKER_00：不，当你使用“主观体验”这个词时，你表明你即将讨论一个关于现实世界的假设状态。
495 00:41:04,708 --> 00:41:05,170 说话人 SPEAKER_00: 好吗？
496 00:41:05,833 --> 00:41:09,666 说话人 SPEAKER_00: 不是什么有趣的内部事情，而是一种假设的客观世界状态。
497 00:41:10,447 --> 00:41:13,639 说话人 SPEAKER_00: 这些有趣的内部事情是不存在的。
498 00:41:15,172 --> 00:41:19,376 说话人 SPEAKER_00: 没有什么，没有质料，没有由质料构成的东西。
499 00:41:19,396 --> 00:41:23,501 说话者 SPEAKER_00：这里只是假设的世界状态，用来解释你的感知系统是如何欺骗你的。
500 00:41:24,344 --> 00:41:29,750 说话者 SPEAKER_02：这就是我们所说的主观体验是这些假设的世界状态的意思吗？
501 00:41:30,190 --> 00:41:31,893 说话者 SPEAKER_02：这就是我们实际使用它的方式。
502 00:41:32,293 --> 00:41:35,036 说话者 SPEAKER_00：所以是预测吗？
503 00:41:35,016 --> 00:41:38,981 说话者 SPEAKER_00: 把预测问题引入其中，有点像是一个无关紧要的干扰。
504 00:41:39,021 --> 00:41:40,103 说话者 SPEAKER_00: 完全是另一个方向。
505 00:41:42,047 --> 00:41:53,963 说话者 SPEAKER_00: 你必须牢记的是，并没有一种叫做主观体验的有趣事物，它是由一些有趣的心理物质构成的。
506 00:41:55,284 --> 00:42:04,516 说话者 SPEAKER_00: 仅仅是一种谈论你的感知系统出错的技术，也就是说，世界必须是什么样的，才能让它说出真相。
507 00:42:05,155 --> 00:42:06,637 说话者 说话者_00: 这就是我们所指的。
508 00:42:07,018 --> 00:42:11,043 说话者 说话者_00: 当我们使用“主观经验”这个短语时，我们表明这是我们正在玩的游戏。
509 00:42:11,403 --> 00:42:18,554 说话者 说话者_00: 我们在玩一个游戏，就是向你描述假设的世界状态，以解释我的感知系统是如何出错的。
510 00:42:20,739 --> 00:42:22,320 说话者 说话者_00: 主观经验不是一件东西。
511 00:42:22,380 --> 00:42:26,286 说话人 SPEAKER_02：任何事物都能拥有感知系统吗？
512 00:42:26,666 --> 00:42:28,150 说话人 SPEAKER_02：一本书能拥有感知系统吗？
513 00:42:28,731 --> 00:42:30,353 说话人 SPEAKER_02：什么定义了感知系统？
514 00:42:31,717 --> 00:42:45,728 说话人 SPEAKER_00：好吧，要有一个感知系统，你可能会认为你需要某种能够对发生在外部世界中的某些事物进行内部表征的东西。
515 00:42:46,130 --> 00:42:46,992 说话者 SPEAKER_00：这就是我的想法。
516 00:42:49,282 --> 00:43:00,467 说话者 SPEAKER_00：所以，就像青蛙看到光亮就扑向苍蝇一样，它显然有一个感知系统，因为它必须看到苍蝇在哪里，对吧？
517 00:43:00,967 --> 00:43:08,523 说话者 SPEAKER_00：我认为一本书没有感知系统，因为它不是在感知世界并形成内部表征。
518 00:43:09,382 --> 00:43:11,724 说话者 SPEAKER_02：大家好，希望你们喜欢今天的节目。
519 00:43:12,126 --> 00:43:20,318 主持人 SPEAKER_02：如果你渴望深入了解物理学、人工智能、意识、哲学，以及我的个人反思，你可以在我的子堆栈中找到所有这些内容。
520 00:43:20,659 --> 00:43:30,293 主持人 SPEAKER_02：订阅者将首先获得新剧集、新帖子以及幕后洞察，还有机会成为志同道合的朝圣者社区的一员。
521 00:43:30,273 --> 00:43:35,880 主持人 SPEAKER_02：通过加入，你将直接支持我的工作，并帮助保持这些对话处于前沿。
522 00:43:36,262 --> 00:43:42,471 主持人 SPEAKER_02：所以点击屏幕上的链接，点击订阅，让我们一起推动知识边界的拓展。
523 00:43:42,891 --> 00:43:44,393 主持人 SPEAKER_02: 谢谢，祝您观看愉快。
524 00:43:44,673 --> 00:43:49,320 主持人 SPEAKER_02: 就这样，如果你在听的话，是 C-U-R-T-J-A-I-M-U-N-G-A-L.org。
525 00:43:49,460 --> 00:43:50,503 主持人 SPEAKER_02: KurtJayMungle.org。
526 00:43:52,405 --> 00:43:55,771 主持人 SPEAKER_00: 因为它没有，它没有感知世界并形成内部表征。
527 00:43:57,092 --> 00:44:00,077 说话人 SPEAKER_02：智能和理性之间的区别是什么？
528 00:44:02,251 --> 00:44:07,117 说话人 SPEAKER_00：好的，所以有各种各样的智能。
529 00:44:08,318 --> 00:44:12,724 说话人 SPEAKER_00：所以你不会指责一只猫是理性的，但一只猫可能非常聪明。
530 00:44:13,764 --> 00:44:22,155 说话人 SPEAKER_00：特别是，当谈到理性时，你通常指的是逻辑推理。
531 00:44:23,836 --> 00:44:28,663 说话者 SPEAKER_00：这与我们大多数事情的做法非常不同，那就是直观推理。
532 00:44:30,161 --> 00:44:38,797 说话者 SPEAKER_00：所以一个恰当的类比就是，如果你拿像 AlphaZero 这样的下棋程序。
533 00:44:39,219 --> 00:44:41,003 说话者 SPEAKER_00：我选择下棋是因为我比围棋更了解它。
534 00:44:41,724 --> 00:44:47,635 说话者 SPEAKER_00：它将有一种可以评估棋盘位置并说“这对我是多好？”的东西。
535 00:44:47,675 --> 00:44:52,204 说话者 SPEAKER_00：它将有一种能够观察棋盘位置并说出对我来说可能的走法的东西。
536 00:44:53,061 --> 00:45:00,101 说话者 SPEAKER_00：然后它会有所谓的蒙特卡洛走法，你知道的，如果我这样走，他那样走，我再这样走，哎呀，那可不好。
537 00:45:01,123 --> 00:45:05,534 说话者 SPEAKER_00：蒙特卡洛走法就像推理。
538 00:45:06,663 --> 00:45:18,351 说话者 SPEAKER_00：神经网络只是说这将是一个好走法，这是对我不利的局面，我们可以进行推理，我们大多数事情都是通过直觉推理来做的。
539 00:45:20,936 --> 00:45:24,485 说话人 SPEAKER_00: 最初他们想通过使用...来完成一切。
540 00:45:25,715 --> 00:45:27,996 说话人 SPEAKER_00: 推理和逻辑推理。
541 00:45:28,777 --> 00:45:30,858 说话人 SPEAKER_00: 那是一个巨大的错误，他们无法完成任务。
542 00:45:31,320 --> 00:45:33,882 说话人 SPEAKER_00: 他们没有处理类比等问题的方法。
543 00:45:34,922 --> 00:45:38,405 说话人 SPEAKER_00: 嗯，神经网络擅长的是直观推理。
544 00:45:39,146 --> 00:45:47,333 说话人 SPEAKER_00: 所以在过去 20 年里，我们使用神经网络来模拟人类的直觉，而不是推理。
545 00:45:47,833 --> 00:45:49,135 说话人 SPEAKER_00: 并且在这方面我们已经取得了很大的进步。
546 00:45:51,677 --> 00:45:55,300 说话人 SPEAKER_02: 智力越高，道德感就越强，是这样吗？
547 00:45:58,806 --> 00:46:06,635 说话人 SPEAKER_00：我最近读到一些关于这个的信息，但当然我不知道它的来源，所以我不知道该不该相信。
548 00:46:09,778 --> 00:46:11,181 说话人 SPEAKER_00：我不太相信这是真的。
549 00:46:14,423 --> 00:46:15,125 说话人 SPEAKER_00：这里有一些证据。
550 00:46:15,164 --> 00:46:17,047 说话人 SPEAKER_00：埃隆·马斯克显然非常聪明。
551 00:46:17,367 --> 00:46:19,469 说话人 SPEAKER_00: 我不会指责他非常有道德。
552 00:46:21,211 --> 00:46:23,934 说话人 SPEAKER_00: 你可以非常道德，但并不特别聪明吗？
553 00:46:24,474 --> 00:46:25,797 说话人 SPEAKER_00: 我认为是的。
554 00:46:27,858 --> 00:46:28,559 说话人 SPEAKER_00: 这就是我的猜测。
555 00:46:29,148 --> 00:46:33,094 说话人 SPEAKER_02：嗯，你说你并不完全确定，那么相反的证据是什么？
556 00:46:33,414 --> 00:46:42,467 说话人 SPEAKER_02：随着你智力的增加，你的道德是否以某种方式成比例地提高的证据是什么？
557 00:46:42,487 --> 00:46:48,237 说话人 SPEAKER_01：嗯，我的意思是，我根本不知道是否存在相关性。
558 00:46:50,119 --> 00:46:50,420 说话人 SPEAKER_01：我明白了。
559 00:46:55,867 --> 00:46:58,411 说话人 SPEAKER_01: 我认为有一些非常聪明但也很坏的人。
560 00:46:59,454 --> 00:47:01,038 说话人 SPEAKER_01: 而非常聪明的人是非常好的。
561 00:47:03,143 --> 00:47:04,445 说话人 SPEAKER_00: 理解是什么意思？
562 00:47:04,485 --> 00:47:06,550 说话人 SPEAKER_00: 好的。
563 00:47:07,992 --> 00:47:10,998 说话者 SPEAKER_00：这是一个我很乐意回答的问题。
564 00:47:11,018 --> 00:47:16,088 说话者 SPEAKER_00：所以，我认为大多数人对于理解有一个错误的模型。
565 00:47:17,050 --> 00:47:19,876 说话者 SPEAKER_00：嗯，如果你看看这些大型语言模型。
566 00:47:20,954 --> 00:47:27,538 说话者 SPEAKER_00：很多人，尤其是来自乔姆斯基语言学派的人，都说他们并不真正理解他们在说什么。
567 00:47:28,340 --> 00:47:32,938 说话者 SPEAKER_00: 他们只是在用统计相关性来预测下一个单词。
568 00:47:34,606 --> 00:47:46,235 说话者 SPEAKER_00: 如果你看那些早期的模型，我认为我可能是第一个使用反向传播来训练权重以预测下一个单词的语言模型。
569 00:47:47,556 --> 00:47:49,719 说话者 SPEAKER_00: 所以你将预测下一个单词的错误反向传播。
570 00:47:50,840 --> 00:48:03,650 说话者 SPEAKER_00: 模型的目的是展示如何学习单词的意义，或者说，展示如何将一串单词转换为特征向量。
571 00:48:05,014 --> 00:48:09,943 说话者 SPEAKER_00: 特征向量之间的交互，这就是理解。
572 00:48:10,625 --> 00:48:25,130 说话者 SPEAKER_00: 理解一串词语，就是将这些词语转换为特征向量，以便你可以利用特征之间的交互来进行预测下一个词语等操作，也可以做其他事情。
573 00:48:26,112 --> 00:48:29,637 说话者 SPEAKER_00: 所以你有一个句子，它是一串符号，
574 00:48:30,681 --> 00:48:32,083 说话者 SPEAKER_00: 我们不讨论词碎片。
575 00:48:32,525 --> 00:48:36,592 说话人 SPEAKER_00：我知道这些变压器使用词片段，但假设它们使用完整的单词。
576 00:48:36,692 --> 00:48:37,572 说话人 SPEAKER_00：这样讨论起来更容易。
577 00:48:37,672 --> 00:48:40,657 说话人 SPEAKER_00：但这只会让它们的工作稍微差一点，仅此而已。
578 00:48:41,179 --> 00:48:41,920 说话人 SPEAKER_00：但它们仍然会工作。
579 00:48:42,802 --> 00:48:48,431 说话人 SPEAKER_00：我给你一个单词串，一些文本。
580 00:48:50,132 --> 00:48:52,436 说话人 SPEAKER_00：意义不在文本中。
581 00:48:52,940 --> 00:49:06,617 说话人 SPEAKER_00：你所做的是将这些单词转换成特征向量，你已经学会了在上下文中特征向量，特征应该如何相互作用来完成诸如消除歧义单词意义等任务。
582 00:49:08,519 --> 00:49:14,268 说话人 SPEAKER_00：一旦你将特征与这些单词关联起来，那就是理解。
583 00:49:15,088 --> 00:49:16,130 说话人 SPEAKER_00：这就是理解。
584 00:49:16,429 --> 00:49:21,597 说话人 SPEAKER_00：在这一点上，理解在大型语言模型和人类中都是如此。
585 00:49:22,639 --> 00:49:26,483 说话人 SPEAKER_00：从这个意义上讲，我们理解和它们理解的方式基本相同。
586 00:49:27,125 --> 00:49:31,088 说话人 SPEAKER_00：当我们理解时，并不是说有一种神奇的内在于理解的东西。
587 00:49:32,030 --> 00:49:36,916 说话人 SPEAKER_00：我总是试图消除那些神秘的内部因素，以便解释事物是如何运作的。
588 00:49:39,358 --> 00:49:46,867 说话人 SPEAKER_00：利用我们的大神经网络，我们能够将这些符号与特征关联起来，使得所有特征都很好地融合在一起。
589 00:49:48,289 --> 00:49:51,211 说话人 SPEAKER_00：这里有一个我相当喜欢的类比。
590 00:49:52,222 --> 00:50:02,096 说话人 SPEAKER_00：如果你想要模拟 3D 形状，并且不太在意表面是否完全准确，你可以使用乐高积木。
591 00:50:02,235 --> 00:50:03,557 说话人 SPEAKER_00：这些是大形状，就像一辆车。
592 00:50:04,318 --> 00:50:07,824 说话人 SPEAKER_00：你可以用乐高积木制作出和保时捷一样的形状。
593 00:50:11,128 --> 00:50:14,273 说话人 SPEAKER_00：表面可能不会完全正确，但空间占用是一样的。
594 00:50:17,277 --> 00:50:20,641 说话人 SPEAKER_00：所以乐高积木是一种建模 3D 结构的通用方式。
595 00:50:23,119 --> 00:50:25,041 说话人 SPEAKER_00: 你不需要很多不同种类的乐高积木。
596 00:50:25,782 --> 00:50:35,755 说话人 SPEAKER_00: 现在，把单词想象成乐高积木，只不过这里有成堆不同名称的乐高积木。
597 00:50:37,097 --> 00:50:41,581 说话人 SPEAKER_00: 更重要的是，每个乐高积木都有一定的灵活性。
598 00:50:42,563 --> 00:50:45,427 说话人 SPEAKER_00: 它不像乐高积木那样是刚性的形状。
599 00:50:46,166 --> 00:50:50,072 说话人 SPEAKER_00：它可以改变方向。
600 00:50:50,338 --> 00:50:51,541 说话人 SPEAKER_00：它并不完全自由。
601 00:50:51,601 --> 00:50:57,719 说话人 SPEAKER_00：名字告诉你它能如何改变，但也有一些灵活性。
602 00:50:57,980 --> 00:51:03,876 说话人 SPEAKER_00：有时会有一个名字，它可能有两种完全不同的形状，但不能是任何形状。
603 00:51:04,682 --> 00:51:16,059 说话者 说话者_00：嗯，我们发明了一个系统，用于模拟比物质的三维分布更复杂的事物，该系统使用高维乐高积木。
604 00:51:16,079 --> 00:51:18,224 说话者 说话者_00：所以乐高积木将有1000个维度。
605 00:51:19,344 --> 00:51:22,429 说话者 说话者_00：如果你是数学家，你就会知道，1000维的空间是非常奇怪的东西。
606 00:51:23,251 --> 00:51:29,019 说话者 说话者_00：嗯，它们有一些灵活性，我给你一些这些乐高积木的名称。
607 00:51:29,793 --> 00:51:33,998 说话者 SPEAKER_00: 每一个都是这个一千维的底层。
608 00:51:34,018 --> 00:51:39,967 说话者 SPEAKER_00: 它们都变形以完美契合，这就是理解。
609 00:51:41,730 --> 00:51:48,119 说话者 SPEAKER_00: 因此解释了如何从一句话中学习一个词的意义，而不需要任何定义。
610 00:51:48,840 --> 00:51:55,750 说话者 SPEAKER_00: 例如，如果我说，她用平底锅把他打了一顿，你就有一种对 scrummed 的理解。
611 00:51:56,253 --> 00:51:59,559 说话人 SPEAKER_00: 这部分是音标，但结尾的 ed 告诉你它是一个动词。
612 00:52:00,820 --> 00:52:04,067 说话人 SPEAKER_00: 你认为这可能意味着她用这个打他的头或者类似的事情。
613 00:52:04,427 --> 00:52:05,630 说话人 SPEAKER_00: 它可能意味着其他的事情。
614 00:52:06,512 --> 00:52:07,914 说话人 SPEAKER_00: 她可能用这个给他留下了深刻印象。
615 00:52:08,394 --> 00:52:11,000 说话人 SPEAKER_00: 你知道，她做的煎蛋卷太好吃了，这给他留下了深刻印象。
616 00:52:11,039 --> 00:52:12,081 说话人 SPEAKER_00: 这可能意味着她给他留下了深刻印象。
617 00:52:12,382 --> 00:52:16,489 说话人 SPEAKER_00: 但可能的意思是她打了他一下，或者类似的事情，像那样具有攻击性的行为。
618 00:52:17,251 --> 00:52:20,117 说话人 SPEAKER_00: 你只从一句话就能看出这一点。
619 00:52:21,041 --> 00:52:23,565 说话人 SPEAKER_00: 没有人告诉我这是 Scromed 的定义。
620 00:52:23,606 --> 00:52:32,898 说话人 SPEAKER_00: 只不过其他所有乐高积木，比如她、他和其他那些词，都采用了能很好地拼合的形状，留下了一个空隙。
621 00:52:32,938 --> 00:52:36,001 说话人 SPEAKER_00: 那个空隙正是 Scromed 需要的形状。
622 00:52:38,585 --> 00:52:40,548 说话人 SPEAKER_00: 所以现在给出了 Scromed 应该有的形状。
623 00:52:41,710 --> 00:52:43,132 说话者 SPEAKER_00：这就是我对语言的理解。
624 00:52:43,532 --> 00:52:49,581 说话者 SPEAKER_00：这是我们发明的一个建模系统，其中每个模块都有一定的灵活性。
625 00:52:49,780 --> 00:52:53,405 说话者 SPEAKER_00：我给你一堆模块，你得想出如何把它们组合在一起。
626 00:52:54,126 --> 00:53:00,356 说话者 SPEAKER_00：但因为它们都有名字，我可以告诉其他人我的模型是什么。
627 00:53:00,898 --> 00:53:01,719 说话人 SPEAKER_00：我可以给他们提供名字。
628 00:53:02,119 --> 00:53:06,085 说话人 SPEAKER_00：如果他们和我分享足够多的知识，他们就可以弄清楚它们是如何相互关联的。
629 00:53:08,751 --> 00:53:17,103 说话人 SPEAKER_00：那么你是建议，帮助观众理解我们头脑中的理解……我认为这是在大语言模型中发生的事情，它们的工作方式与我们相同。
630 00:53:17,860 --> 00:53:19,782 说话人 SPEAKER_00：这意味着它们真的理解了。
631 00:53:19,822 --> 00:53:27,313 说话者 SPEAKER_02：乔姆斯基对语言模型工作方式相同的反论之一是，我们对理解来说输入是稀疏的。
632 00:53:27,534 --> 00:53:29,356 说话者 SPEAKER_02：我们不必把互联网的信息喂给自己。
633 00:53:29,876 --> 00:53:30,719 说话者 SPEAKER_02：那么你对这个怎么看待？
634 00:53:31,059 --> 00:53:34,443 说话者 SPEAKER_00：确实，语言模型是在大量数据上训练的。
635 00:53:34,925 --> 00:53:37,728 说话人 SPEAKER_00：他们比我们统计效率低。
636 00:53:38,108 --> 00:53:41,875 说话人 SPEAKER_00：然而，当孩子们学习一门语言时，他们并不是仅仅通过收听广播来学习的。
637 00:53:42,375 --> 00:53:46,922 说话人 SPEAKER_00：他们通过在现实世界中与周围事物互动来学习语言。
638 00:53:46,902 --> 00:53:51,728 说话人 SPEAKER_00：如果你训练一个多模态模型，你需要远少得多的输入，它不需要那么多的语言。
639 00:53:52,369 --> 00:53:59,418 说话者 SPEAKER_00：如果你给它一个机械臂和摄像头，并且让它与世界互动，它需要的语言就少多了。
640 00:53:59,438 --> 00:54:00,579 说话者 SPEAKER_00：这是第一个论点。
641 00:54:01,179 --> 00:54:02,742 说话者 SPEAKER_00：它可能还是需要比人更多的东西。
642 00:54:04,965 --> 00:54:06,447 说话者 SPEAKER_00：另一个论点是这样的。
643 00:54:08,771 --> 00:54:22,168 说话人 SPEAKER_00：反向传播训练算法非常擅长将大量知识压缩到很少的权重中，这里的“很少”指的是万亿级别，如果你给它大量的经验。
644 00:54:22,188 --> 00:54:32,460 说话人 SPEAKER_00：所以它擅长从这巨大的经验中提取知识，并将其压缩到相对较少的权重中，比如万亿级别的。
645 00:54:33,543 --> 00:54:35,505 说话人 SPEAKER_00：这不是我们面临的问题。
646 00:54:36,126 --> 00:54:37,449 说话人 SPEAKER_00：我们面临的是相反的问题。
647 00:54:37,630 --> 00:54:41,960 说话人 SPEAKER_00: 我们有大量的权重，比如 100 万亿，但我们只活了两亿秒。
648 00:54:42,521 --> 00:54:44,766 说话人 SPEAKER_00: 因此，我们的经验并不多。
649 00:54:44,786 --> 00:54:50,557 说话人 SPEAKER_00: 所以我们需要优化，以便最大限度地利用你所能获得的非常有限的经验。
650 00:54:51,347 --> 00:54:54,873 说话人 SPEAKER_00: 这意味着我们可能没有使用反向传播。
651 00:54:54,893 --> 00:54:57,860 说话人 SPEAKER_00: 我们可能正在使用其他学习算法。
652 00:54:57,880 --> 00:55:01,987 说话人 SPEAKER_00: 在这个意义上，乔姆斯基可能是对的，我们是基于更少的知识进行学习的。
653 00:55:02,869 --> 00:55:09,440 说话人 SPEAKER_00: 但我们学习的是如何将特征与单词关联起来，以及这些特征应该如何相互作用。
654 00:55:10,737 --> 00:55:13,059 说话人 SPEAKER_02: 我们想继续讨论学习和研究。
655 00:55:13,940 --> 00:55:23,454 说话人 SPEAKER_02：Jay McClellan 说，在与你的研究生和其他研究人员开会时，你通常不会在黑板上写方程式，这与其他机器学习研究会议不同。
656 00:55:23,954 --> 00:55:26,557 说话人 SPEAKER_02：相反，你画图，并且做手势。
657 00:55:27,378 --> 00:55:31,563 说话人 SPEAKER_02：那么这种做法的意义是什么？这种方法的优缺点是什么？
658 00:55:31,543 --> 00:55:35,610 说话人 SPEAKER_00：好的，我认为直观地理解，然后再做数学推导。
659 00:55:37,454 --> 00:55:42,684 有些人认为用方程式思考，然后得出结论，之后才获得直觉。
660 00:55:44,768 --> 00:55:54,666 有些人在这两方面都很擅长，比如 David Mackay 直觉很好，数学也很擅长。
661 00:55:55,844 --> 00:56:03,036 他们只是不同的思维方式，但我一直更擅长从空间角度思考，而不是用方程式。
662 00:56:04,179 --> 00:56:12,233 你能告诉我们你的本科经历吗？你是如何改变专业以及为什么这样做，或者是什么原因让你做出这样的选择？
663 00:56:14,507 --> 00:56:28,556 说话者 说话者_00：这是一个很长的故事，我从剑桥开始学习物理、化学和晶体状态，这本质上就是 X 射线晶体学。
664 00:56:29,297 --> 00:56:32,262 说话者 说话者_00：一个月后，我就厌倦了。
665 00:56:32,242 --> 00:56:35,827 说话者 说话者_00：这是我第一次离家生活，工作太辛苦了。
666 00:56:37,268 --> 00:56:39,612 说话者 说话者_00：所以我辞职了，然后重新申请学习建筑学。
667 00:56:40,592 --> 00:56:45,518 说话者 SPEAKER_00：我回来了，在那之后的一天，我决定我永远不可能擅长建筑。
668 00:56:46,019 --> 00:56:47,842 说话者 SPEAKER_00：所以我回到了科学。
669 00:56:48,262 --> 00:56:54,369 说话者 SPEAKER_00：但我后来学习了物理、化学和生理学，我真的很喜欢生理学。
670 00:56:55,648 --> 00:57:02,139 说话者 SPEAKER_00：在那之后的一年里，我决定我想更多地了解心灵，我认为哲学会教我这些。
671 00:57:03,099 --> 00:57:05,744 说话者 SPEAKER_00：所以我放弃了科学，研究哲学了一年。
672 00:57:07,146 --> 00:57:10,811 说话者 SPEAKER_00：并且我了解了一些关于维特根斯坦及其观点的知识。
673 00:57:12,693 --> 00:57:18,061 说话者 SPEAKER_00：但总的来说，最主要的事情是我对哲学产生了抗体。
674 00:57:19,273 --> 00:57:21,557 说话者 SPEAKER_00：主要是因为它全是空谈。
675 00:57:21,577 --> 00:57:26,465 说话者 SPEAKER_00：他们没有独立判断一个理论是否好的方法。
676 00:57:26,485 --> 00:57:28,690 说话者 SPEAKER_00：他们没有，比如，实验。
677 00:57:29,871 --> 00:57:33,197 说话者 SPEAKER_00：听起来好就是好，这对我不满意。
678 00:57:33,657 --> 00:57:44,556 说话者 SPEAKER_00：所以我学习心理学来了解更多关于心灵的知识，我发现这非常令人烦恼，因为心理学家会提出一个非常愚蠢、简单的理论
679 00:57:44,536 --> 00:57:48,621 说话人 SPEAKER_00: 并进行了非常精心设计的实验来验证这个理论是对是错。
680 00:57:49,702 --> 00:57:53,628 说话人 SPEAKER_00: 在开始之前你就能看出这个理论是毫无希望的，那么实验还有什么意义呢？
681 00:57:55,472 --> 00:57:56,833 说话人 SPEAKER_00: 这就是心理学的大部分内容。
682 00:57:58,376 --> 00:58:05,827 说话人 SPEAKER_00: 然后我进入了人工智能领域，在那里我们进行了计算机模拟，我对此感到非常高兴。
683 00:58:07,309 --> 00:58:11,775 说话人 SPEAKER_02：当你成为教授，直到现在，你是如何选择研究问题的？
684 00:58:14,135 --> 00:58:20,123 说话人 SPEAKER_00：我实在不知道我是怎么做到的。
685 00:58:21,684 --> 00:58:30,876 说话人 SPEAKER_00：这是人们所做最复杂的事情之一，我可以大谈我认为我是如何做到的，但你不必一定相信我。
686 00:58:32,858 --> 00:58:38,927 说话人 SPEAKER_00：我认为我做到的一件事是。
687 00:58:40,644 --> 00:58:43,309 说话人 SPEAKER_00：找一个你认为大家都在做错的地方。
688 00:58:43,369 --> 00:58:45,791 说话人 SPEAKER_00：你只是有一种直觉，认为大家都在做错。
689 00:58:47,554 --> 00:58:50,318 说话人 SPEAKER_00：然后看看你能不能想出更好的方法来做。
690 00:58:50,358 --> 00:59:01,032 说话人 SPEAKER_00：通常你会发现，最终你会明白为什么人们会这样做，而你认为更好的方法其实并不好。
691 00:59:01,733 --> 00:59:03,074 说话人 SPEAKER_00: 但偶尔，
692 00:59:04,320 --> 00:59:15,733 说话人 SPEAKER_00: 嗯，比如如果你认为每个人都试图用逻辑来理解智能，而我们应该使用神经网络，理解智能的核心问题在于神经网络中连接强度的适应。
693 00:59:16,655 --> 00:59:18,918 说话人 SPEAKER_00: 嗯，偶尔你会证明自己是正确的。
694 00:59:19,858 --> 00:59:26,567 说话人 SPEAKER_00: 除非你能看到为什么你的直觉是错误的，而标准的方法是正确的。
695 00:59:26,867 --> 00:59:27,867 说话者 SPEAKER_00: 坚持你的直觉。
696 00:59:28,668 --> 00:59:31,172 说话者 SPEAKER_00: 嗯，这就是你做颠覆性新事物的方式。
697 00:59:31,844 --> 00:59:38,179 说话者 SPEAKER_00: 我有一个我喜欢的论点，那就是，如果你有好的直觉，你应该清楚地坚持你的直觉。
698 00:59:38,862 --> 00:59:43,373 说话者 SPEAKER_00: 如果你没有好的直觉，你做什么其实都无关紧要，所以你不妨坚持你的直觉。
699 00:59:45,242 --> 00:59:58,260 说话者 SPEAKER_02：那么，雷·库兹韦尔的直觉究竟是什么，使得他在 2000 年代初，即使我在跟随他的时候，也觉得其中一半的预测都不可能正确。
700 00:59:58,960 --> 01:00:00,503 说话者 SPEAKER_02：而且一次又一次，他都对了。
701 01:00:00,963 --> 01:00:03,867 说话者 SPEAKER_00：嗯，如果你读过他的书，你就会得出这样的结论。
702 01:00:04,409 --> 01:00:08,313 说话者 SPEAKER_00：我怀疑他说的很多他没有过多提及的事情，其实并不正确。
703 01:00:08,293 --> 01:00:21,001 说话者 SPEAKER_00：但据我所知，他主要说的是计算机正在变得越来越快，而且会继续变快，随着计算机变得越来越快，我们能够做的事情也会越来越多。
704 01:00:21,923 --> 01:00:28,597 说话者 SPEAKER_00：用这个论点来说，他在计算机变得最聪明的人的时间点上大致是正确的。
705 01:00:31,851 --> 01:00:39,523 说话者 SPEAKER_02：你的同事中有哪些预测你认为是正确的，但他们不同意，而你的直觉告诉你你是正确的吗？
706 01:00:39,802 --> 01:00:44,670 说话者 SPEAKER_02：我们已经讨论了 AI 和一致性等问题，但可能没有提到这一点，因为那已经是老生常谈了。
707 01:00:48,916 --> 01:00:57,907 说话人 SPEAKER_00：我认为主要的问题在于主观体验，意识等等，我认为大多数人对于心理状态的理解都是完全错误的。
708 01:00:59,610 --> 01:01:00,811 说话人 SPEAKER_00：这更偏向于哲学。
709 01:01:02,411 --> 01:01:09,400 说话人 SPEAKER_00：在技术方面，我仍然相信快速权重将非常重要。
710 01:01:09,740 --> 01:01:12,384 说话人 SPEAKER_00：所以大脑中的突触可以适应很多不同的时间尺度。
711 01:01:14,266 --> 01:01:16,869 说话人 SPEAKER_00：我们在大多数 AI 模型中不使用它。
712 01:01:17,130 --> 01:01:25,119 说话人 SPEAKER_00：我们不使用它的原因是因为你希望有多个使用完全相同权重的训练案例。
713 01:01:26,442 --> 01:01:30,005 说话人 SPEAKER_00：这样做是为了可以进行矩阵-矩阵乘法，这是高效的。
714 01:01:30,340 --> 01:01:37,610 说话人 SPEAKER_00：如果你有快速适应的权重，那么对于每个训练案例，你都会有不同的权重，因为它们会快速适应。
715 01:01:38,710 --> 01:01:41,815 说话人 SPEAKER_00：我所信仰的是一种在慢速权重上叠加快速权重的方式。
716 01:01:41,855 --> 01:01:46,802 说话人 SPEAKER_00：慢速权重按照常规进行适应，但在此基础上，还有快速权重在迅速适应。
717 01:01:47,342 --> 01:01:53,110 说话人 SPEAKER_00：一旦这样做，就会得到各种美好的额外特性，但在我们当前的计算机上，效率会降低。
718 01:01:53,992 --> 01:01:58,777 说话人 SPEAKER_00：如果我们使用模拟计算机来运行这些事情，那就没问题了。
719 01:02:00,782 --> 01:02:08,382 说话人 SPEAKER_00: 我认为最终我们不得不使用快速权重，因为它们带来各种美好的特性。
720 01:02:09,726 --> 01:02:13,898 说话人 SPEAKER_00: 但这目前是大脑和我们所拥有的硬件之间的一大区别。
721 01:02:17,202 --> 01:02:27,873 说话人 SPEAKER_02: 你还公开提到过，你有点躁郁，你有很长一段时间的极度自我批评，然后又有很长一段时间的极度自信。
722 01:02:28,255 --> 01:02:30,297 说话人 SPEAKER_02: 而这有助于你的创造力。
723 01:02:30,336 --> 01:02:32,438 说话人 SPEAKER_00：短暂的自信。
724 01:02:32,458 --> 01:02:33,340 说话人 SPEAKER_00：好的。
725 01:02:33,360 --> 01:02:34,422 说话人 SPEAKER_00：请讲讲那件事。
726 01:02:35,583 --> 01:02:37,965 说话人 SPEAKER_00：所以当我有一个新想法时，我会非常兴奋。
727 01:02:39,266 --> 01:02:41,128 说话人 SPEAKER_00：我实际上可以衡量我的想法。
728 01:02:41,929 --> 01:02:46,315 说话人 SPEAKER_00：所以有时候我的想法只有一磅重，但有时候我的想法有五磅重。
729 01:02:46,682 --> 01:02:51,753 说话人 SPEAKER_00：所以当我有新想法时，我会非常兴奋，以至于没有时间吃饭。
730 01:02:53,016 --> 01:02:54,057 说话人 SPEAKER_00：所以我的体重下降了。
731 01:02:54,619 --> 01:02:55,119 说话人 SPEAKER_00: 哦，我明白了。
732 01:02:55,159 --> 01:03:00,831 说话人 SPEAKER_00: 所以我可以通过我的体重下降多少来衡量我对这个想法有多兴奋。
733 01:03:01,992 --> 01:03:05,400 说话人 SPEAKER_00: 是的，真正的好想法，我会瘦五磅左右。
734 01:03:07,438 --> 01:03:13,150 说话人 SPEAKER_02: 你有没有感觉到自己肩负着曾曾祖父 Bull 的火炬？
735 01:03:14,351 --> 01:03:15,134 说话人 SPEAKER_00: 不，其实不是。
736 01:03:15,474 --> 01:03:21,405 说话人 SPEAKER_00: 我的意思是，我父亲谈论过这种继承，谈论这个很有趣。
737 01:03:21,425 --> 01:03:25,954 说话人 SPEAKER_00: 我有一种来自父亲的高期望感。
738 01:03:27,237 --> 01:03:29,481 说话人 SPEAKER_00: 这些期望不是来自乔治·巴尔的，而是来自我的父亲。
739 01：03：29,612 --> 01：03：30,994 议长 SPEAKER_02：对自己期望很高？
740 01：03：31,695 --> 01：03：33,599 演讲者 SPEAKER_02：为了我的学业成功，是的。
741 01：03：34,681 --> 01：03：38,666 议长 SPEAKER_01：你心目中是否有一位接班人要把火炬传给他？
742 01：03：38,726 --> 01：03：45,175 议长 SPEAKER_01：不完全是。
743 01:03:45,916 --> 01:03:52,527 说话人 SPEAKER_01: 我认为，我不想把这种想法强加给任何人。
744 01:03:54,771 --> 01:03:56,413 说话人 SPEAKER_01: 你为什么不说“不完全是”，而不是“不是”？
745 01:04:00,038 --> 01:04:05,887 说话人 SPEAKER_01: 嗯，我有几个侄子，他们在数量方面非常出色。
746 01:04:05,907 --> 01:04:06,228 说话人 SPEAKER_01: 我明白了。
747 01:04:07,168 --> 01:04:08,572 说话人 SPEAKER_01: 但你不想给他们施加这种压力。
748 01:04:09,672 --> 01:04:09,873 说话人 SPEAKER_01: 不。
749 01:04:12,338 --> 01:04:18,427 说话人 SPEAKER_02: 说到压力，当你离开谷歌时，你发表了一些关于对 AI 安全的担忧的公开声明。
750 01:04:19,789 --> 01:04:25,077 说话人 SPEAKER_02: 在做出这个决定并向全世界表达你的焦虑方面，最困难的是什么？
751 01:04:27,121 --> 01:04:27,581 说话人 SPEAKER_01: 嗯，
752 01:04:31,476 --> 01:04:32,739 说话人 SPEAKER_01: 我认为并不难。
753 01:04:33,320 --> 01:04:34,260 说话人 SPEAKER_01: 我不会说它难。
754 01:04:36,043 --> 01:04:38,327 说话人 SPEAKER_00: 就是我 75 岁，对吧？
755 01:04:38,708 --> 01:04:46,739 说话者 SPEAKER_00：所以我并不是想留在谷歌继续工作，但我感觉因为人工智能安全的原因我不能这么做。
756 01:04:47,260 --> 01:04:48,902 说话者 SPEAKER_00：我本来也打算退休了。
757 01:04:49,282 --> 01:04:50,905 说话者 SPEAKER_00：我不再擅长做研究了。
758 01:04:51,166 --> 01:04:52,849 说话者 SPEAKER_00：我总是忘记变量代表什么。
759 01:04:53,369 --> 01:04:55,833 说话人 SPEAKER_00: 现在是时候退休了。
760 01:04:55,873 --> 01:04:59,137 说话人 SPEAKER_00: 我以为我只要，
761 01:04:59,590 --> 01:05:00,313 说话人 SPEAKER_00: 走出门去。
762 01:05:00,353 --> 01:05:03,530 说话人 SPEAKER_00: 我可以简单提及 AI 或这些航空安全问题。
763 01:05:03,550 --> 01:05:06,967 说话人 SPEAKER_00：我并没有预料到接下来会发生什么。
764 01:05:08,516 --> 01:05:15,603 说话人 SPEAKER_02：现在，你也在另一次采访中提到过，你现在 75、76 岁，它一直在变化。
765 01:05:15,704 --> 01:05:17,206 说话人 SPEAKER_00：它每年都在变化，对吧？
766 01:05:17,226 --> 01:05:17,646 说话人 SPEAKER_02：77。
767 01:05:17,666 --> 01:05:18,807 说话人 SPEAKER_02: 好的，好吧。
768 01:05:18,827 --> 01:05:27,556 说话人 SPEAKER_02: 你公开提到，是的，你在编程时经常忘记变量名，所以你觉得随着年龄的增长，你可能会转向哲学。
769 01:05:27,577 --> 01:05:29,358 说话人 SPEAKER_00: 这就是我们谈论得很多的话题。
770 01:05:29,378 --> 01:05:29,659 说话人 SPEAKER_00: 是的，是的。
771 01:05:29,978 --> 01:05:35,605 说话人 SPEAKER_00: 但这基本上是我 20 岁左右做哲学时所做的哲学。
772 01:05:36,411 --> 01:05:40,684 说话人 SPEAKER_00: 我正在回顾我做哲学时获得的见解，并进一步探索它们。
773 01:05:40,905 --> 01:05:41,206 说话人 SPEAKER_01: 明白了。
774 01:05:46,099 --> 01:05:47,063 说话人 SPEAKER_01: 那么未来有什么计划？
775 01:05:49,539 --> 01:05:59,771 说话人 SPEAKER_00: 我认为世界将会因为人工智能而迅速改变很多。
776 01:06:00,891 --> 01:06:03,554 说话人 SPEAKER_00: 其中一些会非常好，而有一些会非常糟糕。
777 01:06:03,614 --> 01:06:10,762 说话人 SPEAKER_00: 我们需要尽我们所能来减轻不良后果。
778 01:06:10,802 --> 01:06:12,644 说话人 SPEAKER_00: 我认为
779 01:06:12,625 --> 01:06:18,929 说话人 SPEAKER_00：我还能做的有用的事情就是鼓励年轻研究人员关注安全问题。
780 01:06:19,793 --> 01:06:21,639 说话人 SPEAKER_00：所以这是我一直在做的事情。
781 01:06:23,442 --> 01:06:26,045 说话人 SPEAKER_02：安全和其中有一个叫做对齐的东西。
782 01:06:26,465 --> 01:06:28,168 说话人 SPEAKER_02：现在我们作为人类并没有对齐。
783 01:06:28,447 --> 01:06:31,331 说话人 SPEAKER_02：你看我们能否解决对齐问题吗？
784 01:06:32,293 --> 01:06:34,074 说话人 SPEAKER_00：我有点同意这个说法。
785 01:06:34,815 --> 01:06:39,101 说话人 SPEAKER_00：对齐就像让你找到一条与两条垂直线平行的线。
786 01:06:41,364 --> 01:06:41,585 说话人 SPEAKER_00：是的。
787 01:06:42,525 --> 01:06:48,653 说话人 SPEAKER_00：很多人对对齐问题谈论得很天真，好像人类有某种善良一样。
788 01:06:48,853 --> 01:06:49,855 说话人 SPEAKER_00：嗯，
789 01:06:49,835 --> 01:06:52,318 说话人 SPEAKER_00：有些人认为好的，其他人认为不好。
790 01:06:52,378 --> 01:06:54,219 说话人 SPEAKER_00：你在中东经常能看到这种情况。
791 01:06:57,242 --> 01:07:00,085 说话人 SPEAKER_01：所以对齐是一个非常棘手的问题。
792 01:07:01,907 --> 01:07:02,807 说话人 SPEAKER_02：与谁对齐？
793 01:07:02,827 --> 01:07:08,793 说话人 SPEAKER_02：现在你刚刚在跟年轻的 AI 研究人员说话。
794 01:07:08,954 --> 01:07:16,882 说话人 SPEAKER_02：现在你是在跟年轻的数学研究人员、年轻的哲学家、即将进入任何新的 STEM 领域的年轻学生说话，尽管哲学不是 STEM 领域。
795 01:07:18,364 --> 01:07:19,284 说话人 SPEAKER_02: 你的建议是什么？
796 01:07:20,885 --> 01:07:31,324 说话人 SPEAKER_00: 嗯，我的建议是，现在科学研究的兴奋点主要集中在神经网络，现在被称为人工智能。
797 01:07:32,125 --> 01:07:41,222 说话人 SPEAKER_00: 事实上，物理学家现在甚至想要说那是物理学。
798 01:07:41,775 --> 01:07:48,030 说话人 SPEAKER_02: 谁因为神经网络工作获得了诺贝尔物理学奖？
799 01:07:49,153 --> 01:07:49,855 说话人 SPEAKER_02：你记得吗？
800 01:07:50,356 --> 01:07:51,980 说话人 SPEAKER_02：我不记得，但是无论如何，继续吧。
801 01:07:52,742 --> 01:07:53,324 说话人 SPEAKER_02：你认真的吗？
802 01:07:53,384 --> 01:07:54,346 说话人 SPEAKER_02：不，我在开玩笑。
803 01:07:56,291 --> 01:07:57,112 说话人 SPEAKER_00: 好吧，我以为你在开玩笑。
804 01:07:57,132 --> 01:08:00,239 说话人 SPEAKER_00: 我是个好演员，对吧？
805 01:08:02,818 --> 01:08:09,311 说话人 SPEAKER_00: 所以，很明显，诺贝尔委员会认识到科学界现在的大部分兴奋点都在人工智能上。
806 01:08:10,052 --> 01:08:18,567 说话人 SPEAKER_00: 因此，无论是物理学还是化学，诺贝尔奖都授予了从事人工智能或使用人工智能的人。
807 01:08:20,520 --> 01:08:24,926 说话人 SPEAKER_00：所以我想给年轻研究者的建议是，那里有很多令人兴奋的地方。
808 01:08:25,728 --> 01:08:37,662 说话人 SPEAKER_00：但我认为还有其他领域将会取得非常重要的进展，比如如果我们能研制出室温超导体，那将使得在远离太阳能的地方使用太阳能变得容易，诸如此类的事情。
809 01:08:37,722 --> 01:08:40,926 说话人 SPEAKER_00：所以这并不是唯一令人兴奋的领域。
810 01:08:40,966 --> 01:08:46,073 说话人 SPEAKER_00：纳米材料非常令人兴奋，但它们将使用人工智能。
811 01:08:46,052 --> 01:08:52,141 说话人 SPEAKER_00: 我认为科学中最激动人心的领域至少会使用 AI 工具。
812 01:08:54,404 --> 01:08:55,546 说话人 SPEAKER_02: 现在我们已经提到了这一点。
813 01:08:55,606 --> 01:08:57,069 说话人 SPEAKER_02: 现在我们明确地引用一下。
814 01:08:57,088 --> 01:09:02,557 说话人 SPEAKER_02: 你去年因在 AI 和神经网络方面的工作获得了诺贝尔物理学奖。
815 01:09:02,757 --> 01:09:02,997 说话人 SPEAKER_02: 对。
816 01:09:03,698 --> 01:09:04,279 说话人 SPEAKER_02: 你感觉怎么样？
817 01:09:04,319 --> 01:09:05,641 说话人 SPEAKER_02: 你对此感觉如何？
818 01:09:06,122 --> 01:09:07,744 说话人 SPEAKER_02: 听到这个消息是什么感觉？
819 01:09:07,845 --> 01:09:10,448 说话人 SPEAKER_02：在物理学方面，你认为自己是一位物理学家吗？
820 01:09:10,649 --> 01:09:12,212 说话人 SPEAKER_02：这是什么意思？
821 01:09:12,310 --> 01:09:13,591 说话人 SPEAKER_00：不，我不是物理学家。
822 01:09:14,273 --> 01:09:17,356 说话人 SPEAKER_00：我在大学一年级学习物理时，物理学得相当不错。
823 01:09:17,377 --> 01:09:24,065 说话人 SPEAKER_00：我凭借直觉在物理方面取得了第一名，但我的数学从来都不擅长。
824 01:09:24,847 --> 01:09:27,011 说话人 SPEAKER_00：我放弃物理是因为我的数学不够好。
825 01:09:28,112 --> 01:09:31,516 说话人 SPEAKER_00：我想，如果我在数学上更好一些，我就会留在物理领域，也就不会获得诺贝尔奖了。
826 01:09:34,020 --> 01:09:37,305 说话人 SPEAKER_00：所以可能是因为我不擅长数学，这反而是个幸运的事。
827 01:09:39,208 --> 01:09:40,153 说话人 SPEAKER_00：我对它有什么感觉？
828 01:09:40,172 --> 01:09:41,961 说话人 SPEAKER_00：我对此仍然有些困惑。
829 01:09:42,564 --> 01:09:48,510 说话人 SPEAKER_00：主要问题是我所做的与神经网络相关的工作与物理学紧密相连。
830 01:09:48,658 --> 01:09:52,505 说话人 SPEAKER_00：这是一种学习算法，名为玻尔兹曼机，是我和特里·桑诺夫斯基共同开发的。
831 01:09:53,707 --> 01:09:59,135 说话人 SPEAKER_00：它巧妙地使用了统计物理学。
832 01:10:00,277 --> 01:10:02,239 说话人 SPEAKER_00：所以我明白为什么物理学会这样宣称。
833 01:10:03,201 --> 01:10:06,886 说话人 SPEAKER_00：但这并不是当前成功人工智能系统的路径。
834 01:10:06,947 --> 01:10:15,779 说话人 SPEAKER_00：这是一个不同的算法，我也参与其中，称为反向传播，它催生了这个庞大的新人工智能产业。
835 01:10:15,760 --> 01:10:22,328 说话人 SPEAKER_00：我还是觉得有点尴尬，因为我们因为玻尔兹曼机而获奖，但实际上并不是玻尔兹曼机。
836 01:10:23,430 --> 01:10:26,793 说话人 SPEAKER_00：它们很有帮助，但它们并不是真正成功的东西。
837 01:10:29,077 --> 01:10:30,838 说话人 SPEAKER_02：教授，很高兴能和您交流。
838 01:10:31,180 --> 01:10:31,460 说话人 SPEAKER_02：好的。
839 01:10:31,779 --> 01:10:35,324 主持人 SPEAKER_02: 感谢您邀请我进入您的家，并有机会见到您的猫咪。
840 01:10:35,784 --> 01:10:36,747 主持人 SPEAKER_00: 好的。
841 01:10:36,766 --> 01:10:37,127 主持人 SPEAKER_02: 感谢。
842 01:10:39,335 --> 01:10:40,235 主持人 SPEAKER_02: 新更新！
843 01:10:40,556 --> 01:10:41,899 说话人 SPEAKER_02: 开始了一个子堆栈。
844 01:10:41,918 --> 01:10:47,426 说话人 SPEAKER_02: 上面写的关于语言和未定义概念的文章，还有一些其他数学细节。
845 01:10:47,828 --> 01:10:49,210 说话人 SPEAKER_02: 那里正在写更多内容。
846 01:10:49,610 --> 01:10:51,613 说话人 SPEAKER_02: 这是其他地方没有的内容。
847 01:10:51,634 --> 01:10:54,117 说话人 SPEAKER_02：它不在《万物理论》中，也不在 Patreon 上。
848 01:10:54,457 --> 01:10:57,882 说话人 SPEAKER_02：此外，将来某个时候，那里也会放置完整的转录文本。
849 01:10:57,863 --> 01:11:05,011 说话人 SPEAKER_02：很多人问我，嘿，库尔特，你与理论物理学、哲学和意识领域的许多人交谈过。
850 01:11:05,412 --> 01:11:06,153 说话人 SPEAKER_02：你有什么看法？
851 01:11:06,854 --> 01:11:13,743 说话人 SPEAKER_02：在采访中我保持公正，但这个子堆栈是我对这些主题当前思考的一种方式。
852 01:11:15,425 --> 01:11:18,588 说话人 SPEAKER_02：还要感谢我们的合作伙伴，《经济学人》。
853 01:11:20,846 --> 01:11:22,609 说话人 SPEAKER_02：首先，感谢观看。
854 01:11:22,670 --> 01:11:23,471 说话人 SPEAKER_02：感谢收听。
855 01:11:23,813 --> 01:11:28,440 说话人 SPEAKER_02：如果您还没有订阅或点击那个点赞按钮，现在就是时候了。
856 01:11:28,841 --> 01:11:29,143 说话人 SPEAKER_02：为什么？
857 01:11:29,182 --> 01:11:35,595 说话人 SPEAKER_02：因为每个订阅，每个点赞，都能帮助 YouTube 将这个内容推送给更多的人，就像您这样的人。
858 01:11:35,935 --> 01:11:39,362 说话人 SPEAKER_02：此外，这也直接帮助了我，也就是 Kurt。
去年我还发现，外部链接对算法有很大影响，这意味着每次你在 Twitter、Facebook 上分享，甚至在 Reddit 上，等等，YouTube 都会看到，嘿，人们正在 YouTube 之外讨论这个内容，这反过来又极大地帮助了 YouTube 上的分发。
第三，有一个非常活跃的“万物理论”Discord 和 subreddit，人们在这里解释 toes，他们尊重地就理论进行讨论，并作为一个社区共同构建我们的 toe。
861 01：12：08,104 --> 01：12：09,666 演讲者 SPEAKER_02：两者的链接都在描述中。
第四点，你应该知道这个播客在 iTunes 上，它在 Spotify 上，它在所有音频平台上。
863 01:12:16,536 --> 01:12:19,359 说话人 SPEAKER_02：你只需要输入“万物理论”，就能找到它。
864 01:12:19,600 --> 01:12:22,545 说话人 SPEAKER_02：我个人通过重新观看讲座和播客来获得收获。
865 01:12:22,524 --> 01:12:26,689 说话人 SPEAKER_02：我也在评论中看到，嘿，重复收听的人也能从中受益。
866 01:12:26,849 --> 01:12:33,574 说话人 SPEAKER_02：那么，你可以在像 iTunes、Spotify、Google Podcasts 这样的平台上重新收听，无论你使用哪个播客接收器。
867 01:12:33,875 --> 01:12:44,003 说话人 SPEAKER_02: 最后，如果您想支持更多这样的对话，更多这样的内容，那么请考虑访问 patreon.com slash KurtJMungle，并用您喜欢的任何金额进行捐赠。
868 01:12:44,265 --> 01:12:45,326 说话人 SPEAKER_02: 还有 PayPal。
869 01:12:45,525 --> 01:12:46,567 说话人 SPEAKER_02: 还有加密货币。
870 01:12:46,766 --> 01:12:48,448 说话人 SPEAKER_02: 还可以加入 YouTube。
871 01:12:48,748 --> 01:12:52,532 说话人 SPEAKER_02：再次提醒，这是赞助商和您的支持。
872 01:12:52,511 --> 01:12:54,756 说话人 SPEAKER_02：这使我能够全职从事 Toe 工作。
873 01:12:55,016 --> 01:12:58,963 说话人 SPEAKER_02：您还可以提前访问无广告的剧集，无论是音频还是视频。
874 01:12:59,083 --> 01:13:01,548 说话人 SPEAKER_02：在 Patreon 的情况下是音频，在 YouTube 的情况下是视频。
875 01:13:01,668 --> 01:13:05,676 说话人 SPEAKER_02: 例如，你现在正在收听的这一集是在几天前发布的。
876 01:13:06,216 --> 01:13:08,561 说话人 SPEAKER_02: 每一美元的帮助都比你想象的要多。
877 01:13:08,981 --> 01:13:11,407 说话人 SPEAKER_02: 无论怎样，你的观看就是足够的慷慨。
878 01:13:11,707 --> 01:13:12,529 说话人 SPEAKER_01: 非常感谢你。
