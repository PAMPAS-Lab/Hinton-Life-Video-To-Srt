1
00:00:00,031 --> 00:00:01,653
发言人 SPEAKER_01：现在加入我们讨论杰弗里·辛顿的是杰弗里本人。

2
00:00:02,213 --> 00:00:03,234
发言人 SPEAKER_01：杰弗里，非常感谢你加入我们。

3
00:00:03,254 --> 00:00:08,080
发言人 SPEAKER_01：你离开了谷歌的工作，部分原因是你表示希望专注于你对AI的担忧。

4
00:00:08,259 --> 00:00:14,207
发言人 SPEAKER_01：你曾公开表示，AI可能会操纵甚至找到方法杀死人类。

5
00:00:14,807 --> 00:00:15,948
发言人 SPEAKER_01：它如何能杀死人类？

6
00:00:18,812 --> 00:00:25,600
发言人 SPEAKER_00：最终，如果它变得比我们聪明得多，它将非常擅长操纵，因为它会从我们这里学到这一点。

7
00:00:25,968 --> 00:00:31,775
发言人 SPEAKER_00：而且，很少有更聪明的东西被不那么聪明的东西控制的例子。

8
00:00:32,356 --> 00:00:37,384
发言人 SPEAKER_00：它知道如何编程，所以它会找到绕过我们设置的限制的方法。

9
00:00:37,625 --> 00:00:40,268
发言人 SPEAKER_00：它会找到操纵人们去做它想做的事情的方法。

10
00:00:41,310 --> 00:00:41,990
发言人 SPEAKER_01：那我们该怎么办？

11
00:00:42,051 --> 00:00:43,753
发言人 SPEAKER_01：我们现在需要拔掉插头吗？

12
00:00:43,793 --> 00:00:49,823
发言人 SPEAKER_01：我们需要设置更多的限制和安全措施吗？

13
00:00:50,262 --> 00:00:51,384
发言人 SPEAKER_01：我们如何解决这个问题？

14
00:00:53,490 --> 00:00:56,094
发言人 SPEAKER_00：我不确定我们能否解决这个问题。

15
00:00:57,476 --> 00:01:00,883
发言人 SPEAKER_00：我认为我们应该投入大量精力思考如何解决这个问题。

16
00:01:01,584 --> 00:01:03,146
发言人 SPEAKER_00：目前我没有解决方案。

17
00:01:03,246 --> 00:01:09,176
发言人 SPEAKER_00：我只是希望人们意识到这是一个非常严重的问题，我们需要认真思考它。

18
00:01:09,576 --> 00:01:11,198
发言人 SPEAKER_00：我认为我们无法阻止进步。

19
00:01:11,680 --> 00:01:17,689
发言人 SPEAKER_00：我没有签署那份要求停止AI工作的请愿书，因为如果美国人停止，中国人不会停止。

20
00:01:18,290 --> 00:01:20,493
发言人 SPEAKER_00：很难验证人们是否在这样做。

21
00:01:21,301 --> 00:01:25,286
发言人 SPEAKER_01：过去几年有一些举报者一直在警告AI的危险。

22
00:01:25,406 --> 00:01:29,471
发言人 SPEAKER_01：其中一位是蒂姆尼·格布鲁，他因表达担忧而被谷歌解雇。

23
00:01:30,191 --> 00:01:33,596
发言人 SPEAKER_01：回顾过去，你是否希望自己当时能更多地支持这些举报者？

24
00:01:35,879 --> 00:01:37,200
发言人 SPEAKER_00：蒂姆尼其实是个女性。

25
00:01:38,141 --> 00:01:38,902
发言人 SPEAKER_00：哦，抱歉。

26
00:01:39,423 --> 00:01:39,763
发言人 SPEAKER_00：所以。

27
00:01:40,885 --> 00:01:43,046
发言人 SPEAKER_00：他们的担忧与我的不同。

28
00:01:43,768 --> 00:01:49,614
发言人 SPEAKER_00：我认为如果你先离开公司，表达担忧会更容易。

29
00:01:49,635 --> 00:01:50,075
发言人 SPEAKER_00：而且。

30
00:01:51,507 --> 00:01:57,182
发言人 SPEAKER_00：他们的担忧并不像这些AI变得比我们更聪明并接管世界那样具有存在性威胁。

31
00:01:58,786 --> 00:02:05,263
发言人 SPEAKER_01：苹果联合创始人史蒂夫·沃兹尼亚克也在谈论他担心的AI带来的危险，听听他的看法。

32
00:02:07,370 --> 00:02:08,110
发言人 SPEAKER_02：现在AI。

33
00:02:08,131 --> 00:02:15,143
发言人 SPEAKER_02：是另一种更强大的工具，它将被那些你知道的人用于基本上非常邪恶的目的。

34
00:02:15,502 --> 00:02:18,187
发言人 SPEAKER_02：我讨厌看到技术被这样使用。

35
00:02:18,487 --> 00:02:19,188
发言人 SPEAKER_02：它不应该被这样使用。

36
00:02:19,669 --> 00:02:23,156
发言人 SPEAKER_02：可能需要一些类型的监管。

37
00:02:24,198 --> 00:02:25,278
发言人 SPEAKER_01：听起来你同意。

38
00:02:26,701 --> 00:02:28,264
发言人 SPEAKER_01：我同意这一点。

39
00:02:28,283 --> 00:02:28,585
发言人 SPEAKER_01：是的。

40
00:02:28,625 --> 00:02:30,508
发言人 SPEAKER_01：这种监管应该是什么样子？

41
00:02:32,681 --> 00:02:34,805
发言人 SPEAKER_00：我不是监管方面的专家。

42
00:02:34,844 --> 00:02:39,110
发言人 SPEAKER_00：我只是一个科学家，突然意识到这些东西正在变得比我们更聪明。

43
00:02:39,931 --> 00:02:47,502
发言人 SPEAKER_00：我想吹响警笛，说我们应该认真思考如何阻止这些东西控制我们。

44
00:02:48,243 --> 00:02:50,165
发言人 SPEAKER_00：这将非常困难。

45
00:02:50,467 --> 00:02:51,627
发言人 SPEAKER_00：我没有解决方案。

46
00:02:51,669 --> 00:02:52,750
发言人 SPEAKER_00：我希望我有。

47
00:02:52,882 --> 00:02:58,316
发言人 SPEAKER_01：是否需要所有科技公司和政府就此召开会议？

48
00:02:58,817 --> 00:03:03,789
发言人 SPEAKER_01：谷歌、中国等，制定一些规则。

49
00:03:04,170 --> 00:03:08,342
发言人 SPEAKER_01：我们如何防止不良行为者或流氓国家利用AI？

50
00:03:10,093 --> 00:03:18,971
发言人 SPEAKER_00：对于某些事情来说，这非常困难，比如他们使用AI操纵选民或用机器人士兵打仗。

51
00:03:19,792 --> 00:03:23,939
发言人 SPEAKER_00：但对于AI接管世界的存在性威胁，我们都在同一条船上。

52
00:03:24,381 --> 00:03:25,302
发言人 SPEAKER_00：这对我们所有人都不利。

53
00:03:25,783 --> 00:03:29,030
发言人 SPEAKER_00：所以我们可能能够让中国和美国就此类问题达成一致。

54
00:03:29,491 --> 00:03:31,174
发言人 SPEAKER_00：这就像核武器。

55
00:03:31,153 --> 00:03:33,257
发言人 SPEAKER_00：如果发生核战争，我们都会输。

56
00:03:34,078 --> 00:03:35,979
发言人 SPEAKER_00：如果这些东西接管世界，情况也是一样。

57
00:03:36,501 --> 00:03:41,867
发言人 SPEAKER_00：既然我们都在同一条船上，我们应该能够在中国和美国之间达成一致。

58
00:03:41,888 --> 00:03:45,431
发言人 SPEAKER_01：你认为科技公司会是解决方案吗？

59
00:03:45,492 --> 00:03:50,558
发言人 SPEAKER_01：还是说他们在财务上投入太多？

60
00:03:50,598 --> 00:03:57,448
发言人 SPEAKER_01：而且，坦白说，在权力方面，他们不会成为解决方案的一部分？

61
00:03:59,251 --> 00:04:04,408
发言人 SPEAKER_00：我认为科技公司是最有可能知道如何控制这些东西的人。

62
00:04:06,415 --> 00:04:07,599
发言人 SPEAKER_01：杰弗里·辛顿，非常感谢你。

63
00:04:07,659 --> 00:04:07,980
发言人 SPEAKER_01：请再回来。

64
00:04:08,001 --> 00:04:10,509
发言人 SPEAKER_01：我们还有更多问题要问你，感谢你的坦诚。
