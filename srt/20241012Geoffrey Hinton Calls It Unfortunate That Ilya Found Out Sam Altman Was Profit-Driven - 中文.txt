1 00:00:00,031 --> 00:00:12,083 主持人 SPEAKER_01：我们接下来有来自美联社的 Matt O'Brien 的问题，他想请问 Hinton 教授，您能否在电话中更详细地解释一下您对 Sam Altman 的评论？
2 00:00:13,846 --> 00:00:18,530 主持人 SPEAKER_00：所以 OpenAI 的成立非常重视安全性。
3 00:00:20,053 --> 00:00:25,178 主持人 SPEAKER_00：它的主要目标是开发通用人工智能，并确保其安全性。
4 00:00:26,524 --> 00:00:31,634 主持人 SPEAKER_00：我的一位前学生，Ilya Sutskova，曾是首席科学家。
5 00:00:32,595 --> 00:00:41,451 说话人 SPEAKER_00: 随着时间推移，结果发现萨姆·奥特曼对安全的关注远不如对利润的关注。
6 00:00:42,593 --> 00:00:45,478 说话人 SPEAKER_00: 我认为这是不幸的。
7 00:00:48,917 --> 00:00:49,399 说话人 SPEAKER_01: 谢谢。
8 00:00:49,459 --> 00:00:53,203 说话人 SPEAKER_01: 下一个问题来自 PA 媒体的杰西卡·科茨。
9 00:00:53,243 --> 00:00:56,426 说话人 SPEAKER_01：这又是一个问题，是问给 Hinton 教授的。
10 00:00:57,027 --> 00:01:05,736 说话人 SPEAKER_01：她问，你提到了围绕人工智能的不确定未来以及对其潜在机遇和风险的更深入了解的需求。
11 00:01:06,378 --> 00:01:10,862 说话人 SPEAKER_01：你认为政府是否会更加严格地介入监管人工智能吗？
12 00:01:10,903 --> 00:01:14,486 说话人 SPEAKER_01：政府如何更好地支持人工智能研究？
13 00:01:15,783 --> 00:01:22,942 说话人 SPEAKER_00: 我认为政府可以鼓励大公司更多地投入资源进行安全研究。
14 00:01:23,284 --> 00:01:30,805 说话人 SPEAKER_00: 目前，几乎所有资源都投入到使模型变得更好，以便它们可以拥有闪亮的新模型。
15 00:01:30,784 --> 00:01:39,924 说话人 SPEAKER_00: 正在进行一场激烈的竞争，模型也在变得越来越好，这是好事，但我们还需要在 AI 安全方面付出相当的努力。
16 00:01:40,286 --> 00:01:41,728 说话人 SPEAKER_00: 这种努力需要超过 1%。
17 00:01:41,989 --> 00:01:49,587 说话人 SPEAKER_00：可能需要将三分之一的努力投入到 AI 安全上，因为如果这些东西变得不安全，那就非常糟糕。
18 00:01:53,784 --> 00:01:57,968 说话人 SPEAKER_01：我们的下一个问题是来自 Tara Deschamps，来自 CP。
19 00:01:58,429 --> 00:02:03,855 说话人 SPEAKER_01：她问 Hinton 教授，对于诺贝尔奖带来的资金有什么计划吗？
20 00:02:05,775 --> 00:02:06,858 说话人 SPEAKER_00：没有具体的计划。
21 00:02:06,957 --> 00:02:08,639 说话人 SPEAKER_00: 我打算把它捐给慈善机构。
22 00:02:09,780 --> 00:02:18,408 说话人 SPEAKER_00: 但我知道一个慈善机构，我会捐一些钱给它，它为神经多样性年轻人提供工作。
23 00:02:20,330 --> 00:02:23,032 说话人 SPEAKER_00: 我还会捐给其他一些慈善机构，但我还不知道是哪些。
24 00:02:24,497 --> 00:02:29,014 说话人 SPEAKER_01: 他们和《读卖新闻》报在一起。
25 00:02:29,054 --> 00:02:33,850 说话人 SPEAKER_01：他们问，AI 何时能超越人类的能力？
26 00:02:34,332 --> 00:02:36,280 说话人 SPEAKER_01：这会导致什么结果？
27 00:02:37,323 --> 00:02:42,210 说话人 SPEAKER_00：所以没有人知道具体何时，但我认识的多数优秀研究人员都认为这会发生。
28 00:02:43,352 --> 00:02:47,437 说话人 SPEAKER_00：我的猜测是，这可能会在 5 到 20 年之间发生。
29 00:02:47,837 --> 00:02:48,598 说话人 说话人_00: 可能会更长。
30 00:02:48,639 --> 00:02:50,942 说话人 说话人_00: 有非常小的可能性会更快。
31 00:02:50,981 --> 00:02:55,669 说话人 说话人_00: 我们不知道那时会发生什么。
32 00:02:55,649 --> 00:03:07,514 说话人 说话人_00: 所以如果你环顾四周，很少有更智能的事物被不那么智能的事物所控制，这让你不禁要思考，当 AI 比我们更智能时，它是否会接管控制权。
33 00:03:07,967 --> 00:03:10,812 说话人 SPEAKER_01：我们的下一个问题是来自 Victoria Gibson 的。
34 00:03:10,891 --> 00:03:14,637 说话人 SPEAKER_01：再次，她是多伦多星报的记者，这是给 Hinton 教授的问题。
35 00:03:15,237 --> 00:03:23,750 说话人 SPEAKER_01：她问，你提供了一些关于 AI 可能出错的特定例子，比如网络攻击、虚假视频等。
36 00:03:24,350 --> 00:03:29,538 说话人 SPEAKER_01：你能分享一些你认为 AI 可以发挥积极作用的更具体的例子吗？
37 00:03:31,039 --> 00:03:31,479 说话人 说话人_00: 哦，是的。
38 00:03:31,901 --> 00:03:34,784 所以如果你考虑像医疗保健这样的领域，
39 00:03:35,322 --> 00:03:39,425 安大略省预算的大部分都用于医疗保健。
40 00:03:40,435 --> 00:03:42,537 它可以在那里产生巨大的影响。
41 00:03:43,418 --> 00:03:50,905 说话人 SPEAKER_00：我实际上在 2016 年做出过一个预测，那就是到如今，人工智能将能够阅读放射科医生通常阅读的所有扫描。
42 00:03:51,485 --> 00:03:52,826 说话人 SPEAKER_00：那个预测是错误的。
43 00:03:52,866 --> 00:03:54,389 说话人 SPEAKER_00：我有点过于乐观了。
44 00:03:54,848 --> 00:03:58,293 说话人 SPEAKER_00：可能还需要再过五年才会实现，但我们显然正在朝着这个方向前进。
45 00:03:59,092 --> 00:04:02,817 说话人 说话人_00: 人工智能在诊断方面将会更加出色。
46 00:04:03,016 --> 00:04:09,783 说话人 说话人_00: 对于诊断难度较大的病例，医生的正确率已经达到40%。
47 00:04:09,764 --> 00:04:19,879 说话人 说话人_00: 医生，人工智能系统的正确率为50%，医生与人工智能系统的组合正确率可达60%，这是一个很大的提升。
48 00:04:20,439 --> 00:04:24,766 说话人 说话人_00: 在北美，每年有数十万人因诊断错误而死亡。
49 00:04:25,127 --> 00:04:27,891 说话人 SPEAKER_00：随着人工智能的发展，诊断将变得更加准确。
50 00:04:28,377 --> 00:04:48,985 说话人 SPEAKER_00：真正会发生的事情是，你将能够拥有一个 AI 家庭医生，这位医生看过一亿名患者，拥有大量知识，并且能够更好地处理你遇到的任何疾病，因为你的 AI 家庭医生已经见过许多类似的病例。
51 00:04:52,423 --> 00:04:54,387 说话人 SPEAKER_01：谢谢，Hinton 教授。
52 00:04:55,148 --> 00:05:01,798 说话人 SPEAKER_01：现在没有其他问题了，但再次提醒，我们还有时间再回答一两个问题。
53 00:05:01,819 --> 00:05:17,384 主持人：所以如果通话中有任何人在此提出其他问题，我们再次邀请您在屏幕底部的问答框中输入您的姓名和您所代表的媒体，并打出这些问题。
54 00:05:17,365 --> 00:05:36,521 主持人：在我们等待最后几分钟的问题到来之前，Hinton 教授，我们很好奇，今天在新闻发布会上，有没有什么我们没有涉及到的您想提到的内容，或者有没有什么我们在各种媒体提问中遗漏了的问题？
55 00:05:37,581 --> 00:05:43,906 主持人：我们只简要提到了一点，那就是好奇心驱动的硏究。
56 00:05:44,528 --> 00:05:54,797 主持人：所以人工神经网络的基础工作，都是由大学硏究人员完成的，几乎全部是由大学硏究人员完成的，他们只是遵循自己的好奇心。
57 00:05:55,557 --> 00:05:58,100 说话人 SPEAKER_00: 为这种研究提供资金非常重要。
58 00:05:58,600 --> 00:06:07,588 说话人 SPEAKER_00: 它不像其他类型的研究那样昂贵，但为后来非常昂贵且涉及大量技术的项目奠定了基础。