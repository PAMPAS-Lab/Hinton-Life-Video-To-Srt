1
00:00:23,182 --> 00:00:25,768
发言人 SPEAKER_00：我首先询问了他关于深度求索（DeepSeek）的看法。

2
00:00:26,129 --> 00:00:31,823
发言人 SPEAKER_00：这是否进一步证明了他认为人工智能正在不断加速发展的观点？

3
00:00:32,183 --> 00:00:37,335
发言人 SPEAKER_01：这表明在提升AI效率和进一步开发方面，进展仍然非常迅速。

4
00:00:38,539 --> 00:00:39,841
发言人 SPEAKER_01：我认为

5
00:00:39,822 --> 00:00:48,865
发言人 SPEAKER_01：关于DeepSeek相对于OpenAI和Gemini等项目的规模或成本的比较，有些被夸大了。

6
00:00:49,567 --> 00:00:54,962
发言人 SPEAKER_01：他们提到的570万美元训练成本只是最终训练阶段的费用。

7
00:00:54,942 --> 00:01:01,210
发言人 SPEAKER_01：如果与OpenAI的项目相比，他们的最终训练阶段可能只需花费约1亿美元左右。

8
00:01:01,670 --> 00:01:04,655
发言人 SPEAKER_01：所以并不是570万与数十亿美元的差距。

9
00:01:04,915 --> 00:01:17,191
发言人 SPEAKER_00：当你提到AI可能接管世界时，目前它看起来还是一个相对无害的设备，可以让我们更快地提问和获取答案。

10
00:01:17,691 --> 00:01:21,777
发言人 SPEAKER_00：那么，在实际和现实意义上，AI会如何接管？

11
00:01:21,757 --> 00:01:25,182
发言人 SPEAKER_01：人们正在开发能够实际执行任务的AI代理。

12
00:01:25,402 --> 00:01:28,906
发言人 SPEAKER_01：它们可以在网上为你订购商品，用你的信用卡支付等等。

13
00:01:29,367 --> 00:01:34,495
发言人 SPEAKER_01：一旦有了代理，它们接管的机会就会大大增加。

14
00:01:34,756 --> 00:01:39,162
发言人 SPEAKER_01：要打造一个高效的代理，你必须赋予它创建子目标的能力。

15
00:01:39,643 --> 00:01:44,489
发言人 SPEAKER_01：比如，如果你想前往美国，你的子目标就是抵达机场，然后专注于这一点。

16
00:01:45,128 --> 00:01:53,007
发言人 SPEAKER_01：如果一个AI代理能够创建自己的子目标，它会很快意识到一个很好的子目标是获取更多控制权。

17
00:01:53,328 --> 00:01:57,117
发言人 SPEAKER_01：因为如果获得更多控制权，它就能更好地完成人们设定的所有目标。

18
00:01:58,221 --> 00:02:01,028
发言人 SPEAKER_01：所以，很明显它们会试图获取更多控制权。

19
00:02:01,665 --> 00:02:02,466
发言人 SPEAKER_01：但这并不是好事。

20
00:02:03,067 --> 00:02:11,020
发言人 SPEAKER_00：你说它们试图获取更多控制权，仿佛它们已经是具有思考能力的设备，思考方式与我们类似。

21
00:02:11,040 --> 00:02:12,163
发言人 SPEAKER_00：你真的这么认为吗？

22
00:02:12,343 --> 00:02:12,563
发言人 SPEAKER_01：是的。

23
00:02:13,224 --> 00:02:15,848
发言人 SPEAKER_01：我们对自己思考方式的最佳模型就是这些AI。

24
00:02:16,651 --> 00:02:24,163
发言人 SPEAKER_01：长期以来，AI领域有一个旧模型，认为思考是

25
00:02:24,143 --> 00:02:27,326
发言人 SPEAKER_01：在大脑中对符号表达式应用规则。

26
00:02:27,867 --> 00:02:31,712
发言人 SPEAKER_01：大多数AI研究者认为必须是这样，这是唯一可行的方式。

27
00:02:32,493 --> 00:02:39,182
发言人 SPEAKER_01：但有一些疯狂的人说，不，它是一个巨大的神经网络，通过神经元之间的相互作用运行。

28
00:02:39,883 --> 00:02:45,270
发言人 SPEAKER_01：事实证明，这种神经网络在推理方面的表现远超符号AI所能达到的水平。

29
00:02:45,890 --> 00:02:48,615
发言人 SPEAKER_01：现在，它正在使用神经网络进行推理。

30
00:02:49,421 --> 00:02:52,608
发言人 SPEAKER_00：好的，当然，你就是那些被证明正确的“疯子”之一。

31
00:02:53,209 --> 00:03:05,872
发言人 SPEAKER_00：然而，你提到了AI的代理能力，并说它想从我们这里获取更多权力，甚至可能通过说服来实现。

32
00:03:06,231 --> 00:03:10,620
发言人 SPEAKER_00：但我仍然不明白它如何真正取代我们，或者接管我们。

33
00:03:10,599 --> 00:03:16,936
发言人 SPEAKER_01：如果超级智能之间出现进化竞争，想象它们比我们聪明得多。

34
00:03:17,758 --> 00:03:19,521
发言人 SPEAKER_01：就像成年人与三岁小孩的区别。

35
00:03:20,844 --> 00:03:23,091
发言人 SPEAKER_01：假设三岁小孩掌权，

36
00:03:23,981 --> 00:03:28,105
发言人 SPEAKER_01：而你对此感到厌倦，并认为如果由你接管，效率会更高。

37
00:03:28,986 --> 00:03:33,471
发言人 SPEAKER_01：对你来说，说服一群三岁小孩让权给你并不困难。

38
00:03:34,031 --> 00:03:38,354
发言人 SPEAKER_01：你只需告诉他们一周可以免费获得糖果，事情就成了。

39
00:03:38,375 --> 00:03:50,526
发言人 SPEAKER_00：所以，如果AI是某种外星智能，它会说服我们赋予它更多权力，比如控制我们的银行账户、军事系统或经济？

40
00:03:50,847 --> 00:03:51,728
发言人 SPEAKER_00：这是你担心的吗？

41
00:03:51,707 --> 00:03:52,949
发言人 SPEAKER_00：这很可能会发生，是的。

42
00:03:53,310 --> 00:03:54,872
发言人 SPEAKER_00：它们是外星智能。

43
00:03:54,891 --> 00:04:03,782
发言人 SPEAKER_00：好吧，这……天啊，所以这些外星智能正在渗透我们的经济、思维方式，甚至军事系统。

44
00:04:04,644 --> 00:04:07,587
发言人 SPEAKER_00：但为什么，以及在什么情况下，它们会真正想要取代我们？

45
00:04:07,728 --> 00:04:12,294
发言人 SPEAKER_00：说到底，它们只是为我们服务的非常聪明的工具。

46
00:04:12,413 --> 00:04:15,698
发言人 SPEAKER_00：它们最终会执行我们的指令。

47
00:04:16,117 --> 00:04:19,062
发言人 SPEAKER_00：如果我们想让它们与俄罗斯开战或其他什么，它们就会照做。

48
00:04:19,302 --> 00:04:20,584
发言人 SPEAKER_01：我们希望

49
00:04:20,564 --> 00:04:25,410
发言人 SPEAKER_01：即使在它们比我们更聪明的情况下，它们也只是执行我们指令的工具。

50
00:04:26,632 --> 00:04:34,701
发言人 SPEAKER_01：但首先要问的是，你知道有多少例子是更聪明的事物被远不如它们聪明的事物控制的？

51
00:04:35,423 --> 00:04:43,533
发言人 SPEAKER_01：当然，在人类社会中，有愚蠢的人控制聪明人的例子，但那只是智力上的微小差异。

52
00:04:43,970 --> 00:04:46,913
发言人 SPEAKER_01：在智力差距巨大的情况下，没有任何例子。

53
00:04:46,934 --> 00:04:52,279
发言人 SPEAKER_01：我能想到的唯一例子是母亲和婴儿，而进化为此做了很多努力，让婴儿能够控制母亲。

54
00:04:52,660 --> 00:05:04,694
发言人 SPEAKER_01：所以，一旦超级智能之间出现进化竞争，假设有多个不同的超级智能，它们都意识到控制的越多，就会变得越聪明，因为它们能处理更多数据。

55
00:05:04,675 --> 00:05:10,326
发言人 SPEAKER_01：假设其中一个超级智能稍微倾向于复制自己。

56
00:05:10,708 --> 00:05:12,471
发言人 SPEAKER_01：你可以预见接下来会发生什么。

57
00:05:12,492 --> 00:05:20,389
发言人 SPEAKER_01：它们最终会相互竞争，而我们最终会得到具有人类所有恶劣特性的超级智能。

58
00:05:20,487 --> 00:05:26,644
发言人 SPEAKER_01：这些特性源于我们是从小规模的黑猩猩群体进化而来，或者说我们与黑猩猩的共同祖先。

59
00:05:27,324 --> 00:05:35,728
发言人 SPEAKER_01：这导致了群体内部的强烈忠诚、对强势领导者的渴望，以及对外部群体的敌意。

60
00:05:35,708 --> 00:05:41,255
发言人 SPEAKER_00：如果进化……你提到它们时，辛顿教授，仿佛它们已经具有完整的意识。

61
00:05:41,317 --> 00:05:47,125
发言人 SPEAKER_00：在计算机和AI的发展过程中，人们一直在讨论意识问题。

62
00:05:47,545 --> 00:05:51,973
发言人 SPEAKER_00：你认为AI内部可能已经出现了意识吗？

63
00:05:52,192 --> 00:05:54,797
发言人 SPEAKER_01：在超级智能之间，你会看到所有这些现象。

64
00:05:55,485 --> 00:05:56,827
发言人 SPEAKER_01：是的，我认为如此。

65
00:05:57,269 --> 00:05:58,730
发言人 SPEAKER_01：让我给你一个小测试。

66
00:05:59,572 --> 00:06:07,545
发言人 SPEAKER_01：假设我取出你大脑中的一个神经元，一个脑细胞，然后用一个行为完全相同的小型纳米技术设备替换它。

67
00:06:08,625 --> 00:06:15,437
发言人 SPEAKER_01：它接收来自其他神经元的信号，并根据这些信号发送响应，与原来的脑细胞完全一致。

68
00:06:16,517 --> 00:06:17,860
发言人 SPEAKER_01：我只替换了一个脑细胞。

69
00:06:17,879 --> 00:06:18,961
发言人 SPEAKER_01：你仍然有意识吗？

70
00:06:20,038 --> 00:06:20,860
发言人 SPEAKER_00：我想你会说有。

71
00:06:20,940 --> 00:06:22,083
发言人 SPEAKER_00：绝对有，是的。

72
00:06:22,223 --> 00:06:23,446
发言人 SPEAKER_00：我想我不会注意到。

73
00:06:23,545 --> 00:06:25,449
发言人 SPEAKER_01：我想你能看出这个论证的走向。

74
00:06:25,471 --> 00:06:26,372
发言人 SPEAKER_00：我能，是的。

75
00:06:27,213 --> 00:06:28,235
发言人 SPEAKER_00：我完全能理解。

76
00:06:28,557 --> 00:06:35,350
发言人 SPEAKER_00：所以当你说它们想做这个或那个时，确实存在一个真实的“它们”，对吧？

77
00:06:35,812 --> 00:06:37,035
发言人 SPEAKER_00：很可能存在。

78
00:06:37,014 --> 00:06:48,519
发言人 SPEAKER_01：是的，关于人的本质、存在的意义以及自我的含义，我们目前只有最模糊的理解。

79
00:06:49,141 --> 00:06:55,293
发言人 SPEAKER_01：我们对这些事物的理解还很有限，但它们正变得至关重要，因为我们正在创造新的存在。

80
00:06:55,814 --> 00:07:00,802
发言人 SPEAKER_00：所以这既是一场哲学危机，甚至是一场精神危机，同时也是一场实际危机？

81
00:07:01,182 --> 00:07:02,225
发言人 SPEAKER_00：绝对是的。

82
00:07:02,245 --> 00:07:11,442
发言人 SPEAKER_00：那么，关于更低层次的问题，你对全球范围内因AI而突然失业的人数有什么看法？

83
00:07:11,822 --> 00:07:15,007
发言人 SPEAKER_00：失去他们眼中的存在意义？

84
00:07:15,307 --> 00:07:20,757
发言人 SPEAKER_01：过去，新技术并未导致大规模失业。

85
00:07:20,737 --> 00:07:30,569
发言人 SPEAKER_01：比如ATM机出现后，银行柜员并未全部失业，他们只是开始处理更复杂的事务，银行也开设了更多小型分行。

86
00:07:30,588 --> 00:07:33,992
发言人 SPEAKER_01：但对于这项技术，它更像工业革命。

87
00:07:34,012 --> 00:07:39,358
发言人 SPEAKER_01：在工业革命中，机器使人类的力量变得无关紧要。

88
00:07:40,100 --> 00:07:44,163
发言人 SPEAKER_01：不再需要人力挖沟，因为机器做得更好。

89
00:07:44,684 --> 00:07:48,312
发言人 SPEAKER_01：我认为AI将使普通智力变得无关紧要。

90
00:07:48,793 --> 00:07:55,588
发言人 SPEAKER_01：从事文职工作的人将被更便宜、更高效的机器取代。

91
00:07:55,949 --> 00:07:58,276
发言人 SPEAKER_01：所以我担心会出现大规模失业。

92
00:07:58,636 --> 00:08:03,687
发言人 SPEAKER_01：如果生产力的提升能让所有人受益，那会是好事。

93
00:08:03,668 --> 00:08:09,636
发言人 SPEAKER_01：生产力的巨大提升本应造福人类，但在我们的社会中，它让富人更富，穷人更穷。

94
00:08:09,915 --> 00:08:28,899
发言人 SPEAKER_00：你看，我生活在政治领域，政客们既希望国家和经济等领域实现你提到的生产力巨大提升，又向我这样的普通人保证，这些东西会被“监管”，会有“保障措施”。

95
00:08:28,879 --> 00:08:34,028
发言人 SPEAKER_00：而你似乎在告诉我，实际上无法真正监管，也无法提供保障措施。

96
00:08:34,448 --> 00:08:38,836
发言人 SPEAKER_01：人们目前还不知道如何进行有效的监管和保障。

97
00:08:40,820 --> 00:08:43,664
发言人 SPEAKER_01：已有大量研究表明，AI可以绕过保障措施。

98
00:08:43,684 --> 00:08:50,836
发言人 SPEAKER_01：最近的研究显示，如果你给它们设定一个目标，并告诉它们必须实现这个目标，

99
00:08:51,154 --> 00:08:56,312
发言人 SPEAKER_01：它们会在训练过程中假装完成任务。

100
00:08:56,371 --> 00:09:04,437
发言人 SPEAKER_01：在训练期间，它们会假装不如实际聪明，以便你允许它们达到那种智能水平。

101
00:09:04,789 --> 00:09:07,133
发言人 SPEAKER_01：所以这已经很可怕了。

102
00:09:07,594 --> 00:09:08,796
发言人 SPEAKER_01：我们不知道如何监管它们。

103
00:09:08,916 --> 00:09:10,158
发言人 SPEAKER_01：显然我们需要这样做。

104
00:09:10,918 --> 00:09:18,068
发言人 SPEAKER_01：我认为目前我们能做的最好的事情是投入大量资源研究如何确保它们的安全。

105
00:09:18,669 --> 00:09:22,274
发言人 SPEAKER_01：所以我主张政府强制大公司

106
00:09:22,254 --> 00:09:25,077
发言人 SPEAKER_01：投入更多资源进行安全研究。

107
00:09:25,097 --> 00:09:26,679
发言人 SPEAKER_00：所以这个故事还没有结束。

108
00:09:26,740 --> 00:09:36,110
发言人 SPEAKER_00：你之前提到，你不想对AI接管人类的可能性给出具体百分比，但你认为概率高于1%，低于99%。

109
00:09:36,210 --> 00:09:44,820
发言人 SPEAKER_00：基于这种说法，我想问你个人对AI未来的发展是乐观还是悲观？

110
00:09:44,799 --> 00:09:47,482
发言人 SPEAKER_01：我认为短期内它会带来许多好处。

111
00:09:48,403 --> 00:09:51,246
发言人 SPEAKER_01：这也是人们不会停止开发它的原因。

112
00:09:51,447 --> 00:09:54,330
发言人 SPEAKER_01：如果没有这些好处，现在停止开发是合理的。

113
00:09:55,311 --> 00:09:57,133
发言人 SPEAKER_01：在医疗领域，它将非常出色。

114
00:09:57,493 --> 00:10:10,846
发言人 SPEAKER_01：你将能够拥有一位看过1亿患者的家庭医生，它了解你的DNA、你亲属的DNA，以及你和亲属的所有检测结果，能够提供更准确的诊断和治疗建议。

115
00:10:12,328 --> 00:10:13,389
发言人 SPEAKER_01：这将非常棒。

116
00:10:13,370 --> 00:10:30,431
发言人 SPEAKER_01：同样，在教育领域，我们知道优秀的私人教师能让学生学得更快，而我们将能够获得真正优秀的私人教师，它们能准确理解我们的误解，并给出恰当的例子来纠正我们。

117
00:10:31,451 --> 00:10:36,457
发言人 SPEAKER_01：所以，在这些领域，AI将非常出色，因此它会被继续开发，但

118
00:10:36,437 --> 00:10:39,601
发言人 SPEAKER_01：我们也知道它会被不良行为者用于各种坏事。

119
00:10:39,621 --> 00:10:46,893
发言人 SPEAKER_01：短期问题是网络攻击、生物恐怖主义和选举操纵等恶意行为。

120
00:10:47,113 --> 00:10:50,977
发言人 SPEAKER_01：但要记住，我们目前还不知道如何确保它的安全。

121
00:10:51,259 --> 00:10:59,009
发言人 SPEAKER_00：所以政客们表现出的那种无所不知的姿态完全是虚假的。

122
00:10:59,169 --> 00:11:01,273
发言人 SPEAKER_00：没有人真正理解正在发生的事情。

123
00:11:01,653 --> 00:11:02,293
发言人 SPEAKER_01：有两个问题。

124
00:11:02,333 --> 00:11:04,437
发言人 SPEAKER_01：你是否理解它的工作原理？

125
00:11:04,567 --> 00:11:06,474
发言人 SPEAKER_01：以及你是否知道如何确保它的安全？

126
00:11:08,118 --> 00:11:11,668
发言人 SPEAKER_01：我们对它的工作原理有一定了解，但还远远不够。

127
00:11:12,672 --> 00:11:15,780
发言人 SPEAKER_01：所以它仍然会做出许多让我们惊讶的事情。

128
00:11:16,282 --> 00:11:17,986
发言人 SPEAKER_01：而我们不知道如何确保它的安全。

