1 00:00:02,443 --> 00:00:06,528 说话人 SPEAKER_02：为这段视频的主题人物 Geoffrey Hinton 写一个简短的介绍。
2 00:00:09,192 --> 00:00:14,538 说话人 SPEAKER_02：Geoffrey Hinton 是多伦多大学的退休教授，被誉为人工智能之父。
3 00:00:16,161 --> 00:00:21,407 说话人 SPEAKER_02：他最近离开谷歌，以便更自由地讨论不受控制的 AI 发展带来的危险。
4 00:00:23,368 --> 00:00:30,577 说话人 SPEAKER_02：我们在他在伦敦的家中采访了他，谈论了他帮助创造的技术、它的许多好处以及他为什么突然担心人类面临风险。
5 00:00:35,350 --> 00:00:37,152 说话人 SPEAKER_00：我收到了华尔街日报的请求。
6 00:00:37,472 --> 00:00:39,415 说话人 SPEAKER_00：他们希望我更正我的讣告。
7 00:00:39,676 --> 00:00:40,097 说话人 SPEAKER_01：你的意思是什么？
8 00:00:40,838 --> 00:00:42,320 说话人 SPEAKER_00：他们希望我更正我的讣告。
9 00:00:42,340 --> 00:00:43,582 说话人 SPEAKER_01: 他们好像已经预先写好了。
10 00:00:43,601 --> 00:00:46,566 说话人 SPEAKER_00: 他们已经预先写好了我的讣告。
11 00:00:46,585 --> 00:00:48,168 说话人 SPEAKER_00: 我想知道马克·吐温会对此说些什么。
12 00:00:48,189 --> 00:01:01,628 说话人 SPEAKER_01: 所以我想我们这里不需要介绍，我就直接开始了。
13 00:01:03,262 --> 00:01:14,721 说话人 SPEAKER_01：你最近接受了一些采访，在采访中你说，用于聊天机器人和其他生成式人工智能的数字智能可能比我们拥有的生物智能更好。
14 00:01:15,683 --> 00:01:18,468 说话人 SPEAKER_01：你能简要解释一下是什么让你得出这个结论吗？
15 00:01:19,444 --> 00:01:26,334 说话人 SPEAKER_00：所以在数字计算机中，它是设计成你可以明确告诉它要做什么，它会按照你告诉它的去做。
16 00:01:27,275 --> 00:01:34,763 说话人 SPEAKER_00：即使它在学习东西，两个不同的数字计算机也可以用相同的学到的知识做完全一样的事情。
17 00:01:36,006 --> 00:01:44,135 说话人 SPEAKER_00：这意味着你可以制作 10,000 份相同的知识副本，让它们在不同的计算机上运行，
18 00:01:44,638 --> 00:01:49,685 说话人 SPEAKER_00：每当一个副本学到一些东西时，它可以非常高效地将其传达给所有其他副本。
19 00:01:50,966 --> 00:02:01,801 说话人 SPEAKER_00：因此，你可以有 10,000 个数字代理在外，一种蜂群思维，它们可以通过共享神经网络中的连接强度来极其高效地共享知识。
20 00:02:01,820 --> 00:02:02,882 说话人 SPEAKER_00：我们做不到这一点。
21 00:02:03,783 --> 00:02:09,009 说话人 SPEAKER_00：如果你学到一些东西，想要告诉我，你必须使用句子。
22 00:02:09,074 --> 00:02:15,260 说话人 SPEAKER_00：或者图片，那样你只能分享非常有限的信息。
23 00:02:15,801 --> 00:02:22,368 说话人 SPEAKER_00：所以，你向我传达你所学到的东西的速度，远远比不上这些数字智能传达信息的速度。
24 00:02:22,849 --> 00:02:24,010 说话人 SPEAKER_00：这使得它们（它们）更加出色。
25 00:02:24,792 --> 00:02:26,633 说话人 SPEAKER_00：他们之间可以学会很多东西。
26 00:02:27,435 --> 00:02:33,262 说话人 SPEAKER_01：你说数字智能是不朽的，而生物智能是有限的。
27 00:02:34,623 --> 00:02:35,925 说话人 SPEAKER_01：你这是什么意思？
28 00:02:36,377 --> 00:02:50,337 说话人 SPEAKER_00：所以，如果我在一个数字计算机上模拟的神经网络中学习了一些连接强度，那么如果某个计算机损坏了，这些相同的连接强度可以在另一台计算机上使用。
29 00:02:51,539 --> 00:03:00,393 说话人 说话人_00：即使所有的数字计算机都停止工作，如果你把连接强度存储在某个地方，你就可以在另一个数字计算机上运行相同的权重。
30 00:03:01,474 --> 00:03:02,436 说话人 说话人_00：但对我们来说，
31 00:03:03,326 --> 00:03:08,474 说话人 说话人_00：我们学到的知识，连接强度，是特定于我们的大脑的。
32 00:03:08,615 --> 00:03:09,856 说话人 说话人_00：每个大脑都有所不同。
33 00:03:10,317 --> 00:03:12,219 说话人 SPEAKER_00：你大脑中的神经元都略有不同。
34 00:03:12,961 --> 00:03:18,248 说话人 SPEAKER_00：而你学习是为了利用你大脑特有的所有特性。
35 00:03:18,308 --> 00:03:25,098 说话人 SPEAKER_00：因此，一旦你在大脑中学会了连接强度，如果你告诉我那些连接强度，它们对我没有任何好处，因为我的大脑是不同的。
36 00:03:26,445 --> 00:03:32,215 说话人 SPEAKER_00：所以数字计算机是永恒的，因为你可以将同样的知识运行在不同的硬件上。
37 00:03:32,936 --> 00:03:37,704 说话人 SPEAKER_00: 我们之所以不朽，是因为硬件和知识紧密相连。
38 00:03:38,185 --> 00:03:42,451 说话人 SPEAKER_00: 你无法将连接强度与它们运行的特定大脑分开。
39 00:03:43,554 --> 00:03:45,235 说话人 SPEAKER_00: 因此，如果大脑死亡，知识也会死亡。
40 00:03:47,819 --> 00:03:52,587 说话人 SPEAKER_02: 我们为什么要担心数字智能取代生物智能？
41 00:03:53,497 --> 00:04:06,891 说话人 SPEAKER_00: 我认为它更好地共享了众多不同数字代理通过共享相同权重所学习到的知识，他们只需共享权重的更新，现在他们可以同时学习 10,000 种不同的东西。
42 00:04:08,114 --> 00:04:12,318 说话人 SPEAKER_00: 但我也认为数字智能可能比人脑拥有更好的学习算法。
43 00:04:13,259 --> 00:04:19,706 说话人 SPEAKER_00: 所有试图在脑中找到与这些数字智能中的反向传播算法一样有效的学习算法的尝试。
44 00:04:19,687 --> 00:04:21,970 说话人 SPEAKER_00: 在这些数字智能中。
45 00:04:22,610 --> 00:04:24,031 说话人 说话人_00：到目前为止，那些尝试都失败了。
46 00:04:24,692 --> 00:04:30,158 说话人 说话人_00：我们还没有找到任何像反向传播算法那样能够很好地扩展到非常大的系统的东西。
47 00:04:30,738 --> 00:04:32,341 说话人 说话人_00：所以我认为它们有两个优势。
48 00:04:32,380 --> 00:04:39,269 说话人 说话人_00：它们可能有一个更好的学习算法，并且它们可以比生物智能更有效地共享知识。
49 00:04:39,288 --> 00:04:44,233 说话人 SPEAKER_01：在你进入这个领域的时候，机器智能领域有两种思想流派。
50 00:04:45,196 --> 00:04:47,398 说话人 SPEAKER_01：主流和神经网络。
51 00:04:48,644 --> 00:04:51,088 说话人 SPEAKER_01：你能描述一下这两种方法之间的区别吗？
52 00:04:51,608 --> 00:04:53,009 说话人 SPEAKER_00：我可以稍微夸张一下。
53 00:04:53,050 --> 00:04:57,336 说话人 SPEAKER_00：关于智能，有两种不同的模型。
54 00:04:57,978 --> 00:05:00,021 说话人 SPEAKER_00：其中一种模型认为智能就是推理。
55 00:05:01,281 --> 00:05:03,404 说话人 SPEAKER_00：我们通过逻辑来进行推理。
56 00:05:03,906 --> 00:05:05,487 说话人 SPEAKER_00：这就是人类特别的地方。
57 00:05:06,829 --> 00:05:12,639 说话人 SPEAKER_00: 我们应该做的是理解我们实际使用的逻辑。
58 00:05:13,759 --> 00:05:16,204 说话人 SPEAKER_00: 这也与这样的想法有关，
59 00:05:16,858 --> 00:05:29,642 说话人 SPEAKER_00: 你存储的知识是符号表达式，所以我可以对你说一句话，你将能够以某种方式存储它，然后你可以在以后用它来推断其他句子。
60 00:05:30,062 --> 00:05:33,670 说话人 SPEAKER_00: 但你头脑中的东西有点像句子，但经过了清理。
61 00:05:34,814 --> 00:05:42,404 说话人 SPEAKER_00：有一种完全不同的智能模式，那就是学习大脑细胞网络中的连接强度。
62 00:05:43,346 --> 00:05:47,812 说话人 SPEAKER_00：它擅长的是像感知和运动控制这样的东西，而不是推理。
63 00:05:48,014 --> 00:05:50,838 说话人 SPEAKER_00：推理出现得晚得多，而且我们在这方面并不擅长。
64 00:05:51,879 --> 00:05:53,382 说话人 SPEAKER_00：你直到相当老了才会学习如何去做它。
65 00:05:54,704 --> 00:05:58,189 说话人 SPEAKER_00: 事实上，推理实际上是一个非常糟糕的生物智能模型。
66 00:05:58,249 --> 00:06:03,656 说话人 SPEAKER_00: 生物智能关乎控制你的身体和观察事物等方面。
67 00:06:04,531 --> 00:06:08,855 说话人 SPEAKER_00: 那是完全不同的范式，对头脑中内容的理解也完全不同。
68 00:06:09,336 --> 00:06:14,202 说话人 SPEAKER_00: 它不是存储符号的字符串，而是连接强度。
69 00:06:15,163 --> 00:06:23,053 说话人 SPEAKER_00：符号 AI 视角的关键问题是，这些符号表达式的形式是什么，如何用它们进行推理？
70 00:06:24,396 --> 00:06:27,980 说话人 SPEAKER_00：对于神经网络视角，核心问题则完全不同。
71 00:06:28,000 --> 00:06:32,225 说话人 SPEAKER_00：它是，如何学习这些连接强度，以便你可以做所有这些奇妙的事情？
72 00:06:32,593 --> 00:06:35,197 说话人 SPEAKER_00：因此，学习一直是神经网络视角的核心。
73 00:06:35,718 --> 00:06:38,100 说话人 SPEAKER_00：从象征性观点来看，他们说，我们以后再考虑学习的问题。
74 00:06:38,161 --> 00:06:41,605 说话人 SPEAKER_00：首先，你必须弄清楚知识是如何表示的，我们如何进行推理。
75 00:06:42,365 --> 00:06:44,069 说话人 SPEAKER_00：因此，这些观点完全不同。
76 00:06:44,189 --> 00:06:46,812 说话人 SPEAKER_00：一个受到了逻辑的启发，另一个受到了生物学的启发。
77 00:06:47,512 --> 00:06:53,961 说话人 SPEAKER_00：长期以来，逻辑阵营的人们认为从生物学中汲取灵感是愚蠢的。
78 00:06:54,245 --> 00:07:04,680 说话人 SPEAKER_00：这有点奇怪，因为冯·诺伊曼和图灵都曾认为神经网络是攻克智能的方法，但不幸的是他们都英年早逝。
79 00:07:07,504 --> 00:07:11,129 说话人 SPEAKER_02：您能否从高层次上描述一下神经网络是如何工作的？
80 00:07:12,812 --> 00:07:13,392 说话人 SPEAKER_00：我可以尝试一下。
81 00:07:14,494 --> 00:07:19,982 说话人 SPEAKER_00: 让我们先描述一下如何识别物体和图像。
82 00:07:20,165 --> 00:07:24,670 说话人 SPEAKER_00: 假设我们只想说图像中是否有鸟。
83 00:07:25,112 --> 00:07:28,456 说话人 SPEAKER_00: 假设鸟大致位于图像中间，是关注的焦点。
84 00:07:29,057 --> 00:07:31,420 说话人 SPEAKER_00: 你需要说，这是鸟还是不是鸟？
85 00:07:33,303 --> 00:07:34,586 说话人 说话人_00：你可以想象一个图像。
86 00:07:34,646 --> 00:07:36,769 说话人 说话人_00：假设它是一个100像素乘以100像素的。
87 00:07:37,310 --> 00:07:38,511 说话人 说话人_00：那就是10,000个像素。
88 00:07:39,151 --> 00:07:41,035 说话人 说话人_00：每个像素是三种颜色，RGB。
89 00:07:41,555 --> 00:07:43,117 说话人 SPEAKER_00: 这就是 30,000 个数字。
90 00:07:43,975 --> 00:07:53,209 说话人 SPEAKER_00: 在计算术语中，识别图像中的鸟由取 30,000 个数字并输出一个表示是或否是鸟的数字组成。
91 00:07:54,732 --> 00:08:01,723 说话人 SPEAKER_00: 你可以尝试编写一个标准的计算机程序来做这件事，人们尝试了很多年，但始终无法做得很好。
92 00:08:01,963 --> 00:08:03,425 说话人 SPEAKER_00: 比如，他们尝试了 50 年。
93 00:08:05,028 --> 00:08:07,812 说话人 SPEAKER_00: 或者你可以制作一个多层神经网络。
94 00:08:08,374 --> 00:08:11,838 说话人 SPEAKER_00: 我会先告诉你如何手动连接一个神经网络。
95 00:08:12,781 --> 00:08:20,350 说话人 SPEAKER_00: 所以你会做的是，你会有像素，这将是底层，然后你会有一层特征检测器。
96 00:08:21,192 --> 00:08:36,712 说话人 SPEAKER_00: 一个典型的特征检测器可能从垂直像素行中传来大的正连接强度，从相邻的垂直像素行中传来大的负连接强度，其他地方则没有连接强度。
97 00:08:37,434 --> 00:08:45,285 说话人 SPEAKER_00: 如果这两行像素都很亮，它将从这里获得很大的正输入，但也会从那里获得很大的负输入，所以它不会做任何事情。
98 00:08:46,086 --> 00:08:53,317 说话人 SPEAKER_00: 但是如果这些像素很亮，提供大的正输入，而那些像素不亮，所以它不会被这些像素抑制，它会非常兴奋。
99 00:08:53,677 --> 00:08:58,144 说话人 SPEAKER_00: 它会说，嘿，我找到了我喜欢的东西，那就是这里的亮像素和这里的暗像素。
100 00:08:58,985 --> 00:09:00,826 说话人 SPEAKER_00: 那就是一个边缘检测器。
101 00:09:00,846 --> 00:09:06,153 说话人 SPEAKER_00：我刚刚告诉你们如何使用正负权重手动接线，以检测微小的垂直边缘。
102 00:09:07,196 --> 00:09:14,764 说话人 SPEAKER_00：现在想象一下，有成千上万这样的东西在图像的不同位置、不同方向和不同尺度上检测不同的边缘。
103 00:09:15,826 --> 00:09:17,589 说话人 SPEAKER_00：这将是你的第一个特征检测层。
104 00:09:18,570 --> 00:09:21,634 说话人 SPEAKER_00：如果我要手动接线，我的第二层特征检测器
105 00:09:22,457 --> 00:09:28,869 说话人 SPEAKER_00：可能有一个检测器，它能够检测两个在细小角度相交的边缘，就像这样。
106 00:09:29,370 --> 00:09:31,052 说话人 SPEAKER_00：所以它正在寻找这条边和这条边。
107 00:09:31,453 --> 00:09:36,121 说话人 SPEAKER_00：如果它们同时激活，它就会说，嘿，可能这里有一个喙。
108 00:09:36,822 --> 00:09:39,506 说话人 说话人_00：它可能是各种各样的事情，但可能只是个喙。
109 00:09:39,967 --> 00:09:42,152 说话人 说话人_00：所以你有一个有点像喙的特征。
110 00:09:43,634 --> 00:09:47,942 说话人 说话人_00：在那个层面，你可能还有一个检测到形成圆形的一堆边缘的特征。
111 00:09:49,475 --> 00:09:56,101 说话人 说话人_00：因此，你将会有圆形检测器和可能的喙检测器，以及那个层面上的许多其他检测器。
112 00:09:56,121 --> 00:09:58,083 说话者 说话者_00: 但它们检测到的稍微复杂一些的东西。
113 00:09:59,205 --> 00:10:11,818 说话者 说话者_00: 然后在那一层之上，可能会有一些东西检测到一个潜在的喙，它与一个潜在的圆圈、一个潜在的瞳孔在正确的空间关系中，因此可能是鸟的头。
114 00:10:13,399 --> 00:10:15,162 说话者 说话者_00: 那就像是你的第三层。
115 00:10:16,340 --> 00:10:25,467 说话者 说话者_00: 也许在你的第三层中，你还能检测到鸟的脚和翅膀，那么在下一层可能就可以有鸟的检测器了。
116 00:10:25,908 --> 00:10:32,715 说话人 SPEAKER_00：如果这些事物中有几个变得活跃，比如，这里有一个头，有一个翅膀，有一个脚，那可能是一只鸟。
117 00:10:33,936 --> 00:10:39,421 说话人 SPEAKER_00：好吧，我之前已经告诉你们如何手动连接所有这些部件，但你永远不可能做得很好。
118 00:10:40,241 --> 00:10:44,085 说话人 SPEAKER_00：所以，我们不是手动连接所有这些部件，
119 00:10:44,369 --> 00:10:45,971 说话人 SPEAKER_00：我们可以想象尝试去学习它。
120 00:10:46,913 --> 00:10:50,837 说话人 SPEAKER_00：我已经告诉你们我们想学习的内容，但现在我要告诉你们我们是如何学习的。
121 00:10:51,438 --> 00:10:53,322 说话人 SPEAKER_00：我们学习的方式一开始听起来很奇怪。
122 00:10:54,604 --> 00:11:02,975 说话人 SPEAKER_00：不是将所有连接强度都连接起来以获得所需的检测器，而是从随机的连接强度开始，所有连接上的数字都是随机的。
123 00:11:03,937 --> 00:11:10,427 说话人 SPEAKER_00：然后你输入一张鸟的图片，你通过这些特征检测器的层向前推进，它表现得完全随机。
124 00:11:11,369 --> 00:11:15,736 说话人 SPEAKER_00: 输出的鸟类检测器会说 0.5，是鸟。
125 00:11:16,658 --> 00:11:19,443 说话人 SPEAKER_00: 当它确定是鸟时，它会说 1，当它确定不是鸟时，它会说 0。
126 00:11:19,684 --> 00:11:20,986 说话人 SPEAKER_00: 对我来说，它会说大约 0.5。
127 00:11:21,989 --> 00:11:23,471 说话人 SPEAKER_00: 现在你可以问以下问题。
128 00:11:25,095 --> 00:11:27,960 说话人 SPEAKER_00：我该如何更改网络中所有的连接强度？
129 00:11:29,307 --> 00:11:34,980 说话人 SPEAKER_00：所以，与其说 0.5 是一只鸟，假设它是一只鸟，它说 0.51 是一只鸟。
130 00:11:35,741 --> 00:11:42,017 说话人 SPEAKER_00：所以你想问的问题是，我应该如何更改特定的连接强度，使其更有可能是只鸟？
131 00:11:43,279 --> 00:11:49,109 说话人 SPEAKER_00：你可以通过计算你得到的结果和你想要的结果之间的差异来找出答案。
132 00:11:49,470 --> 00:11:52,394 说话人 SPEAKER_00：您想要 1，但实际上得到了 0.5。
133 00:11:52,434 --> 00:11:56,520 说话人 SPEAKER_00：您将这个差值反向传递给网络。
134 00:11:57,162 --> 00:12:00,106 说话人 SPEAKER_00：然后您使用一些微积分，这里就不解释了。
135 00:12:00,086 --> 00:12:11,845 说话人 SPEAKER_00：这样您就能计算出网络中每个连接应该如何调整大小，以便更有可能说出“鸟”这个词。
136 00:12:12,384 --> 00:12:17,153 说话者 SPEAKER_00：然后你稍微调整所有连接强度，使其更有可能说出“鸟”。
137 00:12:18,033 --> 00:12:23,461 说话者 SPEAKER_00：然后你展示一些不是鸟的东西，现在你要调整连接强度，使其不太可能说那是鸟。
138 00:12:24,691 --> 00:12:33,543 说话者 SPEAKER_00：你这样一直进行下去，用很多鸟和非鸟，最终你会发现它发现了所有这些特征检测器。
139 00:12:33,563 --> 00:12:38,211 说话者 SPEAKER_00：它将发现类似喙的东西，类似眼睛的东西，以及检测脚和翅膀的东西，所有这些。
140 00:12:39,032 --> 00:12:50,749 说话人 SPEAKER_00：如果你在成千上万的不同物体上训练它，比如一千种不同类别的物体，它将发现中间特征检测器，这些检测器非常适合识别各种事物。
141 00:12:51,488 --> 00:13:09,708 说话人 SPEAKER_00：这里的魔法在于有一个相对简单的算法叫做反向传播，它将输出中的误差反向传递到网络中，并通过所有连接计算如何改变它们以改善行为，然后你稍微改变一下，再用另一个例子继续。
142 00:13:11,171 --> 00:13:13,813 说话人 SPEAKER_00：令人惊讶的是，这实际上有效。
143 00:13:14,595 --> 00:13:16,937 说话人 SPEAKER_00：多年来，人们认为这只会陷入困境。
144 00:13:17,258 --> 00:13:18,278 说话人 SPEAKER_00: 它会卡在某处。
145 00:13:18,600 --> 00:13:19,240 说话人 SPEAKER_00: 但不，它不会。
146 00:13:19,279 --> 00:13:20,701 说话人 SPEAKER_00: 实际上它工作得非常好。
147 00:13:22,419 --> 00:13:25,664 说话人 SPEAKER_02: 我很好奇，神经网络是如何处理语言的？
148 00:13:28,028 --> 00:13:32,715 说话人 SPEAKER_00: 好的，现在你们已经了解了我们是如何训练它来识别鸟的。
149 00:13:33,456 --> 00:13:45,712 说话人 SPEAKER_00: 想象一下，如果我们用一串词作为输入，你们首先要做的事情是将一个词转换成一个嵌入向量。
150 00:13:46,333 --> 00:13:52,342 说话人 SPEAKER_00: 也就是说，它是一小堆数字，用来捕捉词的意义，或者说是试图捕捉词的意义。
151 00:13:53,621 --> 00:13:58,106 说话人 SPEAKER_00: 因此，在词之后的第一层将是每个词的嵌入向量。
152 00:13:59,808 --> 00:14:13,105 说话者 说话者_00：现在我们将有很多层的嵌入向量层，随着我们通过网络向上移动，我们将使单词的嵌入向量越来越好，因为它们将考虑越来越多的上下文信息。
153 00:14:14,166 --> 00:14:18,270 说话者 说话者_00：那么，假设在这个句子中，我们假设没有任何大写字母，好吗？
154 00:14:18,672 --> 00:14:21,654 说话者 说话者_00：那么，假设在这个句子中你有单词五月，
155 00:14:23,169 --> 00:14:27,955 说话者 说话者_00：嗯，五月最可能的意义是它是情态动词，就像他可能做那样。
156 00:14:29,816 --> 00:14:32,499 说话人 SPEAKER_00: 但显然“五月”这个词还有一个完全不同的含义，即月份。
157 00:14:34,041 --> 00:14:39,586 说话人 SPEAKER_00: 因此最初，它不知道，仅从“五月”这个词来看，它不知道该使用哪个嵌入向量。
158 00:14:40,986 --> 00:14:51,017 说话人 SPEAKER_00: 它将使用一种折衷的向量，介于代表模态的“五月”嵌入向量和代表月份的“五月”嵌入向量之间的某种东西。
159 00:14:52,684 --> 00:14:56,288 说话人 SPEAKER_00: 然后在下一层，它将细化这个向量。
160 00:14:57,169 --> 00:15:02,395 说话人 说话人_00：根据上下文，这将使向量略微更好，取决于它获得的上下文，取决于附近的嵌入向量。
161 00:15:03,057 --> 00:15:13,149 说话人 说话人_00：例如，如果附近有六月的嵌入向量，那么它将使五月的嵌入向量更接近月份，而不是模态。
162 00:15:14,431 --> 00:15:18,995 说话人 说话人_00：但如果附近有木头的嵌入向量，它将使它更接近模态，而不是月份。
163 00:15:21,371 --> 00:15:26,998 说话人 说话人_00：随着您在网络中前进，它可以对这些嵌入向量进行细化，使它们变得越来越好。
164 00:15:28,099 --> 00:15:34,706 说话人 SPEAKER_00: 我们将如何训练它，我们将给它一串单词作为输入。
165 00:15:36,589 --> 00:15:39,793 说话人 SPEAKER_00: 我们将这样做，这里将是一种方法。
166 00:15:39,812 --> 00:15:42,034 说话人 SPEAKER_00: 这并不是真正所做的事情，但很容易理解。
167 00:15:42,936 --> 00:15:46,840 说话人 SPEAKER_00: 对于最后一个词，你只需输入一个中性的词。
168 00:15:46,860 --> 00:15:48,341 说话人 SPEAKER_00: 你说未知。
169 00:15:48,440 --> 00:15:52,927 说话人 SPEAKER_00: 它有一个非常模糊的嵌入向量，几乎是所有单词向量的平均值。
170 00:15:53,006 --> 00:15:54,249 说话人 SPEAKER_00: 它不知道，对吧？
171 00:15:55,370 --> 00:16:02,159 说话人 SPEAKER_00: 现在，当你通过网络前进时，最后一个单词将能够受到前面单词的影响。
172 00:16:03,682 --> 00:16:08,950 说话者 说话者_00：一开始非常模糊，但随着你穿越这些层级，它可以变得越来越精确。
173 00:16:10,052 --> 00:16:14,278 说话者 说话者_00：等你走到网络的尽头，那个嵌入向量
174 00:16:14,966 --> 00:16:23,501 说话者 说话者_00：可能看起来像某个特定单词的嵌入向量，或者是一些单词组合的嵌入向量，或者是几个单词的平均值。
175 00:16:25,063 --> 00:16:39,809 说话者 说话者_00：你通过训练网络，通过走过所有这些层级，并希望最后一个单词的嵌入向量看起来像文本中实际存在的单词的嵌入向量。
176 00:16:40,769 --> 00:16:42,254 说话人 SPEAKER_00：这就是它预测下一个单词的方式。
177 00:16:43,057 --> 00:16:52,347 说话人 SPEAKER_00：它试图将这种中性的嵌入向量转换为与文本中正确出现的单词的嵌入向量相近的向量。
178 00:16:53,914 --> 00:17:12,563 说话人 SPEAKER_00：然后你计算嵌入向量与文本之间的差异，以及产生的嵌入向量之间的误差，并将这个误差反向传播通过网络，它从这一单词反向传播到前面的单词，以便它们能够对这一单词产生正确的影响。
179 00:17:13,744 --> 00:17:17,570 说话人 SPEAKER_00：这就是反向传播算法学习预测下一个单词的过程。
180 00:17:18,853 --> 00:17:22,317 发言人 SPEAKER_01: 因此，尽管该领域取得了一些理论突破，
181 00:17:22,821 --> 00:17:25,846 发言人 SPEAKER_01：这些神经网络长期以来效果都不太好。
182 00:17:26,727 --> 00:17:27,287 发言人 SPEAKER_01：为什么？
183 00:17:28,628 --> 00:17:30,070 发言人 SPEAKER_00：这是多种原因造成的。
184 00:17:31,031 --> 00:17:33,433 说话人 SPEAKER_00：所以我们初始化它们并不好。
185 00:17:34,015 --> 00:17:36,657 说话人 SPEAKER_00：也就是说，我说你放入随机权重，然后学习所有内容。
186 00:17:37,338 --> 00:17:44,086 说话人 SPEAKER_00：但是如果你没有仔细决定随机权重的类型，事情永远不会起飞。
187 00:17:44,067 --> 00:17:48,711 说话人 SPEAKER_00：所以这是它们在具有许多特征检测器层的深度网络中工作不好的技术原因。
188 00:17:49,151 --> 00:17:53,674 说话人 SPEAKER_00：但主要原因是我们没有足够的计算能力，也没有足够的数据。
189 00:17:54,215 --> 00:17:59,701 说话人 SPEAKER_00：所以人们试图在没有太多计算能力的情况下，在相对较小的训练集上训练这些网络。
190 00:18:00,661 --> 00:18:03,364 说话人 SPEAKER_00：在那个环境下，其他方法效果更好。
191 00:18:04,023 --> 00:18:07,507 说话人 SPEAKER_00：神经网络真正发挥作用的条件是有大量数据和强大的计算能力。
192 00:18:08,087 --> 00:18:11,211 说话人 SPEAKER_00: 然后你可以使用一个大型的神经网络，然后它比其他任何东西都好得多。
193 00:18:12,111 --> 00:18:13,972 说话人 SPEAKER_00: 我们当时并没有意识到这一点。
194 00:18:14,289 --> 00:18:19,478 说话人 SPEAKER_00: 所以我们偶尔会幻想，嗯，假设你有很多更多的数据，还有更大的计算机，它将工作得更好。
195 00:18:19,518 --> 00:18:21,601 说话人 SPEAKER_00: 但我们没有意识到它会好得多。
196 00:18:22,442 --> 00:18:30,976 说话人 SPEAKER_00: 因此在 20 世纪 90 年代，神经网络相对是一个沉寂的时期，因为其他方法在小问题上表现更好。
197 00:18:32,377 --> 00:18:36,483 说话人 SPEAKER_00: 在计算机科学领域，很多人对神经网络失去了信心。
198 00:18:37,847 --> 00:18:44,494 说话人 SPEAKER_00: 在心理学领域，他们并没有放弃，因为在心理学领域，他们想要的是类似大脑的东西，而神经网络显然比符号人工智能更接近大脑。
199 00:18:44,955 --> 00:18:48,740 说话人 SPEAKER_00: 但在 20 世纪 90 年代，神经网络在计算机科学领域有点声名狼藉。
200 00:18:49,780 --> 00:18:52,964 说话人 SPEAKER_01：那么让我们快进到另一个十年，到 2000 年代。
201 00:18:55,007 --> 00:19:02,134 说话人 SPEAKER_01：在你看来，有没有一个时刻让你明白你所追求的方法将会取得胜利？
202 00:19:02,174 --> 00:19:04,416 说话人 SPEAKER_00：好的。
203 00:19:04,856 --> 00:19:07,180 说话人 SPEAKER_00：在 2006 年，
我们通过无监督学习初始化权重的方法得到了很大改进，然后反向传播也工作得更好。
205 00:19:14,419 --> 00:19:18,469 发言人 SPEAKER_00：所以很明显，反向传播确实会非常有效。
2009年，我的两位研究生乔治·达尔和阿卜杜拉曼·穆罕默德制作了一个更好的语音识别器，实际上是一个稍微更好的语音识别器，但它的性能略优于当时的技术水平，使用了深度神经网络。
207 00:19:36,520 --> 00:19:40,006 发言人 SPEAKER_00：然后很明显这些东西都会到达某个地方。
208 00:19:40,386 --> 00:19:44,794 说话人 SPEAKER_00：接下来几年，所有大型演讲团队都转向使用神经网络。
209 00:19:46,106 --> 00:19:52,194 说话人 SPEAKER_00：然后在 2012 年，这种语音功能出现在了 Android 上，Android 突然赶上了 Siri。
210 00:19:52,595 --> 00:19:55,157 说话人 SPEAKER_00：它在语音方面的表现和 Siri 一样好，因为它使用了神经网络。
211 00:19:56,159 --> 00:20:07,534 说话人 SPEAKER_00：同年，我的两位研究生，伊利亚·苏特科娃和安德烈·克日什佐夫斯基，开发了一个在识别物体和图像方面非常出色的神经网络。
212 00:20:07,953 --> 00:20:10,376 说话人 SPEAKER_00: 这个结果大大超过了现有技术水平。
213 00:20:10,828 --> 00:20:16,671 说话人 SPEAKER_00: 我认为正是这种组合使得它在语音识别方面已经取得成效并投入生产。
214 00:20:17,494 --> 00:20:21,018 说话人 SPEAKER_00: 大公司都在做这样的事情，我认为公众对此并不十分了解。
215 00:20:21,479 --> 00:20:24,641 说话人 SPEAKER_00: 但突然之间，它在计算机视觉方面的效果变得更好。
216 00:20:25,461 --> 00:20:27,084 说话人 SPEAKER_00: 这是个转折点。
217 00:20:27,584 --> 00:20:34,650 说话人 SPEAKER_00: 在 2012 年，我们以巨大的优势赢得了 ImageNet 竞赛，我们的错误率几乎是其他方法的一半。
218 00:20:35,391 --> 00:20:40,576 说话人 SPEAKER_00: 那是一个公开的数据集，但有一个隐藏的测试集，所以你不能作弊。
219 00:20:41,477 --> 00:20:47,501 说话人 SPEAKER_01: 所以让我们重点谈谈 2012 年，因为你说那是一个真正的转折点。
220 00:20:47,481 --> 00:20:53,490 说话人 SPEAKER_01：你能再次从高层次描述一下 AlexNet 是如何工作的吗？
221 00:20:54,310 --> 00:20:57,173 说话人 SPEAKER_01：我猜这个名字可能是以你的研究生命名的。
222 00:20:57,193 --> 00:21:03,982 说话人 SPEAKER_00：这个名字是为了纪念 Alex Krzyzewski，因为他是一位编程大师，让这个系统运作起来。
223 00:21:05,003 --> 00:21:08,087 说话人 SPEAKER_00：Ilya 帮了很多忙，但主要是 Alex 的工作。
224 00:21:08,989 --> 00:21:13,454 讲者 SPEAKER_00：我向您解释了在反向传播中，您会有这些特征检测器层。
225 00:21:14,498 --> 00:21:24,527 讲者 SPEAKER_00：AlexNet 基本上就是这样的一种网络，但有一千个不同的对象类别，并且大约有七层特征检测器。
226 00:21:25,788 --> 00:21:32,815 讲者 SPEAKER_00：它还使用了由 Yann LeCun 开发的其他一些东西，即卷积网络。
227 00:21:33,516 --> 00:21:35,978 讲者 SPEAKER_00：我现在将尝试解释这些，因为它们非常重要。
228 00:21:38,759 --> 00:21:43,644 说话人 SPEAKER_00: 记得我说过你可以通过检查两行来制作一个鸟喙检测器，对吧？
229 00:21:44,096 --> 00:21:50,487 说话人 SPEAKER_00: 通过有两行这样的，如果你看到这两个特征检测器，那么你就制作一个喙检测器。
230 00:21:50,967 --> 00:21:53,310 说话人 SPEAKER_00: 但那只是针对特定位置，对吧？
231 00:21:54,392 --> 00:22:02,644 说话人 SPEAKER_00: 在卷积神经网络中，当你为某个位置制作一个特征检测器时，你会为图像中的所有位置制作相同的特征检测器。
232 00:22:04,366 --> 00:22:08,973 说话人 SPEAKER_00：那么，如果在这里用喙进行训练，当它在学习时，
233 00:22:09,375 --> 00:22:11,518 说话人 SPEAKER_00：它真的会说，我需要为那个安装一个喙检测器。
234 00:22:11,958 --> 00:22:13,839 说话人 SPEAKER_00：所以它学会了一个检测这个喙的特征。
235 00:22:14,461 --> 00:22:18,384 说话人 SPEAKER_00：它会自动为图像中的其他所有位置制作副本。
236 00:22:19,065 --> 00:22:24,169 说话人 SPEAKER_00：所以如果现在这只鸟出现在不同的位置，它将具有特征检测器来识别它。
237 00:22:25,530 --> 00:22:30,915 说话人 SPEAKER_00：所以将特征检测器复制到每个位置的这种想法，本质上是一个卷积网络。
238 00:22:32,596 --> 00:22:37,000 说话人 SPEAKER_00：这使得整个系统在位置上的泛化能力大大提高。
239 00:22:37,040 --> 00:22:39,163 说话人 SPEAKER_00：现在它可以应对位置变化的情况。
240 00:22:39,666 --> 00:22:42,371 说话人 SPEAKER_00: 因为它在每个位置都有所有这些特征检测器的副本。
241 00:22:43,834 --> 00:23:00,619 说话人 SPEAKER_00: 而且有了卷积网络和多层特征，亚历克斯在一种叫做图形处理单元的东西上非常高效地编程了所有这些，它是为计算机图形开发的，但就像一个微型超级计算机。
242 00:23:01,461 --> 00:23:06,670 说话人 SPEAKER_00: 它可以在很多不同的过程中同时进行大量的计算。
243 00:23:07,307 --> 00:23:10,613 说话人 SPEAKER_00: 因此，与普通计算机相比，它提高了大约 30 倍。
244 00:23:11,473 --> 00:23:14,817 说话人 SPEAKER_00: 因子 30 大约相当于计算机领域 10 年的进步。
245 00:23:15,479 --> 00:23:18,864 说话人 SPEAKER_00: 突然间，我们在计算能力方面可以跃进 10 年。
246 00:23:20,705 --> 00:23:25,153 说话人 SPEAKER_00: 编程这些 GPU 板子非常困难。
247 00:23:26,134 --> 00:23:29,578 说话人 SPEAKER_00: 亚历克斯设法编程了两块板子进行协作，这更加困难。
248 00:23:31,520 --> 00:23:34,986 说话人 SPEAKER_00: 最后一个成分是 ImageNet 数据集。
249 00:23:35,489 --> 00:23:47,625 说话人 SPEAKER_00: 于是有人叫 Fei-Fei Li 和她的合作者收集了一大套图片，然后举办了一场公开竞赛，竞赛中有大约一百万张图片，包含一千种不同的物体。
250 00:23:47,664 --> 00:23:49,968 说话人 SPEAKER_00: 所以每种物体大约有一千个例子。
251 00:23:50,709 --> 00:23:52,652 说话人 SPEAKER_00: 你需要学会识别这些物体。
252 00:23:53,173 --> 00:23:57,417 说话人 SPEAKER_00: 然后测试集将包含不同的图像，这些图像也包含那些物体。
253 00:23:57,699 --> 00:23:59,641 说话人 SPEAKER_00: 因此，您需要对不同的图像进行泛化。
254 00:24:00,522 --> 00:24:03,066 说话人 SPEAKER_00: 结果证明，当时发明的最佳计算机视觉技术
255 00:24:03,383 --> 00:24:10,309 说话人 SPEAKER_00: 的错误率达到了 25%，而 Alex 的错误率是 15%。
256 00:24:11,611 --> 00:24:13,894 说话人 说话人_00: 自那以后，错误率已经下降到大约3%。
257 00:24:14,153 --> 00:24:15,115 说话人 说话人_00: 自那以后，情况好多了。
258 00:24:15,494 --> 00:24:30,369 说话人 说话人_00: 但这是一个巨大的飞跃，计算机视觉领域的人们感到非常惊讶，他们大多数人都表现得非常令人钦佩，就是说，我们从未想过这会奏效，但是，它奏效了，所以我们将改变我们之前所做的事情。
259 00:24:30,686 --> 00:24:32,229 说话人 说话人_00: 这就是科学家们通常不会做的事情。
260 00:24:32,429 --> 00:24:35,511 说话人 SPEAKER_00：科学家们通常只是随着年龄的增长而抱怨这些新东西是无稽之谈。
261 00:24:35,952 --> 00:24:41,199 说话人 SPEAKER_01：那么您如何描述自那时以来在人工智能领域所看到的创新速度？
262 00:24:41,939 --> 00:24:43,361 说话人 SPEAKER_00：它只是越来越快。
263 00:24:43,661 --> 00:24:53,992 说话人 SPEAKER_00：所以如果那时问我，这些神经网络何时能进行比现有技术更好的机器翻译，我会说可能需要 10 年。
264 00:24:54,614 --> 00:24:58,617 说话人 SPEAKER_00：因为机器翻译就是这样一种东西，
265 00:24:58,597 --> 00:25:08,713 说话人 SPEAKER_00：如果你有一个全部关于处理符号串的理论，那么机器翻译就是你的理想问题，因为你有一个语言中的符号串，你必须产生另一个语言的符号串。
266 00:25:09,515 --> 00:25:13,622 说话人 SPEAKER_00：符号派的人认为，嗯，你只是在操作字符串来完成这个。
267 00:25:14,943 --> 00:25:23,678 说话人 SPEAKER_00：神经网络派的人认为，你必须将这个符号串转换成这些大的神经网络活动模式，然后你还得将其转换回符号输出。
268 00:25:25,041 --> 00:25:35,675 说话人 SPEAKER_00：我对机器翻译在短短几年内变得如此出色感到非常惊讶，然后在另一年或两年内，谷歌开始使用它，这极大地提高了机器翻译的质量。
269 00:25:36,396 --> 00:25:48,113 说话人 SPEAKER_00：比如，在中文等语言中，这是从记忆中来的，但计算机翻译和人工翻译之间的差距在短短一夜之间就缩小了一半。
270 00:25:49,307 --> 00:25:50,368 说话人 SPEAKER_00：我认为是中文做到了这一点。
271 00:25:51,029 --> 00:25:52,932 说话人 SPEAKER_00：但在许多语言中，它只是让翻译变得更好。
272 00:25:53,313 --> 00:25:56,317 说话人 说话人_00：从那时起，显然已经好多了。
273 00:25:56,917 --> 00:25:59,280 说话人 说话人_00：但到2015年，它已经工作得相当好了。
274 00:26:00,221 --> 00:26:01,203 说话人 说话人_00：这真的让我很惊讶。
275 00:26:01,304 --> 00:26:02,184 说话人 说话人_00：只用了三年时间。
276 00:26:04,728 --> 00:26:07,152 说话人 SPEAKER_02：你说你对创新的步伐感到惊讶。
277 00:26:07,632 --> 00:26:11,738 说话人 SPEAKER_02：第一次使用像 ChatGPT 这样的大型语言模型时，你有什么想法？
278 00:26:12,178 --> 00:26:13,078 说话人 SPEAKER_02：我们是否让你感到惊讶？
279 00:26:13,118 --> 00:26:18,926 说话人 SPEAKER_00：我只是对它的好感到震惊。
280 00:26:20,019 --> 00:26:25,732 说话人 SPEAKER_00：它给出的回答非常连贯，并且可以进行一些推理。
281 00:26:26,334 --> 00:26:29,480 说话人 SPEAKER_00：虽然目前推理还不够复杂，但会越来越好。
282 00:26:30,261 --> 00:26:38,721 说话人 SPEAKER_00：例如，我现在问的是 GPT-4，我向它提出了一个符号 AI 专家给我的谜题。
283 00:26:39,460 --> 00:26:40,800 说话人 SPEAKER_00：他认为 GPT-4 无法完成。
284 00:26:41,682 --> 00:26:44,125 说话人 SPEAKER_00: 我实际上把谜题做得更难了，它仍然能完成。
285 00:26:44,785 --> 00:26:45,945 说话人 SPEAKER_00: 所以这个谜题是这样的。
286 00:26:46,707 --> 00:26:51,131 说话人 SPEAKER_00: 我家里的房间要么是白色，要么是蓝色，要么是黄色。
287 00:26:53,773 --> 00:26:56,376 说话人 SPEAKER_00: 黄色油漆在一年内会褪成白色。
288 00:26:57,597 --> 00:27:00,461 说话人 说话人_00：两年后，我希望所有房间都是白色的。
289 00:27:00,780 --> 00:27:01,461 说话人 说话人_00：我应该做什么？
290 00:27:04,505 --> 00:27:07,948 说话人 说话人_00：一个人类可能会说，你应该把蓝色的房间刷成白色。
291 00:27:09,025 --> 00:27:15,372 说话人 说话人_00：GPT-4 说的是你应该把蓝色的房间刷成黄色，但这也可以，因为黄色会逐渐变成白色。
292 00:27:16,374 --> 00:27:21,118 说话人 SPEAKER_00：我看不出它是如何做到这一点而不理解问题的。
293 00:27:21,839 --> 00:27:25,663 说话人 SPEAKER_00：它只是预测下一个词并使用统计学的想法。
294 00:27:26,766 --> 00:27:32,231 说话人 SPEAKER_00：在某种程度上这是真的，但并不是大多数人理解的统计学的意思。
295 00:27:33,410 --> 00:27:42,280 说话人 SPEAKER_00：它从数据中找出如何提取句子的意义，并使用句子的意义来预测下一个词。
296 00:27:42,761 --> 00:27:45,546 说话人 SPEAKER_00: 它真的能理解，这相当令人震惊。
297 00:27:46,646 --> 00:27:51,834 说话人 SPEAKER_01: 那么，你对更广泛的反应，公众对 Chat GPT 的反应感到惊讶吗？
298 00:27:53,295 --> 00:27:56,900 说话人 SPEAKER_00: 嗯，鉴于它工作得很好，我想公众的反应并不令人惊讶。
299 00:27:57,160 --> 00:27:58,422 说话人 SPEAKER_00: 但有趣的是，
300 00:27:59,633 --> 00:28:02,576 说话人 说话人_00：大多数人不会说，这不懂。
301 00:28:03,337 --> 00:28:06,020 说话人 说话人_00：他们说，哇，它理解了我说的，并给了我一个连贯的回答。
302 00:28:06,402 --> 00:28:07,303 说话人 说话人_00：我能用它做什么？
303 00:28:08,505 --> 00:28:10,948 说话人 说话人_00：我认为大多数人对此的看法是正确的。
304 00:28:12,048 --> 00:28:15,294 说话人 SPEAKER_00: 当然，它可以用于无数的事情。
305 00:28:16,035 --> 00:28:20,059 说话人 SPEAKER_00: 我认识一个人，他负责处理医疗服务方面的投诉信。
306 00:28:22,022 --> 00:28:26,448 说话人 SPEAKER_00: 以前他用来撰写一封解决问题的信件要花 25 分钟。
307 00:28:27,068 --> 00:28:29,251 说话人 SPEAKER_00: 现在他只需将问题键入
308 00:28:30,598 --> 00:28:33,584 说话人 SPEAKER_00: GPT-4 写信。
309 00:28:34,124 --> 00:28:38,711 说话人 SPEAKER_00: 然后他只看了一下信，决定是否可以发送，现在这需要他五分钟。
310 00:28:39,291 --> 00:28:41,154 说话人 SPEAKER_00: 所以他现在效率提高了五倍。
311 00:28:42,176 --> 00:28:46,242 说话人 SPEAKER_00: 这将在各个地方发生，就像律师助理也会这样。
312 00:28:47,044 --> 00:28:48,747 说话人 SPEAKER_00: 程序员们已经变得那样了。
313 00:28:49,208 --> 00:28:55,897 说话人 SPEAKER_00: 如果程序员得到像 GPT-4 这样的帮助，他们可以更有效率，因为它知道如何编程。
314 00:28:56,923 --> 00:29:01,549 说话人 SPEAKER_00: 你可能认为它只是因为看到了大量的程序才会知道如何编程。
315 00:29:03,732 --> 00:29:06,857 说话人 SPEAKER_00: 所以我有一个非常聪明、编程能力很强的前研究生。
316 00:29:08,179 --> 00:29:12,125 说话者 SPEAKER_00：他进行了一个小实验，他叫做 Radford Neal。
317 00:29:12,565 --> 00:29:22,459 说话者 SPEAKER_00：他使用了 GPT-4，并定义了一种具有非常不寻常语法的新的编程语言。
318 00:29:23,839 --> 00:29:30,906 说话者 SPEAKER_00：在仅用文本定义了这种编程语言给 GPT-4 之后，他然后给它一个程序，问它会做什么？
319 00:29:32,127 --> 00:29:33,128 说话者 SPEAKER_00：它正确地回答了。
320 00:29:34,170 --> 00:29:39,496 说话人 SPEAKER_00：所以基本上，它能够理解一种新编程语言的定义，并找出该语言中的程序会做什么。
321 00:29:40,856 --> 00:29:46,461 说话人 SPEAKER_00：再次强调，在这种情境下，它只是预测下一个单词的想法是没有意义的。
322 00:29:46,501 --> 00:29:48,284 说话人 SPEAKER_00：它必须理解正在发生的事情。
323 00:29:49,204 --> 00:29:52,107 说话人 SPEAKER_01：那么您认为哪些机会最有前景？
324 00:29:53,067 --> 00:29:56,374 说话人 SPEAKER_01：这种 AI 在造福社会方面有何作用？
325 00:29:58,337 --> 00:30:00,182 说话人 SPEAKER_00：很难挑选一个，因为有太多。
326 00:30:01,003 --> 00:30:07,818 说话人 SPEAKER_00：比如，任何涉及输出文本的工作都会大幅提高生产力。
327 00:30:09,030 --> 00:30:12,056 说话人 SPEAKER_00：提高生产力会带来各种问题。
328 00:30:12,076 --> 00:30:17,242 说话人 SPEAKER_00：在我们的社会中，提高生产力并不一定是好事，因为它可能会让富人更富，穷人更穷。
329 00:30:17,903 --> 00:30:21,470 说话人 SPEAKER_00：但在一个公正的社会里，仅仅提高生产力应该是一件好事。
330 00:30:22,171 --> 00:30:23,413 说话人 SPEAKER_00：所以会有这样的事情。
331 00:30:24,233 --> 00:30:26,758 说话人 SPEAKER_00：这对于做出预测来说非常美妙。
332 00:30:26,798 --> 00:30:29,622 说话人 说话人_00：预测天气将更准确。
333 00:30:30,394 --> 00:30:31,757 说话人 说话人_00：人们还不知道具体会提高多少。
334 00:30:32,136 --> 00:30:35,301 说话人 说话人_00：但它已经更擅长预测洪水了。
335 00:30:36,063 --> 00:30:37,364 说话人 说话人_00：它可以预测地震。
336 00:30:38,105 --> 00:30:40,689 说话人 SPEAKER_00：它可以设计新的纳米材料。
337 00:30:41,390 --> 00:30:44,493 说话人 SPEAKER_00：所以对于像太阳能电池板这样的东西，你希望能够设计新的纳米材料。
338 00:30:44,835 --> 00:30:46,256 说话人 SPEAKER_00：或者对于超导性。
339 00:30:46,276 --> 00:30:49,079 说话人 SPEAKER_00：我不知道它是否已经用于超导性，但它很可能已经如此。
340 00:30:49,780 --> 00:30:52,605 说话人 说话人_00：你希望它在高温下。
341 00:30:52,585 --> 00:30:55,069 说话人 说话人_00：它在设计药物方面真的很擅长。
342 00:30:56,471 --> 00:31:01,161 说话人 说话人_00：也就是说，寻找会与某些特定分子结合的分子。
343 00:31:02,222 --> 00:31:05,469 说话人 说话人_00：DeepMind 曾用它创建了 AlphaFold。
344 00:31:06,810 --> 00:31:09,656 说话人 SPEAKER_00：那不是一个聊天机器人，那只是深度学习。
345 00:31:11,019 --> 00:31:15,166 说话人 SPEAKER_00：但深度学习的基本技术已经
346 00:31:16,817 --> 00:31:24,827 说话人 SPEAKER_00：基本上解决了如何从蛋白质的碱基序列中推断其形状的问题。
347 00:31:25,288 --> 00:31:27,231 说话人 SPEAKER_00：如果你知道它采取的形状，你就知道它的功能。
348 00:31:27,731 --> 00:31:30,194 说话人 SPEAKER_00：我认为聊天机器人将无处不在地被使用。
349 00:31:31,917 --> 00:31:33,680 说话人 SPEAKER_01：我们谈论了很多关于医疗保健的话题。
350 00:31:33,700 --> 00:31:38,586 说话人 SPEAKER_01：我的意思是，你谈论了药物发现，但医疗保健也是一个可以真正受益的领域。
351 00:31:38,605 --> 00:31:38,826 说话人 SPEAKER_00：是的。
352 00:31:39,567 --> 00:31:46,757 说话人 SPEAKER_00：在解读医学扫描方面，比如如果你做一个 CT 扫描，CT 扫描中有很多信息，
353 00:31:47,210 --> 00:32:01,724 说话人 SPEAKER_00：而这些信息并没有被利用，大多数医生也不知道这些信息是什么，这将能够从 CT 扫描中获得更多信息，同时还能与医生竞争，说出你有什么癌症或它长得有多大。
354 00:32:01,744 --> 00:32:10,733 说话人 SPEAKER_00：目前，例如，当医生告诉你癌症的大小，你会得到一个数字，比如它是三厘米，一个月前是两厘米。
355 00:32:11,895 --> 00:32:15,259 说话人 SPEAKER_00：现在，如果这东西看起来像章鱼，那么这个数字就不是很有用，对吧？
356 00:32:17,112 --> 00:32:21,938 说话人 SPEAKER_00: 神经网络将能够更好地理解癌症的体积及其变化。
357 00:32:23,318 --> 00:32:25,642 说话人 SPEAKER_00: 因此，在那方面将会非常巨大。
358 00:32:26,202 --> 00:32:30,949 说话人 SPEAKER_00: 而且它已经达到人类水平，对于许多癌症扫描，它将会变得更好。
359 00:32:32,349 --> 00:32:34,873 说话人 SPEAKER_00: 它将非常适合诊断疾病。
360 00:32:35,193 --> 00:32:43,103 发言人 SPEAKER_00：目前，北美有大量人因医生误诊而死亡。
谷歌正在开发一个名为 MedPalm2 的系统，该系统能够进行诊断，现在我认为它的表现已经超过了普通医生。
我不太确定这件事，因为我已经不在谷歌了，而且这件事发生得很近。
363 00:33:00,159 --> 00:33:04,262 说话者 说话者_00：但它的确可以与医生相提并论，而且它会迅速变得更好。
364 00:33:04,282 --> 00:33:09,407 说话人 SPEAKER_00：您难道不想拥有一个全科医生，一个家庭医生吗？
365 00:33:10,148 --> 00:33:12,111 说话人 SPEAKER_00：您遇到一些罕见疾病，
366 00:33:12,394 --> 00:33:16,961 说话人 SPEAKER_00：您希望您的家庭医生已经看过数百例这种罕见疾病的病例。
367 00:33:17,500 --> 00:33:18,923 说话人 SPEAKER_00：而 MedPalm2 将会是这样的。
368 00:33:19,523 --> 00:33:23,368 说话人 SPEAKER_00：最终它将仅在诊断方面变得更好。
369 00:33:25,652 --> 00:33:28,474 说话人 SPEAKER_02：听起来人工智能将带来许多重要益处。
370 00:33:29,537 --> 00:33:32,580 说话人 SPEAKER_02：但你已表达了对当前创新速度的担忧。
371 00:33:33,340 --> 00:33:33,761 说话人 SPEAKER_00：为什么？
372 00:33:34,315 --> 00:33:44,626 说话人 SPEAKER_00：好吧，所以像 50 年一样，我（认为）嗯，49 年来，为了使数字模型更好，我们需要让它们更像大脑工作。
373 00:33:45,327 --> 00:33:55,480 说话人 SPEAKER_00：所以我一直在观察大脑所做的，而数字模型没有做的事情，比如以临时方式快速改变连接强度，这可以使数字模型变得更好。
374 00:33:57,805 --> 00:34:07,291 说话人 SPEAKER_00：而且最近，我意识到因为这些数字模型有一种蜂群思维，当一个智能体学习到某样东西时，所有其他智能体都知道。
375 00:34:07,863 --> 00:34:10,947 说话人 SPEAKER_00：它们实际上可能已经比生物智能更优秀了。
376 00:34:11,829 --> 00:34:18,420 说话人 SPEAKER_00: 我完全改变了看法，不再认为他们需要很长时间才能做到大脑能做的一切。
377 00:34:19,101 --> 00:34:23,931 说话人 SPEAKER_00: 我认为至少还需要 30 到 50 年他们才能超过我们，这是我直到最近才有的想法。
378 00:34:24,952 --> 00:34:29,139 说话人 SPEAKER_00: 几个月前我突然意识到，也许他们已经超过我们了。
379 00:34:29,599 --> 00:34:31,103 说话人 SPEAKER_00: 他们只是规模更小。
380 00:34:31,420 --> 00:34:34,864 说话人 SPEAKER_00: 当它们变得更大时，它们会比我们更聪明。
381 00:34:35,626 --> 00:34:36,666 说话人 SPEAKER_00: 那真的很可怕。
382 00:34:36,686 --> 00:34:43,396 说话人 SPEAKER_00: 意见突然改变，不再是 30 到 50 年，而是 5 年到 20 年左右。
383 00:34:44,157 --> 00:34:51,927 说话人 SPEAKER_00: 因此，我们现在必须认真对待我们现在将如何处理这个问题，这些事物可能会比我们更聪明。
384 00:34:52,260 --> 00:34:53,802 说话人 说话人_00：这是一个充满巨大不确定性的时代。
385 00:34:53,842 --> 00:34:55,364 说话人 说话人_00：没有人真正知道会发生什么。
386 00:34:56,045 --> 00:34:59,869 说话人 说话人_00：也许事情会停滞不前，也许它们不会比我们更聪明。
387 00:34:59,889 --> 00:35:01,110 说话人 说话人_00：但我并不真的相信这一点。
388 00:35:01,451 --> 00:35:02,871 说话人 SPEAKER_00: 我认为他们将会比我们更聪明。
389 00:35:03,231 --> 00:35:12,902 说话人 SPEAKER_00: 但也许当他们比我们更聪明的时候，我们能够让他们保持善良，我们能够让他们比关心自己更多地去关心他人，不像人类。
390 00:35:13,362 --> 00:35:14,023 说话人 SPEAKER_00: 但也许不会。
391 00:35:14,844 --> 00:35:18,387 说话人 SPEAKER_00: 因此我们需要开始认真思考这些问题。
392 00:35:18,527 --> 00:35:20,309 说话人 SPEAKER_00：我对这些问题并不精通。
393 00:35:21,572 --> 00:35:23,875 说话人 SPEAKER_00：我只是这些学习算法的专家。
394 00:35:25,056 --> 00:35:29,501 说话人 SPEAKER_00：我突然意识到这些超级智能可能很快就会到来。
395 00:35:30,541 --> 00:35:38,849 说话人 SPEAKER_00：我只是发出警报，让人们听听那些长期思考如何阻止他们夺取控制权的专家们。
396 00:35:40,251 --> 00:35:45,797 说话人 SPEAKER_00：我希望政治家们能听听那些人的意见，而不是说，嗯，嗯，他们算是科幻派。
397 00:35:46,297 --> 00:35:47,157 说话人 SPEAKER_00：这永远都不会发生。
398 00:35:48,067 --> 00:35:54,434 说话人 SPEAKER_01：有没有什么特别的时刻，你说是最近，你对这个看法有所改变？
399 00:35:54,875 --> 00:36:04,507 说话人 SPEAKER_00：我正在开发适用于生物系统的学习算法，这些算法可以在生物系统中运行，而不使用反向传播。
400 00:36:05,688 --> 00:36:10,614 说话人 说话人_00：我无法让它们像我们在这些数字系统中运行的反向传播算法那样工作得很好。
401 00:36:11,657 --> 00:36:18,606 说话人 说话人_00：对于小型网络来说，它们可以工作，但当规模扩大时，数字网络总是比生物网络扩展得更好。
402 00:36:19,646 --> 00:36:21,829 说话人 说话人_00：我突然想到，可能不是我的错。
403 00:36:22,251 --> 00:36:27,036 说话人 说话人_00：可能不是我的学习算法只是一个差劲的学习算法。
404 00:36:27,056 --> 00:36:29,559 说话人 SPEAKER_00：可能就是这些数字系统本身就更好。
405 00:36:31,440 --> 00:36:37,387 说话人 SPEAKER_00：就在那时，我突然改变了关于我们何时会得到超级智能的看法。
406 00:36:37,407 --> 00:36:41,293 说话人 SPEAKER_00：然后我跟我的一些前学生和前同事谈了谈。
407 00:36:41,780 --> 00:36:44,204 说话人 SPEAKER_00：其中一些人鼓励我公开这个想法。
408 00:36:45,085 --> 00:36:47,630 说话人 SPEAKER_00：不是因为我想推荐任何解决方案。
409 00:36:49,054 --> 00:36:52,199 说话人 SPEAKER_00：并不是说少烧碳一切就会好起来。
410 00:36:54,244 --> 00:36:56,547 说话人 SPEAKER_00：而是因为他们认为
411 00:36:56,831 --> 00:36:58,134 说话人 SPEAKER_00：我在这个领域是出了名的。
412 00:36:58,233 --> 00:37:12,990 说话者 SPEAKER_00：如果我说超级智能可能很快就会到来，政客们可能会开始相信这是可能的，并开始认真倾听那些长期思考如何防止这些事物获得控制的研究人员。
413 00:37:14,012 --> 00:37:23,362 说话者 SPEAKER_01：那么从您的角度来看，政府在确保这些人工智能以负责任的方式发展方面可以发挥什么作用？
414 00:37:23,882 --> 00:37:29,067 说话者 SPEAKER_00：所以，有各种各样的风险，其他人已经谈了很多，我特别不想谈论，比如...
415 00:37:29,637 --> 00:37:33,961 说话者 SPEAKER_00：它们会夺走工作，并增加贫富差距。
416 00:37:34,762 --> 00:37:37,847 说话人 SPEAKER_00: 他们将使人们无法判断新闻是真是假。
417 00:37:38,827 --> 00:37:45,657 说话人 SPEAKER_00: 他们将鼓励社会分裂成两个相互不听取对方意见、持有完全对立观点的战争阵营。
418 00:37:46,898 --> 00:37:49,501 说话人 SPEAKER_00: 他们将制造旨在杀人的人形战斗机器人。
419 00:37:50,081 --> 00:37:52,425 说话人 SPEAKER_00: 所有这些都是众所周知的风险，我并没有谈论。
420 00:37:52,465 --> 00:37:54,246 说话人 SPEAKER_00: 我并不是认为它们不重要。
421 00:37:54,266 --> 00:37:55,708 说话人 SPEAKER_00: 我认为它们可能更加紧迫。
422 00:37:56,929 --> 00:37:59,052 说话人 SPEAKER_00: 但很多人都在谈论那些风险。
423 00:37:59,523 --> 00:38:03,306 说话人 SPEAKER_00: 我所谈论的风险是这些事物最终会变得比我们聪明并最终接管一切的风险。
424 00:38:04,309 --> 00:38:10,556 说话人 说话人_00：为此风险，政府可能可以做一些事情，因为没有人想看到那样。
425 00:38:12,197 --> 00:38:16,023 说话人 说话人_00：如果排除这些超级智能，没有人想要那样。
426 00:38:16,983 --> 00:38:24,012 说话人 说话人_00：因此，所有不同的政府都应该能够达成一致
427 00:38:24,126 --> 00:38:27,797 说话人 说话人_00：他们应该能够共同努力防止这种情况，因为这符合他们的利益。
428 00:38:28,239 --> 00:38:29,061 说话人 SPEAKER_00: 这之前已经发生过。
429 00:38:29,202 --> 00:38:37,849 说话人 SPEAKER_00: 即使在冷战期间，美国和俄罗斯也能共同努力，试图防止发生全球核战争，因为这对所有人来说都很糟糕。
430 00:38:38,891 --> 00:38:46,262 说话人 SPEAKER_00: 对于这种生存威胁，如果可能预防，所有人都应该共同努力来限制它。
431 00:38:46,782 --> 00:38:54,954 说话人 SPEAKER_00: 我不知道是否可以预防它，但至少我们应该能够在应对这一特定威胁，即人工智能接管人类的生存威胁上实现国际合作。
432 00:38:55,956 --> 00:39:03,027 说话人 SPEAKER_00：我认为应该做的一件事是，无论这些内容在哪里开发，尤其是这些大型聊天机器人，
433 00:39:04,693 --> 00:39:15,190 说话人 SPEAKER_00：政府应该鼓励公司投入大量资源，因为这些事物变得越来越智能，进行实验以找出如何控制它们。
434 00:39:16,351 --> 00:39:26,786 说话人 SPEAKER_00：所以他们应该研究这些事物可能会如何尝试逃脱，并在这方面进行实证研究，投入大量资源，因为这是我们唯一的机会。
435 00:39:27,762 --> 00:39:32,487 说话人 SPEAKER_00：在他们变得超级智能之前，我们也许可以进行实验，看看会出什么问题。
436 00:39:33,429 --> 00:39:37,355 说话者 SPEAKER_00：我坚信你需要这方面的实证数据。
437 00:39:37,375 --> 00:39:42,021 说话者 SPEAKER_00：你不能让哲学家、政治家和立法者随意制定规则。
438 00:39:42,702 --> 00:39:47,547 说话者 SPEAKER_00：你需要对这些事物进行实证研究，看看它们是如何出错的，以及你如何控制它们。
439 00:39:48,608 --> 00:39:50,492 说话者 SPEAKER_00：这只能由开发它们的人来完成。
440 00:39:51,893 --> 00:39:56,739 说话人 SPEAKER_00: 既然无法阻止发展，最好的办法就是
441 00:39:57,074 --> 00:40:08,155 说话人 SPEAKER_00: 以某种方式让政府对这些公司施加很大压力，投入大量资源去实证研究如何在他们不如我们聪明时将它们控制住。
442 00:40:09,356 --> 00:40:15,527 说话人 SPEAKER_01: 你如何看待这些大型科技公司在这类发展中所扮演的角色？
443 00:40:15,989 --> 00:40:18,693 说话人 SPEAKER_01: 他们会在没有那种政府监管的情况下这样做吗？
444 00:40:19,079 --> 00:40:27,675 说话人 SPEAKER_00：很多大公司的人，我所知道的那些大公司的高级管理人员都非常担心这个问题，并且确实投入了工作。
445 00:40:28,677 --> 00:40:29,780 说话人 SPEAKER_00：他们对这一点非常关心。
446 00:40:30,561 --> 00:40:32,626 说话人 SPEAKER_00：但他们有对股东的义务。
447 00:40:33,507 --> 00:40:35,572 说话人 SPEAKER_00：我认为这是为了获得高额利润。
448 00:40:36,534 --> 00:40:40,041 说话人 SPEAKER_00: 短期内获得巨大利润，
449 00:40:40,391 --> 00:40:44,760 说话人 SPEAKER_00: 并不与投入大量精力确保其安全的行为相吻合。
450 00:40:45,824 --> 00:40:47,146 说话人 SPEAKER_00: 所以你会在所有行业中看到这一点。
451 00:40:47,847 --> 00:40:59,632 说话人 SPEAKER_00: 在美国的铁路行业中，拥有告知轮子锁定的安全装置需要花钱，大型铁路公司宁愿发生事故也不愿这么做。
452 00:40:59,612 --> 00:41:10,929 说话人 SPEAKER_00：我知道的谷歌是一家大公司，但它并不完全是这样，因为它明白如果发生不好的事情，它将遭受巨大的声誉损失。
453 00:41:11,431 --> 00:41:13,554 说话人 SPEAKER_00：这就是为什么谷歌没有发布这些聊天机器人。
454 00:41:13,574 --> 00:41:14,454 说话人 SPEAKER_00：它将它们保留为私密。
455 00:41:14,755 --> 00:41:16,697 说话人 SPEAKER_00：它不想让它们在世界各地供人们玩耍。
456 00:41:17,259 --> 00:41:26,632 说话人 SPEAKER_00: 它想利用它们来给你提供更好的搜索结果，或者帮你完成 Gmail，但不是把它们给人们去玩。
457 00:41:27,472 --> 00:41:33,440 说话人 SPEAKER_00: 直到 OpenAI 和微软把它们推出来，然后谷歌不得不竞争。
458 00:41:34,101 --> 00:41:39,449 说话人 SPEAKER_00: 但大公司的大人物们真的很在乎他们的声誉，以及不想产生不良影响。
459 00:41:40,451 --> 00:41:49,663 说话人 SPEAKER_00: 但也许可以通过政府采取行动，坚持要求他们在这方面投入大量工作，来让他们更加关注安全问题。
460 00:41:50,545 --> 00:41:52,367 说话人 SPEAKER_00: 还可能有其他事情会发生，比如
461 00:41:54,085 --> 00:42:07,086 说话人 SPEAKER_00: 在公司内部让人们专注于长期存在的威胁是非常困难的，因为他们是由公司支付的，存在利益冲突，这也是我离开谷歌的原因之一。
462 00:42:07,527 --> 00:42:10,992 说话人 SPEAKER_00: 不是因为谷歌做了什么错事，只是我不想有任何利益冲突。
463 00:42:13,376 --> 00:42:19,688 说话人 SPEAKER_00: 大型公司肯定可以做的一件事是，投入更多资金支持研究这些问题的基金会。
464 00:42:20,208 --> 00:42:27,518 说话人 SPEAKER_00: 例如，谷歌投入了 3 亿美元到名为 Anthropic 的基金会，该基金会正在研究这些事物。
465 00:42:29,579 --> 00:42:30,902 说话人 SPEAKER_00: 他们可以投入更多的资金。
466 00:42:32,463 --> 00:42:46,822 说话人 SPEAKER_01: 我很好奇您会给那些刚刚进入这个领域的研究人员什么建议或指导，他们想要确保自己在推进这个领域的同时，也要以负责任的方式进行。
467 00:42:48,777 --> 00:42:57,739 说话人 SPEAKER_00: 好吧，我给出的一个建议是看看有多少人在努力让这些事物变得更好，有多少人在努力防止它们失控。
468 00:42:57,798 --> 00:43:03,353 说话人 SPEAKER_00：你会看到有 99 个人在努力让它们变得更好，而一个人在努力防止它们失控。
469 00:43:03,954 --> 00:43:06,280 说话人 SPEAKER_00：那么你可以在哪里产生最大的影响呢？
470 00:43:06,260 --> 00:43:09,123 说话人 SPEAKER_00：可能是在防止它们失控的工作上。
471 00:43:09,143 --> 00:43:10,563 说话人 SPEAKER_00：这是第一条建议。
472 00:43:11,405 --> 00:43:23,655 说话人 SPEAKER_00：另一条建议是给年轻研究者的普遍建议，那就是寻找你认为大家都在做错的地方，并相信你的直觉。
473 00:43:24,697 --> 00:43:33,465 说话人 SPEAKER_00：直到你弄清楚为什么你的直觉是错误的，相信它，并在你认为别人都做错的时候，尝试其他不同的方法。
474 00:43:34,710 --> 00:43:37,054 说话人 SPEAKER_00：事实上，要么你有好的直觉，要么你没有。
475 00:43:37,675 --> 00:43:43,943 说话人 SPEAKER_00：如果你有好的直觉，你应该听从它们，跟随你的直觉，并在此基础上工作，直到你发现为什么它是错误的。
476 00:43:45,344 --> 00:43:49,289 说话人 SPEAKER_00：如果你有糟糕的直觉，那么你做什么其实都无关紧要，所以你不妨跟随你的直觉。
477 00:43:51,271 --> 00:43:55,737 说话人 SPEAKER_02：你描述的风险令人震惊，但你不能只是按一个开关就关闭它吗？
478 00:43:56,840 --> 00:43:59,643 说话人 SPEAKER_02：人类最终不是仍然处于控制之中吗？
479 00:44:00,483 --> 00:44:04,009 说话人 SPEAKER_00：认为我们可以简单地将其关闭是非常诱人的。
480 00:44:05,827 --> 00:44:08,010 说话人 SPEAKER_00：想象这些事物比我们聪明得多。
481 00:44:08,871 --> 00:44:12,074 说话人 SPEAKER_00：并且记住，他们会阅读马基雅维利所写的所有东西。
482 00:44:12,755 --> 00:44:16,697 说话人 SPEAKER_00：他们会阅读人类欺骗文献中的每一个例子。
483 00:44:17,739 --> 00:44:21,123 说话人 SPEAKER_00：他们会成为人类欺骗的真正专家，因为他们会从我们这里学到这一点。
484 00:44:22,324 --> 00:44:23,525 说话人 SPEAKER_00: 他们会比我们好得多。
485 00:44:24,346 --> 00:44:26,588 说话人 SPEAKER_00: 他们会像你操纵一个小孩一样。
486 00:44:27,509 --> 00:44:29,891 你知道，你会对你的小孩说，你想吃豌豆还是花椰菜？
487 00:44:30,351 --> 00:44:34,215 你的小孩实际上并不需要两者都要。
488 00:44:34,364 --> 00:44:39,449 说话人 SPEAKER_00: 他只考虑他最讨厌的，然后说他要选择另一个。
489 00:44:39,831 --> 00:44:46,679 说话人 SPEAKER_00: 所以如果他们能操纵人们，他们就能操纵人们去按按钮和拉杆。
490 00:44:47,960 --> 00:44:50,163 说话人 SPEAKER_00: 所以我们有一个很好的例子，唐纳德·特朗普。
491 00:44:50,262 --> 00:44:55,630 说话人 SPEAKER_00: 唐纳德·特朗普能操纵人们，所以他可以在没有亲自去过那里的情况下入侵华盛顿的一座建筑。
492 00:44:57,231 --> 00:45:00,996 说话人 SPEAKER_00: 你不必阻止唐纳德·特朗普做任何身体上的事情。
493 00:45:01,887 --> 00:45:04,128 说话人 SPEAKER_00: 你必须阻止他说话，以防止这种情况发生。
494 00:45:05,070 --> 00:45:06,030 说话人 SPEAKER_00: 这些是聊天机器人。
495 00:45:06,731 --> 00:45:12,557 说话人 SPEAKER_00: 所以，仅仅通过谈话，他们无法造成任何真正的伤害，因为这需要人们去造成伤害。
496 00:45:13,018 --> 00:45:17,483 说话人 SPEAKER_00：一旦你能操纵人们，那么你就能完成任何你想做的事情。
497 00:45:20,125 --> 00:45:26,010 说话人 SPEAKER_02：你致力于研究人类大脑的工作原理，并在人工智能发展中发挥了关键作用。
498 00:45:26,711 --> 00:45:28,653 说话人 SPEAKER_02：接下来对你来说，杰弗里·辛顿，是什么？
499 00:45:30,202 --> 00:45:38,070 说话人 SPEAKER_00：好的，我 75 岁了，我已经到了写程序不太擅长的地步，因为我总是忘记我正在使用的变量名和其他类似的事情。
500 00:45:38,711 --> 00:45:42,356 说话人 SPEAKER_00: 我忘了... 我复制粘贴了，却忘记修改粘贴的内容。
501 00:45:43,237 --> 00:45:47,762 说话人 SPEAKER_00: 所以我在编程上慢了很多，这非常令人烦恼。
502 00:45:48,202 --> 00:45:50,804 说话人 SPEAKER_00: 没有像以前那样做得好，这非常令人烦恼。
503 00:45:52,065 --> 00:45:58,572 说话人 SPEAKER_00: 很久以前我就决定，当我达到那个地步时，我会成为一个哲学家。
504 00:45:59,684 --> 00:46:01,188 说话者 SPEAKER_00：所以我将成为一个哲学家。
