1 00：00：00,031 --> 00：00：07,564 演讲者 SPEAKER_00：在他的众多头衔中，他是伦敦大学学院盖茨比分部的创始主任。
2 00：00：07,604 --> 00：00：15,997 演讲者 SPEAKER_00：他是多伦多大学的一名大学教授，也是最近被任命为 Google 的杰出研究员。
3 00：00：15,977 --> 00：00：27,652 演讲者 SPEAKER_00：当然，Jeff 是人工神经网络领域以及机器学习领域的创始人之一和主要人物。
4 00：00：27,672 --> 00：00：30,676 演讲者 SPEAKER_00：他来麻省理工学院也是一件大事。
5 00：00：30,757 --> 00：00：37,445 演讲者 SPEAKER_00：昨天在 CSAIL 上演讲的人，有 500 多人，基本上人们进不来。
6 00：00：37,426 --> 00：00：42,920 演讲者 SPEAKER_00：今天我们从 4 开始，因为我确信它会有类似的效果。
7 00：00：43,962 --> 00：00：54,709 演讲者 SPEAKER_00：还有一场小组讨论，Tommy 六点钟和 Jeff 在同一个房间里组织了一场关于通往智能之路的小组讨论。
8 00：00：55,582 --> 00：01：02,412 议长 SPEAKER_00：所以我就不多说了，因为我们都是来听他的。
9 00：01：02,874 --> 00：01：11,246 演讲者 SPEAKER_00：只是想说，成功的赎金可能是你在他的网页上看到的，上面写着给潜在学生的信息。
10 00：01：11,766 --> 00：01：20,521 演讲者 SPEAKER_00：我不会带任何新的研究生、访问学生、暑期学生或访客，所以请不要申请与我一起工作。
11 00：01：21,001 --> 00：01：21,421 演讲者 SPEAKER_00：杰夫？
12 00：01：27,933 --> 00：01：28,614 议长 SPEAKER_06：非常感谢。
13 00：01：28,834 --> 00：01：31,117 演讲者 SPEAKER_06：但是，如果你想在 Google 找到一份工作，那就另当别的事情了。
14 00：01：35,703 --> 00：01：39,028 演讲者 SPEAKER_06：所以我们使用的神经网络有很多问题。
15 00：01：40,390 --> 00：01：44,596 发言者 SPEAKER_06：他们在语音识别和物体识别方面非常成功，尤其是最近。
16 00：01：45,417 --> 00：01：51,965 演讲者 SPEAKER_06：但是有很多东西与大脑非常不同，我相信这些东西使它们无法发挥出应有的效果。
17 00：01：52,671 --> 00：01：58,703 演讲者 SPEAKER_06：所以有一件事是错误的，任何复杂的工程系统都应该有不同层次的结构。
18 00：01：58,724 --> 00：02：00,728 演讲者 SPEAKER_06：神经网络的结构层次非常少。
19 00：02：01,430 --> 00：02：10,207 演讲者 SPEAKER_06：有神经元，有神经元的层次，它们根本不像皮层中的层次，还有整个神经网络，大多数神经网络就是这样。
20 00：02：12,296 --> 00：02：17,445 演讲者 SPEAKER_06：这些神经网络中缺少的一件事是没有明确的实体概念。
21 00：02：18,266 --> 00：02：23,697 演讲者 SPEAKER_06：所以，对于在座的那些天生论者，我愿意承认，构建神经网络可能是值得的。
22 00：02：24,177 --> 00：02：26,762 演讲者 SPEAKER_06：这与存在实体的想法有关。
23 00：02：27,097 --> 00：02：29,480 演讲者 SPEAKER_06：我想把它构建到架构中。
24 00：02：29,501 --> 00：02：30,643 演讲者 SPEAKER_06：这就是这次演讲的内容。
25 00：02：31,364 --> 00：02：41,500 演讲者 SPEAKER_06：所以我想做的是把我们所谓的层中的神经元分成几个子集，让这些子集中的神经元活动代表同一实体的不同属性。
26 00：02：41,980 --> 00：02：49,492 演讲者 SPEAKER_06：我希望神经网络决定实体是什么以及它们如何相互交互，但我想要实体的那种内置属性。
27 00：02：51,058 --> 00：02：53,084 议长 SPEAKER_06：这就是我要向阿纳特主义者让步的全部内容。
28 00：02：54,608 --> 00：02：59,000 演讲者 SPEAKER_06：我还想推动一个想法，即迷你柱是你代表一个实体的地方。
29 00：03：00,623 --> 00：03：01,727 发言者 SPEAKER_06：每个小纵队一个实体。
30 00：03：03,007 --> 00：03：06,372 演讲者 SPEAKER_06：我要把人造网里的这个东西叫做胶囊。
31 00：03：07,054 --> 00：03：11,099 演讲者 SPEAKER_06：我的想法是胶囊将有两种实例化参数。
32 00：03：11,700 --> 00：03：17,191 发言者 SPEAKER_06：它将有一个显示其实体是否存在的函数，我将主要讨论图像，因此在当前输入图像中。
33 00：03：18,032 --> 00：03：22,759 演讲者 SPEAKER_06：然后它会有其他东西来描述这个实体的属性。
34 00：03：23,300 --> 00：03：26,064 演讲者 SPEAKER_06：如果实体不存在，你可以说出你喜欢的所有属性，没关系。
35 00：03：26,485 --> 00：03：29,570 演讲者 SPEAKER_06：但是，如果实体存在，那么你想知道它的属性。
36 00：03：29,550 --> 00：03：34,979 演讲者 SPEAKER_06：属性将是方向、大小、速度、颜色，诸如此类的各种东西，以及变形。
37 00：03：36,241 --> 00：03：49,705 演讲者 SPEAKER_06：胶囊输出到更高级别的胶囊，因为我希望它在一个层次结构中，是实体存在的概率和实体的广义姿势，在视觉中，它将是一个物体或物体的一部分。
38 00：03：52,250 --> 00：03：54,293 演讲者 SPEAKER_06：这包括各种参数。
39 00：03：57,259 --> 00：04：23,470 演讲者 SPEAKER_06：胶囊的作用在正常的神经网络中没有进行，这就是它们要做的基本计算，它们从较低级别的胶囊中预测它们的广义姿势应该是什么，所以关于多维向量，它们寻找紧密一致的预测。
40 00：04：24,461 --> 00：04：27,005 演讲者 SPEAKER_06：他们不在乎是否有很多预测是异常值。
41 00：04：27,507 --> 00：04：31,334 演讲者 SPEAKER_06：他们关心的是有一小部分预测是一致的。
42 00：04：32,797 --> 00：04：38,627 演讲者 SPEAKER_06：如果你在很多很多年前做过计算机视觉，那么它就会变得很愚蠢，这就是像 RANSAC 和 Hough 变换这样的东西。
43 00：04：40,250 --> 00：04：42,132 演讲者 SPEAKER_06：所以一个胶囊，
44 00：04：42,468 --> 00：04：46,894 演讲者 SPEAKER_06：它有一个高维的姿势空间，可能是 20 维或 50 维。
45 00：04：47,675 --> 00：04：49,139 演讲者 SPEAKER_06：所以这是那个空间的照片。
46 00：04：50,220 --> 00：04：52,144 演讲者 SPEAKER_06：所以说，这是一个 20 维的空间。
47 00：04：52,805 --> 00：04：55,088 演讲者 SPEAKER_06：下面有来自胶囊的预测。
48 00：04：55,127 --> 00：04：56,891 演讲者 SPEAKER_06：这些是预测。
49 00：04：56,990 --> 00：05：01,077 演讲者 SPEAKER_06：这些是预测这个胶囊体姿势的向量。
50 00：05：01,678 --> 00：05：03,882 演讲者 SPEAKER_06：我们想要的是能够找到这个集群的东西。
51 00：05：04,903 --> 00：05：07,968 演讲者 SPEAKER_06：它将输出什么，它将输出什么
52 00：05：08,100 --> 00：05：13,411 演讲者 SPEAKER_06：一种概率，说，嘿，我真的在场，因为你看，这不是偶然发生的。
53 00：05：13,670 --> 00：05：14,413 议长 SPEAKER_06：我真的在那儿。
54 00：05：14,773 --> 00：05：16,295 议长 SPEAKER_06：我有很多证据证明我存在。
55 00：05：17,298 --> 00：05：20,283 议长 SPEAKER_06：我可以输出它的重心，我可以忽略所有这些。
56 00：05：21,464 --> 00：05：23,709 演讲者 SPEAKER_06：现有的神经网络并不擅长这样做。
57 00：05：24,050 --> 00：05：27,797 议长 SPEAKER_06：他们也许能以某种方式伪造它，但他们不是为做那种事情而生的。
58 00：05：28,790 --> 00：05：31,994 演讲者 SPEAKER_06：现在关于高维巧合的重点是它们不是偶然发生的。
59 00：05：33,014 --> 00：05：43,547 演讲者 SPEAKER_06：即使我有一个六维事物，而且我有两个六维事物，每个维度的一致性都低于正常变化的 10%，那么就有百万分之一的几率。
60 00：05：45,108 --> 00：05：52,757 演讲者 SPEAKER_06：所以，如果你看到一些非常一致的事情，那就不是，如果你明白我的意思，这种巧合不可能只是巧合。
61 00：05：54,220 --> 00：05：55,961 议长 SPEAKER_06：肯定是有什么原因造成的。
62 00：05：56,649 --> 00：06：07,584 演讲者 SPEAKER_06：一个模型是，如果你考虑过滤情报信息，如果你看到各种各样的对话，比如说纽约或九月，那没有多大意义。
63 00：06：07,764 --> 00：06：18,639 议长 SPEAKER_06：但是，如果你看到一大堆对话，也许只有四个，比如说纽约，9 月 11 日，你看到其中的四个，你应该非常怀疑，因为现在这是一个高维度的巧合。
64 00：06：18,661 --> 00：06：25,509 演讲者 SPEAKER_06：即使还有很多其他的事情说芝加哥等等，但高维的事实是巧合，应该让你觉得有什么真实的事情发生了。
65 00：06：26,822 --> 00：06：43,586 演讲者 SPEAKER_06：好的，我要争论的是，我要从玛丽安的角度说，为了理解大脑，我们需要弄清楚什么是计算，我要给你一个大脑需要做这个计算的理由，然后我要说，是的，这就是许多专栏都在做的事情。
66 00：06：44,206 --> 00：06：52,036 演讲者 SPEAKER_06：这是疯狂的猜测，但至少这是玛丽安式的疯狂猜测，因为它是基于，它来自需要完成的计算。
67 00：06：54,632 --> 00：07：03,244 演讲者 SPEAKER_06：好的，这就是神经网络目前如何进行对象识别，并且做得非常好，与更糟糕的方法相比。
68 00：07：04,584 --> 00：07：11,153 演讲者 SPEAKER_06：这在很大程度上要归功于 Yann LeCun，他自 1987 年以来一直在进行反向传播来做这件事，并且对这项技术进行了大量开发。
69 00：07：12,696 --> 00：07：13,757 议长 SPEAKER_06：他称它们为卷积网络。
70 00：07：14,517 --> 00：07：18,502 发言者 SPEAKER_06：他们使用多层学习特征检测器。
71 00：07：19,403 --> 00：07：19,904 演讲者 SPEAKER_06：很好。
72 00：07：21,005 --> 00：07：22,648 演讲者 SPEAKER_06：而且特征检测器是本地的。
73 00：07：23,404 --> 00：07：26,528 发言者 SPEAKER_06：地方变得更大，所以随着地域的增加，他们的域也越来越大。
74 00：07：26,548 --> 00：07：31,535 演讲者 SPEAKER_06：他们跨空间复制，因为你相信如果一个功能值得在这里拥有，那么它就值得在那里拥有。
75 00：07：33,918 --> 00：07：34,338 议长 SPEAKER_06：很好。
76 00：07：38,062 --> 00：07：41,687 演讲者 SPEAKER_06：随着你的上升，这些特征检测器的空间域会变得更大，这很好。
77 00：07：42,988 --> 00：07：49,656 发言者 SPEAKER_06：特征提取层与最大池化层、平均池化层或某种池化层交错。
78 00：07：49,677 --> 00：07：52,821 演讲者 SPEAKER_06：池化层的作用是说，
79 00：07：53,257 --> 00：08：02,466 演讲者 SPEAKER_06：我是一个汇集神经元，我要看一层中的神经元，看看附近的神经元，我要关注那些，通常我会关注最活跃的那个。
80 00：08：03,447 --> 00：08：06,990 演讲者 SPEAKER_06：这可能是概率性的，但假设我只关注最活跃的那个。
81 00：08：07,531 --> 00：08：11,235 议长 SPEAKER_06：所以我要报告最活跃的那个的活动水平，然后忘记它在哪里。
82 00：08：12,357 --> 00：08：23,127 演讲者 SPEAKER_06：这会给你带来少量的平移不变性，它会给你带来不那么活跃的神经元，所以你将能够在下一层中拥有更多的特征类型。
83 00：08：24,238 --> 00：08：25,480 议长 SPEAKER_06：这就是我不相信的。
84 00：08：26,322 --> 00：08：28,464 演讲者 SPEAKER_06：这是运作良好的事情中不可或缺的一部分。
85 00：08：30,408 --> 00：08：34,674 演讲者 SPEAKER_06：它这么好用的事实是非常遗憾的，因为它会让它更难摆脱。
86 00：08：36,817 --> 00：08：37,980 演讲者 SPEAKER_06：但事情就是这样。
87 00：08：40,043 --> 00：08：46,972 演讲者 SPEAKER_06：所以正如我刚才所说的，池化给你带来了一些翻译不变性，因为它丢弃了最活跃的特征所在的地方。
88 00：08：47,188 --> 00：08：52,097 演讲者 SPEAKER_06：实际上，如果你有很多重叠的池，它不必丢失位置信息。
89 00：08：52,399 --> 00：08：55,625 议长 SPEAKER_06：但是，如果你这样做，减少单位数量的好处就会减少。
90 00：08：56,687 --> 00：09：03,460 议长 SPEAKER_06：我现在就先说到这里。
91 00：09：07,404 --> 00：09：18,359 演讲者 SPEAKER_06：现在，如果你拿这些卷积网络来说，我昨天已经展示了，用这些卷积网络之一，你可以拿最后一个隐藏层中的活动。
92 00：09：18,979 --> 00：09：23,725 演讲者 SPEAKER_06：如果它被训练成可以识别很多不同类别的物体，你现在可以训练它。
93 00：09：23,784 --> 00：09：25,888 议长 SPEAKER_06：所以，这是我昨天所说的重复，只是简短的。
94 00：09：27,549 --> 00：09：31,254 演讲者 SPEAKER_06：你可以用递归神经网络来训练它，真正给你一个标题。
95 00：09：32,135 --> 00：09：33,256 演讲者 SPEAKER_06：我在这里要跳过一点。
96 00：09：33,618 --> 00：09：35,639 演讲者 SPEAKER_06：嗯，我就给你演示一下它的作用。
97 00：09：35,788 --> 00：09：40,115 议长 SPEAKER_06：所以你给它看这个，你问它，你看到了什么？
98 00：09：40,135 --> 00：09：45,244 演讲者 SPEAKER_06：循环神经网络说两个披萨放在炉灶烤箱的顶部。
99 00：09：46,125 --> 00：09：48,710 演讲者 SPEAKER_06：如果你再运行一次，它是随机的。
100 00：09：48,809 --> 00：09：55,080 演讲者 SPEAKER_06：它会说烤炉上的平底锅上的披萨。
101 00：09：56,056 --> 00：10：00,381 说话者 SPEAKER_06：它是否真的理解了这些关系，或者这是否只是在语言模型中，我们还不知道。
102 00：10：02,144 --> 00：10：03,746 说话者 SPEAKER_06：因为它也学会了建模语言。
103 00：10：05,229 --> 00：10：07,773 演讲者 SPEAKER_06：但这只是为了向你展示卷积网络可以做令人印象深刻的事情。
104 00：10：11,256 --> 00：10：12,078 演讲者 SPEAKER_06：还有另一个字幕。
105 00：10：13,379 --> 00：10：15,342 议长 SPEAKER_06：现在这就是我不相信池化的原因。
106 00：10：15,442 --> 00：10：18,047 演讲者 SPEAKER_06：我相信卷积，我只是不相信池化。
107 00：10：18,230 --> 00：10：21,774 演讲者 SPEAKER_06：这与形状感知的心理学非常不合适。
108 00：10：22,196 --> 00：10：27,663 演讲者 SPEAKER_06：关于形状感知心理学的一些东西，有很强的论点说，我们没有使用卷积神经网络。
109 00：10：29,225 --> 00：10：30,586 议长 SPEAKER_06：它解决了错误的问题。
110 00：10：31,008 --> 00：10：36,995 演讲者 SPEAKER_06：我们不希望神经活动对视点保持不变，至少在最顶端之前是这样。
111 00：10：37,476 --> 00：10：41,282 演讲者 SPEAKER_06：我们想要的是知识对视点是不变的。
112 00：10：41,783 --> 00：10：44,846 演讲者 SPEAKER_06：同样的知识可以应用于具有新观点的事物。
113 00：10：44,866 --> 00：10：47,510 演讲者 SPEAKER_06：这并不意味着活动必须不变。
114 00：10：47,996 --> 00：10：51,220 议长 SPEAKER_06：我稍后会更详细地介绍这些。
115 00：10：52,701 --> 00：11：02,630 演讲者 SPEAKER_06：卷积网络最糟糕的特性是它们没有使用底层线性流形，这将使处理视点的影响变得非常容易。
116 00：11：02,650 --> 00：11：04,913 扬声器 SPEAKER_06：这是计算机图形学中使用的线性流形。
117 00：11：06,494 --> 00：11：08,155 演讲者 SPEAKER_06：这是一段自然的推理。
118 00：11：09,996 --> 00：11：12,399 演讲者 SPEAKER_06：有两件事对视点没有问题。
119 00：11：13,780 --> 00：11：15,101 演讲者 SPEAKER_06：一个是我们。
120 00：11：15,470 --> 00：11：18,413 演讲者 SPEAKER_06：和其他大脑，另一个是计算机图形学。
121 00：11：19,414 --> 00：11：20,716 议长 SPEAKER_06：因此他们的工作方式是一样的。
122 00：11：22,860 --> 00：11：30,529 演讲者 SPEAKER_06：最后一件事是，池化是一种非常糟糕的方式，或者说非常原始的方式，尝试进行路由。
123 00：11：31,471 --> 00：11：37,679 演讲者 SPEAKER_06：所以在视觉中，发生的事情是你改变视角，同样的东西出现在不同的像素上。
124 00：11：38,216 --> 00：11：39,741 演讲者 SPEAKER_06：这在机器学习中并不常见。
125 00：11：40,043 --> 00：11：42,090 演讲者 SPEAKER_06：例如，如果你改变照明，那不会发生。
126 00：11：42,510 --> 00：11：47,005 演讲者 SPEAKER_06：但是当你改变视点时，你已经将信息从一组像素移动到了另一组像素。
127 00：11：47,748 --> 00：11：49,594 演讲者 SPEAKER_06：这就是我所说的维度跳跃。
128 00：11：49,945 --> 00：11：53,751 演讲者 SPEAKER_06：对于机器学习，你最好取消选择它，否则你将无法理解任何事情。
129 00：11：54,553 --> 00：12：05,355 演讲者 SPEAKER_06：想象一下两家医院，一家按年龄、体重和财务状况对患者进行编码，因为它是美国，第二家医院根据体重、财务状况和年龄对患者进行编码。
130 00：12：06,035 --> 00：12：11,447 演讲者 SPEAKER_06：如果你只是获取这些记录并应用机器学习，而不进行整理，你不会期望它工作得很好。
131 00：12：12,322 --> 00：12：16,308 演讲者 SPEAKER_06：但在视觉中，这正是 viewpoint 的作用，我们最好把它整理出来。
132 00：12：16,750 --> 00：12：17,951 扬声器 SPEAKER_06：这是一个路由问题。
133 00：12：17,991 --> 00：12：23,321 演讲者 SPEAKER_06：我们需要获取像素中的信息，并将其正确路由到知道如何处理此类信息的神经元。
134 00：12：24,202 --> 00：12：30,553 演讲者 SPEAKER_06：人们还没有真正面对，大多数神经网络的人还没有真正面对我们必须解决路由问题的问题。
135 00：12：30,854 --> 00：12：34,059 演讲者 SPEAKER_06：做部分空间模型的人已经面对过这个问题，但卷积网络的人却没有。
136 00：12：37,059 --> 00：12：39,022 演讲者 SPEAKER_06：那么，我要回顾一下这四个论点。
137 00：12：39,062 --> 00：12：44,469 演讲者 SPEAKER_06：现在，演讲主要是试图说服你，卷积网络并不好用，即使它们工作得很好。
138 00：12：46,029 --> 00：12：48,833 演讲者 SPEAKER_06：或者更确切地说，卷积网络的最大池化方面并不好。
139 00：12：49,674 --> 00：12：55,461 演讲者 SPEAKER_06：我首先要说的是，这与形状感知心理学不太吻合。
140 00：12：56,982 --> 00：13：04,451 演讲者 SPEAKER_06：所以，当人们塑造感知时，他们是通过在事物上施加矩形坐标系来实现的。
141 00：13：05,950 --> 00：13：11,440 演讲者 SPEAKER_06：如果你拿同一个物体，然后强加一个不同的矩形坐标系，你甚至不会意识到它是同一个物体。
142 00：13：11,921 --> 00：13：13,003 议长 SPEAKER_06：这就是它的影响有多大。
143 00：13：13,644 --> 00：13：17,591 演讲者 SPEAKER_06：我可以给你看一个物体，然后用完全相同的视网膜图像再次给你看一模一样的物体。
144 00：13：18,052 --> 00：13：23,081 演讲者 SPEAKER_06：如果你强加一个不同的坐标系，你甚至不会意识到你以前见过它。
145 00：13：24,344 --> 00：13：26,807 演讲者 SPEAKER_06：这是一个巨大的影响，卷积网络无法解释这一点。
146 00：13：27,006 --> 00：13：34,956 发言者 SPEAKER_06：他们无法解释如何根据坐标系以完全不同的方式处理相同的像素，因为他们没有强加坐标系的概念。
147 00：13：34,976 --> 00：13：37,139 演讲者 SPEAKER_06：嗯，这不一定是真的。
148 00：13：37,179 --> 00：13：44,408 演讲者 SPEAKER_06：可能是神经网络太强大了，以至于有了这些多层，它们有点假装强加的坐标框架，我们不知道这是真是假，但让我们假设它不是。
149 00：13：45,149 --> 00：13：51,398 演讲者 SPEAKER_06：所以我要试着给你一个演示，说明坐标框架的力量。
150 00：13：53,182 --> 00：13：54,745 议长 SPEAKER_06：这是你不会相信的事情。
151 00：13：55,806 --> 00：13：58,548 演讲者 SPEAKER_06：我拿一个简单的物体，比如一个四面体。
152 00：13：59,309 --> 00：14：01,692 演讲者 SPEAKER_06：四面体是具有三角形底座的金字塔。
153 00：14：03,313 --> 00：14：04,696 演讲者 SPEAKER_06：我用飞机把它切开。
154 00：14：04,755 --> 00：14：06,998 演讲者 SPEAKER_06：那是平淡无奇的事情。
155 00：14：07,077 --> 00：14：10,701 演讲者 SPEAKER_06：我用飞机切开，所以得到两块。
156 00：14：11,722 --> 00：14：18,090 议长 SPEAKER_06：然后我找一个聪明人，把两块给他们，然后我说，好吧，做四面体。
157 00：14：18,110 --> 00：14：20,692 议长 SPEAKER_06：我确保他们知道四面体是什么，但他们做不到。
158 00：14：21,684 --> 00：14：24,149 议长 SPEAKER_06：现在这显然是意味着，现在你大概不相信。
159 00：14：24,629 --> 00：14：25,409 演讲者 SPEAKER_06：这只是两块。
160 00：14：25,529 --> 00：14：27,572 议长 SPEAKER_06：你当然可以把它们放在一起，做成一个四面体。
161 00：14：29,014 --> 00：14：31,278 演讲者 SPEAKER_06：嗯，我今天在麻省理工学院的教授身上做一个实验。
162 00：14：32,320 --> 00：14：38,428 演讲者 SPEAKER_06：我 30 年前得到了一个样本，那是一位名叫卡尔·休伊特的教授，他非常聪明。
163 00：14：38,808 --> 00：14：43,817 议长 SPEAKER_06：我把两块给了他，他看了很久。
164 00：14：43,956 --> 00：14：44,738 议长 SPEAKER_06：他没有纵他们。
165 00：14：44,778 --> 00：14：45,578 议长 SPEAKER_06：他看了他们很久。
166 00：14：45,619 --> 00：14：47,642 议长 SPEAKER_06：十分钟后，他写下了一个不可能的证据。
167 00：14：49,072 --> 00：14：51,615 演讲者 SPEAKER_06：所以他解谜的时间是无限的。
168 00：14：53,177 --> 00：15：03,250 演讲者 SPEAKER_06：好的，今天我一直在麻省理工学院的教授们做实验，他们解决问题所花的分钟数大约是他们在麻省理工学院的年限。
169 00：15：04,552 --> 00：15：10,760 演讲者 SPEAKER_06：粗略地说，时间的长短绝对与他们在麻省理工学院的时间长短呈非常正相关。
170 00：15：10,960 --> 00：15：21,360 演讲者 SPEAKER_06：所以现在我要向你展示这个谜题，因为它很非同寻常，它可能如此困难，因为它完全是微不足道的，而且有一个非常明显的解决方法，人们没有弄清楚。
171 00：15：21,801 --> 00：15：24,787 议长 SPEAKER_06：他们几分钟后就想通了，但没关系。
172 00：15：24,807 --> 00：15：25,729 演讲者 SPEAKER_06：这是两部分。
173 00：15：27,700 --> 00：15：29,721 演讲者 SPEAKER_06：对，我现在可以做我的魔术了。
174 00：15：31,403 --> 00：15：32,884 演讲者 SPEAKER_06：这两个部分，你看，它们是一样的。
175 00：15：33,566 --> 00：15：34,486 议长 SPEAKER_06：这是人们所做的。
176 00：15：34,506 --> 00：15：37,809 议长 SPEAKER_06：他们说，好吧，四面体，是的，就像，嗯，那不是四面体。
177 00：15：39,091 --> 00：15：41,453 议长 SPEAKER_06：等一下，那不是四面体。
178 00：15：41,953 --> 00：15：43,855 议长 SPEAKER_06：然后他们试着把两端粘在一起。
179 00：15：45,418 --> 00：15：46,318 议长 SPEAKER_06：然后他们就这样做了。
180 00：15：47,620 --> 00：15：49,942 议长 SPEAKER_06：他们真的在做这件事，人们也亲眼目睹了他们这样做。
181 00：15：50,243 --> 00：15：52,565 议长 SPEAKER_06：他们这样做，然后说，嗯，那不是四面体。
182 00：15：52,585 --> 00：15：53,385 议长 SPEAKER_06：嗯，那呢？
183 00：15：54,147 --> 00：15：55,648 演讲者 SPEAKER_06：那不是四面体。
184 00：15：56,489 --> 00：16：02,258 议长 SPEAKER_06：几分钟后，如果他们年轻，他们就会走，哦。
185 00：16：04,100 --> 00：16：05,984 演讲者 SPEAKER_06：那是个四面体。
186 00：16：06,004 --> 00：16：09,990 演讲者 SPEAKER_06：那么现在，为什么这个谜题几乎是不可能的？
187 00：16：10,030 --> 00：16：11,113 演讲者 SPEAKER_06：为什么这么难？
188 00：16：11,133 --> 00：16：12,995 演讲者 SPEAKER_06：因为这是一个两块拼图。
189 00：16：15,038 --> 00：16：17,602 演讲者 SPEAKER_06：他们是麻省理工学院的教授。
190 00：16：19,101 --> 00：16：24,629 演讲者 SPEAKER_06：哦，顺便说一句，我在谷歌的一位副总裁身上试过这个，只是为了安抚麻省理工学院的教授们。
191 00：16：24,769 --> 00：16：28,934 演讲者 SPEAKER_06：我把这两块交给了谷歌副总裁，我说，这真是个难题，你能做个四面体吗？
192 00：16：28,955 --> 00：16：30,015 议长 SPEAKER_06：他说，是的。
193 00：16：32,418 --> 00：16：32,820 议长 SPEAKER_06：老实说。
194 00：16：37,985 --> 00：16：40,889 议长 SPEAKER_06：所以，他们没有付钱让我这么说，这是真的。
195 00：16：41,342 --> 00：16：43,166 议长 SPEAKER_06：那为什么，怎么会这么难呢？
196 00：16：43,186 --> 00：16：46,010 演讲者 SPEAKER_06：因为你看，你知道这都是由三角形的面孔组成的。
197 00：16：46,130 --> 00：16：47,293 演讲者 SPEAKER_06：看，这里有几个方格。
198 00：16：47,312 --> 00：16：50,538 演讲者 SPEAKER_06：所以你得把这些方格放在一起，因为你得想办法把这些方格去掉。
199 00：16：51,200 --> 00：16：53,364 演讲者 SPEAKER_06：所以你得把方块放在一起，每个人都这样做。
200 00：16：53,884 --> 00：16：56,288 议长 SPEAKER_06：当这不起作用时，他们就会这样做。
201 00：16：56,970 --> 00：16：57,990 议长 SPEAKER_06：那也不行。
202 00：16：58,032 --> 00：16：59,553 议长 SPEAKER_06：这行不通。
203 00：17：01,397 --> 00：17：02,980 议长 SPEAKER_06：他们为什么不这样做呢？
204 00：17：04,006 --> 00：17：08,792 演讲者 SPEAKER_06：嗯，答案是，当我向你展示这件作品时，有一个自然的，哎呀，有一个自然的坐标框架。
205 00：17：09,413 --> 00：17：12,798 演讲者 SPEAKER_06：你可以看到这件作品的自然矩形坐标框架。
206 00：17：12,818 --> 00：17：15,983 演讲者 SPEAKER_06：它有一个长轴，它有一个横轴和上下轴。
207 00：17：17,086 --> 00：17：22,773 演讲者 SPEAKER_06：而且那个坐标系与你用于四面体的自然坐标系完全不一致。
208 00：17：23,647 --> 00：17：27,013 议长 SPEAKER_06：除非你年满 15 岁并且去了美国公立学校。
209 00：17：27,034 --> 00：17：35,851 演讲者 SPEAKER_06：如果你年满 15 岁，在美国公立学校上学，你会得到牛奶装在四面体纸箱里，这些纸箱堆在一起，哎呀，他们就这样堆在一起。
210 00：17：36,351 --> 00：17：40,459 演讲者 SPEAKER_06： 你有一个模型，说那里有一条线，这边有一条线，
211 00：17：40,759 --> 00：17：43,865 演讲者 SPEAKER_06：把所有这些线连接起来，四面体看起来就是那样的。
212 00：17：44,025 --> 00：17：51,477 演讲者 SPEAKER_06：如果你也有那个模型，我称之为四面体，因为它是如此不同，那么很明显，如果你在这里切片，你会得到一个细长的矩形。
213 00：17：51,497 --> 00：17：53,941 演讲者 SPEAKER_06：如果你在那里切片，你会得到一个细长的矩形。
214 00：17：54,260 --> 00：17：57,105 演讲者 SPEAKER_06：有位数学家说，如果你把它切到一半，最好在两者之间。
215 00：17：57,586 --> 00：17：58,827 议长 SPEAKER_06：所以你最好在某个地方找个正方形。
216 00：18：00,171 --> 00：18：04,376 演讲者 SPEAKER_06：如果你有那个模型，我就叫它四面体模型，这个谜题是完全显而易见的。
217 00：18：04,396 --> 00：18：06,160 演讲者 SPEAKER_06：晶体学家会立即完成这项工作。
218 00：18：06,950 --> 00：18：11,175 演讲者 SPEAKER_06：但是一个正常人就是做不出这个谜题。
219 00：18：11,276 --> 00：18：18,144 演讲者 SPEAKER_06：这是因为他们用于四面体的参考框架与你自然地强加给这些作品的参考框架不一致。
220 00：18：19,145 --> 00：18：22,871 演讲者 SPEAKER_06：还有其他次要的东西，比如各个部分与整体有不同的关系。
221 00：18：23,432 --> 00：18：24,492 议长 SPEAKER_06：你没想到。
222 00：18：24,532 --> 00：18：27,297 发言者 SPEAKER_06：因为它们是对称的，所以你期望与整体之间存在不对称的关系。
223 00：18：28,038 --> 00：18：29,900 议长 SPEAKER_06：总之，就是这样。
224 00：18：29,940 --> 00：18：35,708 演讲者 SPEAKER_06：这就是我关于卷积网络在心理学上不正确的证据的结尾。
225 00：18：37,847 --> 00：18：39,410 议长 SPEAKER_06：是的，这足以说服我。
226 00：18：42,334 --> 00：18：46,279 演讲者 SPEAKER_06：Ervin Rock 很久以前就指出了所有这些东西。
227 00：18：46,319 --> 00：19：00,160 演讲者 SPEAKER_06：如果你给人们看一张这样的地图，问他们这是什么国家，大多数人会说，嗯，它有点像澳大利亚，但不是澳大利亚。
228 00：19：01,996 --> 00：19：11,432 议长 SPEAKER_06：但是，如果你告诉人们，你认为萨拉·佩林会认为这是哪个国家，那些有政治头脑的人，啊，他们说这是非洲。
229 00：19：13,798 --> 00：19：15,240 议长 SPEAKER_06：萨拉·佩林居然以为这是一个国家。
230 00：19：15,881 --> 00：19：22,333 演讲者 SPEAKER_06：如果你看到这里的顶部，那么很明显它是非洲。
231 00：19：22,894 --> 00：19：24,897 议长 SPEAKER_06：但是，如果你把最上面的错误强加于人，你就不会认识到它。
232 00：19：25,672 --> 00：19：29,016 发言者 SPEAKER_06：非常熟悉的例子是一个倾斜的正方形。
233 00：19：29,675 --> 00：19：33,119 演讲者 SPEAKER_06：如果你把它看作一个倾斜的正方形，你把它看作一个钻石，那它是两个不同的内部物体。
234 00：19：33,681 --> 00：19：37,084 演讲者 SPEAKER_06：如果你把它看作是一颗钻石，那你就完全不知道这是否是一个直角。
235 00：19：37,684 --> 00：19：41,709 扬声器 SPEAKER_06：我可以把它变成 85 度、95 度或 90 度。
236 00：19：42,130 --> 00：19：43,652 演讲者 SPEAKER_06：他们都不比另一个好看。
237 00：19：44,172 --> 00：19：50,259 演讲者 SPEAKER_06：如果你把它看作一个倾斜的正方形，你就可以准确地判断它是否是直角，大约在一度以内。
238 00：19：50,278 --> 00：19：54,143 演讲者 SPEAKER_06：矩形框架的证据太多了，卷积网络不使用它们。
239 00：19：56,553 --> 00：19：57,513 议长 SPEAKER_06：再来一点证据。
240 00：19：57,834 --> 00：20：08,465 演讲者 SPEAKER_06：好的，所以这告诉我，人们的视觉系统是通过强加直角坐标系来识别事物的，而且可能还有它们的层次结构。
241 00：20：09,105 --> 00：20：10,367 演讲者 SPEAKER_06：就像计算机图形学一样。
242 00：20：10,428 --> 00：20：26,104 演讲者 SPEAKER_06：计算机图形学必须说明部分与整体之间的关系，因此它必须对整体施加一个框架，在零件上施加一个框架，然后告诉你一个矩阵，该矩阵将把整体中相对于整体框架的点映射到相对于部分框架的点。
243 00：20：26,167 --> 00：20：32,816 演讲者 SPEAKER_06：所以都是线性的，这就是线性流形，但你只能通过施加这个坐标系来表达它。
244 00：20：35,640 --> 00：20：41,667 议长 SPEAKER_06：幸运的是，在以后的讨论中，Tommy 有机会指出我说的话都是胡说八道。
245 00：20：41,847 --> 00：20：44,230 议长 SPEAKER_06：我能读懂他的心思。
246 00：20：46,794 --> 00：20：55,585 演讲者 SPEAKER_06：现在让我再给你一些证据，这些证据不仅是我们强加的坐标系，而且我们代表了强加的坐标系。
247 00：20：55,952 --> 00：21：02,160 演讲者 SPEAKER_06：通过一堆独立的神经活动，而不是通过一个神经元说我强加了这个框架。
248 00：21：03,040 --> 00：21：05,223 演讲者 SPEAKER_06：我想告诉你，它存在于一堆不同的神经活动中。
249 00：21：06,846 --> 00：21：10,150 议长 SPEAKER_06：那么假设我给你看这个。
250 00：21：11,351 --> 00：21：18,859 演讲者 SPEAKER_06：在大约 250 毫秒或更短的时间内，你所知道的是一个大写字母 R，顶部在这里。
251 00：21：20,101 --> 00：21：24,306 演讲者 SPEAKER_06：你不知道的是它是正确的 R 还是镜像的 R。
252 00：21：24,893 --> 00：21：30,183 演讲者 SPEAKER_06：要弄清楚，你要做的是你去，块，直到它直立。
253 00：21：30,244 --> 00：21：33,111 议长 SPEAKER_06：然后当它直立时，你说，啊，它面向错误的方向。
254 00：21：33,531 --> 00：21：36,858 演讲者 SPEAKER_06：所以这是一个镜像 R。为什么呢？
255 00：21：37,359 --> 00：21：43,492 演讲者 SPEAKER_06：一个更令人印象深刻的例子是，如果你和一个女人一起去一家高档鞋店，
256 00：21：43,961 --> 00：21：53,211 演讲者 SPEAKER_06：你给她看一双鞋，她可以在大约 250 毫秒内告诉你，它要花多少钱，谁制造的，在哪些其他商店有售。
257 00：21：53,912 --> 00：21：55,693 议长 SPEAKER_06：这有点性别歧视，但你去吧。
258 00：21：57,095 --> 00：22：00,659 演讲者 SPEAKER_06：她分不清这是右手鞋还是左手鞋。
259 00：22：01,799 --> 00：22：02,921 演讲者 SPEAKER_06：嗯，这太非同寻常了。
260 00：22：03,342 --> 00：22：06,704 演讲者 SPEAKER_06：我的意思是，她知道这只鞋的所有这些特性，但她不知道它是右手还是左手。
261 00：22：07,986 --> 00：22：12,770 议长 SPEAKER_06：她必须做这种块、块、块才能让它处于规范方向。
262 00：22：13,662 --> 00：22：14,884 议长 SPEAKER_06：那怎么可能呢？
263 00：22：14,943 --> 00：22：21,731 演讲者 SPEAKER_06：所以我的论点是，你知道这个和观众之间的关系。
264 00：22：21,751 --> 00：22：35,670 演讲者 SPEAKER_06：所以你在以观众为中心的坐标中有这个姿势，你需要知道将这个的内在框架与观众框架联系起来的矩阵是左手矩阵还是右手矩阵。
265 00：22：36,712 --> 00：22：46,588 演讲者 SPEAKER_06： 如果你让矩阵由一堆单独的数字表示，就像你在计算机图形学中所做的那样，要知道它是左手数字还是右手数字，你需要知道矩阵行列式的符号。
266 00：22：47,369 --> 00：22：49,794 演讲者 SPEAKER_06：换句话说，你需要解决一个高阶奇偶校验问题。
267 00：22：50,674 --> 00：22：52,438 议长 SPEAKER_06：颠倒任何一个都会改变答案。
268 00：22：53,579 --> 00：22：57,445 发言者 SPEAKER_06：如果你颠倒任何一个数字的值，答案就会改变。
269 00：22：58,647 --> 00：22：59,328 议长 SPEAKER_06：所以......
270 00：23：00,153 --> 00：23：03,578 演讲者 SPEAKER_06：神经网络不擅长处理高奇偶校验问题，所以这就是我们不能做惯用手的原因。
271 00：23：04,119 --> 00：23：15,201 演讲者 SPEAKER_06：我们不能用手作的事实，我认为我们有力的证据证明，我们对强加的坐标框架的表现，以及它与观众之间的关系，是分布在许多数字上的。
272 00：23：16,282 --> 00：23：18,406 演讲者 SPEAKER_06：就像在计算机图形学中一样。
273 00：23：18,467 --> 00：23：18,567 议长 SPEAKER_06：好的。
274 00：23：22,731 --> 00：23：32,423 演讲者 SPEAKER_06：所以我们解决这个问题的方法是，我们进行一次持续的转换，保持惯用手，直到我们把它归结为只检查一个方向，看看它往哪个方向走。
275 00：23：32,923 --> 00：23：35,086 演讲者 SPEAKER_06：然后我们解决它，这就是我们是如何做到的。
276 00：23：35,688 --> 00：23：40,673 演讲者 SPEAKER_06：所以所有这些心理旋转的东西，它们不是为了识别物体，而是为了处理这个问题，你不知道惯用手。
277 00：23：43,856 --> 00：23：50,325 演讲者 SPEAKER_06：好的，所以论点一的结论是人们使用嵌入在物体中和物体部分的矩形坐标系。
278 00：23：51,048 --> 00：24：05,048 演讲者 SPEAKER_06：他们代表那些坐标系，也就是说，他们代表物体的姿势，它嵌入的坐标系和观众之间的关系，他们代表分布在一堆数字上，而不仅仅是在一个神经元中。
279 00：24：07,512 --> 00：24：08,773 发言者 SPEAKER_06：论点二，等方差。
280 00：24：09,756 --> 00：24：15,463 演讲者 SPEAKER_06：卷积网络试图做的是让表示不随视点而变化。
281 00：24：15,944 --> 00：24：17,847 演讲者 SPEAKER_06：当然，这就是你希望唱片公司做的事情。
282 00：24：19,432 --> 00：24：26,080 演讲者 SPEAKER_06：但是，当你看一张脸时，并不是说你说脸，我不知道它在哪里，它的方向是什么，或者它的大小是多少。
283 00：24：26,761 --> 00：24：30,125 演讲者 SPEAKER_06：你看着一张脸，你确切地知道它的方向是什么，也知道它的确切位置。
284 00：24：30,686 --> 00：24：33,390 演讲者 SPEAKER_06：所以你没有像卷积网络那样丢失这些信息。
285 00：24：33,911 --> 00：24：35,272 议长 SPEAKER_06：你说得非常准确。
286 00：24：36,054 --> 00：24：40,038 演讲者 SPEAKER_06：现在很多神经科学家认为，如果你的感受野很大，那就意味着你的准确性很低。
287 00：24：41,301 --> 00：24：43,244 议长 SPEAKER_06：这与事实完全相反。
288 00：24：43,865 --> 00：24：52,576 演讲者 SPEAKER_06：如果你想对某物的位置有非常高的准确度，而你的神经元数量有限，你应该让它们有非常大的感受野，重叠很多。
289 00：24：53,017 --> 00：24：57,683 演讲者 SPEAKER_06：这样你会得到更高的精度，因为你会把空间分成许多小区域。
290 00：24：58,304 --> 00：25：02,329 演讲者 SPEAKER_06： 你创建的区域数量与这些感受野的表面积成正比。
291 00：25：02,410 --> 00：25：04,913 演讲者 SPEAKER_06：为了获得大量的表面积，你把场做得更大。
292 00：25：05,077 --> 00：25：10,711 发言者 SPEAKER_06：所以，希望这些实例化参数的准确度非常高，这一点是你应该有大的字段。
293 00：25：11,534 --> 00：25：16,605 演讲者 SPEAKER_06：当然，你会失去分辨率，所以你只能负担得起对数量不多的事情这样做。
294 00：25：17,288 --> 00：25：20,234 演讲者 SPEAKER_06：你不能对边缘这样做，因为周围有太多的边缘。
295 00：25：21,093 --> 00：25：22,816 议长 SPEAKER_06：库兹，你不想失去分辨率。
296 00：25：22,875 --> 00：25：28,984 议长 SPEAKER_06：但是当你上升到像面孔这样高层次的东西时，在一些合理的区域里，只有几个面孔。
297 00：25：29,204 --> 00：25：30,006 演讲者 SPEAKER_06：所以你可以有大场。
298 00：25：31,568 --> 00：25：37,758 演讲者 SPEAKER_06：好的，所以我们想要的是，我们想要一个表示形式，当你改变观点时，神经活动也会改变。
299 00：25：38,358 --> 00：25：41,703 演讲者 SPEAKER_06：他们就像视点一样变化。
300 00：25：41,723 --> 00：25：44,468 演讲者 SPEAKER_06：所以没有最大池化的卷积网络就是这样。
301 00：25：45,950 --> 00：25：47,833 演讲者 SPEAKER_06：他们说他们有视点不变性，但一点也不。
302 00：25：48,413 --> 00：25：51,076 演讲者 SPEAKER_06：这是两个，这是活跃的神经元。
303 00：25：51,538 --> 00：25：54,903 发言者 SPEAKER_06：你翻译这两个神经元，然后活跃的神经元翻译。
304 00：25：55,864 --> 00：25：58,969 演讲者 SPEAKER_06：这是相同的模式，但神经元不同。
305 00：25：59,750 --> 00：26：01,813 发言者 SPEAKER_06：这是等方差，对吧？
306 00：26：02,354 --> 00：26：04,936 议长 SPEAKER_06：改变这个，这个改变，改变这个，它以同样的方式改变。
307 00：26：09,083 --> 00：26：13,189 演讲者 SPEAKER_06：现在我想用伪神经科学术语来区分两种类型的等方差。
308 00：26：15,413 --> 00：26：26,128 发言者 SPEAKER_06：在这种情况下，如果我们平移整数个像素，那么这些像素就会移动，这就是我所说的地方等方差。
309 00：26：26,710 --> 00：26：31,636 演讲者 SPEAKER_06：当你改变像素时，代表它的神经元也会改变。
310 00：26：33,038 --> 00：26：35,844 说话者 SPEAKER_06：叫那个地方等方差。
311 00：26：35,864 --> 00：26：44,896 发言者 SPEAKER_06： 有一种不同的等方差，它是速率编码的等方差，它说当我移动对象时，相同的神经元正在编码它，
312 00：26：45,619 --> 00：26：47,461 演讲者 SPEAKER_06：但是神经元的活动正在发生变化。
313 00：26：48,623 --> 00：26：50,605 演讲者 SPEAKER_06：好的，所以这是一个费率代码，而不是一个地点代码。
314 00：26：51,807 --> 00：26：57,472 演讲者 SPEAKER_06：我认为视觉系统中发生的事情是低级的，我们的领域非常小。
315 00：26：58,513 --> 00：27：01,336 演讲者 SPEAKER_06：所以微小的变化会改变费率。
316 00：27：02,498 --> 00：27：08,163 演讲者 SPEAKER_06：然后，如果你的变化超过一点点，你就会变成另一个神经元或另一堆神经元，另一个胶囊。
317 00：27：08,664 --> 00：27：09,786 演讲者 SPEAKER_06：这就是地方编码。
318 00：27：10,727 --> 00：27：11,948 议长 SPEAKER_06：有点像，
319 00：27：12,096 --> 00：27：13,519 扬声器 SPEAKER_06：蜂窝域很小的手机。
320 00：27：13,538 --> 00：27：15,882 演讲者 SPEAKER_06：你稍微移动一下，它就会保持在同一个域中。
321 00：27：16,442 --> 00：27：20,509 演讲者 SPEAKER_06：然后你跳到另一个域，你在里面移动了一点。
322 00：27：20,848 --> 00：27：23,333 演讲者 SPEAKER_06：随着你的上升，这些域会变得更大。
323 00：27：23,894 --> 00：27：27,739 演讲者 SPEAKER_06：所以当你处于高水平时，你可以在不改变哪些神经元正在编码它的情况下走很长一段路。
324 00：27：28,259 --> 00：27：30,823 演讲者 SPEAKER_06：但是神经元的活动会发生变化，只是为了告诉你它在哪里。
325 00：27：32,726 --> 00：27：32,865 议长 SPEAKER_06：好的。
326 00：27：35,849 --> 00：27：37,011 发言者 SPEAKER_06：现在，争论三。
327 00：27：37,813 --> 00：27：39,875 议长 SPEAKER_06：我认为这是最有力的论点。
328 00：27：40,075 --> 00：27：49,108 演讲者 SPEAKER_06：如果你问当前的神经网络是如何处理不变性的，它们所做的就是在很多不同的观点上进行训练。
329 00：27：52,315 --> 00：27：53,636 议长 SPEAKER_06：这很合理。
330 00：27：53,896 --> 00：27：57,563 演讲者 SPEAKER_06：它只需要大量的训练数据，而遍历大量的训练数据需要很多时间。
331 00：27：58,163 --> 00：28：03,893 演讲者 SPEAKER_06：他们没有固有的偏见，即以正确的方式概括不同的观点。
332 00：28：04,753 --> 00：28：06,436 议长 SPEAKER_06：所以我想这又是一回的纳粹主义。
333 00：28：07,852 --> 00：28：16,380 演讲者 SPEAKER_06：我年纪大了，我越来越软弱了，允许这些小东西，你让那些顽固分子在你的模型上站稳脚跟，很快他们就会感染它。
334 00：28：18,883 --> 00：28：28,652 演讲者 SPEAKER_06：好的，所以更好的方法是说有一个线性流形，这就是计算机图形学使用的。
335 00：28：29,512 --> 00：28：33,656 演讲者 SPEAKER_06：如果我们从像素到坐标表示
336 00：28：34,413 --> 00：28：36,576 说话者 SPEAKER_06：物体的碎片，或物体。
337 00：28：37,376 --> 00：28：43,525 演讲者 SPEAKER_06：就是说，它是这种东西，这是它在一堆数字中的姿势，那么一切都是线性的。
338 00：28：45,146 --> 00：28：47,590 议长 SPEAKER_06： 现在你可以做大规模的外推了。
339 00：28：48,070 --> 00：28：53,898 讲者 SPEAKER_06：你可以在这儿用这样的小脸训练，然后我可以给你看一个巨大的倒立脸，你就会正确地认出来。
340 00：28：54,700 --> 00：28：56,542 演讲者 SPEAKER_06：因为在线性流形上，你可以推断。
341 00：28：58,305 --> 00：29：02,631 演讲者 SPEAKER_06：这是神经网络做不到的，如果它们能做到这一点，我们就可以用更少的数据来训练它们。
342 00：29：05,580 --> 00：29：10,166 议长 SPEAKER_06：好的。
343 00：29：10,186 --> 00：29：17,457 演讲者 SPEAKER_06：所以这个想法是，很久以前，很多年了，人们一直在说，你可以把视觉看作是逆向图形。
344 00：29：18,637 --> 00：29：21,442 议长 SPEAKER_06：但他们没有说，他们不是字面上的意思。
345 00：29：22,743 --> 00：29：24,105 议长 SPEAKER_06：我想按字面意思来做。
346 00：29：24,266 --> 00：29：29,512 演讲者 SPEAKER_06：我想在我的系统里进行计算机视觉，我希望它能反向处理图形。
347 00：29：29,711 --> 00：29：43,744 演讲者 SPEAKER_06： 当图形采用一个整体并采用整体的姿势并将其乘以矩阵得到该部分的姿势时，我希望我的计算机视觉系统采用一个零件并采用该部分的姿势，并将其乘以逆矩阵以获得整体的姿势。
348 00：29：45,446 --> 00：29：47,208 演讲者 SPEAKER_06：这就是我所说的反向图形。
349 00：29：47,709 --> 00：29：51,332 演讲者 SPEAKER_06：所以当我说它真的在做逆向图形时，我的意思是字面意思，字面意思。
350 00：29：53,173 --> 00：29：54,375 议长 SPEAKER_06：好的。
351 00：29：55,516 --> 00：29：56,596 议长 SPEAKER_06：如果你这样做，
352 00：29：57,336 --> 00：30：07,464 演讲者 SPEAKER_06：那么你可以把整体和部分之间的关系表示为一个权重矩阵，而这个权重矩阵是完全视点不变的。
353 00：30：08,660 --> 00：30：15,688 演讲者 SPEAKER_06：所以，无论我怎么改变姿势，都是同一个权重矩阵，它采用整体的姿势，并给我部分的姿势，或者它反其道而行之。
354 00：30：15,949 --> 00：30：17,411 演讲者 SPEAKER_06：部分的姿势给了我整体的姿势。
355 00：30：18,211 --> 00：30：21,095 演讲者 SPEAKER_06：所以我在权重上完全独立于视点。
356 00：30：21,736 --> 00：30：22,936 演讲者 SPEAKER_06：这就是我们想要不变性的地方。
357 00：30：22,977 --> 00：30：25,019 演讲者 SPEAKER_06：我们不希望它出现在神经活动中，我们希望它出现在重量中。
358 00：30：25,559 --> 00：30：27,742 演讲者 SPEAKER_06： 这样我们就可以得到权重的完美不变性。
359 00：30：29,325 --> 00：30：35,291 演讲者 SPEAKER_06：现在，如果你有同一个实体的多个实例，你就必须有小的域，这就搞砸了。
360 00：30：35,845 --> 00：30：37,026 演讲者 SPEAKER_06：因为你必须编写多个代码。
361 00：30：37,406 --> 00：30：39,849 演讲者 SPEAKER_06： 而这些胶囊中的每一个一次只能处理一件事。
362 00：30：40,691 --> 00：30：42,794 发言者 SPEAKER_06：因为它使用同时性来进行绑定。
363 00：30：43,173 --> 00：30：45,317 演讲者 SPEAKER_06：它说，在我的胶囊里，我有一堆神经元。
364 00：30：45,998 --> 00：30：48,740 演讲者 SPEAKER_06：这些神经元的活动代表了同一事物的不同特性。
365 00：30：48,760 --> 00：30：51,285 议长 SPEAKER_06： 最好只做一件事。
366 00：30：51,305 --> 00：30：56,330 演讲者 SPEAKER_06： 所以，当事情相距这么远时，你需要这种大小的字段。
367 00：30：56,351 --> 00：30：58,713 演讲者 SPEAKER_06：当事情相距如此之远时，您可以使用这种大小的字段。
368 00：30：59,368 --> 00：31：07,701 演讲者 SPEAKER_06：你可以让场重叠一点，稍微捏造一下，但如果你违反了这一点，你的感知就会完全出错，这就是所谓的拥挤。
369 00：31：08,663 --> 00：31：12,348 演讲者 SPEAKER_06：如果你把东西放在太近的地方，你就很难看到它们。
370 00：31：12,368 --> 00：31：14,291 演讲者 SPEAKER_06：你更擅长看到更远的小事物。
371 00：31：16,134 --> 00：31：17,436 议长 SPEAKER_06：但我不打算强求。
372 00：31：19,380 --> 00：31：27,132 演讲者 SPEAKER_06：那么，鉴于这种世界观，这就是你应该如何进行形状识别，这是 1980 年代的计算机视觉。
373 00：31：28,411 --> 00：31：39,403 发言者 SPEAKER_06：你确定了一些熟悉的部分，比如鼻子，你有一个物流单位，说明它在那里的概率是多少。
374 00：31：39,603 --> 00：31：40,964 发言者 SPEAKER_06：所以这在 1 和 0 之间变化。
375 00：31：41,945 --> 00：31：44,648 议长 SPEAKER_06：所以，这确实是不变的。
376 00：31：48,532 --> 00：31：51,576 演讲者 SPEAKER_06：这儿的这家伙有鼻子的姿势参数。
377 00：31：51,957 --> 00：31：57,742 演讲者 SPEAKER_06：所以，如果我们只是从几何学的角度来思考，这将是，比如说，这里的六个数字告诉你鼻子相对于观众的姿势。
378 00：31：58,886 --> 00：32：06,663 演讲者 SPEAKER_06：然后你有一个矩阵，它对这个姿势进行作，并给你一个预测，这个东西，关于脸的姿势。
379 00：32：08,346 --> 00：32：09,789 议长 SPEAKER_06：你有一张确定的嘴。
380 00：32：11,613 --> 00：32：13,857 演讲者 SPEAKER_06：你有姿势参数。
381 00：32：14,564 --> 00：32：20,230 演讲者 SPEAKER_06：你用这个完全视点不变的矩阵对他们进行运算，你会得到另一个关于面部姿势的预测。
382 00：32：20,871 --> 00：32：24,755 演讲者 SPEAKER_06：如果这些预测大致相同，那就是很好的证据，证明有一张面孔。
383 00：32：25,355 --> 00：32：30,300 演讲者 SPEAKER_06：只有当鼻子和嘴巴以正确的方式关联以形成面部时，这些预测才会大致相同。
384 00：32：31,321 --> 00：32：35,586 演讲者 SPEAKER_06：所以说真的，通过检查这个身份，你是在检查这些是否与做脸正确相关。
385 00：32：36,227 --> 00：32：38,509 议长 SPEAKER_06：如果他们是，你说，嘿，这里有一张脸。
386 00：32：39,029 --> 00：32：42,933 说话者 SPEAKER_06：然后你发出他们预测的平均值，这个和这个的平均值。
387 00：32：43,015 --> 00：32：45,738 议长 SPEAKER_06：你让这一切合二为一，然后你继续。
388 00：32：46,459 --> 00：32：50,304 演讲者 SPEAKER_06：所以这是一种进行重合过滤的方法，可以从较小的零件中识别出较大的部分。
389 00：32：51,704 --> 00：32：52,846 演讲者 SPEAKER_06：这非常有力。
390 00：32：52,886 --> 00：33：02,817 演讲者 SPEAKER_06：可能还有其他胶囊对面部做出不同的预测，如果你有办法在很多噪音中找到一致的小集群，你就会忽略它们。
391 00：33：06,583 --> 00：33：10,007 演讲者 SPEAKER_06：老派的视觉人士会说，为什么这不只是一个霍夫变换呢？
392 00：33：10,027 --> 00：33：10,847 演讲者 SPEAKER_06：那是霍夫变换。
393 00：33：10,867 --> 00：33：12,869 演讲者 SPEAKER_06：这就是霍夫变换的意义所在。
394 00：33：13,053 --> 00：33：19,101 演讲者 SPEAKER_06：这只是一个霍夫变换，但它是以下意义上的现代霍夫变换。
395 00：33：19,721 --> 00：33：25,709 演讲者 SPEAKER_06：在过去，当他们进行霍夫变换时，他们会有相当低维的特征来预测姿势，高维姿势。
396 00：33：26,810 --> 00：33：32,298 演讲者 SPEAKER_06：如果特征的维度低于物体的维度，你就得预测一个子空间。
397 00：33：33,538 --> 00：33：36,423 议长 SPEAKER_06：所以你必须有垃圾箱，你必须把很多选票放进很多垃圾箱里。
398 00：33：38,726 --> 00：33：42,029 议长 SPEAKER_06： 如果你只想投一票，那么你不需要所有这些垃圾箱，
399 00：33：42,652 --> 00：33：47,699 演讲者 SPEAKER_06：那你最好让这些特征和高维事物一样多维度。
400 00：33：48,819 --> 00：33：54,086 演讲者 SPEAKER_06：要获得这样能够可靠地从像素中提取的功能，你需要机器学习，你需要良好的机器学习。
401 00：33：54,807 --> 00：34：03,740 演讲者 SPEAKER_06：他们以前无法使半变换起作用的原因是，他们无法让低级特征具有足够的维度并可靠，以便他们能够进行点预测。
402 00：34：05,883 --> 00：34：10,548 演讲者 SPEAKER_06：好的，这就是我的说法，为什么这与老式的半转换不同，但它是半转换。
403 00：34：12,114 --> 00：34：16,561 演讲者 SPEAKER_06： 我想说的最后一个论点是关于这个路由的。
404 00：34：17,362 --> 00：34：32,603 演讲者 SPEAKER_06：所以这个想法是，视点的作用是改变图像中事物显示的位置，所以现在这些像素上有一个鼻子，假设它是一张脸，假设你在顶部只有一个大脸胶囊。
405 00：34：33,385 --> 00：34：38,932 演讲者 SPEAKER_06：所以你需要将这些像素路由到面部胶囊，在不同的图像中，你需要将这些像素路由到面部胶囊。
406 00：34：39,925 --> 00：34：43,009 演讲者 SPEAKER_06： 我想向你展示一个进行路由的好方法。
407 00：34：43,530 --> 00：34：46,172 演讲者 SPEAKER_06：所以做路由的第一个顺序是你做一个眼球运动。
408 00：34：46,693 --> 00：34：48,615 演讲者 SPEAKER_06：你把你感兴趣的东西放在视网膜的中间。
409 00：34：49,297 --> 00：34：51,139 演讲者 SPEAKER_06：这是一个非常强大的路由算法。
410 00：34：51,880 --> 00：34：59,530 发言者 SPEAKER_06：但是，即使我做了一个触细胞，所以我强迫你固定在一个点上，你仍然可以做路由。
411 00：35：00,391 --> 00：35：03,434 议长 SPEAKER_06：这是你可以怎么做的。
412 00：35：04,528 --> 00：35：17,590 演讲者 SPEAKER_06：嗯，如果你拿卷积网络来说，我已经提到过，他们做路由的方式，如果他们有一个池化单元，它只关注最活跃的家伙，所有这些级别都是一样的，所以这会路由，但只是基于它们的响度。
413 00：35：18,572 --> 00：35：26,284 演讲者 SPEAKER_06：我想要一个路由原则，将信息路由到知道如何处理信息的胶囊。
414 00：35：28,047 --> 00：35：31,211 演讲者 SPEAKER_06：所以这个想法是这样的，
415 00：35：31,427 --> 00：35：34,773 演讲者 SPEAKER_06：你假设，我们将假设世界是不透明的。
416 00：35：35,273 --> 00：35：39,762 演讲者 SPEAKER_06：我们将假设它可以由解析树建模。
417 00：35：40,182 --> 00：35：47,875 演讲者 SPEAKER_06：所以我们假设我们发现的每个部分都有一个父项，那就是单父约束，或者可能没有父项，但它没有多个父项。
418 00：35：48,717 --> 00：35：51,742 演讲者 SPEAKER_06：所以我们想找到它的一部分，而其中就有一个。
419 00：35：53,123 --> 00：35：57,351 演讲者 SPEAKER_06： 所以当你发现一个部分时，假设我发现了一个圆。
420 00：35：57,550 --> 00：36：01,173 演讲者 SPEAKER_06：一个圆圈，我想我有一个有限的世界，里面只有汽车和面孔。
421 00：36：01,775 --> 00：36：08,103 演讲者 SPEAKER_06：圆圈可能是脸的左眼，也可能是脸的右眼，可能是汽车的前轮或汽车的后轮。
422 00：36：08,123 --> 00：36：09,605 议长 SPEAKER_06：我不知道从圆圈里是哪个。
423 00：36：10,445 --> 00：36：22,400 演讲者 SPEAKER_06：我要做的是摆姿势，然后我把它发送到所有这些地方，但我要发送一种重量，它表示我的赌注是四分之一是这个，四分之一是那个，四分之一是那个，四分之一是那个。
424 00：36：22,420 --> 00：36：27,186 演讲者 SPEAKER_06：所以你把它送到这些高级胶囊上，很多弱赌注。
425 00：36：27,166 --> 00：36：32,313 演讲者 SPEAKER_06： 然后高级胶囊需要做的是查看所有这些传入的弱赌注，并找到一堆同意的赌注。
426 00：36：32,373 --> 00：36：48,617 演讲者 SPEAKER_06：当它找到一群同意的人时，那么，低级胶囊体会把它的姿势发送到几个高级胶囊体。
427 00：36：48,900 --> 00：36：52,626 议长 SPEAKER_06：一开始，它等待前者。
428 00：36：52,706 --> 00：36：58,934 演讲者 SPEAKER_06：所以会有一个先验，一个圆圈可能是面的一部分，可能是汽车的一部分，它可能不是冰箱的一部分。
429 00：36：59,333 --> 00：37：04,460 演讲者 SPEAKER_06：所以你不要把它送到冰箱，或者你把它以非常低的重量送到冰箱，用高重量送到一张脸和一辆车上。
430 00：37：07,824 --> 00：37：12,110 演讲者 SPEAKER_06：然后在这些胶囊中，你可以找到集群。
431 00：37：12,751 --> 00：37：14,072 演讲者 SPEAKER_06：这是一个神奇的计算。
432 00：37：14,112 --> 00：37：17,777 演讲者 SPEAKER_06：我不是告诉你你是怎么做这个计算的，但让我们假设我们可以做这个神奇的计算。
433 00：37：18,347 --> 00：37：30,824 演讲者 SPEAKER_06：就像我说的，这是你需要做什么计算的 Marian 方法，这就是我们假设胶囊的作用，我们从任务的性质来推理这个计算，然后它如何做是别人的问题。
434 00：37：31,306 --> 00：37：34,349 议长 SPEAKER_06：嗯，这是我的问题，我不能让它运作得非常好，但我们开始吧。
435 00：37：34,710 --> 00：37：38,094 议长 SPEAKER_06：我稍后会告诉你我现在是怎么做的。
436 00：37：38,344 --> 00：37：43,630 议长 SPEAKER_06：所以你把它发到这里来，它是这个蓝色的预测，它与集群一致。
437 00：37：44,271 --> 00：37：46,954 议长 SPEAKER_06：你把它发过来了，就是这个预测，它与集群不一致。
438 00：37：47,335 --> 00：37：55,184 演讲者 SPEAKER_06：所以现在你想做的是你想发送自上而下的反馈，或者你想进行横向互动，比如说，假设这是自上而下的反馈。
439 00：37：55,224 --> 00：38：01,632 演讲者 SPEAKER_06：这个胶囊的自上而下的反馈说，给我发更多，我可以解释这些东西，请把你的输出发给我。
440 00：38：02,313 --> 00：38：05,836 议长 SPEAKER_06：这家伙说，我无法解释这些东西，请不要把你的输出发给我。
441 00：38：06,543 --> 00：38：13,474 演讲者 SPEAKER_06：还有几次迭代，你会把这个家伙的所有输出都发送到这里，而不是发送到那里。
442 00：38：14,657 --> 00：38：15,918 议长 SPEAKER_06：现在你将拥有一棵能力树。
443 00：38：16,800 --> 00：38：18,884 议长 SPEAKER_06：你已经确定这个属于那个。
444 00：38：20,146 --> 00：38：27,960 演讲者 SPEAKER_06：显然有竞争，但是是的，我正在努力了解基本的想法。
445 00：38：28,514 --> 00：38：36,264 议长 SPEAKER_06：这是我的建议，要么这两个家伙之间的双边互动，说他们身上的权重加起来必须加起来。
446 00：38：36,923 --> 00：38：38,947 议长 SPEAKER_06：这家伙很适合，所以他想要更多的体重。
447 00：38：38,987 --> 00：38：40,989 议长 SPEAKER_06：这家伙不太适合，所以他想要更轻的体重。
448 00：38：41,510 --> 00：38：43,431 议长 SPEAKER_06：所以给这个家伙更多的权重，给这个家伙更少的权重。
449 00：38：43,893 --> 00：38：45,695 议长 SPEAKER_06： 或者你可以通过自上而下的方式来做到这一点。
450 00：38：46,275 --> 00：38：48,998 演讲者 SPEAKER_06：但请注意，自上而下的传播不会像循环的信念传播。
451 00：38：49,079 --> 00：38：53,744 议长 SPEAKER_06：不是说，我要用它来修正我对这里的看法。
452 00：38：53,724 --> 00：38：55,447 扬声器 SPEAKER_06：它只是要用它来路由。
453 00：38：55,487 --> 00：38：59,311 议长 SPEAKER_06：它会说，好吧，这个胶囊可以很好地解释我。
454 00：39：00,273 --> 00：39：02,916 议长 SPEAKER_06：我想把信息路由到这个胶囊。
455 00：39：03,918 --> 00：39：06,541 发言者 SPEAKER_06：所以这是一个协议路由算法。
456 00：39：06,561 --> 00：39：17,556 演讲者 SPEAKER_06：它使用一致性来进行路由，而不是仅仅说，我要忽略所有人，除了我能看到的最响亮的家伙，这就是 Max Pauling 所做的。
457 00：39：21,568 --> 00：39：24,213 演讲者 SPEAKER_06： 那么现在我要向你展示两个计算机程序。
458 00：39：25,074 --> 00：39：29,583 议长 SPEAKER_06：很遗憾，其中一条是我写的。
459 00：39：31,606 --> 00：39：34,150 演讲者 SPEAKER_06：所以这不是一个非常好的程序，它运行得很慢。
460 00：39：35,012 --> 00：39：43,847 演讲者 SPEAKER_06：但是我们的想法是，如果我们能制作这个基本模块，它可以检查高维一致性并抛出异常值，
461 00：39：44,637 --> 00：39：46,420 议长 SPEAKER_06：那我们就可以有一个深层系统了。
462 00：39：47,221 --> 00：39：52,128 演讲者 SPEAKER_06：我们有一个前端问题，那就是你如何获得第一个有姿势的东西？
463 00：39：52,889 --> 00：39：54,612 演讲者 SPEAKER_06：这就是我所说的去渲染图像。
464 00：39：54,632 --> 00：39：59,458 演讲者 SPEAKER_06：从像素强度（你对光线所做的）到姿势（你对几何体所做的）。
465 00：40：00,240 --> 00：40：02,063 演讲者 SPEAKER_06：然后高级别都会以同样的方式工作。
466 00：40：02,083 --> 00：40：04,226 演讲者 SPEAKER_06：他们要把碎片拼凑成越来越大的碎片。
467 00：40：05,447 --> 00：40：09,835 议长 SPEAKER_06：我一开始就要有一个不太深的系统。
468 00：40：10,186 --> 00：40：21,039 演讲者 SPEAKER_06：但是我们想做的是能够利用随机梯度下降和大量数据的力量来学习基于部分的层次结构，除了我已经说过的之外，没有其他手工工程。
469 00：40：21,139 --> 00：40：25,405 演讲者 SPEAKER_06：除了提出这个想法之外，还会有巧合过滤。
470 00：40：25,425 --> 00：40：26,907 议长 SPEAKER_06： 并根据协议重新规划路线。
471 00：40：28,771 --> 00：40：30,032 演讲者 SPEAKER_06：所以这是我的概念证明。
472 00：40：31,594 --> 00：40：35,940 演讲者 SPEAKER_06：我要取 MNIST 数字，我要有小补丁。
473 00：40：37,117 --> 00：40：51,277 演讲者 SPEAKER_06：从以下意义上讲，这将是卷积的，在第一阶段，我将采用一个补丁，它将有一些权重，将其连接到一些隐藏的单元，这就是黑色补丁。
474 00：40：52,179 --> 00：41：00,110 演讲者 SPEAKER_06：将会有一个蓝色的补丁，它将具有完全相同的权重，将其连接到 300 个蓝色单元。
475 00：41：01,371 --> 00：41：06,297 演讲者 SPEAKER_06：好的，所以我处理补丁的方式在任何地方都是完全一样的。
476 00：41：06,547 --> 00：41：07,389 演讲者 SPEAKER_06：这是卷积的。
477 00：41：08,952 --> 00：41：10,494 演讲者 SPEAKER_06：这些将是非线性单位。
478 00：41：11,436 --> 00：41：26,338 演讲者 SPEAKER_06：我要让这些单位做的是给我一些姿势，我实际上用了七个，但我在这里展示了三个，三种不同类型的胶囊的姿势。
479 00：41：26,358 --> 00：41：28,463 说话者 SPEAKER_06：所以胶囊可以检测不同种类的实体。
480 00：41：28,682 --> 00：41：31,947 演讲者 SPEAKER_06：这可能是垂直边缘、水平边缘、角落或类似的东西。
481 00：41：32,400 --> 00：41：34,443 议长 SPEAKER_06：我不打算具体说明这些实体应该是什么。
482 00：41：34,844 --> 00：41：37,748 演讲者 SPEAKER_06：我要从正确答案的梯度下降来学习。
483 00：41：38,891 --> 00：41：51,070 演讲者 SPEAKER_06：但是，系统第一阶段的工作方式是将一些像素强度转换为一些姿势参数的向量，实例化姿势参数。
484 00：41：52,411 --> 00：41：55,016 演讲者 SPEAKER_06：这些将是不同的姿势参数。
485 00：41：55,036 --> 00：41：57,480 演讲者 SPEAKER_06：它们将是不同种类事物的姿势参数。
486 00：41：58,219 --> 00：42：02,548 议长 SPEAKER_06：此外，它会说它是否认为这个东西在那里，所以这将是一个物流单位。
487 00：42：03,250 --> 00：42：08,159 演讲者 SPEAKER_06：一切都会学习，但都会通过所有这些补丁在镜像中共享。
488 00：42：12,027 --> 00：42：13,391 议长 SPEAKER_06：这些将是线性单位。
489 00：42：17,639 --> 00：42：18,320 议长 SPEAKER_06：现在。
490 00：42：19,077 --> 00：42：21,661 演讲者 SPEAKER_06：这些东西将成为我所说的初级胶囊。
491 00：42：21,681 --> 00：42：23,001 演讲者 SPEAKER_06：他们是第一级胶囊。
492 00：42：23,322 --> 00：42：25,826 发言者 SPEAKER_06：它们是你有明确姿势坐标的第一级。
493 00：42：26,447 --> 00：42：28,088 演讲者 SPEAKER_06：我一开始就要有一个非常扁平的系统。
494 00：42：28,128 --> 00：42：29,550 议长 SPEAKER_06：它只有两个级别。
495 00：42：29,570 --> 00：42：32,155 演讲者 SPEAKER_06： 它从第一层进入第二层。
496 00：42：32,896 --> 00：42：36,380 演讲者 SPEAKER_06：我制作了更深层次的系统，但这是最容易理解的。
497 00：42：36,800 --> 00：42：41,608 演讲者 SPEAKER_06：在第二层，它有一堆胶囊。
498 00：42：42,195 --> 00：42：45,061 议长 SPEAKER_06：这里的人数应该和那里的人数一样多。
499 00：42：45,641 --> 00：42：47,525 演讲者 SPEAKER_06：我只是偷懒地玩 PowerPoint，好吗？
500 00：42：47,726 --> 00：42：49,588 议长 SPEAKER_06：很抱歉，我应该在这里放更多的东西。
501 00：42：53,135 --> 00：42：57,382 演讲者 SPEAKER_06：所以你拿一个 A 型初级胶囊，它正在观察黑色斑块。
502 00：42：58,324 --> 00：42：59,967 议长 SPEAKER_06：你从中提取了一些数字。
503 00：43：00,047 --> 00：43：02,411 演讲者 SPEAKER_06：你已经学会了提取这些数字，我们稍后会说怎么提取。
504 00：43：03,733 --> 00：43：06,077 演讲者 SPEAKER_06：然后你应用一个坐标变换。
505 00：43：06,478 --> 00：43：13,849 演讲者 SPEAKER_06：对那个姿势参数向量进行预测，如果那里有零的话。
506 00：43：15,893 --> 00：43：22,722 演讲者 SPEAKER_06：另外，根据它是否处于活动状态，您可以预测零是否存在。
507 00：43：23,525 --> 00：43：25,067 演讲者 SPEAKER_06：这就是我所说的毕加索体重。
508 00：43：25,788 --> 00：43：34,460 演讲者 SPEAKER_06：所以毕加索的权重说，让我们看看胶囊的类型，并预测这个东西是否仅根据类型而忽略所有几何约束而存在。
509 00：43：35,284 --> 00：43：36,766 演讲者 SPEAKER_06：所以如果你看到一只眼睛，可能就有一张脸。
510 00：43：37,407 --> 00：43：46,759 演讲者 SPEAKER_06：即使眼睛在完全错误的位置，如果我把足够的眼睛和鼻子放在周围，你会看到一张脸，或者你会认为那里有一张脸，即使几何结构全是错的，只是因为眼睛进入了脸。
511 00：43：48,061 --> 00：43：50,643 演讲者 SPEAKER_06：所以这就是它说的原因，因为它是一只眼睛，所以可能有一张脸。
512 00：43：53,547 --> 00：43：54,989 议长 SPEAKER_06：这是在做真正的工作。
513 00：43：55,048 --> 00：44：02,018 发言者 SPEAKER_06：它在说，我采取我识别的这个特征的姿势，这个高维特征，我预测零的姿势。
514 00：44：03,414 --> 00：44：07,684 演讲者 SPEAKER_06：你要从所有这些不同的初级胶囊中做同样的事情。
515 00：44：10,148 --> 00：44：12,092 演讲者 SPEAKER_06：你对这个预测也有影响。
516 00：44：13,896 --> 00：44：15,139 发言者 SPEAKER_06：所以这是一张加重的床。
517 00：44：20,710 --> 00：44：21,592 议长 SPEAKER_06：现在
518 00：44：22,213 --> 00：44：32,065 演讲者 SPEAKER_06：对于相同的补丁，对于原始图像中的相同黑色补丁，我将有一个 B 型胶囊，它采用不同类型的特征并进行预测。
519 00：44：32,105 --> 00：44：36,230 演讲者 SPEAKER_06：它预测 0 的姿势和 1 的姿势。
520 00：44：40,134 --> 00：44：51,005 演讲者 SPEAKER_06：除了对不同类型特征的黑色补丁的预测外，我还对不同类型特征的所有其他补丁进行了预测。
521 00：44：51,643 --> 00：44：55,150 演讲者 SPEAKER_06：所以从你正在进行的预测的红色补丁中键入 A 特征和 B 类型特征。
522 00：44：55,451 --> 00：44：58,436 演讲者 SPEAKER_06：所以我在这里得到了一大堆预测。
523 00：44：58,456 --> 00：45：14,664 演讲者 SPEAKER_06：特别是，将黑色补丁中 A 型特征的姿势与此预测相关联的权重矩阵将与红色补丁进行预测的坐标变换相同。
524 00：45：16,130 --> 00：45：38,425 演讲者 SPEAKER_06：这不太对劲，所以我们必须修复它，因为红色斑块在不同的位置，所以它应该预测不同的姿势，所以我们必须修复平移位，我们要说，当我从这个主胶囊中预测这个数字的姿势时，
525 00：45：39,603 --> 00：45：49,217 演讲者 SPEAKER_06：我要取前两个坐标，我要说出它们的位置，然后我要把图像中这个块的位置添加到前两个坐标上。
526 00：45：50,159 --> 00：45：52,003 议长 SPEAKER_06：我只是要把它添加到它计算出的任何内容中。
527 00：45：53,005 --> 00：45：56,630 演讲者 SPEAKER_06：这就是由于补丁偏移而你在位置上得到的偏移。
528 00：45：57,492 --> 00：46：03,822 演讲者 SPEAKER_06：关于补丁的所有其他内容都是一样的，但是当你偏移补丁时，它应该偏移你说的东西所在的地方。
529 00：46：05,050 --> 00：46：06,351 议长 SPEAKER_06：这就是实现的。
530 00：46：06,431 --> 00：46：08,916 发言者 SPEAKER_06：这也意味着前两个坐标将是可解释的。
531 00：46：09,757 --> 00：46：10,778 议长 SPEAKER_06：这就是整个系统。
532 00：46：11,358 --> 00：46：16,005 议长 SPEAKER_06：现在我们想说的是，如果你在这里得到一大堆协议，那就是零。
533 00：46：16,226 --> 00：46：17,789 议长 SPEAKER_06：如果你在这里得到一大堆协议，那就是一堆协议。
534 00：46：19,512 --> 00：46：21,675 议长 SPEAKER_06：所以我们想反向传播。
535 00：46：22,516 --> 00：46：23,818 演讲者 SPEAKER_06：我们知道这门课是什么。
536 00：46：23,858 --> 00：46：24,699 演讲者 SPEAKER_06：假设是 2。
537 00：46：25,159 --> 00：46：27,742 议长 SPEAKER_06：我们希望这里有很多共识，但那里没有太多共识。
538 00：46：28,523 --> 00：46：31,548 议长 SPEAKER_06：所以我们需要一些程度的协议，我们需要能够反向传播它。
539 00：46：32,449 --> 00：46：34,932 议长 SPEAKER_06：我们需要说，如果你在这里没有得到太多的同意，请得到更多。
540 00：46：34,972 --> 00：46：36,956 议长 SPEAKER_06：如果你在这里得到太多的同意，请少一点。
541 00：46：37,597 --> 00：46：39,018 演讲者 SPEAKER_06：然后我们就可以学习所有这些权重了。
542 00：46：39,059 --> 00：46：42,643 演讲者 SPEAKER_06：我们可以学习将像素转换为初级胶囊体姿势的权重。
543 00：46：43,105 --> 00：46：45,367 演讲者 SPEAKER_06：我们可以学习这些坐标转换。
544 00：46：45,347 --> 00：46：49,152 演讲者 SPEAKER_06：这暂时是固定的，所以我们不了解这个。
545 00：46：50,032 --> 00：46：51,855 演讲者 SPEAKER_06：我们学习各种偏见和东西。
546 00：46：52,916 --> 00：46：53,157 议长 SPEAKER_06：所以。
547 00：47：00,304 --> 00：47：00,505 议长 SPEAKER_06：是的。
548 00：47：04,869 --> 00：47：10,697 演讲者 SPEAKER_06：不，因为如果你想从像素强度到特征的姿势，那是高度非线性的。
549 00：47：12,094 --> 00：47：15,719 演讲者 SPEAKER_06：这是从像素强度获取特征的坐标。
550 00：47：16,762 --> 00：47：22,931 演讲者 SPEAKER_06：但是，如果你想从一个特征的姿势变成一个包含它的更大物体的姿势，那是完全线性的。
551 00：47：23,853 --> 00：47：26,215 演讲者 SPEAKER_06：所以你真的、真的不希望那里有任何非线性。
552 00：47：29,922 --> 00：47：30,862 议长 SPEAKER_06：这是个很好的问题。
553 00：47：34,402 --> 00：47：45,121 演讲者 SPEAKER_06：所以，在我实现的这个小系统中，每个高级胶囊，七种特征类型，图像中有 181 个补丁，它得到了那么多预测。
554 00：47：45,161 --> 00：47：48,146 议长 SPEAKER_06：它变得很多，其中许多都非常弱。
555 00：47：48,166 --> 00：47：52,833 演讲者 SPEAKER_06：所以，它的组织是这样让空白的补丁做出非常微弱的预测的。
556 00：47：54,434 --> 00：47：57,717 演讲者 SPEAKER_06：每个预测都有一个赌注。
557 00：47：58,577 --> 00：48：01,681 演讲者 SPEAKER_06：所以对于任何一个主要的胶囊，它都会做出预测。
558 00：48：01,842 --> 00：48：03,983 演讲者 SPEAKER_06：这个预测的赌注总和加起来是 1。
559 00：48：05,065 --> 00：48：11,112 演讲者 SPEAKER_06：这被视为对接下来发生的事情的分数观察。
560 00：48：13,054 --> 00：48：15,777 议长 SPEAKER_06： 那么，高级胶囊正在寻找协议。
561 00：48：15,936 --> 00：48：24,306 演讲者 SPEAKER_06：所以我们需要一些方法，面对所有这些投注，随着这 1,000 多个投注的到来，我们需要某种方式来找到一个非常一致的子集。
562 00：48：25,331 --> 00：48：30,958 演讲者 SPEAKER_06：所以我们要做的是尝试计算这个高级胶囊是否具有良好的一致性。
563 00：48：34,322 --> 00：48：44,675 演讲者 SPEAKER_06：我们要做的是在这个高级胶囊的姿势空间中，我们将高斯和均匀的混合拟合到预测中。
564 00：48：45,516 --> 00：48：47,137 扬声器 SPEAKER_06：假设它是一个 60 空格。
565 00：48：48,603 --> 00：48：55,849 演讲者 SPEAKER_06：我们要问的是，与我只穿制服得到的模型相比，我的预测模型有多好？
566 00：48：57,210 --> 00：49：03,456 演讲者 SPEAKER_06：如果我把高斯和均匀的混合拟合时，我得到的预测要好得多，这些预测的对数概率要好得多。
567 00：49：04,177 --> 00：49：05,998 演讲者 SPEAKER_06：所以我们把它看作是一种无监督的学习问题。
568 00：49：06,018 --> 00：49：08,740 演讲者 SPEAKER_06：你有这么多预测，我想为它们建立一个模型。
569 00：49：08,760 --> 00：49：09,961 演讲者 SPEAKER_06：我有两个备选模型。
570 00：49：10,101 --> 00：49：13,826 发言者 SPEAKER_06：一个是均匀的，另一个是均匀的，在某处有一个高斯分布。
571 00：49：15,047 --> 00：49：17,748 议长 SPEAKER_06：我要让那个高斯的均值四处浮动。
572 00：49：19,096 --> 00：49：26,889 演讲者 SPEAKER_06：所以当这个神经网络运行时，它的高斯均值在浮动，高斯的方差在浮动，高斯的混合比例在浮动。
573 00：49：27,650 --> 00：49：28,612 议长 SPEAKER_06： 什么不是在飘来飘去的？
574 00：49：28,632 --> 00：49：33,760 演讲者 SPEAKER_06：没有浮动的是这些坐标转换和至少一开始下注的权重。
575 00：49：36,485 --> 00：49：41,494 演讲者 SPEAKER_06：所以我们要得到一个分数，看看这个集群有多好。
576 00：49：42,394 --> 00：49：44,157 演讲者 SPEAKER_06：那么让我们假设这个集群，
577 00：49：45,539 --> 00：49：51,106 说话者 SPEAKER_06： 这些红点在高斯下具有非常高的后验概率。
578 00：49：51,827 --> 00：49：56,574 发言者 SPEAKER_06：这些人无法决定是在高斯下还是在制服下，而这些人在制服下。
579 00：49：57,717 --> 00：50：10,675 演讲者 SPEAKER_06：所以我们计算了所有这些数据点的总和，每个数据点都由观测的分数加权，在高斯和均匀的混合下看到它的对数概率。
580 00：50：11,356 --> 00：50：14,922 发言者 SPEAKER_06：我们还计算了刚才给定的 uniform 的对数概率。
581 00：50：15,998 --> 00：50：18,501 演讲者 SPEAKER_06：我们的分数是这些对数属性的差异。
582 00：50：19,802 --> 00：50：25,150 议长 SPEAKER_06：使用类似的东西很重要，因为你想要的是，如果我在这里投了一票，它不会影响分数。
583 00：50：27,094 --> 00：50：28,275 议长 SPEAKER_06：而且不会对分数产生太大影响。
584 00：50：28,976 --> 00：50：31,300 议长 SPEAKER_06：我的意思是，根据你怎么做，它根本不会影响它。
585 00：50：32,902 --> 00：50：35,025 议长 SPEAKER_06：因为在这两种情况下，这都会被编码在制服下。
586 00：50：36,407 --> 00：50：39,271 演讲者 SPEAKER_06：但是如果你找到一个集群，这个分数会更大。
587 00：50：39,291 --> 00：50：41,635 演讲者 SPEAKER_06：如果它是一个紧密的集群，这个分数会好得多。
588 00：50：42,592 --> 00：50：43,833 演讲者 SPEAKER_06：那么现在让我们看看它的作用。
589 00：50：44,875 --> 00：50：45,815 演讲者 SPEAKER_06：所以这就是分数。
590 00：50：45,916 --> 00：50：52,603 演讲者 SPEAKER_06：然后你把这个分数放进一个 Softmax 里，试着决定它是什么类。
591 00：50：53,585 --> 00：50：56,768 演讲者 SPEAKER_06：所以你把它看作是进入 Softmax 的 logit。
592 00：50：57,108 --> 00：50：58,989 演讲者 SPEAKER_06：你先缩放它，因为那是一种黑客攻击。
593 00：51：00,811 --> 00：51：02,094 演讲者 SPEAKER_06：所以这里有一个黑客量表。
594 00：51：03,054 --> 00：51：09,141 演讲者 SPEAKER_06：如果一切都在概率上是正确的，你应该需要一个 1 的刻度，但你不需要。
595 00：51：10,943 --> 00：51：12,784 议长 SPEAKER_06：然后你看看你所做的决定。
596 00：51：12,804 --> 00：51：17,391 议长 SPEAKER_06：如果这是错误的决定，你说，给正确的人提高分数，给错误的人降低分数。
597 00：51：18,233 --> 00：51：20,896 演讲者 SPEAKER_06：然后你把那个分数的导数传播到整个系统。
598 00：51：22,038 --> 00：51：24,842 演讲者 SPEAKER_06：所以有一个涉及做 EM 的内部循环。
599 00：51：25,222 --> 00：51：27,003 演讲者 SPEAKER_06：而且只需要大约四次迭代。
600 00：51：28,746 --> 00：51：29,768 发言者 SPEAKER_06：所以你找到了这个集群。
601 00：51：30,548 --> 00：51：32,130 演讲者 SPEAKER_06：现在，我不相信大脑是这样的。
602 00：51：32,150 --> 00：51：33,333 议长 SPEAKER_06：这就是这个模型的工作方式。
603 00：51：33,632 --> 00：51：36,117 演讲者 SPEAKER_06：我相信大脑必须有其他方法来解决这个计算。
604 00：51：38,139 --> 00：51：40,242 议长 SPEAKER_06：但就目前而言，这是我所拥有的最好的。
605 00：51：40,356 --> 00：51：43,920 演讲者 SPEAKER_06：我做那个计算，现在我只是学习整个系统。
606 00：51：45,463 --> 00：51：59,358 演讲者 SPEAKER_06：在我学会之后，如果你展示了一个这样的数字，你看看你得到的分数和你得到的各种高级胶囊的集群，我不会给你展示所有这些。
607 00：51：59,378 --> 00：52：00,199 议长 SPEAKER_06：这边还有其他的。
608 00：52：00,880 --> 00：52：09,030 演讲者 SPEAKER_06：我只是给你看前两个坐标，因为我知道它们与位置有关。
609 00：52：09,684 --> 00：52：13,128 演讲者 SPEAKER_06：所以零，它得到了很多非常弱的赌注。
610 00：52：13,148 --> 00：52：16,170 演讲者 SPEAKER_06：那些来自什么都没有的补丁。
611 00：52：16,190 --> 00：52：22,416 发言者 SPEAKER_06：这里的圆的大小是高斯计算的那个东西的后验。
612 00：52：23,157 --> 00：52：28,782 演讲者 SPEAKER_06：这是两个标准差，我想，是的。
613 00：52：28,802 --> 00：52：31,324 议长 SPEAKER_06：所以你得到的零票看起来是这样的。
614 00：52：31,846 --> 00：52：34,007 议长 SPEAKER_06：你得到的 5 票是这样的。
615 00：52：34,507 --> 00：52：36,250 议长 SPEAKER_06：他们聚集得更紧密了。
616 00：52：36,836 --> 00：52：41,422 演讲者 SPEAKER_06：所以你的高斯量是更尖锐的高斯量，这意味着它可以给事物带来更高的概率。
617 00：52：42,563 --> 00：52：45,688 演讲者 SPEAKER_06：所以这是方差的对数。
618 00：52：45,748 --> 00：52：49,373 演讲者 SPEAKER_06：当方差的对数为负时，这意味着它是尖锐的。
619 00：52：49,393 --> 00：52：50,494 议长 SPEAKER_06：这是一个尖锐的高斯分布。
620 00：52：50,695 --> 00：52：52,135 议长 SPEAKER_06：这是一个不那么尖锐的高斯。
621 00：52：55,000 --> 00：52：56,061 演讲者 SPEAKER_06：这是你得到的分数。
622 00：52：56,101 --> 00：53：00,025 发言者 SPEAKER_06： 这是混合下的概率与均匀下的概率之间的差值。
623 00：53：01,047 --> 00：53：03,951 演讲者 SPEAKER_06：这个得了高分，其他人得了低分，所以它说这是 5。
624 00：53：05,253 --> 00：53：06,034 议长 SPEAKER_06：再举一个例子。
625 00：53：08,021 --> 00：53：13,315 演讲者 SPEAKER_06：所以我在这里向你展示更多的数字。
626 00：53：13,978 --> 00：53：19,112 演讲者 SPEAKER_06：这个得分很高，因为它是 6 分，而且是一个紧密的集群。
627 00：53：19,260 --> 00：53：26,489 演讲者 SPEAKER_06：这个集群比较紧密，所以对数方差为负一，对数方差为负二分之一，所以这个集群相当紧密。
628 00：53：27,010 --> 00：53：32,376 议长 SPEAKER_06：这有点像 0，但它知道这是 6。
629 00：53：32,396 --> 00：53：37,842 演讲者 SPEAKER_06：现在像这样的系统在 MNIST 上的表现差不多。
630 00：53：38,463 --> 00：53：45,893 演讲者 SPEAKER_06：区别在于，如果你拿一个 MACA 来训练一个卷积神经网络，你可以在 10 分钟到半小时内训练它，
631 00：53：46,244 --> 00：53：50,108 演讲者 SPEAKER_06：如果你把我的 MAC 错误训练一下，需要两天时间。
632 00：53：51,009 --> 00：53：58,117 演讲者 SPEAKER_06：那是因为与通过神经网络进行矩阵运算相比，做所有这些 EM 来获取分数之类的东西的内部循环非常慢。
633 00：53：59,679 --> 00：54：03,222 演讲者 SPEAKER_06：但是，如果我们能找到一种快速的方法来做这些事情，那就很好了。
634 00：54：03,242 --> 00：54：04,204 演讲者 SPEAKER_06：但它确实有效。
635 00：54：04,704 --> 00：54：08,208 说话者 SPEAKER_06：它通过在姿势预测中找到一致性来设法识别数字。
636 00：54：09,690 --> 00：54：10,652 演讲者 SPEAKER_06：这是一个演示。
637 00：54：11,452 --> 00：54：14,496 演讲者 SPEAKER_06：还有另一个演示更有说服力。
638 00：54：15,978 --> 00：54：18,784 演讲者 SPEAKER_06：所以需要做各种各样的事情来让它变得更好。
639 00：54：18,804 --> 00：54：20,286 发言者 SPEAKER_06：我们需要多个同步数字。
640 00：54：20,327 --> 00：54：21,068 议长 SPEAKER_06：我能搞定。
641 00：54：21,088 --> 00：54：21,570 议长 SPEAKER_06：没关系。
642 00：54：22,512 --> 00：54：24,856 议长 SPEAKER_06：在这个例子中，我向你展示了，我们没有重新分配选票。
643 00：54：24,876 --> 00：54：25,818 议长 SPEAKER_06：我们刚刚进行了自下而上的投票。
644 00：54：25,838 --> 00：54：28,425 议长 SPEAKER_06：而且我们没有根据协议路由来重新加权它们。
645 00：54：28,925 --> 00：54：34,358 议长 SPEAKER_06：所以我需要补充一下，目前有人正在通过协议添加路由，它会效果更好。
646 00：54：35,030 --> 00：54：39,594 演讲者 SPEAKER_06：我们没有更深的层次结构，我们没有真实的图像，它们只是 MNIST，还有很多工作要做。
647 00：54：41,295 --> 00：54：51,123 演讲者 SPEAKER_06：我们所做的一件事是尝试获得主要胶囊，不是通过反向传播你在数字分类中犯的错误，而是通过进行无监督学习。
648 00：54：51,664 --> 00：54：57,730 演讲者 SPEAKER_06：你喜欢做无监督学习，从像素到有姿势的实体。
649 00：54：58,650 --> 00：55：04,715 演讲者 SPEAKER_06：所以第一阶段，如果你能用无监督学习来做，它会少得多
650 00：55：04,965 --> 00：55：09,773 演讲者 SPEAKER_06：例如，您需要的标记数据要少得多。
651 00：55：15,242 --> 00：55：21,010 演讲者 SPEAKER_06：我们想取消渲染图像，并将其放到具有姿势的实体上，这些实体没有监督。
652 00：55：22,512 --> 00：55：23,853 议长 SPEAKER_06：我们有几种方法可以做到这一点。
653 00：55：24,755 --> 00：55：26,197 议长 SPEAKER_06：这是......
654 00：55：26,295 --> 00：55：27,780 议长 SPEAKER_06：这就是我们真正想做的事情。
655 00：55：27,820 --> 00：55：33,193 演讲者 SPEAKER_06：为了简化 PowerPoint，我只是假设我们得到了二维姿势，这只是位置。
656 00：55：33,815 --> 00：55：36,882 演讲者 SPEAKER_06：但实际上，我们要为完整姿势做这个，也就是完整的仿射。
657 00：55：38,987 --> 00：55：39,849 议长 SPEAKER_06：所以你有个图片。
658 00：55：40,706 --> 00：55：53,778 演讲者 SPEAKER_06：你想通过一些非线性单元，然后走出去，在这些不同的胶囊中，你想得到一个实体的位置，在这个例子中，是实体的强度。
659 00：55：54,259 --> 00：55：58,123 演讲者 SPEAKER_06：所以我把概率变成了强度，这是一个轻微的捏造，我以后需要做这些事情。
660 00：56：00,704 --> 00：56：08,132 发言者 SPEAKER_06：我现在描述的工作是 Tehman Telemann 最近发表的论文中所做的工作。
661 00：56：10,322 --> 00：56：12,726 演讲者 SPEAKER_06：这就是我们想要实现的目标。
662 00：56：12,746 --> 00：56：16,693 演讲者 SPEAKER_06：我们希望这些人学会成为实体，由他们决定自己应该成为什么样的实体。
663 00：56：16,914 --> 00：56：21,961 议长 SPEAKER_06：我们希望他们告诉我们他们的姿势和他们有多少。
664 00：56：26,188 --> 00：56：30,576 演讲者 SPEAKER_06：我们要做的是拥有一个简单的图形模型。
665 00：56：31,568 --> 00：56：36,153 议长 SPEAKER_06：哦，天哪，你看，我告诉过你，如果你让那些天生主义者进来，那他们就会接手。
666 00：56：36,574 --> 00：56：40,521 演讲者 SPEAKER_06：所以我们现在要有一个先有的图形模型，但那只是为了这个系统。
667 00：56：41,322 --> 00：56：55,501 演讲者 SPEAKER_06：我们将尝试学习重建图像，首先提取胶囊，然后从胶囊中重建图像，但使用内置图形。
668 00：56：56,402 --> 00：56：57,744 演讲者 SPEAKER_06：原来是这样运作的。
669 00：57：00,052 --> 00：57：00,954 议长 SPEAKER_06：你已经看到了这个。
670 00：57：01,795 --> 00：57：09,422 演讲者 SPEAKER_06：这是要学习的，所有这些学习，所有这些学习，它将学习提取某种实体，以及实体的姿势和实体的强度。
671 00：57：11,543 --> 00：57：14,306 演讲者 SPEAKER_06： 它知道自己是哪个实体，因为它是这些神经元。
672 00：57：16,208 --> 00：57：19,931 发言者 SPEAKER_06：然后这些实例化参数将被馈送到图形系统。
673 00：57：20,612 --> 00：57：24,175 演讲者 SPEAKER_06：根据这些参数的图形系统将不得不重建图像。
674 00：57：25,335 --> 00：57：29,199 演讲者 SPEAKER_06：图形系统将为每个实体学习一个小模板。
675 00：57：29,516 --> 00：57：44,400 演讲者 SPEAKER_06：但是，与普通的神经网络不同，图形系统将能够根据这个 X 和 Y 来转换这个模板，它能够缩放模板，根据 I 缩放这里的强度，然后它会将其添加到图像中。
676 00：57：46,322 --> 00：57：56,097 演讲者 SPEAKER_06：所以你已经连接了一些图形，你在这里学习了反转图形，但它也会学习这些实体应该是什么。
677 00：57：56,855 --> 00：58：02,221 演讲者 SPEAKER_06：你只是，当你连接图形时，你连接的东西只是获取你学到的一些实体并翻译它的能力。
678 00：58：03,402 --> 00：58：05,965 议长 SPEAKER_06： 更一般地说，做一个完整的仿射。
679 00：58：06,867 --> 00：58：07,588 议长 SPEAKER_06：好的，现在。
680 00：58：11,132 --> 00：58：16,378 演讲者 SPEAKER_06：如果你问它在建模数字中学习了什么模板，这些就是它学习的模板。
681 00：58：16,657 --> 00：58：21,043 发言者 SPEAKER_06：你可以看到它们是小块的绳子，末端有羽毛，所以你可以把它们加在一起，然后做成一个漂亮的数字。
682 00：58：23,847 --> 00：58：25,849 议长 SPEAKER_06：现在是可以的时候，
683 00：58：28,985 --> 00：58：32,130 演讲者 SPEAKER_06：是的，这东西可以对这些模板应用完整的仿射。
684 00：58：33,132 --> 00：58：36,356 演讲者 SPEAKER_06：那么让我们看看它现在是如何分解数字的。
685 00：58：39,282 --> 00：58：42,847 演讲者 SPEAKER_06：所以如果你给它看这个数字，这就是它的重建。
686 00：58：44,050 --> 00：58：50,981 演讲者 SPEAKER_06：对于它的 10 个胶囊中的每一个，这是胶囊的贡献。
687 00：58：51,001 --> 00：58：54,047 演讲者 SPEAKER_06：所以如果你看一下这个胶囊，它做出了不同的贡献。
688 00：58：54,922 --> 00：58：58,085 演讲者 SPEAKER_06：但你会看到它找到相应的部分。
689 00：58：58,126 --> 00：59：01,931 发言者 SPEAKER_06：对于这 6 个，循环的那部分编码在这里。
690 00：59：02,451 --> 00：59：04,833 发言者 SPEAKER_06：对于这两个，它在这里编码了这段曲线。
691 00：59：06,757 --> 00：59：10,521 发言者 SPEAKER_06：对于这 8 个，它在这里编码了曲线的底部。
692 00：59：11,583 --> 00：59：15,327 演讲者 SPEAKER_06：所以，当你把它们加起来时，这些贡献在重建数字方面做得非常好。
693 00：59：15,367 --> 00：59：18,652 演讲者 SPEAKER_06：它对重建非常有效。
694 00：59：18,672 --> 00：59：23,577 议长 SPEAKER_06：好的，到目前为止，我们所做的是自下而上地学习
695 00：59：24,284 --> 00：59：30,552 演讲者 SPEAKER_06：关于这些作品应该是什么样子的，我们已经学会了如何查看图像并提取这些作品的姿势。
696 00：59：32,496 --> 00：59：38,083 演讲者 SPEAKER_06：那么现在，在无人监督的情况下完成了这些工作，现在让我们尝试在此基础上做一些监督学习。
697 00：59：39,284 --> 00：59：42,969 演讲者 SPEAKER_06：记住，在你摆好姿势之后，一切都是线性的，所以生活会很轻松。
698 00：59：44,893 --> 00：59：48,978 演讲者 SPEAKER_06：所以，如果我们只有两个姿势参数，那就这么简单。
699 00：59：48,998 --> 00：59：53,565 演讲者 SPEAKER_06：你拿每个胶囊，你拿它的姿势参数，你从图像中提取它，
700 00：59：53,865 --> 00：59：56,128 演讲者 SPEAKER_06：你把它们全部连接起来，你就会得到一个大向量。
701 00：59：57,550 --> 01：00：03,298 演讲者 SPEAKER_06：当然，如果它是一个特定的形状，那么所有这些家伙之间就有很多共同的信息。
702 01：00：03,440 --> 01：00：04,681 议长 SPEAKER_06：他们都以正确的方式联系在一起。
703 01：00：05,141 --> 01：00：09,407 演讲者 SPEAKER_06：它们都可以随着你对形状的看法而改变，但它们之间有关系。
704 01：00：10,510 --> 01：00：22,827 演讲者 SPEAKER_06：所以如果你对此进行因子分析，因子分析会找到潜在因素，所以 6 个用于仿射，4 个用于变形，这些潜在因素很好地模拟了这一点。
705 01：00：24,088 --> 01：00：32,523 演讲者 SPEAKER_06：因为当你改变观点时，所有这些东西都在变化，通过改变因子所代表的仿射，你可以完美地建模。
706 01：00：34,106 --> 01：00：41,257 演讲者 SPEAKER_06：所以因子载荷，这里的这三个因子载荷，实际上将模拟整体和部分之间的关系。
707 01：00：41,818 --> 01：00：46,266 议长 SPEAKER_06：然后通过安装因子分析器，如果我只有一个数字，
708 01：00：46,735 --> 01：00：47,396 议长 SPEAKER_06：我能做到。
709 01：00：47,815 --> 01：00：51,778 演讲者 SPEAKER_06：现在我实际上有了一些数字的混合，所以我要拟合一个因子分析器的混合。
710 01：00：52,179 --> 01：00：54,782 议长 SPEAKER_06：如果我能放下其中的 10 个就好了，但那效果不太好。
711 01：00：55,322 --> 01：00：57,585 演讲者 SPEAKER_06：所以我们安装了 25 个因子分析仪的混合物。
712 01：00：59,545 --> 01：01：10,255 演讲者 SPEAKER_06：实际上，如果你只拟合 10 个因子分析器的混合物，你可以拟合因子分析器，因子分析器的混合物，你可以将其拟合到原始像素。
713 01：01：10,775 --> 01：01：15,239 演讲者 SPEAKER_06：如果你适合原始像素，这些就是因子分析器的方法。
714 01：01：16,199 --> 01：01：27,590 演讲者 SPEAKER_06：如果你把因子分析仪安装到胶囊上，然后把它们告诉胶囊做什么，然后根据它们告诉胶囊做什么来重建，这就是因子分析器的方法。
715 01：01：28,492 --> 01：01：29,652 议长 SPEAKER_06：这都是无人监督的。
716 01：01：30,733 --> 01：01：32,235 演讲者 SPEAKER_06：所以你可以看出它做得相当不错。
717 01：01：32,757 --> 01：01：39,903 演讲者 SPEAKER_06：4 和 9 有点困惑，但它真的是 10 个方向，这里有 10 个类。
718 01：01：41,425 --> 01：01：45,429 演讲者 SPEAKER_06：事实上，如果你看一下这个因子分析器，你看一下这 10 个因子，
719 01：01：46,438 --> 01：01：55,632 演讲者 SPEAKER_06：你看看改变一个因素有什么作用，如果你取平均值并减去两个标准差，你就会得到。
720 01：01：56,094 --> 01：01：57,956 发言者 SPEAKER_06：如果你加上两个标准差，你就会得到那个。
721 01：01：58,016 --> 01：02：00,039 议长 SPEAKER_06：所以这是处理斜体的一个因素。
722 01：02：00,961 --> 01：02：03,525 议长 SPEAKER_06：这是循环的一个因素，依此类推。
723 01：02：03,885 --> 01：02：08,253 演讲者 SPEAKER_06：现在在这个数据中，我们实际上没有做太多的仿射变换，所以大多数因素都是右变形。
724 01：02：11,077 --> 01：02：14,623 议长 SPEAKER_06：如果你用了 25 个因素，哦，忘了那个。
725 01：02：15,902 --> 01：02：23,532 演讲者 SPEAKER_06：如果你现在想识别很少的标记示例，你可以做的是你可以做标准的反向传播。
726 01：02：23,552 --> 01：02：28,039 扬声器 SPEAKER_06：MNIST 上具有 60,000 个示例的标准反向传播大约有 1.6% 的误差。
727 01：02：28,739 --> 01：02：30,601 演讲者 SPEAKER_06：通过各种技巧，你可以把它降低到 1% 左右。
728 01：02：31,684 --> 01：02：44,019 演讲者 SPEAKER_06：如果你做一个非常聪明的事情，叫做 Bruno Mallert 开发的散射变换，他们非常高兴，因为他们设法将其除以大约 30 倍。
729 01：02：45,367 --> 01：02：48,951 演讲者 SPEAKER_06：实际上，30,000 你得到 1.7，所以说 15。
730 01：02：50,012 --> 01：02：52,335 演讲者 SPEAKER_06：有 2,000 个标记的例子，他们也能做得一样好。
731 01：02：52,936 --> 01：02：54,918 议长 SPEAKER_06：所以他们的统计效率要高得多。
732 01：02：55,518 --> 01：02：58,222 议长 SPEAKER_06：他们可以通过 2,000 个示例获得这个错误率。
733 01：02：59,443 --> 01：03：12,420 演讲者 SPEAKER_06：如果你做我刚才给你展示的那种无监督学习，你有 25 个集群，也就是说，你对主胶囊的这些串联实例化参数做 25 个因子分析器的混合，
734 01：03：13,614 --> 01：03：24,851 演讲者 SPEAKER_06：做完这些之后，你只需拿每个因子分析器，然后你说，例如，我最有信心应该去那个因子分析器，告诉我它的名字是什么。
735 01：03：25,313 --> 01：03：26,233 议长 SPEAKER_06：告诉我它的等级是什么。
736 01：03：26,934 --> 01：03：28,617 演讲者 SPEAKER_06：所以你得问 25 个问题。
737 01：03：29,619 --> 01：03：35,887 演讲者 SPEAKER_06：如果你问 25 个问题，你平均会得到 1.75% 的错误。
738 01：03：37,271 --> 01：03：41,597 演讲者 SPEAKER_06：所以现在这更接近人类能做的事情了。
739 01：03：42,775 --> 01：03：48,621 演讲者 SPEAKER_06：你给他们看了很多数字，他们问你几个问题，然后他们就知道如何对这些数字进行分类了。
740 01：03：50,844 --> 01：03：59,614 演讲者 SPEAKER_06：所以这是一个例子，因为我们抓住了线性流形，我们使无监督学习工作正确，所以它找到了自然类。
741 01：04：00,574 --> 01：04：03,297 演讲者 SPEAKER_06：做完这些之后，你可以用很少的标签来学习。
742 01：04：04,619 --> 01：04：12,427 议长 SPEAKER_06：是的，我刚才都说了。
743 01：04：13,927 --> 01：04：14,487 议长 SPEAKER_06：到此为止。
744 01：04：15,710 --> 01：04：34,197 议长 SPEAKER_06：好的，我说完了。
745 01：04：36,202 --> 01：04：37,182 议长 SPEAKER_06：无人监督，
746 01：04：39,677 --> 01：04：43,121 议长 SPEAKER_06：好的，那么问题是，这与外面的那些人相比如何？
747 01：04：43,141 --> 01：04：47,347 演讲者 SPEAKER_06：这与在无人监督的情况下先有监督相比如何？
748 01：04：47,586 --> 01：04：51,170 演讲者 SPEAKER_06：就像无监督的预训练一样，大概，然后是有监督的要好得多。
749 01：04：53,693 --> 01：05：02,123 演讲者 SPEAKER_06：所以，如果你做标准的无监督，然后是有监督的，如果你说堆叠自动编码器，你的作用就跟 Bruner 和 Mallet 差不多。
750 01：05：03,445 --> 01：05：04,547 议长 SPEAKER_06：你不会做得比这好多少了。
751 01：05：04,987 --> 01：05：06,188 议长 SPEAKER_06：也许你可以降到 1,000。
752 01：05：06,869 --> 01：05：09,532 议长 SPEAKER_06：但这几乎比这好了两个数量级。
753 01：05：10,728 --> 01：05：12,329 扬声器 SPEAKER_06：因为你抓住了线性歧管。
754 01：05：17,757 --> 01：05：18,217 议长 SPEAKER_06：是吗？
755 01：05：18,237 --> 01：05：27,110 演讲者 SPEAKER_03：也许这个问题的另一个版本是，它与做某种更通用的混合模型相比如何，比如像素上的因子混合分析器？
756 01：05：27,130 --> 01：05：31,655 议长 SPEAKER_03：我记得以前，你会放一瓶 MNIST，嗯，大概 10 瓶
757 01：05：36,157 --> 01：05：37,699 议长 SPEAKER_06：没有这个好。
758 01：05：38,161 --> 01：05：40,625 演讲者 SPEAKER_06：所以你可以看看混合物成分的纯度。
759 01：05：44,931 --> 01：05：45,070 未知 说话者：不，不。
760 01：05：45,090 --> 01：05：47,614 议长 SPEAKER_06：显然要好得多，但你可以把它拿来比较一下。
761 01：05：47,635 --> 01：05：47,715 议长 SPEAKER_06：是的。
762 01：05：48,036 --> 01：05：50,079 议长 SPEAKER_06：嗯，那不会让你的误差降低到 1.7%。
763 01：05：50,099 --> 01：05：59,672 演讲者 SPEAKER_06：但是如果你能标记出来，那将是一个相当不错的 100% 模型。
764 01：05：59,693 --> 01：05：59,813 议长 SPEAKER_06：对。
765 01：05：59,833 --> 01：06：01,255 议长 SPEAKER_06：我认为要达到 1.7% 的错误，你可能
766 01：06：01,876 --> 01：06：04,161 扬声器 SPEAKER_06：你可能需要修复大约 1,000 个组件。
767 01：06：04,822 --> 01：06：06,447 议长 SPEAKER_06：我是说，我得检查一下。
768 01：06：06,706 --> 01：06：08,692 议长 SPEAKER_06：我怀疑你是否能在里面有 100 个组件。
769 01：06：08,711 --> 01：06：16,510 议长 SPEAKER_06：我试过那些模型，试过很多组件，有 100 个组件，如果你能降到 1.7%，我会非常惊讶。
770 01：06：21,922 --> 01：06：34,481 演讲者 SPEAKER_04：物体感知，似乎非常年幼的孩子可以追踪像原始物体这样的东西，这些物体没有完全充实详细的形状表示，但可能会有某种模糊的块是基于的，我们有连续性。
771 01：06：34,920 --> 01：06：46,277 演讲者 SPEAKER_04：我想知道你是否认为这种表示形式对于从像素空间或姿势空间学习这种映射很有用，从而促进它作为引导函数。
772 01：06：47,050 --> 01：06：55,998 演讲者 SPEAKER_06：你是不是想说，实际上他们的低分辨率通过抑制细节是有帮助的，他们只是在低分辨率下看到了它的本质，他们可以更轻松地学习？
773 01：07：01,764 --> 01：07：02,266 议长 SPEAKER_06：可能。
774 01：07：02,286 --> 01：07：03,146 议长 SPEAKER_06：我不想发表评论。
775 01：07：03,206 --> 01：07：08,452 议长 SPEAKER_06：我还没有想过这个问题，我想在说什么之前想一想。
776 01：07：08,472 --> 01：07：09,813 议长 SPEAKER_06：我没有不同意。
777 01：07：09,853 --> 01：07：11,454 议长 SPEAKER_06：可能会有帮助，但我不知道。
778 01：07：18,454 --> 01：07：43,427 演讲者 SPEAKER_06：等等，当你说为什么人类这么坏时，问题是，这其中的一个关键方面是关系的东西是固定的，事实上它是一个线性的转变。
779 01：07：43,827 --> 01：07：47,431 演讲者 SPEAKER_06：那么为什么人类如此不擅长对物体进行这种旋转转换呢？
780 01：07：47,614 --> 01：07：52,661 议长 SPEAKER_06：所以，你可能说他们这么糟糕有两件事。
781 01：07：53,583 --> 01：07：58,849 演讲者 SPEAKER_06：人类实际上非常擅长识别有趣方向的物体。
782 01：07：59,510 --> 01：08：04,876 演讲者 SPEAKER_06：你不会为此做非常精细的区分，但如果我给你看一张倒置的脸，你马上就知道这是一张倒置的脸。
783 01：08：05,237 --> 01：08：07,400 议长 SPEAKER_06：你不知道这是谁的，但你马上就知道这是一张倒过来的脸。
784 01：08：08,001 --> 01：08：09,282 演讲者 SPEAKER_06：所以你马上就做这种事。
785 01：08：10,684 --> 01：08：13,807 议长 SPEAKER_06：这可能会有 10 毫秒的惩罚。
786 01：08：14,581 --> 01：08：19,067 演讲者 SPEAKER_06：但是心理旋转大约需要 100 毫秒才能让它恢复正常。
787 01：08：19,087 --> 01：08：20,507 演讲者 SPEAKER_06：所以这是一个不同的数量级。
788 01：08：21,550 --> 01：08：33,645 演讲者 SPEAKER_06：所以，你真的必须做一些缓慢的心理旋转，做出惯用手判断，或者做一些事情，比如，这架三角钢琴能不能穿过这个工作室的门，你必须在那里做身体上的作。
789 01：08：35,627 --> 01：08：38,489 演讲者 SPEAKER_06：但是认可，你实际上很擅长处理不同的取向。
790 01：08：38,631 --> 01：08：42,175 议长 SPEAKER_06：我给你看的那个大写字母 R，你立刻就知道它是一个大写字母 R。
791 01：08：43,807 --> 01：08：46,135 议长 SPEAKER_06：当我说立即时，大约在 250 毫秒内。
792 01：08：46,957 --> 01：08：48,681 演讲者 SPEAKER_06：然后你花了 100 毫秒来旋转。
793 01：08：48,703 --> 01：08：52,975 演讲者 SPEAKER_06：如果它是 3D 的东西，你会旋转得更慢。
794 01：08：52,994 --> 01：08：53,797 发言者 SPEAKER_06：那是二维的。
795 01：08：53,978 --> 01：08：57,328 演讲者 SPEAKER_06：在 3D 中，你也会做心理旋转，但要慢得多。
796 01：09：06,369 --> 01：09：07,051 演讲者 SPEAKER_06：为了学习？
797 01：09：07,131 --> 01：09：07,971 演讲者 SPEAKER_05：是的，为了学习。
798 01：09：08,412 --> 01：09：15,539 演讲者 SPEAKER_05：你能做什么样的启发式或计算近似值来缩短那个时间？
799 01：09：16,520 --> 01：09：18,582 议长 SPEAKER_06：我相信你能把它降低很多。
800 01：09：20,685 --> 01：09：22,867 演讲者 SPEAKER_06：你可以先不用 MATLAB 编程。
801 01：09：25,609 --> 01：09：28,432 演讲者 SPEAKER_06：或者更好的是，你可以先不让我编程。
802 01：09：29,154 --> 01：09：32,056 演讲者 SPEAKER_06：那会给你一个数量级。
803 01：09：32,694 --> 01：09：41,748 演讲者 SPEAKER_06：但它的真正本质是，它与普通神经网络的不同之处在于，它的核心是寻找活动向量之间的一致性。
804 01：09：42,128 --> 01：09：45,494 发言者 SPEAKER_06：它不是在寻找权重向量和活动向量之间的一致性。
805 01：09：45,814 --> 01：09：46,655 演讲者 SPEAKER_06：这就是过滤器的作用。
806 01：09：47,698 --> 01：09：51,524 演讲者 SPEAKER_06：我们想要的是活动向量之间的一致性，这是在协方差结构之后。
807 01：09：52,585 --> 01：09：58,854 演讲者 SPEAKER_06： 还有那个计算，在一大堆随机的东西中找到这些高维一致性，
808 01：09：59,931 --> 01：10：01,533 议长 SPEAKER_06：必须有办法让它变得高效。
809 01：10：01,554 --> 01：10：03,195 演讲者 SPEAKER_06：我有一些关于如何提高效率的想法。
810 01：10：03,296 --> 01：10：04,658 议长 SPEAKER_06：如果它们有效，我会谈谈这些。
811 01：10：06,340 --> 01：10：07,360 议长 SPEAKER_06：但这就是让它变慢的原因。
812 01：10：12,787 --> 01：10：16,671 演讲者 SPEAKER_01：这里的胶囊非常直观。
813 01：10：16,771 --> 01：10：18,734 演讲者 SPEAKER_01：我们正在使用神经网络来解决许多其他类型的问题。
814 01：10：18,755 --> 01：10：24,240 演讲者 SPEAKER_01：您有什么想法吗 胶囊可以解决其他问题？
815 01：10：24,261 --> 01：10：24,461 议长 SPEAKER_06：一些。
816 01：10：25,061 --> 01：10：27,524 议长 SPEAKER_06：那么让我们开始发言。
817 01：10：28,601 --> 01：10：32,646 演讲者 SPEAKER_06：我有一个长期受苦的研究生，我让他写了一篇论文。
818 01：10：33,307 --> 01：10：35,069 演讲者 SPEAKER_06：我正在尝试将这些想法应用到演讲中。
819 01：10：37,792 --> 01：10：42,078 演讲者 SPEAKER_06：他是一个非常好的学生，这些想法很难在演讲中发挥作用。
820 01：10：42,457 --> 01：10：51,588 演讲者 SPEAKER_06：但举个例子，你可以应用，你可以说频率和发作时间的变化，以及振幅的变化。
821 01：10：52,057 --> 01：10：57,262 演讲者 SPEAKER_06：你可以尝试让实体告诉你，这个复杂的声学事件正在发生。
822 01：10：57,743 --> 01：10：59,104 议长 SPEAKER_06：这就是它发生的时候。
823 01：10：59,145 --> 01：11：01,006 议长 SPEAKER_06：这是它发生的频率。
824 01：11：01,887 --> 01：11：03,609 演讲者 SPEAKER_06： 这是它发生的幅度。
825 01：11：04,449 --> 01：11：10,877 演讲者 SPEAKER_06：最后，他设法让使用 Capsule 的思想在语音中工作的东西和标准神经网络一样工作。
826 01：11：11,157 --> 01：11：12,519 演讲者 SPEAKER_06：但它们对视觉来说更自然。
827 01：11：13,979 --> 01：11：19,405 议长 SPEAKER_00：我就到此为止。
828 01：11：19,426 --> 01：11：20,185 议长 SPEAKER_00：你有问题吗？
829 01：11：20,206 --> 01：11：20,867 议长 SPEAKER_00：让我提醒你，这是一个小组。
830 01：11：20,948 --> 01：11：25,743 演讲者 SPEAKER_00：在这个房间里，6 点，在通往智能的道路上，在所有司机之间，到外面的接待处。