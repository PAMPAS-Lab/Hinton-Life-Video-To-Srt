1 00:00:11,589 --> 00:00:29,582 说话人 说话人_00：在过去的10年里，人工智能在计算机视觉、语音识别、机器翻译、机器人技术、医学、计算生物学、蛋白质折叠预测等领域经历了突破性的进展，而且这些突破似乎没有停止的迹象。
2 00:00:30,507 --> 00:00:33,371 说话人 说话人_00：这些突破并没有显示出任何停止的迹象。
3 00:00:34,031 --> 00:00:41,481 说话人 说话人_00：更不用说，这些人工智能的突破正直接推动着价值数万亿美元的公司和许多许多新创业公司的业务。
4 00:00:42,804 --> 00:00:48,731 说话人 说话人_00：在这些突破的背后，是人工智能的一个单一子领域——深度学习。
5 00:00:50,073 --> 00:00:52,978 说话人 SPEAKER_00：那么，深度学习是在何时何地起源的？
6 00:00:53,738 --> 00:00:57,003 说话人 SPEAKER_00：它又是何时成为最突出的 AI 方法的？
7 00:00:57,996 --> 00:01:00,621 说话人 SPEAKER_00：今天的嘉宾与此息息相关。
8 00:01:01,502 --> 00:01:07,730 说话人 说话人_00：今天的嘉宾可以说是人工智能历史上最重要的人物，并且至今仍在引领这一领域的潮流。
9 00:01:08,792 --> 00:01:12,436 说话人 说话人_00：奖项，相当于计算机科学的诺贝尔奖。
10 00:01:13,659 --> 00:01:17,444 说话人 说话人_00: 今天嘉宾的工作被引用超过五十万次。
11 00:01:18,346 --> 00:01:25,775 说话人 说话人_00: 这意味着有超过五十万篇，并且还在增加的其他研究论文是基于他的工作。
12 00:01:27,123 --> 00:01:34,513 说话人 说话人_00: 今天嘉宾从事深度学习研究已有半个世纪之久，其中大部分时间处于相对的默默无闻之中。
13 00:01:35,415 --> 00:01:47,012 说话人 说话人_00：但在2012年，他展示了深度学习在图像识别方面优于其他任何计算机视觉方法，并且差距非常大。
14 00:01:47,953 --> 00:01:54,143 说话人 说话人_00：这个结果，这个时刻，被称为 ImageNet 时刻，改变了整个 AI 领域。
15 00:01:54,933 --> 00:01:58,718 说话人 说话人_00：几乎所有人都放弃了他们之前在做的事情，转而使用深度学习。
16 00:02:00,280 --> 00:02:17,020 说话人 说话人_00：今天嘉宾的前学生包括 Vlad Nii，他们通过在 Atari 游戏学习方面的第一个重大成果将 DeepMind 推向了世界，还包括我们第一季度的嘉宾，OpenAI 的创始人兼研究总监 Ilya Sutskever。
17 00:02:18,163 --> 00:02:24,770 主持人：事实上，我们播客中的每一位嘉宾都是在今天嘉宾的工作基础上进行建设的。
18 00:02:25,324 --> 00:02:31,171 说话人 说话人_00：我当然是在谈论无人能出其右的杰弗里·辛顿。
19 00:02:31,192 --> 00:02:32,913 说话人 说话人_00：杰弗里，欢迎来到节目。
20 00:02:32,954 --> 00:02:34,235 主持人：很高兴您能来。
21 00:02:34,917 --> 00:02:36,378 主持人 SPEAKER_01：非常感谢您的邀请。
22 00:02:37,479 --> 00:02:40,424 说话人 说话人_00：很高兴能在节目中和你交谈。
23 00:02:40,723 --> 00:02:46,330 说话人 说话人_00：我想我们可以直接深入探讨，也许这是我能够问你的最高层次的问题。
24 00:02:47,932 --> 00:02:51,417 说话人 说话人_00：什么是神经网络，为什么我们应该关心它？
25 00:02:51,650 --> 00:02:55,616 说话人 说话人_01：如果你已经对神经网络了解很多，请原谅我的简化。
26 00:02:57,337 --> 00:02:59,360 说话人 SPEAKER_01：这是你大脑的工作方式。
27 00:02:59,381 --> 00:03:02,425 说话人 SPEAKER_01：它有很多小的处理元素，称为神经元。
28 00:03:02,445 --> 00:03:04,187 说话人 SPEAKER_01：而且每隔一段时间，一个神经元就会发出“砰”的声音。
29 00:03:05,370 --> 00:03:09,134 说话者 SPEAKER_01：它之所以会发出“砰”的声音，是因为它在听到来自其他神经元的“砰”声。
30 00:03:09,776 --> 00:03:16,826 说话人 SPEAKER_01：每次它听到来自另一个神经元的 ping 声，它都会给它拥有的某些输入存储添加一点权重。
31 00:03:17,467 --> 00:03:20,491 说话人 SPEAKER_01：当它获得足够的输入时，它会发出 ping 声。
32 00:03:21,282 --> 00:03:31,894 说话者 SPEAKER_01：因此，如果你想了解大脑是如何工作的，你所需要知道的就是神经元在接收到“砰”声时如何调整它们所增加的权重。
33 00:03:32,814 --> 00:03:33,877 说话人 SPEAKER_01：这就是你需要知道的一切。
34 00:03:34,037 --> 00:03:36,439 说话人 SPEAKER_01：调整这些权重肯定有一些程序。
35 00:03:36,479 --> 00:03:38,322 说话人 SPEAKER_01：如果我们能弄清楚，我们就会知道大脑是如何工作的。
36 00:03:38,602 --> 00:03:43,467 说话人 SPEAKER_00：这就是你长期以来的追求，试图弄清楚大脑是如何工作的。
37 00:03:43,888 --> 00:03:45,971 说话人 说话人_00: 我们的情况如何？
38 00:03:46,390 --> 00:03:49,634 说话人 说话人_00: 我们作为领域是否理解大脑的工作原理？
39 00:03:49,936 --> 00:03:55,324 说话人 说话人_01：好的，我一直认为我们将在未来五年内破解它，因为这样想很有成效。
40 00:03:56,806 --> 00:03:59,330 说话人 说话人_01：但实际上我现在认为我们将在未来五年内破解它。
41 00:03:59,349 --> 00:04:01,212 说话人 SPEAKER_01：我觉得我们越来越接近了。
42 00:04:01,973 --> 00:04:05,117 说话人 说话人_01: 我现在相当确信这并不是反向传播。
43 00:04:05,879 --> 00:04:11,388 说话人 说话人_01: 所以我认为，现有的所有 AI 都是建立在与大脑所做完全不同的事情之上的。
44 00:04:12,650 --> 00:04:14,812 说话人 SPEAKER_01：从高层次来看，它必须是一样的。
45 00：04：14,853 --> 00：04：19,098 演讲者 SPEAKER_01：也就是说，你有很多参数，这些参数是神经元之间的权重。
46 00：04：19,079 --> 00：04：24,425 演讲者 SPEAKER_01：你根据大量的训练示例调整了这些参数。
47 00:04:25,105 --> 00:04:28,209 说话者 SPEAKER_01：如果你有数十亿个参数，这会导致发生美妙的事情。
48 00：04：29,271 --> 00：04：31,954 演讲者 SPEAKER_01：大脑是这样的，深度学习也是这样的。
49 00:04:32,634 --> 00:04:38,442 说话人 SPEAKER_01：问题是，你是如何得到调整这些参数的梯度的？
50 00:04:38,521 --> 00:04:41,745 说话人 SPEAKER_01：那么你想要的是一个衡量你做得如何的指标。
51 00:04:42,307 --> 00:04:46,891 说话人 SPEAKER_01：然后你想要调整参数，使它们提高这个衡量做得如何的指标。
52 00:04:47,007 --> 00:04:57,011 说话人 SPEAKER_01：但我的信念目前是，反向传播，这是目前深度学习工作的方式，与大脑的行为相当不同。
53 00:04:57,372 --> 00:04:58,956 说话人 SPEAKER_01：大脑以不同的方式获得梯度。
54 00:04:59,516 --> 00:05:00,338 说话人 SPEAKER_00：这很有趣。
55 00:05:00,939 --> 00:05:04,088 说话人 SPEAKER_00：是你这么说，杰夫，因为你实际上...
56 00:05:04,675 --> 00:05:11,266 说话人 SPEAKER_00：撰写了关于反向传播训练神经网络的论文，它现在正推动着所有人正在做的事情。
57 00:05:11,987 --> 00:05:18,237 说话人 说话人_00：现在你这么说，实际上，可能是我们该弄清楚的时候了，哦，你认为我们应该把它调整得接近大脑的运作方式吗？
58 00:05:18,396 --> 00:05:22,463 说话人 说话人_00：或者你认为反向传播可能比大脑的运作方式更好？
59 00:05:23,084 --> 00:05:24,185 说话人 SPEAKER_01：首先让我纠正你。
60 00:05:25,208 --> 00:05:31,358 说话人 说话人_01：是的，我们确实写了关于反向传播的最被引用的论文，Rommel、Hunt、Williams 和我。
61 00:05:31,759 --> 00:05:35,903 讲者 SPEAKER_01：反向传播已经被多位作者所知晓。
62 00:05:36,404 --> 00:05:40,428 讲者 SPEAKER_01：我们真正做的是展示了它能够学习有趣的表示。
63 00:05:40,449 --> 00:05:42,130 讲者 SPEAKER_01：所以并不是我们发明了反向传播。
64 00:05:43,391 --> 00:05:48,456 说话人 SPEAKER_01：罗梅尔哈特重新发明了反向传播，我们证明了它能够学习有趣的表示，例如，例如，词嵌入。
65 00:05:49,017 --> 00:05:58,947 讲者 SPEAKER_01：我认为反向传播可能比我们大脑中压缩大量信息到少量连接的方法要高效得多。
66 00:05:59,569 --> 00:06:02,514 其中，少量连接，我的意思是只有几十亿个。
67 00:06:05,559 --> 00:06:10,706 所以大脑的问题在于连接非常便宜。
68 00:06:12,288 --> 00:06:14,872 我们有数百万亿个连接。
69 00:06:15,934 --> 00:06:19,500 说话人 SPEAKER_01：经验非常昂贵。
70 00:06:21,161 --> 00:06:27,230 说话人 SPEAKER_01：所以我们愿意将大量参数投入到少量经验中。
71 00:06:27,615 --> 00:06:31,060 说话人 SPEAKER_01：而我们所使用的神经网络则正好相反。
72 00:06:31,901 --> 00:06:38,689 说话人 SPEAKER_01：它们拥有大量经验，并试图将输入与输出相关联的信息纳入参数中。
73 00:06:39,410 --> 00:06:50,603 说话人 SPEAKER_01：我认为反向传播比大脑在执行这项任务时更高效，但可能不是从少量数据中抽象出大量结构那么好。
74 00:06:51,983 --> 00:07:00,899 讲者 SPEAKER_00：嗯，这自然引发了一个问题，当然，您在这方面有什么假设的解决方案吗？
75 00:07:01,581 --> 00:07:09,314 说话人 SPEAKER_01：我有一种很长的观点，那就是我们需要无监督的目标函数。
76 00:07:09,855 --> 00:07:12,961 讲者 SPEAKER_01：所以我主要是在谈论感知学习。
77 00:07:14,882 --> 00:07:16,384 说话人 SPEAKER_01：我认为这是关键。
78 00:07:16,404 --> 00:07:23,415 说话人 SPEAKER_01：如果你可以通过观察世界来学习一个好的模型，那么你就可以基于这个模型而不是原始数据来采取行动。
79 00:07:24,656 --> 00:07:27,439 说话人 SPEAKER_01：这将使做正确的事情变得容易得多。
80 00:07:28,461 --> 00:07:33,968 说话人 SPEAKER_01：我坚信大脑正在使用许多小的局部目标函数。
81 00:07:34,990 --> 00:07:43,843 讲者 SPEAKER_01：所以，与其说是一个训练来优化一个目标函数的端到端系统，我认为它使用了很多小的局部优化。
82 00:07:44,413 --> 00:08:13,880 讲者 SPEAKER_01：举个例子，我认为一个好的目标函数是，虽然很难实现，那就是如果你观察图像的一小块区域，并尝试提取你认为存在的某种表示，你现在可以将从图像的这一小块区域得到的表示与通过获取其他附近区域的表示并基于这些预测该区域图像应该包含的内容的上下文赌注进行比较。
83 00:08:15,007 --> 00:08:27,041 讲者 SPEAKER_01：显然，一旦你对领域非常熟悉，从上下文和局部提取的特征所做的预测将一致，通常是一致的，当它们不一致时你会非常惊讶。
84 00:08:27,581 --> 00:08:31,067 说话人 SPEAKER_01：如果他们分歧很大，一次试验就能学到很多东西。
85 00:08:31,846 --> 00:08:36,712 说话人 SPEAKER_01：这就是我认为大脑可以从所谓的分歧中学到很多的一个例子。
86 00:08:37,924 --> 00:08:43,590 说话人 SPEAKER_01：要实现这一点很困难，但我坚信类似的东西将成为目标函数。
87 00:08:44,169 --> 00:09:03,967 说话人 SPEAKER_01：如果你想象一个大的图像和图像中的许多小局部块，这意味着你将获得大量关于局部提取的内容和图像各处的上下文预测之间一致性的反馈，以及在不同表示层次上的反馈。
88 00:09:05,068 --> 00:09:07,610 说话人 SPEAKER_01：因此我们可以得到更加丰富得多。
89 00：09：08,552 --> 00：09：14,245 演讲者 SPEAKER_01：这些协议的反馈与上下文预测有关，但要完成所有这些工作是很困难的。
90 00：09：15,388 --> 00：09：16,831 议长 SPEAKER_01：但我认为会是这样的。
91 00：09：17,734 --> 00：09：20,519 议长 SPEAKER_00：现在，你描述的内容让我印象深刻
92 00:09:21,614 --> 00:09:26,499 讲者 讲者_00：人们试图在自监督和无监督学习中做的事情的一部分。
93 00:09:26,519 --> 00:09:34,486 说话人 SPEAKER_00：实际上，您与几位合作者共同撰写了这一领域的突破性论文，SimClear 论文。
94 00:09:34,886 --> 00:09:38,551 说话人 说话人_00：您如何看待 SimClear 工作与更广泛的学习之间的对比？
95 00:09:38,591 --> 00:09:44,076 说话人 说话人_00：您如何看待最近出现的掩码自编码器，这与您刚才描述的内容有何关联？
96 00:09:44,256 --> 00:09:49,782 说话人 说话人_01：它与我所描述的内容关系非常密切。这是证明这种目标函数是好的证据。
97 00:09:51,634 --> 00:09:52,976 说话人 SPEAKER_01：我没有撰写《Simpler》论文。
98 00:09:54,500 --> 00:09:59,087 说话人 SPEAKER_01：Tim Chen 在主要合作者的帮助下撰写了 Simpler 论文。
99 00:09:59,688 --> 00:10:15,616 说话人 SPEAKER_01：我的名字出现在论文上是为了表示一般性的启发，但我确实很久以前和 Sue Becker 一起撰写了一篇关于从两个不同的图像块中获取的表示之间达成一致性的想法的论文。
100 00:10:16,693 --> 00:10:26,687 说话人 SPEAKER_01：所以，我认为这是通过两个相同图像块之间的表示达成一致来实现自监督学习的这一想法的起源。
101 00:10:28,948 --> 00:10:38,922 说话人 SPEAKER_01：我和 Sue 使用的方法当时没有很好地工作，因为当时我们没有理解的一个微妙的东西，但现在我明白了。
102 00:10:40,403 --> 00:10:44,147 说话人 SPEAKER_01：如果愿意，我可以解释，但我可能失去大部分观众。
103 00:10:44,846 --> 00:10:45,888 说话人 SPEAKER_00：嗯，我很好奇。
104 00:10:46,168 --> 00:10:50,913 说话人 SPEAKER_00：我想听听，但也许我们在聚焦之后再稍微退一步看看会更好。
105 00:10:51,374 --> 00:10:57,960 说话人 说话人_00：你提到当前的方法使用端到端学习、反向传播来驱动端到端学习。
106 00:10:58,701 --> 00:11:09,110 说话人 说话人_00：你说转向从更少的数据中学习并从更少的数据中提取更多信息将是取得进展、更接近大脑学习方式的关键。
107 00:11:09,344 --> 00:11:16,913 说话人 说话人_01：是的，通过拥有许多许多小的局部目标函数，你可以获得更大的学习带宽。
108 00:11:16,932 --> 00:11:30,970 说话人 SPEAKER_00：当我们观察这些局部目标函数时，比如填充图像中被遮挡的部分，或者可能填充回一个单词，如果我们看看今天的科技，实际上，这就是当前的边界，你也有所贡献。
109 00:11:30,990 --> 00:11:39,299 众多人在研究如何有效地从无标签数据中学习，因为这比使用人工劳动成本低得多。
110 00:11:39,634 --> 00:11:45,302 尽管如此，他们仍然使用反向传播，同样的机制。
111 00:11:45,523 --> 00:11:55,777 所以我不喜欢主自动编码器的地方在于，你有一组输入块，然后通过许多层表示。
112 00:11:57,038 --> 00:12:01,524 说话人 SPEAKER_01：在网络的输出端，你尝试重建缺失的输入补丁。
113 00:12:02,450 --> 00:12:11,167 说话人 SPEAKER_01：我认为大脑有这些层次的表现形式，但在每个层次上，你都在尝试重建下一层次的内容。
114 00:12:11,187 --> 00:12:15,976 说话人 SPEAKER_01：所以并不是说经过很多很多层然后又回到起点。
115 00:12:16,017 --> 00:12:22,450 说话人 SPEAKER_01：就是这些层级，每个层级都在尝试重建下一层级的结构。
116 00:12:23,087 --> 00:12:24,710 说话人 SPEAKER_01：所以我认为这更像是大脑的工作方式。
117 00:12:25,471 --> 00:12:28,414 说话人 SPEAKER_01：那么问题来了，你能在不使用反向传播的情况下做到这一点吗？
118 00:12:28,735 --> 00:12:36,083 说话人 SPEAKER_01：显然，如果你要经过很多层级，然后在输出端重建缺失的补丁，你需要通过所有这些层级来获取信息。
119 00:12:37,225 --> 00:12:41,471 说话人 SPEAKER_01：既然我们有反向传播，它已经内置到所有模拟器中，你不妨就这样做。
120 00:12:42,010 --> 00:12:44,774 说话人 SPEAKER_01：但我认为大脑并不是这样做的。
121 00:12:44,794 --> 00:12:48,418 说话人 SPEAKER_00：现在想象一下大脑正在用所有这些局部目标来完成这项工作。
122 00:12:49,740 --> 00:12:52,504 说话人 SPEAKER_00：您认为对于我们的工程系统，
123 00:12:52,567 --> 00:12:57,332 说话人 SPEAKER_00：在某种程度上，是否有三个选择需要做出，这似乎很重要。
124 00:12:57,552 --> 00:12:59,816 说话人 SPEAKER_00：其中一个选择是目标是什么？
125 00:13:00,096 --> 00:13:02,839 说话人 SPEAKER_00：我们想要优化的局部目标是什么？
126 00:13:03,620 --> 00:13:09,605 说话人 SPEAKER_00：第二个选择是使用什么算法来优化它？
127 00:13:09,686 --> 00:13:16,953 说话人 SPEAKER_00：然后第三个选择是关于如何连接执行这种学习的神经元的架构。
128 00:13:17,754 --> 00:13:20,937 说话人 SPEAKER_00：在这三个中，似乎都是这三个。
129 00:13:21,761 --> 00:13:25,567 说话人 SPEAKER_00：这可能就是我们没有做对的那块缺失的拼图，或者你怎么看？
130 00:13:26,109 --> 00:13:33,760 说话人 SPEAKER_01：如果你对感知学习感兴趣，我认为很明显你想要视网膜映射，一个视网膜映射的层次结构。
131 00:13:34,662 --> 00:13:36,784 说话人 SPEAKER_01：所以架构是局部连接性。
132 00:13:38,027 --> 00:13:41,812 说话人 SPEAKER_01：关于这一点，关键在于
您可以通过假设在逆时区图中一个局部区域中的某些内容将由为其提供信息的逆时区图中的相应局部区域所决定，来解决很多信用分配问题。
所以你并不是试图在系统中降低层级，找出像素如何确定图像中远处发生的事情。
135 00：14：07,639 --> 00：14：09,303 演讲者 SPEAKER_01：你只使用本地交互。
136 00:14:09,745 --> 00:14:11,148 说话者 SPEAKER_01：这给了你很多局部性。
137 00:14:11,969 --> 00:14:15,596 说话人 SPEAKER_01：你不利用它才奇怪呢。
138 00:14:16,657 --> 00:14:22,167 说话人 SPEAKER_01：目前神经网络做的一件事是，它们假设在每一个局部位置都会使用相同的函数。
139 00:14:22,287 --> 00:14:25,113 说话人 SPEAKER_01：卷积神经网络可以做到这一点，Transformer 也可以。
140 00:14:27,155 --> 00:14:36,373 说话人 SPEAKER_01：我认为大脑不能这样做，因为这会涉及到权重共享，并且需要在每个局部位置进行完全相同的计算，以便可以使用相同的权重。
141 00:14:37,355 --> 00:14:39,558 说话人 SPEAKER_01：我认为大脑不太可能这样做。
142 00:14:40,113 --> 00:15:08,398 说话人 SPEAKER_01：但实际上有一种方法可以实现权重共享的功能，就像大脑中的卷积神经网络所做的那样，比人们之前提出的更可信，那就是如果你有尝试与局部提取内容达成一致的上下文预测，那么想象一下有一系列列在进行局部预测，并查看附近的列以获取上下文预测。
143 00:15:09,138 --> 00:15:13,982 说话人 SPEAKER_01：你可以把上下文看作是局部事物的老师，但反过来也是如此。
144 00:15:14,823 --> 00:15:17,866 说话人 SPEAKER_01：但把上下文看作是吸引局部事物的老师。
145 00:15:19,087 --> 00:15:25,634 说话人 SPEAKER_01：所以你可以把上下文中的信息看作是提炼成了局部提取器。
146 00:15:26,635 --> 00:15:28,357 说话人 SPEAKER_01：但这适用于所有的局部提取器。
147 00:15:29,519 --> 00:15:35,365 说话人 SPEAKER_01：你们所拥有的就是相互蒸馏，他们都在为彼此提供教学信号。
148 00:15:35,868 --> 00:15:49,423 说话人 SPEAKER_01：这意味着关于在一个位置应该提取什么知识正在转移到其他位置，如果他们试图达成一致，如果你试图让不同位置就某事达成一致。
如果，例如，你找到一个鼻子和一个嘴巴，那么你希望它们都同意它们是同一张脸的一部分。
150 00：15：56,231 --> 00：15：59,174 发言者 SPEAKER_01： 所以他们都应该产生相同的表示。
那么，你试图在不同位置获得相同表示的事实，使得知识可以从一个位置提炼到另一个位置。
152 00:16:06,894 --> 00:16:10,500 说话者 SPEAKER_01：而且这比实际权重共享有一个很大的优势。
153 00:16:11,341 --> 00:16:16,389 说话人 SPEAKER_01：显然，从生物学的角度来看，一个优势是这些不同位置的详细架构不必完全相同。
154 00:16:17,370 --> 00:16:20,696 说话人 SPEAKER_01：但另一个优势是前端处理不必相同。
155 00:16:21,336 --> 00:16:25,803 说话人 SPEAKER_01：所以如果你看你的视网膜，视网膜的不同部分有不同的感受野大小。
156 00:16:26,576 --> 00:16:28,740 说话人 SPEAKER_01：而卷积神经网络试图忽略这一点。
157 00:16:29,360 --> 00:16:35,932 说话人 SPEAKER_01：它们有时具有多个不同的分辨率，并在每个分辨率上进行卷积，但它们无法处理不同的前端处理。
158 00:16:38,235 --> 00:16:50,695 说话者 SPEAKER_01：而如果你正在从一个地方提炼知识到另一个地方，你所试图做的是从光阵列到这些不同位置的表示中获取相同的功能。
159 00:16:52,091 --> 00:17:04,782 说话者 SPEAKER_01：在两个不同的位置对光阵列进行预处理不同是可以的，你仍然可以从光阵列到表示的功能中提炼知识，尽管前端处理不同。
160 00:17:05,943 --> 00:17:13,509 说话人 SPEAKER_01：因此，虽然蒸馏比实际共享权重效率低，但它更加灵活，也更加符合神经实现。
161 00:17:14,391 --> 00:17:21,896 讲者 SPEAKER_01：对我来说，大约一年前我有一个很大的启示，那就是我们必须有一种类似于权重共享的东西才能高效。
162 00:17:22,450 --> 00:17:27,137 但如果你试图让相邻的事物就表示达成一致，局部蒸馏是可行的。
163 00:17:28,059 --> 00:17:36,074 说话者 SPEAKER_01：但试图让它们达成一致的想法，为你提供了在一个位置获取知识以监督另一个位置知识的信号。
164 00:17:37,615 --> 00:17:43,767 说话者 SPEAKER_00：杰夫，你认为，你所描述的，一种思考方式可以说，嘿，我们是在分享。
165 00:17:44,084 --> 00:17:46,990 说话人 SPEAKER_00：它很聪明，因为它做的是大脑也会做的事情。
166 00:17:47,010 --> 00:17:48,074 说话人 SPEAKER_00：它只是以不同的方式来做。
167 00:17:48,374 --> 00:17:50,199 说话人 SPEAKER_00：所以我们应该继续进行权重共享。
168 00:17:50,740 --> 00:17:59,121 说话人 SPEAKER_00: 另一种思考方式是，实际上我们不应该继续进行权重共享，因为大脑的做法有所不同，这可能是我们不同做法的原因。
169 00:18:00,042 --> 00:18:00,944 说话人 SPEAKER_00: 你是怎么想的？
170 00:18:01,127 --> 00:18:06,032 说话人 SPEAKER_01: 我认为大脑不进行权重共享，因为它很难将突触强度传输到其他地方。
171 00:18:06,834 --> 00:18:08,496 说话人 SPEAKER_01: 如果它们都坐在 RAM 中，那就非常容易了。
172 00:18:09,436 --> 00:18:14,122 说话人 SPEAKER_01：所以，我认为我们应该继续在 convlets 和 transformers 中做卷积操作。
173 00:18:14,462 --> 00:18:15,304 说话人 SPEAKER_01：我们应该共享权重。
174 00:18:16,525 --> 00:18:28,198 说话人 SPEAKER_01：我们应该通过共享权重来共享知识，但请记住，大脑并不是通过共享权重来共享知识的，而是通过共享从输入到输出的函数，并使用蒸馏来传递知识。
175 00:18:29,630 --> 00:18:37,537 说话人 SPEAKER_00：现在还有另一个话题被广泛讨论，那就是大脑与我们的当前神经网络有显著的不同。
176 00:18:37,696 --> 00:18:38,538 说话人 SPEAKER_00：那就是。
177 00:18:39,258 --> 00:18:46,265 说话人 SPEAKER_00：神经元使用脉冲信号工作，这与我们 GPU 中的人工神经元非常不同。
178 00:18:47,045 --> 00:18:58,134 说话人 SPEAKER_00：所以我非常好奇您的看法，这是否仅仅是工程上的差异，或者您认为其中可能还有更多我们需要更好地理解的东西，以及脉冲信号的好处？
179 00:18:58,756 --> 00:19:00,919 说话人 SPEAKER_01：我认为这不仅仅是一个工程上的差异。
180 00:19:00,939 --> 00:19:15,199 说话人 SPEAKER_01：我认为一旦我们理解了为什么这种硬件如此出色，为什么你可以在这种硬件上以如此节能的方式做这么多事情，我们就会看到使用脉冲神经元对大脑来说是合理的。
181 00:19:15,380 --> 00:19:17,623 说话人 SPEAKER_01：例如，视网膜不使用脉冲神经元。
182 00:19:17,962 --> 00:19:20,507 说话人 SPEAKER_01：视网膜使用非脉冲神经元进行大量处理。
183 00:19:21,288 --> 00:19:26,855 说话人 SPEAKER_01：所以一旦我们明白大脑皮层为什么要使用这些，
184 00:19:27,358 --> 00:19:30,242 讲者 SPEAKER_01：我们就会看到这对生物学来说是对的。
185 00:19:30,763 --> 00:19:38,275 说话人 SPEAKER_01：我认为这取决于学习算法，以及如何为脉冲神经元网络获取梯度。
186 00:19:38,855 --> 00:19:40,458 说话人 SPEAKER_01：目前，没有人真正知道。
187 00:19:40,837 --> 00:19:48,409 说话人 SPEAKER_01：目前人们所做的是说，你看，脉冲神经元的问题在于有两种截然不同的决策。
188 00:19:49,391 --> 00:19:51,773 说话人 SPEAKER_01：其中一种是它何时产生脉冲？
189 00：19：52,515 --> 00：19：54,597 议长 SPEAKER_01：另一个是，它是否会飙升？
所以这里有一个离散的决定，神经元应该放电还是不放电？
191 00:19:59,007 --> 00:20:01,568 说话者 SPEAKER_01：然后是神经元何时激增的连续变量。
192 00:20:02,690 --> 00:20:10,499 说话者 SPEAKER_01：试图优化这种系统的那些人已经提出了各种类型的代理函数，这些函数可以稍微平滑一些，以便得到连续函数。
193 00:20:10,858 --> 00:20:11,960 说话人 SPEAKER_01：它们看起来不太对。
194 00:20:13,862 --> 00:20:15,624 说话人 SPEAKER_01：如果能有一个学习算法那就太好了。
195 00:20:16,184 --> 00:20:25,294 说话人 SPEAKER_01：实际上，在 2000 年左右，我和 Andy Brown 在 NIPS 上发表了一篇关于尝试学习脉冲 Boltzmann 机的论文。
196 00:20:25,544 --> 00:20:30,128 说话人 SPEAKER_01：但能有一个适用于脉冲神经元的优秀学习算法那就太好了。
197 00:20:30,528 --> 00:20:33,772 说话人 SPEAKER_01：我认为这是阻碍突触神经元硬件发展的主要因素。
198 00:20:34,492 --> 00:20:42,882 说话人 SPEAKER_01：所以像曼彻斯特的 Steve Furber 这样的人，以及其他许多人，已经意识到可以通过这种方式制造出更节能的硬件。
199 00:20:43,342 --> 00:20:44,624 说话人 SPEAKER_01：他们已经构建了庞大的系统。
200 00:20:45,163 --> 00:20:47,246 说话人 SPEAKER_01：他们还没有一个适用于它的优秀学习算法。
201 00:20:47,266 --> 00:20:53,593 说话者 SPEAKER_01：我认为在我们找到一个好的学习算法之前，我们无法真正利用脉冲神经元的潜力。
202 00:20:53,573 --> 00:21:00,686 说话者 SPEAKER_01：对于它们来说，有一件显而易见的事情可以在传统神经网络中难以实现，那就是一致性。
203 00:21:01,548 --> 00:21:07,601 说话者 SPEAKER_01：所以如果你拿一个标准的人工神经元，简单地问一个问题，它能否判断其两个输入是否具有相同的值？
204 00:21:08,663 --> 00:21:09,163 说话人 SPEAKER_01：嗯，它不能。
标准神经元，一个标准的类神经元，并不是一件容易的事情。
如果您使用脉冲神经元，构建一个系统非常容易，如果两个脉冲同时到达，它们会使神经元放电，如果它们在不同时间到达，则不会。
所以使用尖峰的时间似乎是一种衡量一致性的非常好的方法。
208 00：21：29,166 --> 00：21：30,989 演讲者 SPEAKER_01：我们知道生物系统就是这样做的。
所以你可以看到声音传来的方向，或者说通过两只耳朵接收到信号的时差来听到声音传来的方向。
210 00:21:43,826 --> 00:21:52,680 说话人 SPEAKER_01：如果你以光速来计算，大约是一个纳秒，而声音大约是一个毫秒。
如果我在你面前横向移动几英寸，到达两只耳朵的时间延迟和到达两只耳朵的路径长度，差异仅为一英寸的小部分。
212 00:22:09,204 --> 00:22:10,527 说话者 SPEAKER_01：因此
213 00:22:10,759 --> 00:22:16,027 说话人 SPEAKER_01：两个耳朵接收到信号的时间差只有短短的千分之一秒。
214 00:22:16,468 --> 00:22:19,051 说话者 SPEAKER_01：我们可以处理这个问题，猫头鹰甚至能处理得更好。
215 00:22:19,692 --> 00:22:29,886 说话人 SPEAKER_01：因此我们在测量，我们对大约 30 微秒的时间非常敏感，以便从声音中获得立体声。
216 00:22:31,328 --> 00:22:35,654 说话人 SPEAKER_01：我不记得猫头鹰对什么敏感，但我想它比 30 微秒要好得多。
217 00:22:36,375 --> 00:22:37,897 说话人 SPEAKER_01：我们通过有两个轴突，一个从一只耳朵出发，一个从另一只耳朵出发，并且当这些尖峰同时到达时，细胞就会放电来实现这一点。
218 00:22:38,619 --> 00:22:46,334 说话者 SPEAKER_01：两个具有不同方向的轴突，一个来自一个耳朵，一个来自另一个耳朵，然后当这些尖峰同时到达时，细胞就会放电。
219 00:22:47,115 --> 00:22:48,719 说话人 SPEAKER_01：这是一个简化，但大致如此。
220 00:22:51,143 --> 00:22:54,690 说话者 SPEAKER_01：所以，我们知道尖峰时间可以用于处理像这样极其敏感的事情。
221 00:22:55,892 --> 00:23:02,063 说话者 SPEAKER_01：如果尖峰时间没有被用来精确地排序，那将会非常令人惊讶，但我们真的不知道如何做到这一点。
222 00:23:02,869 --> 00:23:13,909 说话者 SPEAKER_01：长期以来，我一直认为如果能用尖峰时间来检测诸如自监督学习或类似的事情的协议，那将会非常棒。
223 00:23:14,767 --> 00:23:26,608 说话者 SPEAKER_01：如果我提取了你的嘴巴和鼻子，或者更确切地说，提取了它们的表示，那么我现在可以预测你整个脸部的某些信息。
224 00:23:27,130 --> 00:23:29,273 说话者 SPEAKER_01：而且从你的鼻子，我可以预测你整个脸部的某些信息。
225 00:23:30,096 --> 00:23:33,642 说话人 SPEAKER_01：如果你的嘴和鼻子位置正确，可以做出面部表情，那么这些预测就会一致。
226 00:23:33,662 --> 00:23:37,769 说话人 SPEAKER_01：如果能用尖峰时间来观察这些预测是否一致，那就太好了。
227 00:23:38,459 --> 00:23:41,125 说话人 SPEAKER_01：但要做到这一点很难。
228 00:23:41,184 --> 00:23:46,896 说话人 SPEAKER_01：其中一个原因是很难做到这一点，因为我们不知道，我们没有训练脉冲神经元网络的良好算法。
229 00:23:47,557 --> 00:23:50,183 说话人 SPEAKER_01：这就是我现在关注的一件事。
230 00:23:50,243 --> 00:23:52,848 说话人 SPEAKER_01：我们如何为脉冲神经元网络找到好的训练算法？
231 00:23:53,349 --> 00:23:55,674 说话人 SPEAKER_01：我认为这将对硬件产生重大影响。
232 00:23:56,633 --> 00:24:11,849 说话人 SPEAKER_00：你提出的问题非常有趣，因为我怀疑从事这方面工作的人并不多，与最近在大型语言模型或其他更明显取得进展的问题相比，我想。
233 00:24:12,750 --> 00:24:20,920 说话人 SPEAKER_01：是的，弄清楚大量非常聪明的人正在做什么，然后去做其他事情，总是一个好主意。
234 00:24:22,097 --> 00:24:41,528 说话人 SPEAKER_00: 我认为挑战，当然，对于大多数人来说，包括我自己，但我也确实从许多学生那里听到这个问题，就是去做别人没有做的事情很容易，但确保你做的事情确实相关却很难，因为还有许多其他事情可能并不那么相关，你可能会浪费时间去关注它们。
235 00:24:42,089 --> 00:24:44,173 说话人 SPEAKER_01: 是的，这需要良好的直觉。
236 00:24:44,575 --> 00:24:47,618 说话人 SPEAKER_00: 是的，比如听你说话，可能会有所帮助。
237 00:24:48,279 --> 00:24:59,252 说话者 SPEAKER_00：所以我实际上有一个后续问题，就是你刚才说的，杰夫，那就是视网膜并不使用所有脉冲神经元。
238 00:24:59,333 --> 00:25:06,461 说话人 SPEAKER_00：你是说大脑有两种类型的神经元，一些更像是我们的人工神经元，而另一些则是脉冲神经元吗？
239 00:25:07,643 --> 00:25:10,886 说话者 SPEAKER_01：我不确定视网膜是否更像是我们的人工神经元，但
240 00:25:11,913 --> 00:25:16,960 说话者 SPEAKER_01：当然，大脑皮层，新皮层有脉冲神经元。
241 00:25:18,020 --> 00:25:26,291 说话者 SPEAKER_01：它的主要通信方式是通过从一个参数细胞向另一个参数细胞发送尖峰。
242 00:25:26,311 --> 00:25:34,983 说话者 SPEAKER_01：我认为，除非我们理解为什么大脑会选择发送尖峰，否则我们不会理解大脑。
243 00:25:35,003 --> 00:25:41,633 说话人 SPEAKER_01：有一段时间，我认为我有一个很好的论点，这个论点不涉及脉冲的精确时间。
244 00:25:42,135 --> 00:25:43,238 说话者 SPEAKER_01：论点是这样的。
245 00:25:44,078 --> 00:25:53,571 讲者 SPEAKER_01：大脑处于拥有大量参数而相对数据较少的状态，这是我们通常使用的典型神经网络的状况。
246 00:25:53,592 --> 00:25:58,479 讲者 SPEAKER_01：在这种状态下，如果不使用非常强的正则化，就存在过拟合的风险。
247 00:25:59,980 --> 00:26:05,548 讲者 SPEAKER_01：而一个好的正则化技术是 dropout，每次使用神经网络时，你会忽略一大堆单元。
248 00:26:07,171 --> 00:26:12,057 说话人 SPEAKER_01：所以，也许神经元发送尖峰的事实
249 00:26:13,372 --> 00:26:18,960 说话人 SPEAKER_01：他们真正传达的是潜在的泊松率。
250 00:26:18,980 --> 00:26:21,604 说话人 SPEAKER_01：所以让我们假设它是泊松分布，这对于这个论点来说足够接近了。
251 00:26:23,026 --> 00:26:31,377 说话人 SPEAKER_01：有一个泊松过程，它会随机发送尖峰，但这个过程的速度会变化，这由神经元的输入决定。
252 00:26:32,779 --> 00:26:37,826 说话人 SPEAKER_01：你可能认为你想将一个神经元的真实值速率发送到另一个神经元。
253 00:26:38,566 --> 00:26:45,615 说话人 SPEAKER_01：但是如果你想要进行大量的正则化，你可以发送带有噪声的真实值率。
254 00:26:46,877 --> 00:26:49,821 说话人 SPEAKER_01：添加噪声的一种方法就是使用尖峰。
255 00:26:50,162 --> 00:26:51,203 说话人 SPEAKER_01：这将添加很多噪声。
256 00:26:52,705 --> 00:27:03,401 说话人 SPEAKER_01：因此，这就是 dropout 的动机，因为在任何精细的时间窗口中，大多数神经元都不参与其中。
257 00:27:04,402 --> 00:27:08,488 说话人 SPEAKER_01：你们可以把尖峰看作是...
258 00:27:08,688 --> 00:27:16,817 说话人 SPEAKER_01：作为底层泊松率的表示，这只是一个非常、非常嘈杂的表示，听起来像是一个非常、非常糟糕的想法，因为它非常、非常嘈杂。
259 00:27:17,258 --> 00:27:21,163 说话人 SPEAKER_01：但实际上，一旦你了解了正则化的概念，当你有太多参数时，这是一个非常好的主意。
260 00:27:22,223 --> 00:27:28,211 说话人 SPEAKER_01：所以我对这个想法仍然怀有深深的喜爱，那就是我们实际上根本就没有使用尖峰时间。
261 00:27:29,071 --> 00:27:35,859 说话人 SPEAKER_01：这仅仅是使用泊松率的非常嘈杂的表示作为良好的正则化器。
262 00:27:37,055 --> 00:27:45,002 说话人 SPEAKER_01：我认为在科学研究中，不要完全承诺于一个想法而忽略其他想法的证据是很重要的。
263 00:27:45,644 --> 00:27:50,970 说话人 SPEAKER_01：但如果你这样做，你会在每几年之间不断变换想法。
264 00:27:51,951 --> 00:27:56,276 说话人 SPEAKER_01：所以有些年份我认为神经网络是确定性的。
265 00:27:56,476 --> 00:27:59,479 说话人 SPEAKER_01：我的意思是，我们应该有确定性的神经网络，这正是 Backpot 所使用的。
266 00:28:00,200 --> 00:28:02,761 说话人 SPEAKER_01：而且我认为，每隔几年，大约是五年一个周期。
267 00:28:03,202 --> 00:28:06,066 说话人 SPEAKER_01：我认为，不，不，最好的随机性非常重要。
268 00:28:06,349 --> 00:28:08,711 说话人 SPEAKER_01：这改变了所有事物的味道。
269 00:28:08,731 --> 00:28:11,816 说话人 SPEAKER_01：玻尔兹曼机本质上是随机的，这对它们来说非常重要。
270 00:28:13,616 --> 00:28:17,480 说话人 SPEAKER_01：但主要的是不要完全承诺于其中任何一个，而是要开放接受两者。
271 00:28:19,022 --> 00:28:33,538 说话人 SPEAKER_00：现在，如果我们更深入地思考你刚才说的，关于突触神经元的重要性以及如何有效地训练突触神经元网络，如果我们现在就先不考虑训练部分，鉴于
272 00:28:33,838 --> 00:28:36,683 说话人 SPEAKER_00：看起来它更加节能。
273 00:28:38,086 --> 00:28:51,249 说话人 SPEAKER_00：人们是否希望分发纯推理芯片，这种芯片是你，你预先训练的，然后将其编译到脉冲神经元芯片上，以实现非常低的功耗推理能力。
274 00:28:51,650 --> 00:28:52,371 说话人 SPEAKER_00：那呢？
275 00:28:52,907 --> 00:28:56,773 说话人 SPEAKER_01：是的，很多人都有这样的想法，这是一个非常合理的想法。
276 00:28:57,233 --> 00:29:15,220 说话人 SPEAKER_01：这可能是在使用脉冲神经网络的道路上的一个进化阶段，因为一旦你开始使用它们进行推理，并且它有效，人们已经在做这件事了，并且它已经证明更节能，各家公司已经生产了这些大型脉冲系统。
277 00:29:17,173 --> 00:29:29,471 说话人 SPEAKER_01：既然你已经在做推理，那么你会越来越感兴趣于如何以更充分地利用可用的尖峰时间的方式来学习。
278 00:29:30,271 --> 00:29:41,407 说话人 SPEAKER_01：所以你可以想象一个系统，在这个系统中你使用反向传播来学习，但不是在模拟硬件上，或者不是在这个低功耗硬件上。
279 00:29:42,068 --> 00:29:46,674 说话人 SPEAKER_01：然后你将其转移到低功耗硬件上，这样是可以的。
280 00:29:48,442 --> 00:29:50,667 说话人 SPEAKER_01：但我们真的希望能在硬件中直接学习。
281 00:29:51,670 --> 00:30:06,924 讲者 讲者_00：现在，有一件事让我印象非常深刻，杰夫，那就是我想起你在 2005、6、7、8 年左右时的演讲，当时我还是一名博士生，基本上是在 AlexNet 之前。
282 00:30:07,461 --> 00:30:12,326 讲者 讲者_00：我认为那些演讲在主题上与你现在所热衷的有很多相似之处。
283 00:30:13,248 --> 00:30:17,310 讲者 讲者_00：而且几乎感觉 AlexNet 在你的道路上是一个例外。
284 00:30:18,553 --> 00:30:35,628 讲者 讲者_00：你是如何从如此紧密地思考大脑可能的工作方式，转变为决定首先解释什么是 AlexNet，以及它是如何产生的，以及从研究受限玻尔兹曼机，试图了解大脑的工作方式，到我说，
285 00:30:35,980 --> 00:30:39,547 说话人 SPEAKER_00：你们突然展示的更传统的神经网络方法实际上可行吗？
286 00:30:40,449 --> 00:30:43,795 说话人 SPEAKER_01：嗯，如果你是学者，你就得筹集研究经费。
287 00:30:43,835 --> 00:30:50,728 说话人 SPEAKER_01：而且有真正可行的事情是很方便的，即使它们不是你感兴趣的方式。
288 00:30:51,789 --> 00:30:52,751 说话人 SPEAKER_01：所以这部分原因就在这里。
289 00:30:52,852 --> 00:30:53,874 说话人 SPEAKER_01: 随遇而安。
290 00:30:54,095 --> 00:30:58,021 说话人 SPEAKER_01: 如果你能让反向传播工作得很好，
291 00:30:58,001 --> 00:31:12,123 说话人 SPEAKER_01: 当时，大约在 2006 年、2005 年，我对这样一个想法着迷，即你可以使用受限玻尔兹曼机堆栈来预训练特征检测器，然后恢复工作会容易得多。
292 00:31:13,404 --> 00:31:18,271 说话人 SPEAKER_01: 结果，有了足够的数据，这在语音识别中是有的，
293 00:31:18,859 --> 00:31:25,710 说话人 SPEAKER_01：后来，由于李飞飞及其团队在图像识别方面的贡献，有了足够的数据，你就不需要预训练了。
294 00:31:26,069 --> 00:31:27,392 说话人 SPEAKER_01：尽管预训练正在回归。
295 00:31:27,512 --> 00:31:29,596 说话人 SPEAKER_01：我的意思是，GPT-3 有预训练。
296 00:31:30,396 --> 00:31:32,859 说话人 SPEAKER_01：预训练是一个非常好的主意。
297 00:31:35,324 --> 00:31:38,167 说话人 SPEAKER_01：但是一旦我们
298 00:31:39,463 --> 00:31:42,086 说话人 SPEAKER_01：可以预训练，这将使反向传播工作得更好。
299 00:31:42,146 --> 00:31:50,153 说话人 SPEAKER_01：这为语音识别带来了巨大的进步，这是 George Darl 和 Abdulrahman Mohamed 在 2009 年所做的事情。
300 00:31:52,076 --> 00:32:06,130 说话人 SPEAKER_01：然后 Alex，当时是我的研究生，开始将同样的想法应用于视觉。
301 00:32:06,261 --> 00:32:12,971 说话人 SPEAKER_01：很快我们就发现，实际上并不需要这种预训练，尤其是如果你有 ImageNet 数据的话。
302 00:32:14,673 --> 00:32:20,441 说话人 SPEAKER_01：事实上，这个项目部分得益于 Ilya 的坚持。
303 00:32:21,040 --> 00:32:26,949 说话人 SPEAKER_01：我记得有一天 Ilya 来到实验室说，现在我们语音识别已经成功了，这东西真的管用。
304 00:32:27,529 --> 00:32:29,873 说话人 SPEAKER_01：我们必须在别人之前完成 ImageNet。
305 00:32:31,304 --> 00:32:38,875 说话人 SPEAKER_01：回顾过去，我了解到 Jan LeCun 正在进入实验室，说，看，我们必须在别人之前用卷积神经网络做 ImageNet。
306 00:32:40,277 --> 00:32:45,223 说话人 SPEAKER_01：Jan 的学生和博士后说，哦，但我正忙于做其他事情。
307 00:32:45,644 --> 00:32:49,009 发言人 SPEAKER_01：他实际上无法让某人承诺这一点。
308 00:32:49,765 --> 00:32:53,172 说话人 SPEAKER_01：伊利亚最初无法让人们为此做出承诺。
309 00:32:53,992 --> 00:32:58,281 说话人 SPEAKER_01：因此伊利亚说服亚历克斯为此做出承诺，为他预处理数据。
310 00:32:58,301 --> 00:32:59,683 说话人 SPEAKER_01：所以他不必预处理数据。
311 00:32:59,703 --> 00:33:02,048 说话人 SPEAKER_01：数据已经全部预处理，正好是他需要的。
312 00:33:02,789 --> 00:33:04,153 说话人 SPEAKER_01：然后亚历克斯真的大显身手了。
313 00:33:04,173 --> 00:33:06,136 说话人 SPEAKER_01：亚历克斯是一位出色的程序员。
314 00:33:06,724 --> 00:33:10,989 说话人 SPEAKER_01：亚历克斯能让几块 GPU 真正发挥出威力。
315 00:33:11,128 --> 00:33:13,991 说话人 SPEAKER_01：他在家里的卧室里让它们一起工作。
316 00:33:14,913 --> 00:33:19,356 说话人 SPEAKER_01：我认为他的父母没有意识到他们支付了大部分费用，因为那是电费。
317 00:33:21,479 --> 00:33:25,782 说话人 SPEAKER_01：但他在这上面对卷积神经网络进行了出色的编程。
318 00:33:28,105 --> 00:33:32,750 说话人 SPEAKER_01：所以伊利亚说，我们必须这么做，并在设计等方面帮助了亚历克斯。
319 00:33:33,290 --> 00:33:35,752 说话人 SPEAKER_01: Alex 完成了非常复杂的编程工作。
320 00:33:35,917 --> 00:33:40,832 说话人 SPEAKER_01: 我提供了支持，并给出了一些想法，比如使用 Dropout。
321 00:33:40,963 --> 00:33:43,067 说话人 SPEAKER_01：我也做了一些很好的管理工作。
322 00:33:43,207 --> 00:33:58,967 说话人 SPEAKER_01：我并不经常擅长管理，但我非常自豪我所做的工作，那就是亚历克斯·克雷齐乌斯基（Alex Krzyzewski）不得不写一篇深度论文来证明他能够理解研究文献，这是你在博士项目中进行几年后必须做的事情。
323 00:33:59,688 --> 00:34:00,929 说话人 SPEAKER_01：而且他并不喜欢写作。
324 00:34:01,650 --> 00:34:06,836 说话人 SPEAKER_01: 他其实并不想进行深度测试，但是已经过了截止日期，系里正在催促我们。
325 00:34:07,711 --> 00:34:18,974 说话人 SPEAKER_01: 所以我对他说，每次你在 ImageNet 上的性能提高 1%，你就可以延迟深度测试一周。
326 00:34:20,978 --> 00:34:24,065 说话者 SPEAKER_01：亚历克斯推迟了他的深度规则好几个星期。
是的，仅就背景而言，许多研究人员当然知道这一点，但也许并非每个人都知道。
328 00:34:31,346 --> 00:34:42,300 说话人 说话人_00：我和 Alex 以及 Ilya 的结果将错误率降低了一半，与 ImageNet 图像识别竞赛的先前工作相比，这几乎是... 大概吧。
329 00:34:42,420 --> 00:34:45,885 说话人 说话人_01：我以前是教授，所以并没有完全减半。
330 00:34:46,144 --> 00:34:46,545 说话人 说话人_01：差不多。
331 00:34:46,925 --> 00:34:51,893 说话人 说话人_01：它将错误率从大约26%降低到大约16%或15%，具体取决于你如何计算。
332 00:34:52,210 --> 00:34:54,293 说话人 SPEAKER_01：它没有切成两半，但几乎切成了。
333 00:34:54,432 --> 00:34:55,153 说话人 SPEAKER_00：几乎减半。
334 00:34:55,213 --> 00:34:57,936 说话人 SPEAKER_00：而往年，进步只有 1%或 2%。
335 00:34:58,617 --> 00:35:02,222 说话人 SPEAKER_00：这里则完全不同。
336 00:35:02,503 --> 00:35:09,311 说话人 SPEAKER_00：这就是为什么大家都放弃了他们之前所做的事情，那就是手动设计计算机视觉方法，试图直接编程。
337 00:35:09,351 --> 00:35:13,135 说话人 SPEAKER_00：计算机如何通过深度学习理解什么是图像？
338 00:35:13,657 --> 00:35:16,500 说话人 SPEAKER_01：我必须在这里说一件重要的事情。
339 00:35:17,021 --> 00:35:22,166 说话人 SPEAKER_01：Yann LeCun 多年致力于卷积神经网络的研究。
340 00:35:22,467 --> 00:35:27,451 说话人 SPEAKER_01：实际上，那个系统应该是由他和他的实验室开发的。
341 00:35:28,052 --> 00:35:30,373 说话人 SPEAKER_01：我们有一些小技巧，但它们并不是最重要的。
342 00:35:30,393 --> 00:35:35,177 说话人 SPEAKER_01：重要的是将卷积网络应用于大数据集，并使用 GPU。
343 00:35:36,900 --> 00:35:44,666 说话人 SPEAKER_01：所以 Jan 在这方面运气不太好，他没有赢得胜利，但他使用了他所开发的大多数技术。
344 00:35:44,967 --> 00:35:51,192 说话人 SPEAKER_00：他没有像多伦多和您那样吸引到俄罗斯移民来实现这一点。
345 00:35:51,577 --> 00:35:55,041 说话人 SPEAKER_01：嗯，一个是俄罗斯人，一个是乌克兰人，不要混淆这两个。
346 00:35:55,061 --> 00:36:00,710 说话人 SPEAKER_01：尽管乌克兰人说俄语，但不要把俄语和乌克兰语混淆。
347 00:36:00,731 --> 00:36:01,771 说话人 SPEAKER_01：这是一个不同的国家。
348 00:36:03,275 --> 00:36:09,503 说话人 SPEAKER_00：那么，Jeff，这一刻实际上也标志着你职业生涯的一个重大转变。
349 00:36:10,706 --> 00:36:14,090 说话人 SPEAKER_00：因为据我所知，你以前从未参与过
350 00:36:15,387 --> 00:36:26,248 说话人 说话人_00：但不久之后，这标志着您从纯学术到最终加入谷歌的转变。
351 00:36:27,030 --> 00:36:27,893 说话人 说话人_00：您能谈谈这方面的情况吗？
352 00:36:27,932 --> 00:36:28,713 说话人 说话人_00：这对您来说怎么样？
353 00:36:28,833 --> 00:36:29,615 说话人 说话人_00: 喜欢。
354 00:36:29,731 --> 00:36:31,132 说话人 说话人_00: 你有没有任何内部阻力？
355 00:36:31,454 --> 00:36:34,938 说话人 说话人_01: 我可以说明为什么发生了这个转变，是什么触发了它。
356 00:36:34,958 --> 00:36:37,682 说话人 SPEAKER_01: 嗯，我很好奇。
357 00:36:38,163 --> 00:36:42,610 说话人 SPEAKER_01：所以我有一个学习障碍的儿子，他需要未来的保障。
358 00:36:42,909 --> 00:36:44,413 说话人 SPEAKER_01：所以我需要一笔钱。
359 00:36:45,094 --> 00:36:48,978 说话人 SPEAKER_01：我认为获得一笔钱的一种方式是教授 Coursera 课程。
360 00:36:50,161 --> 00:36:53,646 说话人 SPEAKER_01：因此我在 2012 年上了 Coursera 的神经网络课程。
361 00:36:54,081 --> 00:36:57,387 说话人 SPEAKER_01: 那是 Coursera 早期的课程之一，所以他们的软件不太好。
362 00:36:57,407 --> 00:36:59,108 讲者 SPEAKER_01：所以，做起来非常令人烦恼。
363 00:36:59,148 --> 00:37:02,934 讲者 SPEAKER_01：当时确实非常令人烦恼。
364 00:37:03,594 --> 00:37:06,539 讲者 SPEAKER_01：我对软件不太擅长，所以我不喜欢那样。
365 00:37:07,440 --> 00:37:11,786 说话人 SPEAKER_01: 从我的角度看，这相当于
366 00:37:12,981 --> 00:37:16,532 说话人 SPEAKER_01：你同意每周提供一本教科书的章节，每周一章。
367 00:37:18,757 --> 00:37:23,650 说话人 SPEAKER_01：所以你必须提供这些视频，然后会有很多人观看这些视频。
368 00:37:23,670 --> 00:37:28,324 说话人 SPEAKER_01：比如有时候第二天，约书亚·本吉奥会说，你为什么这么说？
369 00:37:28,304 --> 00:37:32,492 说话人 SPEAKER_01：你知道，这将是那些知识很少，但也知识很多的人。
370 00:37:33,155 --> 00:37:34,036 说话人 SPEAKER_01: 因此，这很紧张。
371 00:37:34,137 --> 00:37:35,940 说话人 SPEAKER_01：你知道，如果你犯错误，它们会被捕捉到。
372 00:37:36,282 --> 00:37:44,900 说话人 SPEAKER_01：不像正常讲座那样，如果你对某事稍微有些困惑，就可以踩着维持踏板，混过去。
373 00:37:45,702 --> 00:37:47,106 说话人 SPEAKER_01：这里，你必须弄清楚。
374 00:37:48,148 --> 00:38:01,585 说话人 SPEAKER_01：最初与多伦多大学的协议是，如果这些课程能赚到钱，我希望是这样，那么赚到的钱会与大学教授分成。
375 00:38:02,126 --> 00:38:07,634 说话人 SPEAKER_01：他们没有具体说明分割比例，但人们假设可能是 50-50 或者类似的比例。
376 00:38:08,594 --> 00:38:09,496 说话人 SPEAKER_01：我对这个结果是可以接受的。
377 00:38:10,297 --> 00:38:15,304 讲者 SPEAKER_01：大学在准备视频方面没有提供任何支持。
378 00:38:16,684 --> 00:38:36,190 讲者 SPEAKER_01：然后我开始上课，当我无法退出时，教务长未经与我或其他人协商，单方面做出决定，如果资金来自 Coursera，大学将拿走所有资金，教授分文不得，这与教科书的情况正好相反。
379 00:38:37,954 --> 00:38:40,918 说话人 SPEAKER_01：这个过程非常像购买教科书。
380 00:38:41,217 --> 00:38:44,041 讲者 SPEAKER_01：我实际上请求大学帮助我准备视频。
381 00:38:44,326 --> 00:38:49,963 说话人 SPEAKER_01：然后音频视频人员回来告诉我，你知道制作视频有多贵吗？
382 00:38:50,867 --> 00:38:53,795 说话人 SPEAKER_01：实际上我确实有想法，因为我一直在做这件事。
383 00:38:55,108 --> 00:39:02,599 说话人 SPEAKER_01：所以我对我所在的大学非常生气，因为他们单方面取消了给我报酬的想法。
384 00:39:02,900 --> 00:39:04,181 说话人 SPEAKER_01：他们说这是我的教学工作的一部分。
385 00:39:04,722 --> 00:39:06,625 说话人 SPEAKER_01：实际上，这并不是我的教学内容。
386 00:39:07,204 --> 00:39:14,715 讲者 SPEAKER_01：它显然是基于我作为教学一部分所给的讲座，但我同时也在做我的教学，我没有用这门课程来教学。
387 00:39:15,637 --> 00:39:21,824 讲者 SPEAKER_01：这让我非常生气，以至于我愿意考虑成为教授的替代方案。
388 00:39:22,126 --> 00:39:37,329 讲者 SPEAKER_01：那时，我们突然受到了各种公司的兴趣，他们要么提供资金，要么给予大额拨款，要么资助创业公司。
389 00:39:38,612 --> 00:39:44,420 说话人 SPEAKER_01：很明显，许多大公司只是非常想参与其中。
390 00:39:46,072 --> 00:39:51,039 说话人 SPEAKER_01：我本来说不，我研究工作是国家付我工资的。
391 00:39:51,880 --> 00:39:54,704 说话人 SPEAKER_01：我不想从我的研究中额外赚钱。
392 00:39:55,025 --> 00:39:57,088 说话人 SPEAKER_01：我更愿意继续进行研究。
393 00：39：57,108 --> 00：40：05,699 演讲者 SPEAKER_01：但是因为在大学的那次特殊经历骗了我钱......现在，事实证明他们并没有欺骗我，因为
394 00:40:05,679 --> 00:40:13,634 说话人 SPEAKER_01：但那让我下定决心，好吧，我要找其他方式赚钱。
395 00：40：13,853 --> 00：40：19,824 议长 SPEAKER_00：我的原则就这样结束了。
结果是，这些公司实际上是，如果你读过 Cade Metz 的《天才创造者》一书，我上周为了这次对话重读的，如果你读过这本书，它实际上是从你为这些公司举办拍卖以尝试收购你的公司开始的，这是本书相当独特的一个开头。
397 00:40:43,768 --> 00:40:44,409 说话人 说话人_00：非常有趣。
398 00:40:44,829 --> 00:40:45,851 说话人 说话人_00：那您觉得呢？
399 00:40:45,891 --> 00:40:49,474 说话人 SPEAKER_01：当时是在 NIPS 会议上发生的。
400 00:40:49,572 --> 00:40:57,682 说话人 说话人_01：Terry 曾在塔霍湖的赌场组织了 NIPS 会议。
401 00:40:58,605 --> 00:41:12,523 说话人 SPEAKER_01：所以在酒店的地下室，有这些烟雾缭绕的房间，里面满是人们拉动一臂的赌博机，大灯光闪烁，显示你赢了 25,000 美元等等，还有人在其他方式赌博。
402 00:41:14,025 --> 00:41:16,068 说话人 SPEAKER_01：楼上，我们在进行拍卖。
403 00:41:16,740 --> 00:41:19,326 说话人 SPEAKER_01：我们感觉就像是在电影里。
404 00:41:20,246 --> 00:41:24,114 说话人 SPEAKER_01：我们感觉就像是在看那部电影，《社交网络》一样。
405 00:41:24,175 --> 00:41:25,096 说话人 SPEAKER_01：感觉有点那样。
406 00:41:25,536 --> 00:41:26,018 说话人 SPEAKER_01：太棒了。
407 00:41:26,900 --> 00:41:30,746 说话人 SPEAKER_01：我们之所以这么做，是因为我们根本不知道我们的价值。
408 00:41:32,389 --> 00:41:38,039 说话人 SPEAKER_01：我咨询了一位律师，一位知识产权律师，他说，有两条路可以走。
409 00:41:38,880 --> 00:41:40,824 说话人 SPEAKER_01: 你可以雇佣一名专业谈判员。
410 00:41:41,715 --> 00:41:50,266 说话人 SPEAKER_01: 在这种情况下，你最终会为一家公司工作，但他们会对你的态度很糟糕。
411 00:41:50,286 --> 00:41:51,708 说话人 SPEAKER_01: 或者你可以直接进行拍卖。
412 00:41:52,809 --> 00:41:58,775 说话人 SPEAKER_01: 据我所知，这是第一次有这样一个小型团体直接进行拍卖。
413 00:41:58,856 --> 00:41:59,876 说话人 SPEAKER_01: 我们在 Gmail 上运行了它。
414 00:42:00,717 --> 00:42:08,246 说话人 SPEAKER_01: 我在暑假期间在谷歌工作过，所以我足够了解谷歌，知道他们不会阅读我们的 Gmail。
415 00:42:10,657 --> 00:42:12,739 说话人 SPEAKER_01: 我仍然相当确信他们没有阅读我们的 Gmail。
416 00:42:14,199 --> 00:42:15,541 说话人 SPEAKER_01: 微软并不这么自信。
417 00:42:17,903 --> 00:42:20,786 说话人 SPEAKER_01：我们刚刚进行了一场拍卖，人们需要给我发邮件提交他们的出价。
418 00:42:21,987 --> 00:42:27,253 说话人 SPEAKER_01: 然后，我们立即将带有 Gmail 时间戳的邮件发送给其他人。
419 00:42:27,273 --> 00:42:31,036 说话人 SPEAKER_01：价格一直在以五十万美元的幅度上涨。
420 00:42:31,157 --> 00:42:35,139 说话人 SPEAKER_01：我想一开始是五十万美元，然后涨到了一百万美元。
421 00:42:36,041 --> 00:42:40,005 说话人 SPEAKER_01: 是的，那真的很令人兴奋。
422 00:42:41,099 --> 00:42:43,789 说话人 SPEAKER_01: 我们发现我们比想象的更有价值。
423 00:42:46,338 --> 00:42:52,762 说话人 SPEAKER_01: 回顾起来，我们可能本可以得到更多，但我们得到了一个我们认为天文数字的金额。
424 00:42:53,722 --> 00:43:01,750 说话人 SPEAKER_01: 然后，我们基本上想为谷歌工作，所以我们停止了拍卖，以确保我们能加入谷歌。
425 00:43:01,769 --> 00:43:04,492 说话人 说话人_00：据我了解，您现在还在谷歌。
426 00:43:05,213 --> 00:43:06,355 说话人 SPEAKER_01：我今天还在谷歌。
427 00:43:06,394 --> 00:43:08,175 说话人 说话人_01：已经过去了九年。
428 00:43:08,215 --> 00:43:09,538 说话人 说话人_01：我在那里已经十年了。
429 00:43:10,197 --> 00:43:13,481 说话人 SPEAKER_01：我觉得在那里工作 10 年后我会得到某种奖项，因为这是非常罕见的。
430 00:43:14,762 --> 00:43:17,806 说话人 SPEAKER_01：尽管人们通常在谷歌比在其他公司待的时间更长。
431 00:43:17,826 --> 00:43:19,067 说话人 SPEAKER_01：是的，我喜欢那里。
432 00:43:19,387 --> 00:43:22,851 说话人 SPEAKER_01：我喜欢那里的主要原因是因为
433 00:43:23,117 --> 00:43:27,103 主持人 SPEAKER_01：大脑团队是一个非常棒的团队，我和 Jeff Dean 相处得非常好。
434 00:43:28,784 --> 00:43:33,670 主持人 SPEAKER_01：他非常聪明，但处理起来非常直接。
435 00:43:34,452 --> 00:43:39,137 主持人 SPEAKER_01：他想让我做的事情就是做我想做的事情，那就是基础研究。
436 00:43:40,719 --> 00:43:45,065 主持人 SPEAKER_01：他认为我应该做的事情是尝试提出全新的算法，而这正是我想做的事情。
437 00:43:45,847 --> 00:43:47,989 说话人 SPEAKER_01: 这只是一个非常合适的搭配。
438 00:43:48,269 --> 00:43:51,454 说话人 SPEAKER_01: 我不擅长管理一个团队，以提高语音识别率 1%。
439 00:43:51,514 --> 00:43:52,635 说话人 SPEAKER_01: 我在这方面会很无望。
440 00:43:52,902 --> 00:43:55,686 说话人 SPEAKER_00: 嗯，最好是再次彻底改变这个领域，对吧？
441 00:43:56,128 --> 00:43:56,367 说话人 SPEAKER_01: 嗯。
442 00:43:58,731 --> 00:44:00,896 说话人 SPEAKER_01: 我想再试一次。
443 00:44:01,235 --> 00:44:02,237 说话人 SPEAKER_00: 我非常期待。
444 00:44:02,619 --> 00:44:03,981 说话人 SPEAKER_00: 我一点也不感到惊讶。
445 00:44:04,681 --> 00:44:14,860 说话人 SPEAKER_00：现在，当我看你的职业生涯，Jeff，其中一些信息实际上来自那本书，因为我第一次读那本书之前并不知道这些。
446 00:44:15,768 --> 00:44:25,862 说话人 SPEAKER_00：你是，你是多伦多大学的计算机科学教授，现在应该是名誉教授了，但你是计算机科学专业的，但你从未获得过计算机科学学位。
447 00:44:26,141 --> 00:44:33,431 说话人 SPEAKER_00：你获得了心理学学位，而且你曾经一度是一名木匠。
448 00:44:35,094 --> 00:44:35,775 说话人 SPEAKER_00：这是怎么发生的？
449 00:44:35,795 --> 00:44:42,204 说话人 SPEAKER_00：你是如何从研究心理学到成为一名木匠，再到涉足人工智能领域的？
450 00:44:42,324 --> 00:44:43,847 说话人 SPEAKER_00：你的这条道路是怎样的？
451 00:44:43,987 --> 00:44:44,947 说话人 SPEAKER_00：你是如何看待这个问题的？
452 00:44:45,333 --> 00:44:55,987 说话人 SPEAKER_01：我在剑桥的最后一年非常艰难，非常不快乐，考试后不久就辍学了，然后成为了一名木匠。
453 00:44:57,030 --> 00:45:02,818 说话人 SPEAKER_01：我一直更喜欢木工胜过其他任何事情。
454 00:45:04,621 --> 00:45:14,715 说话人 SPEAKER_01：所以在高中时，会有各种课程，然后你可以留在晚上做木工，这正是我最期待的事情。
455 00:45:16,416 --> 00:45:17,398 说话人 SPEAKER_01：所以我成为了一名木匠。
456 00:45:17,418 --> 00:45:22,262 说话人 SPEAKER_01：然后我做了大约六个月的木匠之后，实际上作为木匠是没法谋生的。
457 00:45:23,023 --> 00:45:26,827 说话人 SPEAKER_01：我曾经是一名木匠和装饰师，我通过装饰赚钱，但我在木工中找到了乐趣。
458 00:45:27,608 --> 00:45:36,318 说话人 SPEAKER_01：关键是，木工的工作比看起来要辛苦，而装饰的工作比看起来要轻松。
459 00:45:36,478 --> 00:45:42,023 说话人 SPEAKER_01：所以你可以按小时收取更高的装饰费用，除非你是一名非常出色的木匠。
460 00:45:42,824 --> 00:45:44,465 说话人 SPEAKER_01：然后我遇到了一位真正的木匠。
461 00:45:45,407 --> 00:45:48,980 说话人 SPEAKER_01：我意识到我在木工方面完全无望。
462 00:45:50,403 --> 00:45:57,949 说话人 SPEAKER_01：所以他正在为地下室制作一扇门，为地下人行道下的潮湿的煤仓。
463 00:45:58,925 --> 00:46:06,697 说话人 SPEAKER_01：他正在取木材，并排列它们，使它们向相反方向弯曲，以相互抵消。
464 00:46:07,597 --> 00:46:12,025 说话人 SPEAKER_01：这体现了一种对工艺流程的理解和思考。
465 00:46:12,045 --> 00:46:12,947 说话者 SPEAKER_01：这从未在我脑海中出现过。
466 00:46:13,367 --> 00:46:17,793 说话者 SPEAKER_01：他也可以拿一块木头，用手工锯正好锯成方形。
467 00:46:18,364 --> 00:46:20,608 说话者 SPEAKER_01：他向我解释了一些有用的东西。
468 00:46:21,088 --> 00:46:29,918 说话者 SPEAKER_01：他说，如果你想锯一块木头成方形，你必须将锯木台与房间对齐，并将木头与房间对齐。
469 00:46:30,880 --> 00:46:36,585 说话人 SPEAKER_01：如果它与房间不齐，就不能裁剪成方形，这在坐标系方面非常有趣。
470 00:46:39,429 --> 00:46:46,498 说话人 SPEAKER_01：所以无论如何，因为我与他相比非常绝望，我决定我最好回到人工智能领域。
471 00:46:46,697 --> 00:46:53,088 说话人 SPEAKER_00：当你说回到人工智能领域时，据我理解，这是在爱丁堡大学，你那里去读博士？
472 00:46:53,688 --> 00:46:56,192 说话人 SPEAKER_01：是的，我去那里读博士。
473 00:46:56,492 --> 00:47:05,186 说话人 SPEAKER_01：我去和一位名叫克里斯托弗·兰格-希金斯（Christopher Langer-Higgins）的杰出教授一起攻读神经网络博士，他真的很聪明。
474 00:47:06,708 --> 00:47:10,072 说话人 SPEAKER_01：他在 30 多岁时几乎获得了诺贝尔奖。
475 00:47:10,356 --> 00:47:14,302 说话人 SPEAKER_01：因为解决了关于硼氢化物结构的问题。
476 00:47:15,103 --> 00:47:26,398 说话人 SPEAKER_01：我仍然不明白那是什么，因为它全部与量子力学有关，但关键在于 360 度的旋转不是恒等算子，而是 720 度。
477 00:47:27,139 --> 00:47:29,621 说话人 SPEAKER_01：你想要在这些关于它的书中找到的东西。
478 00:47:30,382 --> 00:47:31,605 说话人 SPEAKER_01：无论如何，
479 00:47:33,525 --> 00:47:36,329 说话人 SPEAKER_01：他对神经网络和全息图的关系很感兴趣。
480 00:47:36,971 --> 00:47:45,284 说话人 SPEAKER_01：就在我到达爱丁堡的那天，他因为阅读了 Winograd 的论文而失去了对神经网络的兴趣，并完全转变了观念。
481 00:47:45,344 --> 00:47:49,150 说话人 SPEAKER_01：他认为神经网络是错误思考方式。
482 00:47:49,349 --> 00:47:51,313 说话人 SPEAKER_01：我们应该做符号人工智能。
483 00:47:51,753 --> 00:47:53,416 说话人 SPEAKER_01：他对 Winograd 的论文印象深刻。
484 00:47:54,637 --> 00:47:57,862 说话人 SPEAKER_01：所以我们有了，
485 00:47:58,061 --> 00:47:59,443 说话人 SPEAKER_01：他很有正直感。
486 00:48:00,143 --> 00:48:04,447 说话人 SPEAKER_01：尽管他完全不同意我所做的事情，但他并没有阻止我去做。
487 00:48:05,168 --> 00:48:11,153 说话人 SPEAKER_01：他一直试图让我做更多像 Winograd Caesars 那样的事情，但他允许我继续做我正在做的事情。
488 00:48:12,135 --> 00:48:16,298 说话人 SPEAKER_01：是的，我有点孤僻。
489 00:48:16,378 --> 00:48:22,144 说话人 SPEAKER_01: 在那个七十年代初，其他所有人都在说，明斯基和帕普特已经证明神经网络是无稽之谈。
490 00:48:22,644 --> 00:48:23,746 说话人 SPEAKER_01: 你为什么要做这些？
491 00:48:23,786 --> 00:48:24,407 说话人 SPEAKER_01: 这太疯狂了。
492 00:48:26,007 --> 00:48:33,219 说话人 SPEAKER_01: 事实上，我第一次给那个小组做的演讲是关于如何用神经网络实现真正的递归。
493 00:48:35,342 --> 00:48:38,467 说话人 SPEAKER_01：这次演讲是在 1973 年，所以 49 年前。
494 00:48:39,708 --> 00:48:51,829 说话人 SPEAKER_01：所以我的第一个项目之一，我最近发现了它的一个报告，就是你想让一个神经网络能够绘制一个形状。
495 00:48:52,635 --> 00:48:57,603 说话人 SPEAKER_01：并且你想让它能够将形状分解成部分。
496 00:48:58,523 --> 00:49:05,693 说话人 SPEAKER_01：并且你想让形状的一部分能够由与整个形状绘制相同的神经网络来绘制。
497 00:49:07,096 --> 00:49:18,811 说话者 SPEAKER_01：所以绘制整个形状的神经硬件必须记住它在整个形状中的位置，以及整个形状的朝向和大小。
498 00:49:19,297 --> 00:49:25,132 说话者 SPEAKER_01：但现在它必须离开，你希望使用完全相同的神经元来绘制形状的一部分。
499 00:49:26,494 --> 00:49:36,277 说话者 SPEAKER_01：因此你需要一个地方来记住整个形状是什么，以及你在其中走了多远，这样你就可以在完成这个子程序、形状的这一部分后返回到那里。
500 00:49:37,101 --> 00:49:39,606 说话者 SPEAKER_01：问题是，神经网络将如何记住这一点？
501 00:49:39,666 --> 00:49:42,130 说话人 SPEAKER_01：因为显然你不能只是复制神经元。
502 00:49:42,150 --> 00:49:49,822 说话人 SPEAKER_01：所以我成功开发了一个系统，该系统通过具有快速赫布权重并不断适应的系统来记住它。
503 00:49:49,862 --> 00:49:58,958 说话人 SPEAKER_01：我们正在适应，以便可以通过提供该状态的一部分来检索它最近的状态，然后说，填写其余部分。
504 00:50:00,304 --> 00:50:08,717 说话人 SPEAKER_01：因此，我有一个神经网络，它执行真正的递归，重复使用相同的神经元和相同的权重来执行递归调用，就像它用于高级调用一样。
505 00:50:09,719 --> 00:50:10,400 说话人 SPEAKER_01: 那是在 1973 年。
506 00:50:11,001 --> 00:50:20,695 说话人 SPEAKER_01: 我认为人们没有理解这次演讲，因为我不擅长演讲，他们还问，你为什么要用神经网络做递归呢？
507 00:50:20,735 --> 00:50:22,197 说话人 SPEAKER_01: 你可以用 Lisp 做递归。
508 00:50:24,041 --> 00:50:26,565 说话人 SPEAKER_01: 他们没有理解这个观点，那就是
509 00:50:26,882 --> 00:50:32,588 说话人 SPEAKER_01：除非我们让神经网络做到递归，否则我们永远无法解释许多事情。
510 00:50:32,608 --> 00:50:36,291 说话人 SPEAKER_01：而现在这又成了一个有趣的问题。
511 00:50:36,992 --> 00:50:42,679 说话人 SPEAKER_01：所以我打算再等一年，直到那个想法变得像古董一样，真正的古董，它将会有 50 年的历史。
512 00:50:43,338 --> 00:50:46,322 说话人 SPEAKER_01：然后我会整理那时我所做的研究。
513 00:50:47,023 --> 00:50:49,144 说话人 SPEAKER_01：这一切都是关于快速权重作为记忆。
514 00:50:49,445 --> 00:50:52,889 说话人 SPEAKER_00：所以我这里有很多问题，Geoff。
515 00:50:52,969 --> 00:50:53,969 说话人 SPEAKER_00：第一个问题是，
516 00:50:55,047 --> 00:51:01,432 说话人 SPEAKER_00：你站在这个房间里，这里每个人都，你是博士生或者刚从博士生毕业。
517 00:51:02,052 --> 00:51:09,199 说话人 SPEAKER_00: 你站在一个房间里，几乎每个人都告诉你你所从事的工作是浪费时间。
518 00:51:09,239 --> 00:51:13,422 说话人 SPEAKER_00: 你怎么会有这种想法？
519 00:51:13,543 --> 00:51:14,885 Speaker SPEAKER_00: 你从哪里得到这种信念？
520 00:51:15,684 --> 00:51:19,969 说话人 SPEAKER_01: 我认为这很大一部分原因在于我的教育背景。
521 00:51:19,989 --> 00:51:23,231 说话人 SPEAKER_01：所以我父亲是个共产主义者。
522 00:51:24,898 --> 00:51:29,905 说话人 SPEAKER_01：但他却把我送到一所昂贵的私立学校，因为那里的科学教育很好。
523 00:51:31,588 --> 00:51:33,391 说话人 SPEAKER_01：我在那里从七岁开始上学。
524 00:51:34,813 --> 00:51:42,563 说话人 SPEAKER_01：我上过幼儿园，那是一所基督教学校，其他所有孩子都信仰上帝。
525 00:51:42,583 --> 00:51:47,891 Speaker SPEAKER_01: 就是在家里，有人教我那是胡说。
526 00:51:48,692 --> 00:51:49,893 Speaker SPEAKER_01: 我觉得
527 00:51:51,005 --> 00:51:51,865 说话人 SPEAKER_01：那是胡说。
528 00:51:52,666 --> 00:52:01,474 说话人 SPEAKER_01：所以我习惯了其他人都是错的，而且是明显错误的。
529 00:52:03,396 --> 00:52:04,797 说话人 SPEAKER_01：我认为这很重要。
530 00:52:06,480 --> 00:52:14,708 Speaker SPEAKER_01: 我认为你需要，我差点就要说，你需要信仰，这种情况下很奇怪。
531 00:52:15,849 --> 00:52:18,851 说话人 SPEAKER_01：你需要对科学有信心来
532 00:52:20,063 --> 00:52:25,731 说话人 SPEAKER_01：愿意仅仅因为它是显然正确的就去做事情，即使其他人说它是胡说八道。
533 00:52:27,472 --> 00:52:28,735 事实上，不是其他人。
534 00:52:28,815 --> 00:52:34,422 在20世纪70年代初，几乎所有做人工智能的人都认为这是胡说，或者说几乎所有的人都这么认为。
535 00:52:36,385 --> 00:52:41,692 说话人 SPEAKER_01：但如果您稍微早一点看，如果您在 50 年代看，冯·诺伊曼和图灵都相信神经网络。
536 00:52:42,914 --> 00:52:48,501 说话人 SPEAKER_01：图灵尤其相信使用强化学习训练的神经网络。
537 00:52:49,527 --> 00:52:59,641 说话人 SPEAKER_01：我仍然相信，如果他们俩没有早早去世，人工智能的整个历史可能都会非常不同，因为他们都是足够强大的思想家，足以安抚一个领域。
538 00:53:01,083 --> 00:53:07,972 说话人 SPEAKER_01：他们对大脑是如何工作的非常感兴趣。
539 00:53:07,992 --> 00:53:09,835 说话人 SPEAKER_01：所以，我认为我们俩都早逝只是运气不好。
540 00:53:10,536 --> 00:53:12,659 说话人 SPEAKER_01: 嗯，英国情报可能已经介入了。
541 00:53:14,021 --> 00:53:19,347 说话人 SPEAKER_00: 现在，你相信这个，当时，很多人并不相信。
542 00:53:20,137 --> 00:53:25,887 说话人 SPEAKER_00: 获得重大突破帮助了我，几乎今天所做的一切。
543 00:53:26,027 --> 00:53:29,632 说话人 SPEAKER_00: 现在某种程度上，下一个问题，对吧？
544 00:53:30,074 --> 00:53:34,701 说话人 SPEAKER_00：嗯，不仅仅是深度学习有效，而且效果非常好。
545 00:53:34,822 --> 00:53:40,170 说话人 说话人_00：问题变成了，这是否是我们所需要的全部，还是我们还需要其他的东西？
546 00:53:40,952 --> 00:53:47,461 说话人 说话人_00：您曾经说过，可能我并不是字面意义上的引用您的话，但就深度学习而言，我们将完成一切。
547 00:53:47,661 --> 00:53:56,717 说话人 SPEAKER_01：我真正想说的是，我有时说话不够准确，然后人们就会指出我的错误，就像说我们不需要放射科医生一样。
548 00:53:58,259 --> 00:54:06,512 说话人 SPEAKER_01：所以我真正想说的是，使用随机梯度下降来调整大量参数。
549 00:54:07,034 --> 00:54:10,159 说话人 SPEAKER_01：这就是我所说的深度学习的样子。
550 00:54:11,438 --> 00:54:14,222 说话人 SPEAKER_01：你获取梯度的方法可能不是反向传播。
551 00:54:15,083 --> 00:54:22,012 说话人 SPEAKER_01：而你获取梯度的东西可能不是某个最终的性能指标，而是这些众多的局部目标函数。
552 00:54:22,914 --> 00:54:24,317 说话人 SPEAKER_01：但我认为这就是大脑的工作方式。
553 00:54:24,356 --> 00:54:25,978 说话人 SPEAKER_01：我认为这可以解释一切。
554 00:54:26,018 --> 00:54:26,199 说话人 SPEAKER_01：是的。
555 00:54:26,739 --> 00:54:29,463 说话人 说话人_00：很高兴看到它得到了证实。
556 00:54:30,925 --> 00:54:38,998 说话人 SPEAKER_01：所以我想说的是，我们现在的计算机非常适合做银行业务。
557 00:54:39,652 --> 00:54:42,416 说话人 SPEAKER_01：因为他们能记住你账户里的金额。
558 00:54:43,097 --> 00:54:46,240 说话人 SPEAKER_01：如果你进去，他们说你大概有这么多，那就不会那么好了。
559 00:54:46,460 --> 00:54:50,065 说话人 说话人_01：我们并不真的确定，因为我们没有做到那么精确，但大概就是这个量级。
560 00:54:52,148 --> 00:54:59,056 说话人 说话人_01：我们不希望这种事情发生在做银行业务的电脑或者指导航天飞机的电脑上。
561 00:54:59,076 --> 00:55:01,518 说话人 SPEAKER_01：我们真的希望它能完全正确地给出答案。
562 00:55:02,360 --> 00:55:06,505 说话人 SPEAKER_01：而且它们与我们非常不同。
563 00:55:08,067 --> 00:55:09,188 说话人 SPEAKER_01：我认为
564 00:55:09,539 --> 00:55:25,101 说话人 SPEAKER_01：人们并没有充分意识到我们关于计算将如何进行的决定，那就是我们的知识将永生。
565 00:55:25,688 --> 00:55:33,739 说话人 SPEAKER_01：所以如果你看看现有的计算机，你有一个计算机程序，或者你可能只是有很多神经网络的权重。
566 00:55:34,460 --> 00:55:36,443 说话人 SPEAKER_01：这是一个不同类型的程序。
567 00:55:36,945 --> 00:55:42,313 说话人 说话人_01：但如果你的硬件坏了，你可以在另一块硬件上运行相同的程序。
568 00:55:43,541 --> 00:55:45,264 说话人 SPEAKER_01：这使得知识永生。
569 00:55:45,644 --> 00:55:48,748 说话人 SPEAKER_01：这并不取决于那块特定硬件是否能够幸存。
570 00:55:49,369 --> 00:55:56,818 说话人 SPEAKER_01：现在，永生的代价是巨大的，因为这意味着两块不同的硬件必须完全相同地执行同样的任务。
571 00:55:57,099 --> 00:56:06,731 说话人 SPEAKER_01：显然，还有错误纠正等等，但在进行所有错误纠正之后，它们必须完全相同地执行，这意味着它们最好是数字的或者主要是数字的。
572 00:56:07,387 --> 00:56:19,523 说话人 SPEAKER_01：它们可能要做的事情就像把数字相乘，这需要消耗大量的能量来使事物非常精确，而这并不是硬件真正想要的。
573 00:56:19,563 --> 00:56:27,876 说话人 SPEAKER_01：因此，一旦你承诺你的程序或神经网络的永生，
574 00:56:28,295 --> 00:56:36,563 说话人 SPEAKER_01：你就承诺了非常昂贵的计算和非常昂贵的制造过程。
575 00:56:37,025 --> 00:56:41,971 说话人 SPEAKER_01：你需要精确地制造这些事物，可能是在二维空间内，然后将许多二维事物组合在一起。
576 00:56:43,452 --> 00:56:52,782 说话人 SPEAKER_01：如果你愿意放弃永生，在小说中，你通常得到的回报是爱。
577 00:56:52,983 --> 00:57:00,311 说话人 SPEAKER_01：如果我们愿意放弃永生，我们将得到的回报是非常低能耗的计算和非常便宜的制造。
578 00:57:01,293 --> 00:57:08,001 所以，我们不应该制造计算机，而应该种植它们。
579 00:57:09,483 --> 00:57:12,226 我们应该使用纳米技术来种植三维空间中的东西。
580 00:57:13,387 --> 00:57:16,371 每一个都会略有不同。
581 00:57:17,273 --> 00:57:19,715 说话人 SPEAKER_01：所以我想象中的画面是，如果你拿一盆植物，
582 00:57:20,219 --> 00:57:24,903 说话人 SPEAKER_01：然后你把它从盆里拔出来，有一个根球，它的形状和盆是一样的，对吧？
583 00:57:25,824 --> 00:57:32,172 说话人 SPEAKER_01：所以所有不同的盆栽植物都有相同形状的根球，但根的细节都不同，但它们都在做同样的事情。
584 00:57:32,192 --> 00:57:38,760 说话人 SPEAKER_01：它们从土壤中提取养分，它们有相同的功能，它们基本上是相同的，但细节都大不相同。
585 00:57:41,722 --> 00:57:43,144 说话人 SPEAKER_01：这就是真实大脑的样子。
586 00:57:44,025 --> 00:57:47,829 说话人 SPEAKER_01：我认为这就是我所说的有生之年的计算机将会是什么样子。
587 00:57:48,534 --> 00:57:52,139 说话人 SPEAKER_01：这些是生长出来的而不是制造出来的计算机。
588 00:57:53,681 --> 00:57:55,443 说话人 SPEAKER_01：你不能编程它们，它们只是学习。
589 00:57:55,485 --> 00:57:58,748 说话人 SPEAKER_01：它们显然必须内置一个学习算法。
590 00:58:00,070 --> 00:58:13,389 说话人 SPEAKER_01：它们学习，它们可以在模拟中完成大部分计算，因为模拟非常适合做像将电压乘以电阻并将其转换为电荷然后累加电荷这样的工作。
591 00:58:13,969 --> 00:58:16,213 说话人 SPEAKER_01：已经有芯片能做这样的事情。
592 00:58:16,396 --> 00:58:21,362 说话人 SPEAKER_01：问题是接下来你做什么，你如何在那些芯片中学习？
593 00:58:22,204 --> 00:58:26,449 说话人 SPEAKER_01：目前，人们提出了反向传播或各种玻尔兹曼机的版本。
594 00:58:28,331 --> 00:58:29,512 说话人 SPEAKER_01：我认为我们还需要其他东西。
595 00:58:30,574 --> 00:58:45,052 说话人 SPEAKER_01：但我认为在不远的将来，我们将看到凡人计算机，它们非常便宜，可以通过学习获得所有知识，并且能耗非常低。
596 00:58:46,518 --> 00:58:51,425 说话人 SPEAKER_01：而这些凡人计算机，当它们死亡时，它们就死亡，它们的知识也随之消亡。
597 00:58:52,427 --> 00:58:57,134 说话者 SPEAKER_01：看权重是没有用的，因为那些权重只适用于那种硬件。
598 00:58:57,916 --> 00:59:01,420 说话者 SPEAKER_01：所以你必须将知识提炼到其他计算机中。
599 00:59:01,440 --> 00:59:07,110 说话者 SPEAKER_01：所以当这些凡人计算机变老时，它们将不得不做很多播客，试图将知识传递给年轻的凡人计算机。
600 00:59:07,130 --> 00:59:09,413 说话者 SPEAKER_00：你第一个构建的，我很乐意使用那个。
601 00:59:10,695 --> 00:59:11,195 说话人 SPEAKER_00：让我知道。
602 00:59:12,659 --> 00:59:14,922 说话人 SPEAKER_00: 所以杰夫，这让我想起了另一件事
603 00:59:15,762 --> 00:59:26,556 说话人 SPEAKER_00: 我心里一直有一个问题想问你，那就是，当你想到今天的神经网络时，那些备受瞩目的网络非常非常大。
604 00:59:26,876 --> 00:59:34,184 说话人 SPEAKER_00: 我的意思是，可能没有大脑那么大，但在某种程度上，开始接近那个规模了，对吧？
605 00:59:34,304 --> 00:59:35,467 说话人 SPEAKER_00：大型语言模型。
606 00:59:36,949 --> 00:59:43,456 说话人 SPEAKER_00：结果看起来非常、非常令人印象深刻。
607 00:59:43,554 --> 00:59:57,414 说话人 SPEAKER_00：所以，一方面，我想了解一下您对这些模型的观点，您在其中看到了什么，以及您认为的局限性是什么；另一方面，我也想了解一下您对光谱另一端的看法？
608 00:59:57,815 --> 01:00:04,364 说话人 SPEAKER_00：例如，蚂蚁的大脑显然比人类小得多，然而
609 01:00:04,784 --> 01:00:14,728 说话人 SPEAKER_00：可以说，我们人工开发的视觉运动系统还达不到蚂蚁或蜜蜂等昆虫的水平。
610 01:00:15,431 --> 01:00:22,387 说话人 SPEAKER_00：我对这个范围以及最近在语言模型方面的重大进展也很感兴趣，您对此有何看法？
611 01:00:22,992 --> 01:00:28,117 说话人 SPEAKER_01：所以蜜蜂可能在你看来很小，但我认为蜜蜂大约有一百万个神经元。
612 01:00:29,099 --> 01:00:38,650 说话人 SPEAKER_01：所以我认为蜜蜂与 GPT-3 更接近，当然比蚂蚁更接近，但实际上蜜蜂是一个相当大的神经网络。
613 01:00:39,590 --> 01:00:44,697 说话人 SPEAKER_01：我的信念是，
614 01:00:44,929 --> 01:00:55,902 说话人 SPEAKER_01：如果你使用很多参数的系统，并且用某种梯度下降和某种合理的目标函数来合理地调整它们，那么你会从中得到一些很棒的性质。
615 01:00:56,762 --> 01:01:07,114 说话人 SPEAKER_01：您会得到所有这些像 GPT-3 和不太被提及的谷歌等效产品那样的涌现特性。
616 01:01:07,934 --> 01:01:09,536 说话人 SPEAKER_01：这并不是某种
617 01:01:09,820 --> 01:01:12,842 说话人 SPEAKER_01：解决他们是否和我们以同样的方式做事的问题。
618 01:01:13,427 --> 01:01:15,139 说话人 SPEAKER_01：我认为，
619 01:01:18,072 --> 01:01:23,021 说话人 SPEAKER_01：我们在很多方面做了更多像递归这样的工作，我认为我们在神经网络中也这样做。
620 01:01:23,983 --> 01:01:28,190 说话人 SPEAKER_01：我在去年放在网上的论文《GLOM》中试图解决这些问题。
621 01:01:29,432 --> 01:01:30,815 说话人 SPEAKER_01：嗯，我把它叫做 GLOM。
622 01:01:30,835 --> 01:01:32,780 说话人 SPEAKER_01：这是如何在神经网络中实现部分-整体层次结构。
623 01:01:33,300 --> 01:01:34,742 说话人 SPEAKER_01：所以你肯定需要结构。
624 01:01:35,403 --> 01:01:40,012 说话人 SPEAKER_01：如果你所说的符号计算仅仅是部分-整体结构，
625 01:01:40,481 --> 01:01:41,943 说话人 SPEAKER_01: 然后我们进行符号计算。
626 01:01:42,364 --> 01:01:44,947 说话人 SPEAKER_01：这通常不是人们所说的符号计算。
627 01:01:45,748 --> 01:01:57,244 说话人 SPEAKER_01：严格的符号计算意味着你使用符号，并且使用仅依赖于你正在处理的符号字符串形式的规则来操作符号。
628 01:01:58,226 --> 01:02:04,934 说话人 SPEAKER_01：并且一个符号，符号的唯一属性是它要么与某个其他符号相同，要么不同。
629 01:02:05,737 --> 01:02:09,021 说话人 SPEAKER_01: 也许这指向了某个东西，它可以作为一个指针来获取某个东西。
630 01:02:10,063 --> 01:02:12,086 说话人 SPEAKER_01：而神经网络与那非常不同。
631 01:02:13,469 --> 01:02:24,344 说话人 SPEAKER_01：所以那种硬性的符号处理，我认为我们不会那样做，但我们确实处理部分与整体层次结构，但我认为我们在庞大的神经网络中这样做。
632 01:02:26,447 --> 01:02:33,237 说话人 SPEAKER_01: 我目前对 GPT-3 是否真正理解它在说什么感到有些迷茫？
633 01:02:33,570 --> 01:02:35,414 说话人 SPEAKER_01: 我认为这相当清楚。
634 01:02:35,454 --> 01:02:41,023 说话人 SPEAKER_01: 它不仅仅像老式的 Eliza 程序，只是重新排列符号串。
635 01:02:41,284 --> 01:02:42,907 说话人 SPEAKER_01: 我一点也不知道它在说什么。
636 01:02:43,768 --> 01:02:49,679 说话人 SPEAKER_01: 相信这个原因是因为你说在英语中，给我展示一只戴着红帽子的仓鼠的图片。
637 01:02:50,159 --> 01:02:52,262 说话人 SPEAKER_01: 它画了一只戴着红帽子的仓鼠。
638 01:02:53,364 --> 01:02:59,054 说话人 SPEAKER_01: 你相当确信它之前从未匹配过这对。
639 01:02:59,170 --> 01:03:03,577 说话人 SPEAKER_01: 因此它必须理解英语字符串和图片之间的关系。
640 01:03:04,697 --> 01:03:23,726 说话人 SPEAKER_01: 在它做到这一点之前，如果你问过这些怀疑者，这些神经网络怀疑者，神经网络否认者，让我们称他们为神经网络否认者，如果你问过他们，嗯，你怎么证明它理解了？
641 01:03:24,364 --> 01:03:29,050 说话人 SPEAKER_01：我认为他们会接受这样的观点，如果你要求画一个东西，有人就会画出那个东西，那么它就理解了。
642 01:03:29,911 --> 01:03:37,278 说话人 SPEAKER_01：就像 Winograd 的论文一样，你要求它把蓝色的方块放入绿色的盒子中，它就会把蓝色的方块放入绿色的盒子中。
643 01:03:37,318 --> 01:03:39,440 说话人 SPEAKER_01：因此，这是很好的证据表明它理解了你所说的话。
644 01:03:42,063 --> 01:03:46,509 说话人 SPEAKER_01：但现在它做到了，当然，怀疑者会说，这并不算数。
645 01:03:47,650 --> 01:03:49,512 说话人 SPEAKER_01: 基本上没有什么能满足他们。
646 01:03:49,559 --> 01:03:54,224 说话人 SPEAKER_00: 是的，对于真正的怀疑论者来说，目标线总是在移动。
647 01:03:56,447 --> 01:04:07,061 说话人 SPEAKER_00: 现在，有一个最近的例子，谷歌的那个，保罗模型，在论文中展示了它如何有效地解释笑话是如何工作的。
648 01:04:07,302 --> 01:04:08,443 说话人 SPEAKER_01: 那是非常非凡的。
649 01:04:08,463 --> 01:04:11,507 说话人 SPEAKER_00: 这似乎是对语言有很深的理解。
650 01:04:12,068 --> 01:04:14,570 说话人 SPEAKER_01: 不，这只是重新排列了它在训练集中已有的词汇。
651 01:04:14,751 --> 01:04:16,072 说话人 SPEAKER_00: 你这么认为吗？
652 01:04:17,420 --> 01:04:23,610 说话人 SPEAKER_01: 不，我看不出它是如何在没有理解正在发生的事情的情况下生成这些解释的。
653 01:04:24,112 --> 01:04:31,965 说话人 SPEAKER_01：现在，我仍然认为，因为它是用反向传播训练的，所以它最终会形成与我们非常不同的理解。
654 01:04:33,288 --> 01:04:41,722 说话人 SPEAKER_01：显然，对抗性图像可以告诉你很多，但你也可以通过使用它们的纹理来识别物体。
655 01:04:42,512 --> 01:04:47,259 说话人 SPEAKER_01：而且你可以正确地认为它已经推广到了那些物体的其他实例。
656 01:04:47,940 --> 01:04:50,043 说话人 SPEAKER_01: 但这与我们做的完全不同。
657 01:04:51,505 --> 01:04:53,648 说话人 SPEAKER_01：我喜欢以昆虫和花朵为例。
658 01:04:53,987 --> 01:04:55,931 说话人 SPEAKER_01：所以昆虫能看到紫外线。
659 01:04:56,952 --> 01:05:01,137 说话人 SPEAKER_01：所以对我们来说看起来一样的两种花，对昆虫来说可能完全不同。
660 01:05:01,978 --> 01:05:06,764 说话人 SPEAKER_01：现在，因为花对我们来说看起来一样，我们就说昆虫看错了？
661 01:05:07,387 --> 01:05:13,733 说话人 SPEAKER_01：因为这些花朵与昆虫共同进化，向昆虫发出紫外线信号，告诉它们这是哪种花。
662 01:05:14,335 --> 01:05:18,039 说话人 SPEAKER_01：所以很明显，昆虫已经正确地接收到了信号，我们只是看不到区别。
663 01:05:18,059 --> 01:05:20,282 说话人 SPEAKER_01：这就是另一种思考对抗样本的方式。
664 01:05:22,744 --> 01:05:27,849 说话人 SPEAKER_01：它说这是一只鸵鸟，在我们看来却像一辆校车。
665 01:05:28,530 --> 01:05:31,875 说话人 SPEAKER_01：但实际上，如果你在纹理领域看，它实际上是一只鸵鸟。
666 01:05:31,894 --> 01:05:35,077 说话人 SPEAKER_01：所以问题是，谁是对的？
667 01:05:35,137 --> 01:05:36,599 说话人 SPEAKER_01：至于昆虫的情况，
668 01:05:37,237 --> 01:05:41,384 说话人 SPEAKER_01：仅仅因为两种花在我们看来长得一模一样，并不意味着它们真的相同。
669 01:05:41,724 --> 01:05:43,567 说话人 SPEAKER_01：昆虫是对的，它们确实非常不同。
670 01:05:44,128 --> 01:05:48,775 说话人 SPEAKER_01：在这种情况下，是电磁谱的不同部分在指示我们未注意到的差异。
671 01:05:49,295 --> 01:06:00,731 说话人 SPEAKER_00：但是，在图像识别方面，对于我们的当前神经网络，你可以争论，也许因为我们构建了它们，并希望它们在我们的世界中为我们做事情，
672 01:06:00,829 --> 01:06:05,998 说话人 SPEAKER_00：我们真的不希望只是说，好吧，它们做对了，而我们做错了。
673 01:06:06,239 --> 01:06:08,481 说话人 SPEAKER_00: 我的意思是，他们需要识别汽车和行人。
674 01:06:09,324 --> 01:06:09,724 说话人 SPEAKER_01: 是的，我同意。
675 01:06:09,744 --> 01:06:12,869 说话人 SPEAKER_01: 我只是想表明，你认为的对错并不像你想的那么简单。
676 01:06:13,650 --> 01:06:27,612 说话人 SPEAKER_01: 我在《Glom》论文中的部分观点是尝试构建更类似于我们的感知系统，这样它们更有可能犯和我们一样的错误。
677 01:06:28,065 --> 01:06:30,909 说话者 SPEAKER_01：并且不会犯出非常不同的错误。
678 01:06:31,429 --> 01:06:46,586 说话者 SPEAKER_01：显然，比如如果你有一辆自动驾驶汽车，如果它犯了任何正常人类驾驶员都会犯的错误，那在我们看来似乎比犯出非常愚蠢的错误更能接受。
679 01:06:47,568 --> 01:06:52,632 说话者 SPEAKER_00：所以，杰夫，据我理解，你也认为睡眠是个值得关注的问题。
680 01:06:52,672 --> 01:06:54,175 说话者 SPEAKER_00：你能多说一点吗？
681 01:06:55,201 --> 01:06:58,063 说话人 SPEAKER_01: 是的，我经常在晚上睡不着的时候想这件事。
682 01:07:00,166 --> 01:07:06,333 说话人 SPEAKER_01: 关于睡眠，有一个有趣的现象，那就是动物都会睡觉。
683 01:07:06,414 --> 01:07:07,335 说话人 SPEAKER_01: 果蝇也会睡觉。
684 01:07:08,275 --> 01:07:10,778 说话人 SPEAKER_01: 可能是为了防止它们在黑暗中飞来飞去。
685 01:07:10,938 --> 01:07:16,686 说话人 SPEAKER_01: 但如果你剥夺人们的睡眠，他们就会变得非常奇怪。
686 01:07:17,485 --> 01:07:20,789 说话人 SPEAKER_01: 就像如果你剥夺某人的睡眠三天，他们就会开始出现幻觉。
687 01:07:21,311 --> 01:07:24,954 说话人 SPEAKER_01: 如果你剥夺某人的睡眠一周，他们就会变得精神错乱，可能永远无法恢复。
688 01:07:25,693 --> 01:07:29,101 说话人 SPEAKER_01: 这些是 Sierra 做的很好的实验，我想。
689 01:07:29,300 --> 01:07:33,389 说话人 SPEAKER_01：问题是，为什么？
690 01:07:33,429 --> 01:07:37,518 说话人 SPEAKER_01：睡眠的计算功能是什么？
691 01:07:37,539 --> 01:07:40,664 说话人 SPEAKER_01：它可能有一些非常重要的功能。
692 01:07:41,168 --> 01:07:43,411 说话人 SPEAKER_01：剥夺它会使你完全崩溃。
693 01:07:44,253 --> 01:07:54,951 说话人 SPEAKER_01：所以现在的理论有比如它是用于巩固记忆，或者可能是从海马体向皮层下载东西，这有点奇怪，因为最初我必须通过皮层才能到达海马体。
694 01:07:57,456 --> 01:08:02,684 说话人 SPEAKER_01：所以，早在 80 年代初，我和 Terry Stanofsky 有一个叫做脉冲运动的理论。
695 01:08:03,867 --> 01:08:07,092 说话人 SPEAKER_01：这理论部分基于弗朗西斯·克里克的洞察。
696 01:08:07,342 --> 01:08:20,822 说话人 SPEAKER_01：当他在思考 Hopfield 网络时，弗朗西斯·格里金和米奇森有一篇关于睡眠和你会用随机的东西去冲击网络，并告诉它不要对随机的东西感到满意的论文。
697 01:08:21,523 --> 01:08:27,832 说话人 SPEAKER_01：所以在 Hopfield 网络中，你给它一些想要记忆的东西，它会改变权重，使该向量的能量更低。
698 01:08:28,974 --> 01:08:33,501 说话人 SPEAKER_01：而想法是，如果你也给它随机向量，并说，使能量更高，整个系统会运行得更好。
699 01:08:34,543 --> 01:08:50,658 说话人 SPEAKER_01：这导致了 Boltzmann 机器，我们意识到，如果你不提供随机的东西，而是从马尔可夫链生成东西，即模型自己的马尔可夫链，并说，使这些情况更不可能，使数据更可能，这实际上是一种最大似然学习。
700 01:08:50,719 --> 01:08:55,302 说话人 SPEAKER_01：因此我们对此非常兴奋，因为我们认为，好吧，这就是睡眠的作用。
701 01:08:55,863 --> 01:08:57,664 说话人 SPEAKER_01: 睡眠是学习的负面阶段。
702 01:08:58,845 --> 01:09:03,369 说话人 SPEAKER_01: 现在在对比学习中再次出现，其中你有，
703 01:09:03,686 --> 01:09:07,952 说话人 SPEAKER_01: 来自同一图像的两个补丁，你试图让它们具有相似的表现。
704 01:09:08,733 --> 01:09:14,621 说话人 SPEAKER_01: 以及来自不同图像的两个补丁，你试图让它们具有足够不同的表现。
705 01:09:14,881 --> 01:09:20,188 说话人 SPEAKER_01：一旦它们不同，你就不再使它们更加不同，而是停止它们变得过于相似。
706 01:09:20,207 --> 01:09:21,649 说话人 SPEAKER_01：这就是对比学习的原理。
707 01:09:22,831 --> 01:09:28,297 说话人 SPEAKER_01：现在，在玻尔兹曼机中，实际上无法将正相和负相分开。
708 01:09:28,318 --> 01:09:32,023 说话人 SPEAKER_01：你必须混合正例和负例。
709 01:09:32,458 --> 01:09:34,902 说话人 SPEAKER_01: 否则，整个事情就会出错。
710 01:09:34,921 --> 01:09:38,104 说话人 SPEAKER_01: 我尝试了很多次，不要将它们交织在一起。
711 01:09:38,185 --> 01:09:42,448 说话人 SPEAKER_01: 要做很多正面例子然后做很多负面例子相当困难。
712 01:09:43,650 --> 01:10:01,368 说话人 SPEAKER_01: 几年前我发现了一件事，这让我非常兴奋，并导致我同意接受很多演讲邀请，后来因为无法做得更好，我取消了这些演讲。那就是，通过对比学习，你实际上可以分离正负两个阶段。
713 01:10:02,158 --> 01:10:09,668 说话人 SPEAKER_01：所以你可以举出很多正例，然后举出很多反例。
714 01:10:09,689 --> 01:10:30,815 说话人 SPEAKER_01：这很好，因为这意味着你可以有一个视频处理管道，你在清醒时尝试使事物相似，而在睡眠时尝试使事物不同，如果你能弄清楚睡眠如何为你生成视频。
715 01:10:31,470 --> 01:10:42,021 说话人 SPEAKER_01：如果你能将正负阶段分开，在不同的时间进行，先进行一系列正更新，然后进行一系列负更新，这将使对比学习领域变得更加可行。
716 01:10:43,384 --> 01:10:48,949 说话人 SPEAKER_01：即使是标准的对比学习，你也可以做得相当不错。
717 01:10:49,570 --> 01:10:51,372 说话人 SPEAKER_01: 你必须使用很多动量以及类似的东西。
718 01:10:51,412 --> 01:10:53,614 说话人 SPEAKER_01: 有各种小技巧让它工作，但你确实可以做到。
719 01:10:55,636 --> 01:10:59,942 说话人 SPEAKER_01: 所以我现在认为睡眠的功能很可能是对负面例子进行反学习。
720 01:11:00,596 --> 01:11:03,039 说话人 SPEAKER_01: 睡眠的作用可能是进行负例的反学习。
721 01:11:04,902 --> 01:11:06,644 说话人 SPEAKER_01: 正是因为这个，你才不记得你的梦。
722 01:11:07,145 --> 01:11:08,105 说话人 SPEAKER_01: 你不想记住它们。
723 01:11:08,126 --> 01:11:09,787 说话人 SPEAKER_01: 你正在忘记它们。
724 01:11:09,807 --> 01:11:10,689 说话人 SPEAKER_01: 克里克指出了这一点。
725 01:11:11,149 --> 01:11:17,556 说话人 SPEAKER_01：你会在醒来时记得那些在快速权重中的内容，因为快速权重是临时存储。
726 01:11:17,658 --> 01:11:19,539 说话人 SPEAKER_01：所以这并不是在学习。
727 01:11:19,560 --> 01:11:20,560 说话人 SPEAKER_01：它仍然以同样的方式工作。
728 01:11:21,301 --> 01:11:23,904 说话人 SPEAKER_01：但是长期记忆，
729 01:11:24,137 --> 01:11:25,779 说话人 SPEAKER_01：关键是要摆脱那些东西。
730 01:11:25,899 --> 01:11:32,787 说话人 SPEAKER_01：这就是你为什么每晚要梦很多小时，但当你醒来时，你只能记得你醒来时梦的最后几分钟。
731 01:11:35,369 --> 01:11:42,818 说话人 SPEAKER_01：我认为这是比我所见过的任何其他睡眠理论都更可信的理论，因为它解释了为什么如果你去掉了它，整个系统就会崩溃。
732 01:11:43,578 --> 01:11:47,063 说话人 SPEAKER_01：你会陷入灾难性的错误，开始产生幻觉，做各种奇怪的事情。
733 01:11:48,083 --> 01:11:53,149 说话人 SPEAKER_01：让我再谈谈对比学习中需要负例的必要性。
734 01:11:54,091 --> 01:12:12,488 说话人 SPEAKER_01：如果你有一个神经网络，它试图优化某个内部目标函数，比如它所具有的表示类型，或者上下文预测和局部预测之间的一致性，它希望这种一致性是真实数据的一个属性。
735 01:12:13,295 --> 01:12:18,940 说话人 SPEAKER_01：在神经网络内部的问题在于，你可能会在你的输入中得到各种各样的相关性。
736 01:12:18,980 --> 01:12:19,881 说话人 SPEAKER_01：我是一个神经元，对吧？
737 01:12:19,902 --> 01:12:21,925 说话人 SPEAKER_01：所以我得到了各种输入的相关性。
738 01:12:21,944 --> 01:12:24,387 说话人 SPEAKER_01：这些相关性与真实数据无关。
739 01:12:24,627 --> 01:12:27,211 说话人 SPEAKER_01：它们是由网络的连接和网络中的权重引起的。
740 01:12:27,992 --> 01:12:33,938 说话人 SPEAKER_01：如果这两个神经元都在看同一个像素，它们会有相关性，但这并不能告诉你关于数据的信息。
741 01:12:35,159 --> 01:12:42,507 说话人 SPEAKER_01: 所以问题是，你是如何学习提取关于真实数据的结构，而不是关于你网络连接的结构
742 01:12:42,792 --> 01:12:44,814 说话人 SPEAKER_01: 而是要找到正例中的结构，而不是负例中的结构。
743 01:12:46,137 --> 01:12:53,630 说话人 SPEAKER_01: 要做到这一点，就是给它提供正例，并说，在正例中找到负例中没有的结构。
744 01:12:54,390 --> 01:12:57,015 说话人 SPEAKER_01: 因为负例会经过完全相同的连接。
745 01：12：58,958 --> 01：13：07,212 演讲者 SPEAKER_01：如果结构不在反例中，而是在正面例子中，那么结构是关于正面和反例之间的差异，而不是关于你的布线。
所以人们不太考虑这一点，但如果你有强大的学习算法，最好不要让它们学习神经网络自身的权重和连接方式。
747 01：13：18,262 --> 01：13：19,265 议长 SPEAKER_01：这不是有趣的地方。
现在，当你想到那些没有睡觉然后开始出现幻觉的人时，幻觉是否只是有效地尝试做同样的事情？
749 01:13:27,256 --> 01:13:28,738 说话人 SPEAKER_00: 你是在清醒的时候做的吗？
750 01:13:29,319 --> 01:13:31,844 说话人 SPEAKER_01: 显然，你可以小睡一会儿，这非常有帮助。
751 01:13:32,585 --> 01:13:36,069 说话人 SPEAKER_01: 也许当你清醒时出现的幻觉与睡眠起着相同的作用。
752 01:13:36,134 --> 01:13:43,404 说话人 SPEAKER_01: 我的意思是，我进行的所有实验都表明，最好不要连续清醒 16 个小时，然后睡 8 个小时。
753 01:13:43,425 --> 01:13:45,929 说话人 SPEAKER_01：保持几个小时清醒和几个小时睡眠更好。
754 01:13:45,948 --> 01:13:49,394 说话人 SPEAKER_01：所以，很多人发现小憩很有帮助。
755 01:13:49,875 --> 01:13:53,640 说话人 SPEAKER_01：爱因斯坦经常小憩，而且他做得很好。
756 01:13:55,243 --> 01:14:00,149 说话人 SPEAKER_00：是的，他确实做得很好。
757 01:14:01,126 --> 01:14:05,631 说话人 SPEAKER_00：你提到了另一件事，就是学生超越老师的概念。
758 01:14:06,472 --> 01:14:07,514 说话人 SPEAKER_00：这是什么意思？
759 01:14:07,554 --> 01:14:26,997 说话人 SPEAKER_01：好的，很久以前，我在 MNIST 上做了一项实验，MNIST 是一个用于识别手写数字的标准数字数据库，你取数据，训练数据，然后对其进行破坏。
760 01:14:28,143 --> 01:14:36,993 说话人 SPEAKER_01：通过将错误的标签替换为其他九个标签中的任何一个，80%的时间进行替换。
761 01:14:38,657 --> 01:14:46,426 说话人 SPEAKER_01：现在你有一个数据集，其中标签正确的时间是 20%，错误的时间是 80%。
762 01:14:48,429 --> 01:14:51,233 说话人 SPEAKER_01：那么问题是，你能从中学习吗？
763 01:14:52,675 --> 01:14:53,855 说话人 SPEAKER_01：那么你从中学得怎么样？
764 01:14:54,596 --> 01:14:57,440 说话人 SPEAKER_01：答案是你可以学会将其正确率提高到 95%。
765 01:14:58,349 --> 01:15:05,278 说话人 SPEAKER_01: 现在你有一个 80%的时候都是错的老师，而学生 95%的时候是对的。
766 01:15:06,920 --> 01:15:08,903 说话人 SPEAKER_01: 所以学生比老师好得多。
767 01:15:10,043 --> 01:15:13,788 说话人 SPEAKER_01: 而这不是每次你得到一个例子，你就破坏它。
768 01:15:13,908 --> 01:15:16,192 说话人 SPEAKER_01: 你拿训练例子，你一次性破坏它们。
769 01:15:16,552 --> 01:15:24,963 说话者 SPEAKER_01：所以你不能简单地平均掉不同... 你可能能够平均掉不同训练案例中相似图像的腐败。
770 01:15:25,889 --> 01:15:29,635 说话者 SPEAKER_01：如果你问，嗯，如果你有损坏的，你需要多少个训练案例？
771 01:15:30,756 --> 01:15:37,046 说话者 SPEAKER_01：这很有趣，因为之前有一个小图像数据集，其中包含 8000 万张带有大量错误标签的小图像。
772 01:15:37,747 --> 01:15:45,399 说话者 SPEAKER_01：问题是，你是宁愿有一百万个标签不稳定的物品，还是宁愿有 10000 个标签准确的物品？
773 01:15:47,201 --> 01:15:53,010 说话人 SPEAKER_01：我有一个假设，重要的是标签和真实情况之间的互信息量。
774 01:15:54,525 --> 01:15:59,972 说话人 SPEAKER_01：所以如果标签有 90%的时间被损坏，标签和真实情况之间就没有互信息。
775 01:16:01,475 --> 01:16:05,420 说话人 SPEAKER_01：如果它们有 80%的时间被损坏，那么只有很少的互信息。
776 01:16:05,439 --> 01:16:06,041 说话人 SPEAKER_01：您是这样认为的吗？
777 01:16:06,081 --> 01:16:09,525 说话人 SPEAKER_01: 我认为这大约是，我的记忆中是每案例 0.06 比特。
778 01:16:10,346 --> 01:16:14,412 说话人 SPEAKER_01: 而如果没有纠正，大约是每案例 3.3 比特。
779 01:16:14,452 --> 01:16:15,753 说话人 SPEAKER_01: 所以这只是微不足道的一点点。
780 01:16:16,354 --> 01:16:22,643 说话人 SPEAKER_01: 然后问题是，嗯，假设我通过放入尽可能多的互信息来平衡训练集的大小。
所以，如果相互信息有50%，我是否有50倍的例子，现在就能得到相同的表现？
782 01：16：32,076 --> 01：16：35,161 议长 SPEAKER_01：答案是，是的，你这样做的幅度在两倍以内。
我的意思是，训练集实际上需要是那么大两倍，但大致来说，你可以通过标签和真实值之间的互信息量来看到训练样本有多有用。
784 01:16:45,720 --> 01:16:48,765 说话者 SPEAKER_01：最近我发现你有一些将模拟转换为现实的方法。
785 01:16:48,948 --> 01:16:53,595 说话人 SPEAKER_01：您正在使用神经网络对真实数据进行标记，而这些标签并不完美。
786 01:16:54,497 --> 01:16:59,246 说话人 SPEAKER_01：然后您使用那些标签所训练的学生，而这个学生比它所学习过的老师更好。
787 01:17:00,027 --> 01:17:03,432 说话人 SPEAKER_01：人们总是困惑，学生怎么可能比老师更好？
788 01:17:05,275 --> 01:17:06,878 说话人 SPEAKER_01：但在神经网络中，这非常简单。
789 01:17:08,220 --> 01:17:10,364 说话人 SPEAKER_01：学生将比老师更优秀。
790 01:17:10,835 --> 01:17:15,180 说话人 SPEAKER_01：如果有足够的训练数据，即使老师很不可靠。
791 01:17:15,721 --> 01:17:20,710 说话人 SPEAKER_01：我和 Melody Guan 几年前关于一些医学数据有一篇论文。
792 01:17:21,490 --> 01:17:23,233 说话人 SPEAKER_01：论文的第一部分讨论了这一点。
793 01:17:23,974 --> 01:17:30,604 说话人 SPEAKER_01: 但经验法则基本上是，重要的是分配的标签和真实情况之间的互信息。
794 01:17:31,505 --> 01:17:33,448 说话人 SPEAKER_01: 这说明了训练样本的价值。
795 01:17:34,350 --> 01:17:36,672 说话人 SPEAKER_01: 因此，你可以用很多不稳定的样本来凑合。
796 01:17:37,818 --> 01:17:38,559 说话人 SPEAKER_00: 这太有趣了。
797 01:17:38,618 --> 01:17:55,247 讲者 SPEAKER_00：现在，在我们刚才提到的那个工作中，Jeven，还有我最近看到相当受欢迎的工作中，通常教师会提供带有噪声的标签，但并不是所有带有噪声的标签都被使用。
798 01:17:55,287 --> 01:17:59,774 讲者 SPEAKER_00：有一种观点认为，只关注教师更自信的那些标签。
799 01:18:00,599 --> 01:18:03,726 说话人 SPEAKER_00: 你的描述并不真正关心那个。
800 01:18:03,747 --> 01:18:04,748 说话人 SPEAKER_01: 是的，你不需要做那件事。
801 01:18:04,829 --> 01:18:05,631 说话人 SPEAKER_01: 你不必这么做。
802 01:18:05,671 --> 01:18:06,412 说话人 SPEAKER_01: 这是一个好方法。
803 01:18:07,034 --> 01:18:10,764 说话人 SPEAKER_01: 可能只看那些你有理由相信老师做对了的，会有帮助。
804 01:18:11,386 --> 01:18:13,130 说话人 SPEAKER_01: 即使只是看它们，也能行。
805 01:18:13,752 --> 01:18:14,854 说话人 SPEAKER_01: 并且存在一个相变。
806 01:18:16,158 --> 01:18:17,881 说话人 SPEAKER_01: 以 MNIST 为例，
807 01:18:18,756 --> 01:18:26,024 说话人 SPEAKER_01: 梅洛绘制了一张图表，一旦你正确识别出大约 20%的标签，你的学生就能正确识别出 95%。
808 01:18:27,065 --> 01:18:35,555 说话人 SPEAKER_01: 但是当你降到大约 15%正确率时，你会突然遇到一个相变，因为学生必须理解。
809 01:18:36,015 --> 01:18:47,328 说话人 SPEAKER_01: 老师在说这些标签，学生必须从某种意义上理解哪些案例是对的，哪些案例是错的，并看到标签和输入之间的关系。
810 01:18:48,270 --> 01:18:53,055 讲师：一旦学生看到了这种关系，错误标记的东西就非常明显是错误的。
811 01:18:54,136 --> 01:18:56,059 讲师：所以如果它是随机错误标记的，那就没问题。
812 01:18:57,439 --> 01:19:02,125 讲者 SPEAKER_01: 但是有一个相变阶段，你需要做得足够好，这样学生才能理解这个概念。
813 01:19:03,046 --> 01:19:05,207 讲者 SPEAKER_01: 这就解释了为什么我们的学生都比我们聪明。
814 01:19:07,270 --> 01:19:09,752 讲者 SPEAKER_00: 我们都需要在很小一部分时间里做对。
815 01:19:10,873 --> 01:19:11,073 讲者 SPEAKER_01: 对。
816 01:19:11,134 --> 01:19:16,359 讲者 SPEAKER_01：我相信学生们在做一些这样的数据整理，你说了什么，学生们就会想，哦，这太垃圾了。
817 01:19:16,378 --> 01:19:17,399 讲者 SPEAKER_01：我不会听那个。
818 01:19:18,257 --> 01:19:22,063 讲者 SPEAKER_01: 这些是你遇到的最优秀的学生。
819 01:19:22,082 --> 01:19:23,706 讲者 SPEAKER_00: 是的，这些学生有时会让我们感到惊讶。
820 01：19：26,670 --> 01：19：36,703 演讲者 SPEAKER_00：现在，在神经网络学习中，尤其是当你构建模型时，真正重要的一件事是了解它学习的是什么。
821 01:19:36,904 --> 01:19:41,050 说话者 说话者_00：人们经常试图以某种方式可视化学习过程中发生的事情。
822 01:19:41,711 --> 01:19:48,180 说话者 说话者_00：其中最常见的一种可视化技术被称为 t-SNE。
823 01:19:48,463 --> 01:19:50,186 说话人 SPEAKER_00：这是你发明的东西，Geoff。
824 01:19:50,207 --> 01:19:52,292 说话人 SPEAKER_00：所以我很好奇，你是怎么想到这个的？
825 01：19：52,431 --> 01：19：55,377 议长 SPEAKER_00：也许先描述一下它的作用，然后再描述它背后的故事是什么？
826 01:19:56,220 --> 01:20:08,784 说话人 SPEAKER_01：所以如果你有一些高维数据，你试图绘制它的 2D 或 3D 图，你可以只绘制前两个主成分。
827 01:20:09,354 --> 01:20:13,460 说话人 SPEAKER_01：但是主成分分析关注的是正确地获取大的距离。
828 01:20:14,140 --> 01:20:20,768 说话人 SPEAKER_01：所以如果两件事物非常不同，主成分分析非常关注在二维空间中将它们区分得非常不同。
829 01:20:20,787 --> 01:20:25,654 说话人 SPEAKER_01：它根本不在乎这些小的差异，因为它是在大差异的平方上操作的。
830 01:20:27,216 --> 01:20:32,561 说话人 SPEAKER_01：所以它不太能很好地保留相似性，尤其是在高维相似性方面。
831 01:20:32,710 --> 01:20:35,573 说话人 SPEAKER_01：而你通常感兴趣的正好相反。
832 01:20:35,675 --> 01:20:36,315 说话人 SPEAKER_01: 你有一些数据。
833 01：20：36,336 --> 01：20：38,018 议长 SPEAKER_01：你对什么很感兴趣。
834 01:20:38,538 --> 01:20:42,123 说话人 SPEAKER_01：你不在乎它是否对大距离有点错误，只要它对小距离正确即可。
所以我很久以前就有这样一个想法：如果我们把距离转换成成对的概率呢？
836 01:20:53,983 --> 01:21:00,152 说话者 SPEAKER_01：T-stands 有各种版本，但假设我们将其转换成成对的概率，也就是说，
837 01:21:00,806 --> 01:21:04,592 说话人 SPEAKER_01：距离小的配对是可能的，距离大的配对是不可能的。
838 01:21:06,255 --> 01:21:11,061 说话人 SPEAKER_01：因此，我们将距离转换为概率，使得小的距离对应大的概率。
839 01:21:11,903 --> 01:21:19,173 说话人 SPEAKER_01：我们通过在数据点周围放置高斯分布来实现这一点，并计算其他数据点在此高斯分布下的密度。
840 01:21:19,854 --> 01:21:21,677 说话者 SPEAKER_01：那是一个未归一化的概率。
841 01:21:21,717 --> 01:21:22,859 发言人 SPEAKER_01：然后你将这些东西标准化。
842 01:21:24,220 --> 01:21:30,189 发言人 SPEAKER_01：然后您尝试在 2D 中布置这些点，以保留这些概率。
843 01:21:31,856 --> 01:21:33,279 说话人 SPEAKER_01：因此它不会太在意。
844 01:21:33,380 --> 01:21:36,283 说话人 SPEAKER_01：如果两个点相距较远，它们的双点概率会非常低。
845 01:21:36,645 --> 01:21:39,770 说话者 SPEAKER_01：它并不关心这两个点的相对位置。
846 01:21:39,789 --> 01:21:42,694 说话人 SPEAKER_01：它关注的是具有高概率的相对位置。
847 01:21:42,715 --> 01:21:44,278 说话人 SPEAKER_01：这产生了相当不错的地图。
848 01:21:44,798 --> 01:21:46,561 说话者 SPEAKER_01：这被称为随机近邻嵌入。
因为我们想到了这个，你放一个高斯分布，然后根据高斯分布下的密度随机选择一个邻居。
850 01:21:54,073 --> 01:21:55,355 说话者 说话者01：我和武士们一起做了这项工作。
851 01:21:55,976 --> 01:21:58,100 说话者 SPEAKER_01：它有非常简单漂亮的导数。
852 01:21:58,198 --> 01:22:00,421 说话者 SPEAKER_01：这让我相信我们找到了一些东西。
853 01:22:00,981 --> 01:22:03,685 说话人 SPEAKER_01: 我们得到了很好的地图，但它们往往把事物聚集在一起。
854 01:22:04,685 --> 01:22:11,273 说话人 SPEAKER_01: 显然，将高维数据转换为低维数据存在一个基本问题。
855 01:22:12,194 --> 01:22:15,778 说话人 SPEAKER_01：所以 SNE（随机邻域嵌入）倾向于将事物聚集在一起。
856 01:22:16,417 --> 01:22:19,662 说话人 SPEAKER_01: 这是因为高维空间和低维空间的本质。
857 01:22:20,443 --> 01:22:27,210 说话人 SPEAKER_01：在高维空间中，一个数据点可以接近很多其他点，而它们彼此之间并不一定很近。
858 01:22:28,489 --> 01:22:32,895 说话人 SPEAKER_01：而在低维空间中，如果它们都接近这个数据点，它们都必须彼此接近。
859 01:22:34,157 --> 01:22:39,342 说话人 SPEAKER_01：所以你在将高维空间的接近度嵌入到低维空间时遇到了问题。
860 01:22:40,824 --> 01:22:49,215 说话人 SPEAKER_01：当我做 SNE 的时候，我有了这样一个想法，因为我正在使用概率作为这种中间货币。
861 01:22:49,398 --> 01:23:02,396 说话人 SPEAKER_01：应该有一个混合模型，应该有一个混合版本，其中你说在高维空间中，一对的概率与高斯分布中 s 平方距离的 e 的负数次幂成正比。
862 01:23:02,417 --> 01:23:06,283 说话人 SPEAKER_01：而在低维空间中，假设你有两个不同的映射。
863 01:23:07,283 --> 01:23:13,092 说话人 SPEAKER_01：一对的概率是第一个 2D 映射中距离的 e 的负数次幂与第二个 2D 映射中距离的平方的 e 的负数次幂的和。
864 01:23:13,511 --> 01:23:16,898 Speaker SPEAKER_01: 并且 e 的负平方距离在第二个 2D 地图中。
865 01:23:17,520 --> 01:23:29,983 说话人 SPEAKER_01：这样，如果我们有一个像“银行”这样的词，我们试图将相似的词放在一起，那么在一张地图上“银行”可以靠近“贪婪”，在另一张地图上可以靠近“河流”，而“河流”永远不会靠近“贪婪”。
866 01:23:31,265 --> 01:23:36,194 说话人 SPEAKER_01：所以，我非常推崇这个想法，因为这确实是一个很棒的想法，你可以拥有多种地图的混合。
867 01:23:36,832 --> 01:23:37,993 说话人 SPEAKER_01：我们设法让它实现了。
868 01:23:38,014 --> 01:23:39,775 说话人 SPEAKER_01：伊利亚是第一批从事这项工作的人之一。
869 01:23:40,195 --> 01:23:41,597 Speaker SPEAKER_01: 詹姆斯·库克对它做了很多工作。
870 01:23:42,359 --> 01:23:44,199 说话者 SPEAKER_01：还有几位其他学生也在做这项工作。
871 01：23：44,480 --> 01：23：47,262 议长 SPEAKER_01：我们从来没有真正让它运作良好。
872 01:23:48,805 --> 01:23:51,807 说话人 SPEAKER_01：我很失望，不知怎么地我竟然能利用我所做的混合。
873 01:23:53,069 --> 01:24:02,899 Speaker SPEAKER_01: 然后我转向了一个更简单的版本，我称之为 Unisni，它是高斯分布和均匀分布的混合。
874 01:24:02,918 --> 01:24:05,862 说话人 SPEAKER_01：这个方法效果要好得多。
875 01:24:07,056 --> 01:24:12,283 说话人 SPEAKER_01：所以，这个想法是在一个映射中，所有对都是等可能的。
876 01:24:13,386 --> 01:24:18,953 说话人 SPEAKER_01：这为你提供了一种背景概率，它通过大距离传递，是一种小的背景概率。
877 01:24:19,673 --> 01:24:27,725 Speaker SPEAKER_01: 然后在另一个地图中，你贡献的概率与你在该地图中的平方距离成正比。
878 01:24:28,726 --> 01:24:36,016 说话人 SPEAKER_01：但这意味着在另一张地图上，如果它们想要的话，事物可以相隔很远，因为那时
879 01:24:37,042 --> 01:24:42,070 说话人 SPEAKER_01: 他们需要一些概率，由均匀映射来处理。
880 01:24:42,091 --> 01:24:50,884 说话人 SPEAKER_01：然后我收到了来自名叫劳伦斯·范·德·马滕的人的一篇评论文章，我以为这是一篇已发表的论文，因为它的形式是这样的，但实际上并不是。
881 01:24:51,845 --> 01:24:53,467 说话人 SPEAKER_01：他想来和我一起做研究。
882 01:24:53,769 --> 01:24:56,292 说话人 SPEAKER_01：我以为他有一篇已发表的论文，所以邀请他来一起做研究。
883 01:24:57,054 --> 01:24:58,737 说话人 SPEAKER_01: 结果证明他非常出色。
884 01:24:59,157 --> 01:25:01,921 说话人 SPEAKER_01：幸亏我误以为这是一篇已发表的论文。
885 01:25:02,582 --> 01:25:04,805 说话人 SPEAKER_01：然后我们开始了 Unisne。
886 01:25:05,865 --> 01:25:18,259 说话人 SPEAKER_01：然后我意识到实际上 unisny 是使用高斯分布和非常非常宽的高斯分布（均匀分布）的特例。
887 01:25:18,279 --> 01:25:20,501 说话人 SPEAKER_01：那么如果我们使用整个高斯分布层次结构会怎样呢？
888 01:25:21,261 --> 01:25:25,326 说话人 SPEAKER_01: 许多许多不同宽度的高斯分布，这被称为 t 分布。
889 01:25:26,367 --> 01:25:30,430 说话人 SPEAKER_01：这导致了 t-sny，t-sny 的效果要好得多。
890 01:25:31,452 --> 01:25:34,454 说话人 SPEAKER_01：t-sny 有一个非常不错的特性，
891 01:25:35,109 --> 01:25:49,307 说话人 SPEAKER_01：它可以在多个尺度上展示事物，因为它具有一种 D 的平方的倒数性质，当距离变得很大时，它的行为就像重力一样，类似于星系团等。
892 01:25:49,547 --> 01:25:52,412 说话人 SPEAKER_01: 有星系簇、星系和恒星簇等等。
893 01:25:53,012 --> 01:25:56,797 说话人 SPEAKER_01: 你可以在很多不同的层面上看到结构。
894 01:25:56,877 --> 01:25:59,381 说话人 SPEAKER_01: 你可以看到核心结构和精细结构都显现出来。
895 01:26:01,162 --> 01:26:04,306 说话人 SPEAKER_01: 现在用于所有这些的目标函数是
896 01:26:04,810 --> 01:26:15,028 说话人 SPEAKER_01：这种高斯分布下的相对密度是从我之前与 Alberto Pacanaro 合作的研究中得出的，我们觉得很难发表。
897 01:26:16,831 --> 01:26:28,471 说话人 SPEAKER_01：我收到一封评审意见，说，是的，当这项工作被某个会议拒绝时，评审意见说，Hinton 已经研究了这个想法七年了，但没有人感兴趣。
898 01:26:29,836 --> 01:26:34,185 说话人 SPEAKER_01: 我把这些评论当作告诉我，我正在做一些非常原创的事情。
899 01:26:35,347 --> 01:26:39,475 说话人 SPEAKER_01: 这实际上包含了一个现在使用的功能，我想它被称为 NCE。
900 01:26:39,777 --> 01:26:41,359 说话人 SPEAKER_01: 它被用于这些对比方法中。
901 01:26:42,381 --> 01:26:45,127 说话人 SPEAKER_01: t-SNE 实际上是那个函数的一个版本。
902 01:26:46,002 --> 01:26:48,305 说话人 SPEAKER_01: 但它被用于制作地图。
903 01:26:48,945 --> 01:26:56,877 说话人 SPEAKER_01: 所以 t-SNE 有一个非常长的历史，就是从原始 SNE 开始，然后尝试制作混合版本，但这根本不起作用，一次又一次地不起作用。
904 01:26:57,438 --> 01:27:03,125 说话人 SPEAKER_01：最终，他们偶然发现，使用 t 分布是正确的。
905 01:27:03,466 --> 01:27:04,667 那就是混合的方式。
906 01:27:04,726 --> 01:27:12,097 说话人 SPEAKER_01：然后 Lauren 来了，Lauren 非常聪明，也是一位优秀的程序员，他让这一切都完美地工作起来。
907 01:27:12,118 --> 01:27:15,402 说话人 SPEAKER_00: 这真的很有趣，因为它似乎有很多
908 01:27:16,427 --> 01:27:27,248 说话人 SPEAKER_00：这些天，很多进步，更大的想法起着很大的作用，但这里似乎真正做对细节是让它完全工作的唯一方法。
909 01:27:27,729 --> 01:27:28,972 说话人 SPEAKER_01：通常你需要两者。
910 01:27:30,194 --> 01:27:35,244 说话人 SPEAKER_01：你必须有一个大想法，这样它才会是有趣和原创的，但你也要做对细节。
911 01:27:36,127 --> 01:27:37,710 说话人 SPEAKER_01: 毕业生就是这样用的。
912 01:27:38,921 --> 01:27:41,051 说话人 SPEAKER_00: 所以杰夫，谢谢你。
913 01:27:41,091 --> 01:27:48,966 说话人 SPEAKER_00: 感谢我们本季度的最后一集第一部分的这次精彩对话。