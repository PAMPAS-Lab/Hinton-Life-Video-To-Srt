1 00:00:02,561 --> 00:00:06,495 说话人 SPEAKER_03: 这是杰夫·辛顿。
2 00:00:07,378 --> 00:00:12,977 说话人 SPEAKER_03: 由于背部疾病，他已经 12 年多不能长时间坐着。
3 00:00:14,137 --> 00:00:14,958 说话人 SPEAKER_02: 我讨厌站着。
4 00:00:15,019 --> 00:00:17,382 说话人 SPEAKER_02: 我更愿意坐着，但如果我坐着，我的椎间盘就会突出。
5 00:00:18,402 --> 00:00:18,643 说话人 SPEAKER_02: 好吧。
6 00:00:19,123 --> 00:00:21,507 说话人 SPEAKER_03: 至少现在站立式办公桌很时尚。
7 00:00:21,527 --> 00:00:22,687 说话人 SPEAKER_03: 是的，但我已经领先了。
8 00:00:23,489 --> 00:00:25,911 说话人 SPEAKER_03: 当它们还不时尚的时候，我就已经开始站了。
9 00:00:27,814 --> 00:00:33,140 说话人 SPEAKER_03：由于他不能坐在车里或公交车上，Hinton 总是步行。
10 00:00:39,628 --> 00:00:42,491 说话人 SPEAKER_03：这种步行方式充分展现了 Hinton 和他的决心。
11 00:00:43,146 --> 00:00:55,420 说话人 SPEAKER_03：近 40 年来，Hinton 一直在尝试让计算机像人类一样学习，这个几乎所有人都认为疯狂或至少无望的追求，直到它彻底改变了这个领域。
12 00:00:56,881 --> 00:00:58,743 说话人 SPEAKER_02：谷歌认为这是公司的未来。
13 00:00:58,765 --> 00:01:00,326 说话人 SPEAKER_02: 亚马逊认为这是公司的未来。
14 00:01:00,807 --> 00:01:02,128 说话人 SPEAKER_02: 苹果认为这是公司的未来。
15 00:01:02,609 --> 00:01:06,072 说话人 SPEAKER_02: 我自己的部门认为这些可能都是胡说，我们不应该再继续这样做。
16 00:01:09,195 --> 00:01:12,579 说话人 SPEAKER_02: 所以我让所有人都同意了，除了我自己的部门。
17 00:01:19,765 --> 00:01:27,096 说话人 SPEAKER_03：你显然在英国长大，你有一个充满著名数学家和经济学家的非常显赫的家庭。
18 00:01:27,177 --> 00:01:29,421 说话人 SPEAKER_03：我很想知道那对你来说是什么样的。
19 00:01:29,460 --> 00:01:31,364 说话人 SPEAKER_02：是的，压力很大。
20 00:01:32,745 --> 00:01:36,552 说话人 SPEAKER_02：我想在我大约七岁的时候，我就意识到我必须获得博士学位。
21 00:01:38,656 --> 00:01:41,260 说话人 SPEAKER_03: 你反抗过那个，还是随波逐流了？
22 00:01:41,280 --> 00:01:42,602 说话人 SPEAKER_02: 我时不时地辍学。
23 00:01:42,843 --> 00:01:44,305 说话人 SPEAKER_02: 我曾经当过一段时间的木匠。
24 00:01:46,629 --> 00:01:53,061 说话人 SPEAKER_03: Jeff Hinton 很早就对弄清楚大脑如何工作这一想法着迷了。
25 00:01:55,325 --> 00:02:09,752 说话人 SPEAKER_03：他从生理学开始，研究大脑的工作解剖学，然后转向心理学，最后终于选择了计算机科学方法来模拟大脑，并涉足人工智能。
26 00:02:10,896 --> 00:02:17,205 说话人 SPEAKER_02：我的感觉是，如果你想真正理解一个复杂的设备，比如大脑，你应该自己造一个。
27 00:02:18,247 --> 00:02:20,891 说话人 SPEAKER_02：我的意思是，你可以看看汽车，你可以认为你可以理解汽车。
28 00:02:20,931 --> 00:02:26,239 说话人 SPEAKER_02：当你尝试造一辆汽车时，你突然发现，引擎盖下必须有这些东西，否则它就不工作。
29 00:02:26,319 --> 00:02:26,460 说话人 SPEAKER_02: 嗯。
30 00:02:28,562 --> 00:02:38,877 说话人 SPEAKER_03: 当杰夫开始思考这些想法时，他受到了一些海外的 AI 研究者的启发，特别是这位，弗兰克·罗森布拉特。
31 00:02:39,752 --> 00:02:45,401 说话人 SPEAKER_01: 罗森布拉特在 20 世纪 50 年代末开发了他称之为感知器的东西。
32 00:02:45,421 --> 00:02:51,012 说话人 SPEAKER_01: 那是一个神经网络，一个模仿大脑的计算机系统。
33 00:02:53,014 --> 00:02:57,241 说话人 SPEAKER_00: 基本思想是一系列称为神经元的微小单元。
34 00:02:57,562 --> 00:03:03,431 说话人 SPEAKER_00: 这些是小小的计算单元，但实际上它们是根据人脑的计算方式来建模的。
35 00:03:04,372 --> 00:03:12,024 说话人 SPEAKER_00: 它们接收传入的数据，就像我们从感官接收数据一样，并且实际上可以学习，因此神经网络可以随着时间的推移学习做出决策。
36 00:03:15,368 --> 00:03:25,242 说话人 SPEAKER_03: 罗森布拉特希望你能给神经网络提供大量数据，比如男性和女性的图片，它最终可以学会如何区分他们，就像人类一样。
37 00:03:28,567 --> 00:03:29,788 说话人 SPEAKER_03：只有一个问题。
38 00:03:30,629 --> 00:03:31,831 说话人 SPEAKER_01：它工作得不太好。
39 00:03:32,943 --> 00:03:37,550 说话人 SPEAKER_01：罗森布拉特，他的神经网络是一层神经元。
40 00:03:38,651 --> 00:03:41,736 说话人 SPEAKER_01：它的功能非常有限，极其有限。
41 00:03:42,878 --> 00:03:48,548 说话人 SPEAKER_01：他的一个同事在 60 年代末写了一本书，展示了这些局限性。
42 00:03:51,451 --> 00:03:56,439 说话人 SPEAKER_01：这几乎让整个研究领域陷入了长达 10 年的停滞。
43 00:03:57,562 --> 00:03:59,084 说话人 SPEAKER_01：没有人愿意在这个领域工作。
44 00:03:59,144 --> 00:04:00,806 说话人 SPEAKER_01：他们确信这永远不会成功。
45 00:04:01,764 --> 00:04:03,787 说话人 SPEAKER_03：几乎没有人。
46 00:04:05,027 --> 00:04:07,069 说话人 SPEAKER_02：对我来说，这显然是正确的方向。
47 00:04:08,031 --> 00:04:14,075 说话人 SPEAKER_02：大脑是一个大的神经网络，所以必须是这样的东西可以在我们的大脑中工作，因为它在我们的大脑中是有效的。
48 00:04:15,037 --> 00:04:16,358 说话人 SPEAKER_02：对此从未有过任何怀疑。
49 00:04:16,798 --> 00:04:25,065 说话人 SPEAKER_03：那么，你认为是什么让你在别人都放弃的时候还想要继续，仅仅是因为你认为这是正确的方向吗？
50 00:04:25,526 --> 00:04:26,648 说话人 SPEAKER_02：知道其他人都是错的。
51 00:04:26,728 --> 00:04:30,050 说话人 SPEAKER_02：好的。
52 00:04:31,464 --> 00:04:37,934 说话人 SPEAKER_03：Pinton 决定他对这些神经网络的工作原理有一个想法，不管怎样他都要去追求。
53 00:04:39,696 --> 00:04:43,581 说话人 SPEAKER_03：他曾在美國的研究機構間轉悠了一陣子。
54 00:04:44,622 --> 00:04:50,992 说话人 SPEAKER_03：他對大多數機構都由國防部資助感到有些厭倦，於是開始尋找其他可以去的地方。
55 00:04:51,012 --> 00:04:54,096 说话人 SPEAKER_03：我不想接受國防部的資金。
56 00:04:54,776 --> 00:05:00,004 说话人 SPEAKER_02：我不太喜歡這些東西會被用於我不認為是正當的目標。
57 00:05:01,182 --> 00:05:05,665 说话人 SPEAKER_03：他突然听说加拿大可能对资助人工智能感兴趣。
58 00:05:06,487 --> 00:05:12,213 说话人 SPEAKER_02：这对我来说非常吸引人，我可以去这个文明的城市，然后继续我的工作。
59 00:05:12,233 --> 00:05:13,613 说话人 SPEAKER_02：所以我来到了多伦多大学。
60 00:05:15,276 --> 00:05:21,541 说话人 SPEAKER_02：然后在 20 世纪 80 年代中期，我们发现如何制造更复杂的神经网络，以便它们能够解决简单神经网络无法解决的问题。
61 00:05:21,581 --> 00:05:29,028 说话人 SPEAKER_01：他和他的合作者开发了一种多层神经网络，即深度神经网络。
62 00:05:29,937 --> 00:05:32,521 说话人 SPEAKER_01：这在很多方面开始起作用。
63 00:05:34,103 --> 00:05:42,338 说话人 SPEAKER_01：在 20 世纪 80 年代末，一位名叫迪安·波莫勒的先生利用神经网络建造了一辆自动驾驶汽车，并在公共道路上行驶。
64 00:05:42,358 --> 00:05:49,992 说话人 SPEAKER_01：90 年代，简·勒·库恩建造了一个能够识别手写数字的系统，最终被用于商业用途。
65 00:05:51,173 --> 00:05:52,637 说话人 SPEAKER_01: 但他们又遇到了天花板。
66 00:05:56,245 --> 00:06:00,252 说话人 SPEAKER_02: 因为数据不够多，计算能力也不足，所以效果并不理想。
67 00:06:01,274 --> 00:06:06,884 说话人 SPEAKER_02: 因此，人工智能和计算机科学领域的人士认为神经网络只是空想，基本上。
68 00:06:08,365 --> 00:06:09,809 说话人 SPEAKER_02: 所以这让人非常失望。
69 00:06:09,869 --> 00:06:20,767 说话人 SPEAKER_03：在 90 年代到 2000 年代期间，杰夫是地球上为数不多的仍在追求这项技术的人之一。
70 00:06:22,654 --> 00:06:27,062 说话人 SPEAKER_03：他会出现在学术会议上，然后被赶到后屋。
71 00:06:27,122 --> 00:06:31,327 说话人 SPEAKER_03：他被视为真正的局外人。
72 00:06:31,348 --> 00:06:36,735 说话人 SPEAKER_03：有没有想过这项技术根本行不通，你有过一些自我怀疑？
73 00:06:37,237 --> 00:06:37,357 说话人 SPEAKER_02: 不。
74 00:06:37,476 --> 00:06:40,362 说话人 SPEAKER_02: 我的意思是，有很多次我都在想，我觉得这件事是行不通的。
75 00:06:42,644 --> 00:06:45,168 说话人 SPEAKER_03: 但是 Jeff 对这件事着迷，无法停止。
76 00:06:46,464 --> 00:06:55,478 说话人 SPEAKER_03: 他一直坚持计算机可以学习的观点，直到大约 2006 年，当世界赶上 Hinton 的想法。
77 00:07:00,725 --> 00:07:03,069 说话人 SPEAKER_02：现在的计算机速度非常快。
78 00:07:03,088 --> 00:07:05,892 说话人 SPEAKER_02：现在它的表现就像我在 80 年代中期所预期的。
79 00:07:06,192 --> 00:07:07,975 说话人 SPEAKER_02：它解决了一切问题。
80 00:07:07,995 --> 00:07:16,067 说话人 SPEAKER_03：超快芯片的出现和互联网上产生的海量数据为 Hinton 的算法提供了神奇的推动力。
81 00:07:17,767 --> 00:07:20,653 说话人 SPEAKER_03：突然，计算机能够识别图像中的内容。
82 00:07:21,774 --> 00:07:26,423 说话人 SPEAKER_03：然后，它们能够识别语音并实现一种语言到另一种语言的翻译。
83 00:07:27,766 --> 00:07:34,238 说话人 SPEAKER_03：到 2012 年，像“神经网络”和“机器学习”这样的词已经出现在《纽约时报》的头条上。
84 00:07:35,201 --> 00:07:39,709 说话人 SPEAKER_03：你必须走过这些岁月，然后突然间，在短短几个月的时间里，
85 00:07:40,516 --> 00:07:41,476 说话人 SPEAKER_03：它就起飞了。
86 00:07:41,497 --> 00:07:45,942 说话人 SPEAKER_03：它终于感觉到了，啊，世界终于来到了我的视野中了吗？
87 00:07:45,963 --> 00:07:49,247 说话人 SPEAKER_03：人们终于恢复理智，这让人感到一种解脱。
88 00:07:54,052 --> 00:07:58,918 说话人 SPEAKER_03：对于辛顿来说，这是数十年来辛勤劳作后的一个明显救赎时刻。
89 00:08:00,880 --> 00:08:03,824 说话人 SPEAKER_03：对于加拿大来说，这意味着更多。
90 00:08:05,887 --> 00:08:10,151 说话人 SPEAKER_03：Hinton 和他的学生将这个国家定位为 AI 超级大国。
91 00:08:11,177 --> 00:08:26,233 说话人 SPEAKER_03：这是任何人和任何计算机都无法预测的。
