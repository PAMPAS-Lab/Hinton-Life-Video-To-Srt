1 00:00:00,031 --> 00:00:06,437 演讲者 演讲者_00：现在，我非常荣幸和自豪地介绍我们的第二位演讲者，杰弗里·辛顿。
2 00:00:07,998 --> 00:00:12,243 演讲者 演讲者_00：杰弗里·辛顿于1947年出生于英国伦敦。
3 00:00:12,682 --> 00:00:18,548 演讲者 演讲者_00：他在1970年从剑桥大学获得实验心理学学士学位。
4 00:00:18,568 --> 00:00:27,878 演讲者 演讲者_00：1978年，他获得爱丁堡大学的人工智能博士学位。
5 00:00:28,937 --> 00:00:40,731 讲者 SPEAKER_00: 在博士后研究之后，他在匹兹堡的卡内基梅隆大学担任了五年的计算机科学系教职。
6 00:00:41,771 --> 00:00:53,865 讲者 SPEAKER_00: 1987 年，他被任命为加拿大多伦多大学的计算机科学教授，现在他是该校的荣誉退休教授。
7 00:00:55,009 --> 00:01:04,740 讲者 SPEAKER_00: 在 2013 年至 2023 年期间，他在学术研究和谷歌大脑之间分配时间。
8 00:01:06,063 --> 00:01:16,495 讲者 SPEAKER_00: 请和我一起欢迎杰弗里·辛顿教授上台，向我们讲述今年诺贝尔物理学奖的获奖成果。
9 00:01:34,177 --> 00:01:36,399 说话人 SPEAKER_01：今天，我要做一件非常愚蠢的事情。
10 00:01:37,040 --> 00:01:42,704 说话人 SPEAKER_01：我将尝试向普通听众描述一个复杂的技术概念，而不使用任何方程式。
11 00:01:44,867 --> 00:01:46,888 说话人 SPEAKER_01：首先，我必须解释霍普菲尔德网络。
12 00:01:47,549 --> 00:01:51,033 说话人 SPEAKER_01：我将解释具有 1 或 0 状态的二进制神经元的版本。
13 00:01:51,974 --> 00:01:54,236 说话人 SPEAKER_01：所以在右边，您会看到一个小的 Hopfield 网络。
14 00:01:55,037 --> 00:01:59,762 说话人 SPEAKER_01：最重要的是，神经元之间具有对称加权连接。
15 00:02:02,694 --> 00:02:07,721 说话人 SPEAKER_01：整个网络的全球状态被称为配置，这样我们看起来有点像物理学。
16 00:02:08,783 --> 00:02:12,469 说话人 SPEAKER_01：每个配置都有一个“良好度”。
17 00:02:13,290 --> 00:02:20,981 说话人 SPEAKER_01：配置的优良性简单来说就是所有同时开启的神经元之间权重的总和。
18 00:02:21,383 --> 00:02:26,509 说话人 SPEAKER_01：所以那些红色框中的权重，把它们加起来，希望是四。
19 00:02:27,091 --> 00:02:30,896 说话人 SPEAKER_01：这就是该网络配置的优良性。
20 00:02:30,877 --> 00:02:33,241 说话人 SPEAKER_01：能量就是优良性的相反数。
21 00:02:36,305 --> 00:02:38,889 说话人 SPEAKER_01：因此，这些网络将趋于能量最小值。
22 00:02:38,909 --> 00:02:50,067 说话人 SPEAKER_01：Hopfield 网络的核心在于每个神经元可以局部计算它需要做什么来降低能量，其中能量代表不良。
23 00:02:50,823 --> 00:02:58,429 说话人 SPEAKER_01：如果来自其他活跃神经元的总加权输入为正，则神经元应该打开。
24 00:02:59,413 --> 00:03:03,567 说话人 SPEAKER_01：如果来自其他活跃神经元的总加权输入为负，则应该关闭。
25 00:03:05,098 --> 00:03:12,087 说话人 SPEAKER_01：如果每个神经元都继续使用那个规则，并且我们随机选择它们并继续应用那个规则，我们最终会达到能量最小值。
26 00:03:12,829 --> 00:03:16,193 说话人 SPEAKER_01：所以右边的配置实际上是一个能量最小值。
27 00:03:16,873 --> 00:03:18,656 说话人 SPEAKER_01：它的能量是负 4。
28 00:03:19,497 --> 00:03:22,901 说话人 SPEAKER_01：如果你取任何一个神经元，那些处于开启状态的神经元想要保持开启状态。
29 00:03:22,961 --> 00:03:24,362 说话人 SPEAKER_01：他们获得全部正面输入。
30 00:03:24,683 --> 00:03:25,965 说话人 SPEAKER_01：那些想要保持关闭的，他们想要保持关闭。
31 00:03:25,985 --> 00:03:27,167 说话人 SPEAKER_01：他们获得全部负面输入。
32 00:03:27,828 --> 00:03:29,789 说话人 SPEAKER_01：但这并不是唯一的能量最低点。
33 00:03:30,091 --> 00:03:32,655 说话人 SPEAKER_01：Hopfield 网络可以有多个能量最小值。
34 00:03:33,256 --> 00:03:39,145 说话人 SPEAKER_01：它最终到达的位置取决于你从哪里开始，以及你做出的随机决策序列。
35 00:03:41,688 --> 00:03:44,312 说话人 SPEAKER_01：抱歉，关于更新哪个神经元的随机决策序列。
36 00:03:46,735 --> 00:03:48,258 说话人 SPEAKER_01：这样就是一个更好的能量最小值了。
37 00:03:48,679 --> 00:03:50,902 说话人 SPEAKER_01：现在我们已经打开了右侧的单元三角形。
38 00:03:51,723 --> 00:03:55,169 说话人 SPEAKER_01：而且它的良好度为 3 加 3 减 1 等于 5。
39 00:03:56,812 --> 00:03:59,034 说话人 SPEAKER_01：因此，能量减 5，这是一个更好的最小值。
40 00:04:00,718 --> 00:04:07,669 说话人 SPEAKER_01：现在，Hopfield 提出，使用这类网络的一个好方法是将能量最小值对应到记忆中。
41 00:04:08,491 --> 00:04:14,161 说话者 SPEAKER_01：然后使用这个二进制决策规则来决定是否激活或关闭神经元，这可以清理不完整的记忆。
42 00:04:14,882 --> 00:04:20,971 说话者 SPEAKER_01：所以，从一个部分记忆开始，然后不断应用这个决策规则，它就会将其清理干净。
43 00:04:20,951 --> 00:04:27,257 说话者 SPEAKER_01：因此，当它们代表记忆时，将能量最小化设定为一种内容可寻址内存的方式。
44 00:04:28,218 --> 00:04:34,384 说话者 SPEAKER_01：您可以通过仅激活内存中的某些项来访问内存中的项目，然后使用这个规则，它就会将其补充完整。
45 00:04:37,105 --> 00:04:44,012 说话人 SPEAKER_01：特里·桑福斯和我，特里曾是 Upfield 的学生，我们提出了这些网状物的一种不同用途。
46 00:04:44,773 --> 00:04:49,997 说话人 SPEAKER_01：与其用它们来存储记忆，我们不如用它们来构建对感官输入的解释。
47 00:04:51,108 --> 00:04:52,771 说话人 SPEAKER_01：所以想法是，你有一个网络。
48 00:04:53,271 --> 00:04:55,374 说话人 SPEAKER_01：它既有可见神经元也有隐藏神经元。
49 00:04:55,694 --> 00:05:00,122 说话人 SPEAKER_01：可见神经元是您向其展示感官输入的地方，可能是一个二进制图像。
50 00:05:01,223 --> 00:05:04,709 说话人 SPEAKER_01：隐藏神经元是它构建对那个感官输入的解释的地方。
51 00:05:07,312 --> 00:05:11,939 说话人 SPEAKER_01：网络配置的能量代表了解释的糟糕程度。
52 00:05:12,339 --> 00:05:14,262 说话人 SPEAKER_01：因此，我们希望解释的能量低。
53 00:05:15,610 --> 00:05:17,791 说话人 SPEAKER_01：我将给您举一个具体的例子。
54 00:05:18,353 --> 00:05:21,136 说话人 SPEAKER_01：考虑一下顶部那个模糊的线条图。
55 00:05:21,156 --> 00:05:22,797 说话人 SPEAKER_01：人们有两种看待它的方式。
56 00:05:23,918 --> 00:05:26,942 说话人 SPEAKER_01：有一种解释，这通常是您首先看到的。
57 00:05:27,281 --> 00:05:28,543 说话人 SPEAKER_01：还有另一种解释。
58 00:05:29,024 --> 00:05:34,528 说话人 SPEAKER_01：当你看到有一个凸形物体时，这显然是对同一二维线图的不同的三维解释。
59 00:05:35,250 --> 00:05:40,014 说话人 SPEAKER_01：那么我们能否让这些网络之一产生对同一线图的两种不同解释？
60 00:05:41,259 --> 00:05:45,826 说话人 SPEAKER_01：嗯，我们首先需要思考图像中的一条线能告诉你关于三维边缘的什么信息。
61 00:05:47,247 --> 00:05:49,610 说话人 SPEAKER_01：所以那条绿色线是图像平面。
62 00:05:49,670 --> 00:05:55,238 说话人 SPEAKER_01：想象一下你透过窗户看，你在窗户上绘制场景中世界上的边缘。
63 00:05:55,819 --> 00:05:59,103 说话人 SPEAKER_01：所以那条小黑线是图像中的线。
64 00:06:00,365 --> 00:06:04,572 说话人 SPEAKER_01：而两条红线是从你的眼睛通过那条线的两端看到的视线。
65 00:06:05,533 --> 00:06:09,158 说话人 SPEAKER_01：那么，世界上哪个边缘能造成这种情况呢？
66 00:06:09,408 --> 00:06:11,290 说话人 SPEAKER_01：嗯，有很多边缘可能造成了这种情况。
67 00:06:11,790 --> 00:06:14,053 说话人 SPEAKER_01：有一个边缘可能造成了那个二维线。
68 00:06:14,514 --> 00:06:17,317 说话人 SPEAKER_01：但是还有另一个，还有另一个，还有另一个。
69 00:06:17,899 --> 00:06:20,622 说话人 SPEAKER_01：所有这些边缘都会在图像中形成同一条线。
70 00:06:21,244 --> 00:06:26,610 说话人 SPEAKER_01：所以视觉问题是要从图像中的单条线反向推断出这些边缘中哪一个是真实存在的。
71 00:06:29,413 --> 00:06:33,699 说话人 SPEAKER_01：如果物体是不透明的，你一次只能看到其中之一，因为它们都会相互遮挡。
72 00:06:34,321 --> 00:06:38,165 说话人 SPEAKER_01：所以你知道图像中的那条线必须描绘这些边缘之一，但你不知道是哪一个。
73 00:06:39,394 --> 00:06:47,367 说话人 SPEAKER_01：我们可以构建一个网络，我们从将线条转换为线神经元激活开始。
74 00:06:47,387 --> 00:06:48,810 说话人 SPEAKER_01：假设我们已经有这个了。
75 00:06:49,050 --> 00:06:55,701 说话人 SPEAKER_01：我们有大量神经元来表示图像中的线条，我们只打开其中的一小部分来表示这张特定图像中的线条。
76 00:06:56,802 --> 00:07:00,829 说话人 SPEAKER_01：现在，每条线都可能代表多个不同的 3D 边缘。
77 00:07:00,809 --> 00:07:07,557 说话人 SPEAKER_01：我们所做的是将这条线神经元连接到一大堆 3D 边缘神经元，并通过兴奋性连接。
78 00:07:07,617 --> 00:07:08,478 说话人 SPEAKER_01：这些是绿色的。
79 00:07:08,959 --> 00:07:10,901 说话人 SPEAKER_01：但我们知道我们一次只能看到其中之一。
80 00:07:10,961 --> 00:07:13,985 说话人 SPEAKER_01：所以我们让这些边缘神经元相互抑制。
81 00:07:14,685 --> 00:07:17,889 说话人 SPEAKER_01：现在我们已经捕捉到了很多关于感知光学方面的内容。
82 00:07:19,370 --> 00:07:21,754 说话人 SPEAKER_01：我们为所有的线神经元都这样做。
83 00:07:22,391 --> 00:07:26,036 说话人 SPEAKER_01：现在的问题是，我们应该激活哪些边缘神经元？
84 00:07:26,776 --> 00:07:28,620 说话人 SPEAKER_01：为了这个，我们需要更多信息。
85 00:07:29,199 --> 00:07:31,583 说话人 SPEAKER_01：我们在解读图像时有一些原则。
86 00:07:32,163 --> 00:07:39,172 说话人 SPEAKER_01：如果你在图像中看到两条线，你会假设如果它们在图像中相交，它们在深度上也会相交。
87 00:07:39,192 --> 00:07:43,016 说话人 SPEAKER_01：也就是说，它们在两条线在图像中相交的深度上。
88 00:07:42,997 --> 00:07:45,721 说话人 SPEAKER_01：因此我们可以为这个添加额外的连接。
我们可以在每个 3D 边缘神经元之间建立连接，这些神经元在深度上连接，并且它们具有相同的末端。
90 00：07：58,341 --> 00：08：01,627 演讲者 SPEAKER_01：如果他们以直角加入，我们可以建立更强的联系。
91 00：08：01,747 --> 00：08：05,173 演讲者 SPEAKER_01：我们真的很喜欢看到物体以直角连接的图像。
所以我们放入了一大堆这样的连接，现在我们希望的是，如果我们设置好连接强度，我们就能得到一个网络，它可以稳定在两种状态之一，对应于那两种对内克立方体的不同解释。
93 00:08:19,701 --> 00:08:22,487 说话人 SPEAKER_01：这引发了两个主要问题。
94 00:08:23,463 --> 00:08:33,634 说话人 SPEAKER_01：第一个问题，如果我们打算使用隐藏神经元来对可见神经元状态所表示的图像进行解释，那就是搜索问题。
95 00:08:34,695 --> 00:08:37,116 说话人 SPEAKER_01：我们如何避免陷入局部最优解？
96 00:08:37,136 --> 00:08:41,662 说话人 SPEAKER_01：我们可能会陷入一个相当糟糕的解释，而无法跳出来达到更好的解释。
97 00:08:42,743 --> 00:08:44,764 说话人 SPEAKER_01：第二个问题是学习。
98 00:08:45,826 --> 00:08:51,511 说话人 SPEAKER_01：我似乎暗示我会手动添加所有这些连接，但我们希望神经网络能够添加所有这些连接。
99 00:08:54,259 --> 00:09:01,317 说话人 SPEAKER_01：所以我们通过使神经元产生噪声来大致解决搜索问题。
100 00:09:01,684 --> 00:09:20,456 说话人 SPEAKER_01：所以如果你有确定性的神经元，比如在标准的 Hopfield 网络中，如果系统陷入一个能量最小值，比如 A，那么那里的球就是整个系统的配置，它不能从 A 到 B，因为神经元的决策规则只允许能量下降。
101 00:09:21,138 --> 00:09:22,880 说话人 SPEAKER_01：右边的图是决策规则。
102 00:09:23,162 --> 00:09:25,065 说话人 SPEAKER_01：如果输入为正，则开启。
103 00:09:25,385 --> 00:09:26,847 说话人 SPEAKER_01：如果输入为负，则关闭。
104 00:09:28,921 --> 00:09:32,846 说话人 SPEAKER_01：我们希望能够从 A 到 B，但这意味着我们必须在能量上爬坡。
105 00:09:33,427 --> 00:09:37,272 说话者 SPEAKER_01：解决这个问题的方法是拥有嘈杂的神经元，随机二进制神经元。
106 00:09:37,972 --> 00:09:39,654 说话者 SPEAKER_01：它们仍然只有二进制状态。
107 00:09:39,695 --> 00:09:43,379 说话者 SPEAKER_01：它们的状态要么是 1 要么是 0，但它们是概率性的。
108 00:09:44,019 --> 00:09:47,585 说话者 SPEAKER_01：如果它们接收到大的正输入，它们几乎总是会被激活。
109 00:09:47,644 --> 00:09:50,067 说话者 SPEAKER_01：在大的负输入下，它们几乎总是关闭。
110 00:09:50,048 --> 00:09:54,599 说话者 SPEAKER_01：但如果输入柔和，如果它在 0 附近，那么它们会表现出概率行为。
111 00:09:54,840 --> 00:09:57,264 说话者 SPEAKER_01：如果是正输入，它们通常打开，但偶尔会关闭。
112 00:09:57,706 --> 00:10:01,054 说话者 SPEAKER_01：如果是小的负输入，它们通常关闭，但偶尔会打开。
113 00:10:02,037 --> 00:10:03,681 说话人 SPEAKER_01：但它们没有真实值。
114 00:10:03,701 --> 00:10:07,450 说话人 SPEAKER_01：它们总是二进制，但只是做出这些概率性决策。
115 00:10:09,269 --> 00:10:19,839 说话人 SPEAKER_01：因此，如果我们想使用这些隐藏神经元来解释二进制图像，我们就在可见单元上固定二进制图像。
116 00:10:20,200 --> 00:10:22,182 说话人 SPEAKER_01：这指定了输入是什么。
117 00:10:23,003 --> 00:10:24,663 说话人 SPEAKER_01：然后我们随机选择一个隐藏神经元。
118 00:10:25,445 --> 00:10:29,609 说话人 SPEAKER_01：我们查看它从其他活动隐藏神经元接收到的总输入。
119 00:10:30,029 --> 00:10:31,610 说话人 SPEAKER_01：然后我们将它们都从随机状态开始。
120 00:10:32,471 --> 00:10:35,394 说话人 SPEAKER_01：如果它接收到的总输入为正，我们可能将其打开。
121 00:10:35,414 --> 00:10:38,618 说话人 SPEAKER_01：但如果只是小的正输入，我们可能就将其关闭。
122 00:10:38,597 --> 00:10:46,431 说话人 SPEAKER_01：所以我们继续实施这个规则，如果输入大是正的，就打开；如果是大的负输入，就关闭；如果是软的，就做出概率性决策。
123 00:10:47,111 --> 00:10:53,942 说话人 SPEAKER_01：如果我们继续这样做，挑选隐藏神经元，系统最终将接近所谓的热平衡状态。
124 00:10:54,504 --> 00:10:57,489 说话人 SPEAKER_01：这对非物理学家来说是一个难以理解的概念，我稍后会解释。
125 00:10:58,509 --> 00:11:05,701 说话人 SPEAKER_01：一旦达到热平衡，隐藏神经元的态就是对输入的解释。
126 00:11:06,965 --> 00:11:12,801 说话人 SPEAKER_01：所以在那条线图的例子中，隐藏神经元，你希望每个线单元有一个激活的隐藏神经元。
127 00:11:13,201 --> 00:11:17,995 说话人 SPEAKER_01：然后你得到一个解释，这将是那两个尼克尔立方体的解释之一。
128 00:11:18,015 --> 00:11:22,408 说话人 SPEAKER_01：我们希望低能量解释是对数据的良好解释。
因此，对于这条线绘制，如果我们能学习到 2D 线神经元和 3D 边缘神经元之间的正确权重，以及 3D 边缘神经元之间的正确权重，那么希望网络的低能量状态将对应于良好的解释，即看到 3D 矩形物体。
130 00：11：47,649 --> 00：11：48,831 议长 SPEAKER_01：所以热平衡。
131 00：11：49,714 --> 00：11：53,922 发言者 SPEAKER_01：这不是你最初所期望的，而是系统稳定到了一个稳定的状态。
132 00：11：55,365 --> 00：11：57,909 议长 SPEAKER_01：稳定的不是系统的状态。
133 00:11:58,390 --> 00:12:01,937 说话人 SPEAKER_01：稳定的是一种更加抽象的东西，很难去思考。
134 00:12:01,976 --> 00:12:06,485 说话人 SPEAKER_01：这是系统配置的概率分布。
135 00:12:06,466 --> 00:12:09,610 说话人 SPEAKER_01：这对普通人来说非常难以理解。
136 00:12:09,629 --> 00:12:13,375 说话人 SPEAKER_01：它最终会达到一个特定的分布，称为玻尔兹曼分布。
137 00:12:13,936 --> 00:12:24,110 说话人 SPEAKER_01：在玻尔兹曼分布中，系统在达到热平衡后处于特定配置的概率完全由该配置的能量决定。
138 00:12:24,570 --> 00:12:28,134 说话人 SPEAKER_01：因此，在低能量配置中找到它的概率更高。
139 00:12:28,716 --> 00:12:34,043 说话人 SPEAKER_01：所以，热平衡、良好状态、低能量状态比不良状态更可能。
140 00:12:35,288 --> 00:12:42,077 说话人 SPEAKER_01：现在，为了思考热平衡，物理学家使用了一个技巧，它允许普通人理解这个概念。
141 00:12:43,058 --> 00:12:43,440 说话人 SPEAKER_01：希望如此。
142 00:12:45,341 --> 00:12:50,450 说话人 SPEAKER_01：你只需想象一个非常庞大的集合，数以亿计的它们，都是相同的网络。
143 00:12:50,590 --> 00:12:52,613 说话人 SPEAKER_01：你拥有这些数以亿计的霍普菲尔德网络。
144 00:12:52,993 --> 00:12:55,456 说话人 SPEAKER_01：它们的权重完全相同。
145 00:12:55,437 --> 00:13:12,230 说话人 SPEAKER_01：它们本质上是一样的系统，但你从不同的随机状态开始启动它们，它们都会做出自己独立的随机决策，并且会有一定比例的系统具有每种配置，最初这个比例将完全取决于你如何启动它们。
146 00:13:12,211 --> 00:13:15,376 说话人 SPEAKER_01：也许你可以随机启动它们，这样所有配置的可能性都是相同的。
147 00:13:15,937 --> 00:13:21,948 说话人 SPEAKER_01：在这个庞大的集合中，你将得到每个可能配置的系统数量相等。
148 00:13:22,429 --> 00:13:28,259 说话人 SPEAKER_01：然后你开始运行这个更新神经元的算法，使它们倾向于降低能量，但偶尔也会上升。
149 00:13:29,182 --> 00:13:35,974 说话人 SPEAKER_01：逐渐地，任何一种配置中系统的比例将趋于稳定。
150 00:13:35,953 --> 00:13:38,879 说话人 SPEAKER_01：所以任何一个系统将在不同的配置之间跳跃。
151 00:13:39,500 --> 00:13:43,788 说话人 SPEAKER_01：但特定配置中所有系统的比例将是稳定的。
152 00:13:44,571 --> 00:13:49,519 说话人 SPEAKER_01：因此，一个系统可能离开某个配置，但其他系统将进入该配置。
153 00：13：49,780 --> 00：13：51,403 发言者 SPEAKER_01：这叫详细余额。
154 00:13:51,423 --> 00:13:53,607 说话人 SPEAKER_01：系统的稳定比例将保持不变。
155 00:13:53,587 --> 00:13:55,511 说话人 SPEAKER_01：这就是物理的全部内容了。
156 00:13:58,537 --> 00:14:01,042 说话人 SPEAKER_01：那么现在让我们想象一下生成一张图片。
157 00:14:01,261 --> 00:14:03,525 说话人 SPEAKER_01：不是解释一张图片，而是生成一张图片。
158 00:14:04,248 --> 00:14:10,399 说话人 SPEAKER_01：要生成图像，你首先为所有神经元、隐藏神经元和可见神经元选择随机状态。
159 00:14:10,379 --> 00:14:15,850 说话人 SPEAKER_01：然后你选择一个隐藏或可见神经元，并使用常规随机规则更新其状态。
160 00:14:15,870 --> 00:14:18,073 说话人 SPEAKER_01：如果它接收大量正输入，可能将其打开。
161 00:14:18,414 --> 00:14:20,097 说话人 SPEAKER_01：接收大量负输入，可能将其关闭。
162 00:14:20,458 --> 00:14:22,822 说话人 SPEAKER_01：如果它很软，它的行为有点随机。
163 00:14:23,565 --> 00:14:25,148 说话人 SPEAKER_01：然后你继续这样做。
164 00:14:26,782 --> 00:14:34,311 说话人 SPEAKER_01：如果你反复这样做，直到系统接近热平衡，那么你查看可见单元的状态。
165 00:14:35,171 --> 00:14:47,024 说话人 SPEAKER_01：现在这是一个网络从它所相信的分布中生成的图像，即玻尔兹曼分布，其中低能量配置比高能量配置更可能出现。
166 00:14:47,605 --> 00:14:51,549 说话人 SPEAKER_01：但它相信存在许多可能的替代图像。
167 00:14:52,091 --> 00:14:55,995 说话人 SPEAKER_01：您可以通过运行此过程来选择它所相信的其中一项。
168 00:14:57,258 --> 00:14:57,677 说话人 SPEAKER_01：好的。
169 00:15:00,041 --> 00:15:02,624 说话人 SPEAKER_01：那么，在玻尔兹曼机中学习的目的是什么？
170 00:15:03,183 --> 00:15:09,691 说话人 SPEAKER_01：在玻尔兹曼机中学习的目的是让它生成图像时，就像在做梦一样。
171 00:15:10,032 --> 00:15:12,354 说话人 SPEAKER_01：这只是随机想象事物。
172 00:15:13,635 --> 00:15:22,184 说话人 SPEAKER_01：当它生成图像时，这些图像看起来就像它在感知真实图像时感知到的图像。
173 00:15:22,164 --> 00:15:30,863 说话人 SPEAKER_01：如果我们能实现这一点，那么隐藏神经元的态实际上是一种解释真实图像的好方法。
174 00:15:31,403 --> 00:15:33,688 说话人 SPEAKER_01：他们将捕捉图像的潜在原因。
175 00:15:34,048 --> 00:15:34,850 说话人 SPEAKER_01：至少这是希望。
176 00:15:35,471 --> 00:15:37,355 说话人 SPEAKER_01：另一种说法是
177 00:15:37,336 --> 00:15:48,182 说话人 SPEAKER_01：学习网络中的权重等同于找出如何使用那些隐藏神经元，以便网络生成看起来像真实图像的图像。
178 00:15:49,065 --> 00:15:50,889 说话人 SPEAKER_01：这似乎是一个非常困难的问题。
179 00:15:51,210 --> 00:15:53,876 说话人 SPEAKER_01：大家都认为这将非常复杂。
180 00:15:53,856 --> 00:15:59,621 说话人 SPEAKER_01：结果，我和 Terry 有一个非常乐观的方法。
181 00:16:01,663 --> 00:16:22,682 说话人 SPEAKER_01：问题是，你能从一个神经网络开始，一个 Hopfield 网络，这种随机的 Hopfield 网络，它有很多隐藏神经元，它们之间有随机的权重，它们与可见神经元之间也有随机的权重，所以这是一个很大的随机神经网络，然后你给它展示很多图像，我们希望得到一些看起来荒谬的结果，那就是
182 00:16:23,640 --> 00:16:31,068 说话人 SPEAKER_01：在感知大量真实图像后，它将创建隐藏单元之间的所有连接，以及隐藏单元和可见单元之间的所有连接。
183 00:16:31,590 --> 00:16:39,698 说话人 SPEAKER_01：它将正确地加权这些连接，以便能够对图像进行合理的解释，例如 3D 边缘在直角处相交。
184 00:16:41,159 --> 00:16:42,621 说话人 SPEAKER_01：这听起来非常乐观。
185 00:16:43,462 --> 00:16:47,427 说话人 SPEAKER_01：你可能认为执行这种学习的算法会非常复杂。
关于 Boltzmann 机的神奇之处在于有一个非常简单的学习算法可以做到这一点。
1983年，塔拉索夫斯基和我发现了这个。
188 00：16：58,840 --> 00：17：02,667 演讲者 SPEAKER_01：学习算法是这样的。
189 00：17：03,368 --> 00：17：04,269 演讲者 SPEAKER_01：它有两个阶段。
190 00:17:05,050 --> 00:17:05,912 说话人 SPEAKER_01：存在一个唤醒阶段。
191 00:17:06,633 --> 00:17:09,357 说话人 SPEAKER_01：这是网络被呈现图像的阶段。
192 00:17:09,699 --> 00:17:11,821 说话人 SPEAKER_01：你将图像夹在可见单元上。
193 00:17:11,801 --> 00:17:15,509 说话人 SPEAKER_01：你让隐藏单元摇晃并达到热平衡状态。
194 00:17:16,611 --> 00:17:29,973 说话人 SPEAKER_01：然后，一旦隐藏单元与可见神经元达到热平衡，对于每对连接的神经元，无论是两个隐藏神经元还是可见神经元和隐藏神经元，如果它们都处于激活状态，就在它们之间的权重上增加一小部分。
195 00:17:30,515 --> 00:17:32,598 说话人 SPEAKER_01：这是一个相当简单的学习规则。
196 00:17:32,919 --> 00:17:36,105 说话人 SPEAKER_01：这是唐纳德·赫布的信徒们会喜欢的学习规则。
197 00:17:38,548 --> 00:17:39,611 说话人 SPEAKER_01：然后是睡眠阶段。
198 00:17:40,231 --> 00:17:45,419 说话人 SPEAKER_01：显然，如果你只运行唤醒阶段，权重只会越来越大。
199 00:17:46,019 --> 00:17:49,305 说话人 SPEAKER_01：很快，它们都会变成正值，所有神经元都会一直开启。
200 00:17:49,705 --> 00:17:50,467 说话人 SPEAKER_01：这样没什么好处。
201 00:17:51,387 --> 00:17:53,010 说话人 SPEAKER_01：你需要将其与睡眠阶段结合起来。
202 00:17:53,411 --> 00:17:57,116 说话人 SPEAKER_01：在睡眠阶段，你可以把网络想象成在做梦。
203 00:17:57,477 --> 00:18:03,425 说话人 SPEAKER_01：你通过更新所有神经元的态，包括隐藏的和可见的，来达到热平衡。
204 00:18:03,405 --> 00:18:12,282 说话人 SPEAKER_01：一旦你做到了这一点，达到了热平衡，对于每一对连接的神经元，如果它们都处于激活状态，你将从中减去一小部分权重。
205 00:18:12,923 --> 00:18:14,646 说话人 SPEAKER_01：这是一个相当简单的学习算法。
206 00:18:15,469 --> 00:18:17,432 说话人 SPEAKER_01：它做得非常正确，这真的很令人惊讶。
207 00:18:19,296 --> 00:18:21,279 说话人 SPEAKER_01：所以，平均来说，
208 00:18:22,036 --> 00:18:31,776 说话人 SPEAKER_01：这个学习算法会改变权重，以增加网络在“做梦”时生成的图像看起来像它在“感知”时看到的图像的概率。
209 00:18:32,758 --> 00:18:35,845 说话人 SPEAKER_01：这不是面向普通观众的，所以你不必阅读接下来的两行。
210 00:18:37,047 --> 00:18:39,893 说话人 SPEAKER_01：对于统计学家和机器学习人员来说，
211 00:18:39,873 --> 00:18:50,755 说话人 SPEAKER_01：该算法所做的是，在期望上，这意味着它非常嘈杂，并且经常做错事情，但从平均意义上来说，它遵循对数似然梯度的方向。
212 00:18:51,236 --> 00:19:00,835 即，在期望上，它所做的是使网络在“做梦”时生成图像的可能性更大，这些图像与它在清醒时看到的图像相似。
213 00:19:00,815 --> 00:19:10,874 或者换句话说，权重的变化使得网络认为合理的、低能量的图像与它在清醒时看到的图像相似。
214 00:19:10,894 --> 00:19:18,367 说话人 SPEAKER_01：当然，学习所做的是，在学习算法中发生的事情是在后面，你在降低能量
215 00:19:18,347 --> 00:19:23,242 说话人 SPEAKER_01：整个网络配置的能量，当它看到真实数据时，它会得出这样的结论。
216 00:19:23,604 --> 00:19:26,813 说话人 SPEAKER_01：而当它处于睡眠状态时，你会提高这些配置的能量。
217 00:19:27,375 --> 00:19:33,031 说话人 SPEAKER_01：所以你试图让它相信你在清醒时看到的东西，不相信你在睡眠时梦到的东西。
218 00:19:36,251 --> 00:19:48,063 说话人 SPEAKER_01: 好的，那么如果你问达到热平衡的过程实现了什么，它实现了令人惊叹的事情，那就是网络中每个权重需要知道所有其他权重的一切。
219 00:19:48,423 --> 00:19:51,712 说话人 SPEAKER_01: 而要知道如何改变一种方式，你需要了解所有其他权重的一些信息。
220 00:19:51,692 --> 00:19:52,535 说话人 SPEAKER_01: 它们都是相互作用的。
221 00:19:53,076 --> 00:19:57,564 说话人 SPEAKER_01: 但你需要知道的一切都体现在两个相关性的差异中。
222 00:19:58,244 --> 00:20:09,246 说话者 SPEAKER_01：当网络观察数据时，两个神经元同时激活的频率与网络未观察数据时它们同时激活的频率之间的差异显示出来，当它处于流式传输状态时。
223 00:20:09,226 --> 00:20:16,596 说话者 SPEAKER_01：在这两种情况下测量的相关性，以某种方式告诉所有权重它们需要知道的所有其他权重的信息。
224 00:20:17,277 --> 00:20:27,891 说话者 SPEAKER_01：这之所以令人惊讶，是因为在像反向传播这样的算法中，所有神经网络现在实际上都使用这种算法，你需要进行反向传递来传递关于其他权重的信息。
225 00:20:28,451 --> 00:20:32,836 说话者 SPEAKER_01：而反向传递的行为与正向传递非常不同。
226 00:20:32,817 --> 00:20:37,626 说话人 SPEAKER_01：在前向传播中，你正在将神经元的活动传递给后续层的神经元。
227 00:20:38,208 --> 00:20:41,114 说话人 SPEAKER_01：在后向传播中，你正在传递敏感性。
228 00:20:41,193 --> 00:20:49,711 说话人 SPEAKER_01：你正在传递一种完全不同的数量，这使得反向传播作为大脑工作原理的理论变得相当不可能。
229 00:20:49,692 --> 00:21:03,798 说话人 SPEAKER_01：因此，当 Terry 提出了这个理论，Boltzmann 机的学习过程，我们完全相信这一定是大脑工作的方式，我们决定我们要去获得诺贝尔生理学或医学奖。
230 00:21:04,661 --> 00:21:12,695 说话人 SPEAKER_01：我们从未想过，如果大脑不是这样工作，我们也能获得诺贝尔物理学奖。
231 00:21:14,650 --> 00:21:16,673 说话人 SPEAKER_01：好的，只有一个问题。
232 00:21:17,453 --> 00:21:24,045 说话人 SPEAKER_01：问题是，对于非常大的网络和大的权重，达到热平衡是一个非常缓慢的过程。
233 00:21:24,464 --> 00:21:25,948 说话人 SPEAKER_01：如果权重非常小，你可以快速完成。
234 00:21:25,968 --> 00:21:29,051 说话人 SPEAKER_01：但是当权重很大时，学习了一些东西之后，它变得非常慢。
235 00:21:29,794 --> 00:21:32,698 说话人 SPEAKER_01：所以实际上，玻尔兹曼机是一个美好的浪漫想法。
236 00:21:32,738 --> 00:21:37,164 说话人 SPEAKER_01：这是一个美丽简单的学习算法。
237 00:21:37,144 --> 00:21:38,730 说话人 SPEAKER_01：它正在做一件非常复杂的事情。
它正在构建由隐藏单元组成的整个网络，这些单元通过一个非常简单的算法来解释数据。
239 00：21：45,089 --> 00：21：47,297 议长 SPEAKER_01：唯一的问题是他们太慢了。
240 00：21：48,079 --> 00：21：50,647 演讲者 SPEAKER_01：玻尔兹曼机器就是这样。
241 00：21：51,859 --> 00：21：53,722 演讲者 SPEAKER_01：讲座真的应该到此结束。
242 00:21:53,942 --> 00:22:05,882 说话人 SPEAKER_01：但是 17 年后，我意识到如果你对玻尔兹曼机限制很多，只有不相互连接的隐藏单元，那么你可以得到一个学习算法更快。
243 00:22:06,963 --> 00:22:11,691 说话人 SPEAKER_01：所以如果隐藏神经元之间没有连接，那么唤醒阶段就变得非常简单。
244 00:22:12,565 --> 00:22:16,030 说话人 SPEAKER_01：你所做的是将一个输入夹在可见单元上，以表示一个图像。
245 00:22:16,833 --> 00:22:20,459 说话人 SPEAKER_01：然后现在可以并行更新所有隐藏神经元。
246 00:22:21,842 --> 00:22:23,644 说话人 SPEAKER_01：现在你们已经达到了热平衡。
247 00:22:23,664 --> 00:22:24,846 说话人 SPEAKER_01：你们只需更新一次。
248 00:22:25,288 --> 00:22:30,676 说话人 SPEAKER_01：它们只观察可见输入，并根据接收到的输入随机选择它们两个状态中的一个。
249 00:22:30,696 --> 00:22:33,021 说话人 SPEAKER_01：现在你们已经一步达到热平衡。
250 00:22:33,663 --> 00:22:34,944 说话人 SPEAKER_01：太好了。
251 00:22:34,924 --> 00:22:38,829 说话人 SPEAKER_01：对于隐藏神经元，你仍然存在问题。
252 00:22:38,910 --> 00:22:51,484 说话人 SPEAKER_01：在睡眠阶段，你必须将网络置于某种随机状态，更新隐藏神经元，更新可见神经元，更新隐藏神经元，更新可见神经元，你需要持续很长时间才能达到热平衡。
253 00:22:51,505 --> 00:22:53,027 说话人 SPEAKER_01：因此算法仍然无望。
254 00:22:53,647 --> 00:22:55,069 说话人 SPEAKER_01：但结果发现有一个捷径。
255 00:22:55,730 --> 00:23:02,838 说话人 SPEAKER_01：这个捷径并不完全正确，有点尴尬，但在实践中效果还不错。
256 00:23:02,818 --> 00:23:04,321 说话人 SPEAKER_01：所以这个捷径是这样的。
257 00:23:05,083 --> 00:23:06,946 说话人 SPEAKER_01：你把数据放在可见单元上。
258 00:23:07,146 --> 00:23:07,807 说话人 SPEAKER_01：这是一张图片。
259 00:23:08,829 --> 00:23:11,214 说话人 SPEAKER_01：然后你并行更新所有隐藏神经元。
260 00:23:12,096 --> 00:23:14,560 说话人 SPEAKER_01：现在它们已经与数据达到热平衡。
261 00:23:15,481 --> 00:23:20,451 说话人 SPEAKER_01：你现在更新所有可见单元，这就是我们所说的重建。
262 00:23:21,133 --> 00:23:23,096 说话人 SPEAKER_01：它将像数据一样，但又不完全相同。
263 00:23:23,958 --> 00:23:26,041 说话人 SPEAKER_01：现在你再次更新所有隐藏单元。
264 00:23:26,815 --> 00:23:27,556 说话人 SPEAKER_01：然后你停止。
265 00:23:27,596 --> 00:23:27,996 说话人 SPEAKER_01：就这样。
266 00:23:28,036 --> 00:23:28,476 说话人 SPEAKER_01: 你做完了。
267 00:23:28,516 --> 00:23:43,169 说话人 SPEAKER_01: 你学习的方式是测量当展示数据时，神经元 i 和 j（可见神经元 i 和隐藏神经元 j）同时激活的频率，并且它们与数据达到平衡。
268 00:23:43,769 --> 00:23:49,954 说话人 SPEAKER_01: 你还测量当展示重建数据时，它们同时激活的频率，并且它们与重建数据达到平衡。
269 00:23:50,535 --> 00:23:53,136 说话人 SPEAKER_01: 这种差异就是你的学习算法。
270 00:23:53,478 --> 00:23:56,400 说话人 SPEAKER_01：您只需按比例调整那个差异的权重。
271 00:23:56,836 --> 00:23:58,901 说话人 SPEAKER_01：实际上效果相当不错。
272 00:23:59,281 --> 00:24:00,705 说话人 SPEAKER_01：而且它要快得多。
273 00:24:00,885 --> 00:24:03,292 说话人 SPEAKER_01：足够快，使得玻尔兹曼机最终变得实用。
274 00:24:04,154 --> 00:24:08,465 说话人 SPEAKER_01: 好吧。
275 00:24:09,172 --> 00:24:23,654 说话人 SPEAKER_01: 所以 Netflix 实际上使用了受限玻尔兹曼机结合其他方法来决定为你推荐哪些新电影，基于所有类似你的用户的偏好。
276 00:24:24,496 --> 00:24:25,277 说话人 SPEAKER_01: 而且它们确实有效。
277 00:24:25,317 --> 00:24:26,278 说话人 SPEAKER_01: 他们赢得了比赛。
278 00:24:26,499 --> 00:24:33,390 说话人 SPEAKER_01：这种结合了玻尔兹曼机和这些其他方法，赢得了 Netflix 关于如何预测用户喜好的竞赛。
279 00:24:35,310 --> 00:24:48,588 说话人 SPEAKER_01：但是当然，仅仅有未相互连接的隐藏神经元，是无法构建特征检测层的，而这些层是识别图像中的物体或识别语音中的单词所必需的。
280 00:24:48,990 --> 00:24:55,218 说话人 SPEAKER_01：这似乎是对只有一层隐藏单元且它们之间没有连接的严格限制。
281 00:24:55,239 --> 00:24:56,539 说话人 SPEAKER_01：但实际上，你可以绕过这个限制。
282 00:24:57,981 --> 00:25:02,127 说话人 SPEAKER_01：所以你可以堆叠这些受限的机器和设备。
283 00:25:02,597 --> 00:25:08,267 说话人 SPEAKER_01：你所做的是，你将你的数据展示给受限玻尔兹曼机（RBM）。
284 00:25:08,989 --> 00:25:10,270 说话人 SPEAKER_01：它只有一个隐藏层。
285 00:25:10,651 --> 00:25:19,586 说话人 SPEAKER_01：使用这种对比发散算法，它上下波动，你可以学习一些权重，以便隐藏单元能够捕捉数据中的结构。
286 00:25:20,468 --> 00:25:25,415 说话人 SPEAKER_01：隐藏单元变成了特征检测器，能够捕捉数据中常见的相关事物。
287 00:25:26,492 --> 00:25:34,444 说话人 SPEAKER_01：然后你将那些隐藏活动模式，隐藏单元中的二进制活动模式，视为数据。
288 00:25:35,185 --> 00:25:39,853 说话人 SPEAKER_01：所以你只需将它们复制到另一个 RBM 中，它们就是另一个 RBM 的数据。
289 00:25:40,594 --> 00:25:48,585 说话人 SPEAKER_01：第二个 RBM 会查看这些已经捕捉到数据相关性的特征，并捕捉这些特征之间的相关性。
290 00:25:49,326 --> 00:25:53,192 说话人 SPEAKER_01：然后你继续这样做，这样你就能捕捉到越来越复杂的相关性。
291 00:25:53,694 --> 00:25:55,839 说话人 SPEAKER_01：因此你可以学习到第二组权重 W2。
292 00:25:56,481 --> 00:25:57,944 说话人 SPEAKER_01：你可以随心所欲地做很多次。
293 00:25:58,686 --> 00:25:59,829 说话人 SPEAKER_01：让我们学习第三组权重。
294 00:26:01,192 --> 00:26:10,134 说话人 SPEAKER_01：所以现在我们有一系列独立的玻尔兹曼机，每个都在寻找前一个玻尔兹曼机隐藏单元中的结构。
295 00:26:10,115 --> 00:26:17,968 说话人 SPEAKER_01：然后你可以将这些玻尔兹曼机堆叠起来，把它们当作前馈网络来处理。
296 00:26:18,048 --> 00:26:19,911 说话人 SPEAKER_01：所以忽略连接是对称的这个事实。
297 00:26:20,451 --> 00:26:29,165 说话人 SPEAKER_01：现在就使用单向连接，因为你在第一隐藏层中已经提取出了能够捕捉原始数据相关性的特征。
298 00:26:29,666 --> 00:26:37,219 说话人 SPEAKER_01：然后在第二隐藏层中，你提取出了能够捕捉第一隐藏层中提取的特征的相关性的特征，依此类推。
299 00:26:37,199 --> 00:26:41,065 说话人 SPEAKER_01：所以你得到了越来越多的高级特征，这些特征是相关性之间的相关性。
300 00:26:42,468 --> 00:26:50,359 说话人 SPEAKER_01：这样堆叠好后，你就可以添加一个最终的隐藏层，就像这样，然后你可以进行监督学习。
301 00:26:50,420 --> 00:26:55,228 说话人 SPEAKER_01：也就是说，现在你可以开始教它关于事物的名称，比如猫和狗。
302 00:26:55,648 --> 00:26:57,672 说话人 SPEAKER_01：这些都是类别标签。
303 00:26:57,652 --> 00:27:00,134 说话人 SPEAKER_01：你需要学习这些类别标签的权重。
304 00:27:00,755 --> 00:27:05,901 说话人 SPEAKER_01：但是你从初始化这个网络开始，这个网络是通过学习堆叠的玻尔兹曼机初始化的。
305 00:27:06,520 --> 00:27:07,843 说话人 SPEAKER_01：然后发生两件美妙的事情。
306 00:27:08,242 --> 00:27:14,950 说话人 SPEAKER_01：第一件美妙的事情是，如果你这样初始化，网络的学习速度会比用随机权重初始化快得多。
307 00:27:15,391 --> 00:27:21,297 说话人 SPEAKER_01：因为网络已经学习到了很多用于建模数据结构的合理特征。
308 00:27:21,277 --> 00:27:25,743 说话人 SPEAKER_01：它还没有学会事物的名称，但它已经学会了数据中的结构。
309 00:27:26,005 --> 00:27:30,752 说话人 SPEAKER_01：然后学习事物的名称相对较快，就像小孩子们一样。
310 00:27:31,314 --> 00:27:36,602 说话人 SPEAKER_01：他们不需要被告诉那是牛，2000 次之前他们就知道了那是牛。
311 00:27:37,363 --> 00:27:42,412 说话人 SPEAKER_01：他们自己理解了牛的概念，然后他们的妈妈说那是牛，他们就明白了。
312 00:27:43,673 --> 00:27:45,596 说话人 SPEAKER_01：嗯，可能有两倍。
313 00:27:48,209 --> 00:27:53,714 说话人 SPEAKER_01：这使得学习识别物体和图像等技能变得更快。
314 00:27:55,297 --> 00:27:57,519 说话人 SPEAKER_01：这也使得网络具有更好的泛化能力。
315 00:27:57,859 --> 00:28:02,384 说话人 SPEAKER_01：因为它们在大多数学习过程中没有使用标签，现在不需要很多标签了。
316 00:28:02,964 --> 00:28:06,249 说话人 SPEAKER_01：他们没有从标签中提取所有信息。
317 00:28:06,608 --> 00:28:09,231 说话人 SPEAKER_01：他们从数据的相关性中提取信息。
318 00:28:10,272 --> 00:28:14,857 说话人 SPEAKER_01：这使得它们在需要较少标签的情况下具有更好的泛化能力。
319 00:28:16,188 --> 00:28:17,349 说话人 SPEAKER_01：所以这一切都很棒。
320 00:28:18,372 --> 00:28:37,571 说话人 SPEAKER_01：大约在 2006 年至 2011 年之间，人们在使用，尤其是在我的实验室和 Yoshua Bengio 的实验室以及 Jan 的实验室，人们使用堆叠的 RBMs 来预训练前馈神经网络，然后应用反向传播。
321 00:28:37,551 --> 00:28:50,634 说话人 SPEAKER_01：2009 年，我的实验室里的两位学生 George Dahl 和 Abdulrahman Mohamed 展示了这种技术比现有技术中识别语音音素片段的最佳技术略好。
322 00:28:51,978 --> 00:28:55,964 说话人 SPEAKER_01：这之后改变了语音识别领域。
323 00:28:55,944 --> 00:29:09,904 说话人 SPEAKER_01：我的研究生们加入了各个领先的语音团队，2012 年，基于这一点的技术，堆叠的机器，在谷歌投入生产，并提高了语音识别能力。
324 00:29:09,964 --> 00:29:14,510 说话人 SPEAKER_01：突然，Android 上的语音识别变得好多了。
325 00:29:15,992 --> 00:29:29,522 说话人 SPEAKER_01：不幸的是，对于玻尔兹曼机来说，一旦我们证明了这些深度神经网络如果用受限玻尔兹曼机进行预训练的话确实效果很好，人们就找到了其他初始化权重的方法，他们不再使用玻尔兹曼机的堆叠。
326 00:29:31,446 --> 00:29:34,153 说话人 SPEAKER_01：但如果你是化学家，你就会知道酶是非常有用的东西。
327 00:29:34,133 --> 00:29:47,454 说话人 SPEAKER_01：尽管 RBM 不再被使用，但它们使我们从认为深度神经网络永远不会工作转变为看到如果以这种方式初始化，深度神经网络实际上可以很容易地被制作出来工作。
328 00:29:48,557 --> 00:29:50,921 说话人 SPEAKER_01：一旦完成转换，你就不需要这种酶了。
329 00:29:51,321 --> 00:29:54,386 说话人 SPEAKER_01：所以把它们看作是历史上的酶。
330 00:29:55,665 --> 00:30:08,339 说话人 SPEAKER_01：然而，使用睡眠进行“遗忘”的想法，以获得更符合生物学的算法并避免反向传播，我认为这个想法还有很多潜力。
331 00:30:08,881 --> 00:30:19,292 说话人 SPEAKER_01：我仍然乐观，当我们最终理解大脑是如何学习的时候，它将涉及到利用睡眠来进行“遗忘”。
332 00:30:20,753 --> 00:30:21,816 说话人 SPEAKER_01：我还是很乐观的。
333 00:30:22,896 --> 00:30:23,917 说话人 SPEAKER_01：我觉得我完成了。
334 00:30:55,116 --> 00:30:56,233 说话人 SPEAKER_00：非常好。
335 00:30:56,253 --> 00:30:57,432 说话人 SPEAKER_00：非常感谢您。
请现在与我一起欢迎两位获奖者上台，共同接受我们最热烈的掌声。
