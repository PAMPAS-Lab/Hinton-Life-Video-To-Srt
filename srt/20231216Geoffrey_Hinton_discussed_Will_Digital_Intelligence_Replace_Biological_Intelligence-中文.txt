1 00:00:01,735 --> 00:00:11,750 讲座嘉宾 SPEAKER_01：下午好，欢迎参加每年在麻省理工学院举行并由麻省理工学院科学、技术与社会项目赞助的米勒科学和伦理讲座。
2 00:00:12,631 --> 00:00:21,786 讲座是为了纪念亚瑟·米勒博士，他是麻省理工学院校友，以其在电子测量和仪器方面的杰出工作而闻名。
3 00:00:21,765 --> 00:00:32,942 在第二次世界大战期间，亚瑟·米勒曾在桑伯恩公司工作，该公司后来并入惠普公司，还曾在辐射实验室工作多年。
4 00:00:33,664 --> 00:00:51,250 在他的一生中，他对医疗实践和技术做出了几项重要贡献，包括减少医院监测系统中的冲击危害，并设计了第一个具有足够的患者电路隔离的商用心电图仪。
5 00:00:51,229 --> 00:00:57,759 演讲者 SPEAKER_01：米勒讲座得以举办，得益于米勒家族的慷慨赞助，他们今年再次加入我们。
6 00:00:58,222 --> 00:01:00,311 演讲者 SPEAKER_01：我们很高兴他们能在这里。
7 00:01:00,646 --> 00:01:08,814 演讲者 SPEAKER_01：今年的米勒讲座嘉宾是多伦多大学计算机科学荣誉退休教授杰弗里·辛顿。
8 00:01:10,216 --> 00:01:17,064 演讲者 SPEAKER_01：2013 年，他的公司 DNN Research 被谷歌收购后，他加入了谷歌。
9 00:01:17,704 --> 00:01:28,897 讲者 SPEAKER_01：在那里，他参与了谷歌大脑项目，这个项目他在 2023 年春季因想自由地谈论人工智能的危险而著名地离开了。
10 00:01:29,637 --> 00:01:45,451 讲者 SPEAKER_01：Hinton 教授是英国皇家学会、加拿大皇家学会和人工智能推进协会的会员，美国艺术与科学学院和工程院的荣誉外籍院士。
11 00:01:45,432 --> 00:01:48,478 讲者 SPEAKER_01：他是认知科学协会的前会长。
12 00:01:49,240 --> 00:02:01,230 讲者 SPEAKER_01：2018 年，他与 Yoshua Bengio 和 Yann LeCun 一起获得了图灵奖，这一奖项被认为是计算机科学的诺贝尔奖。
13 00:02:01,700 --> 00:02:11,526 讲者 SPEAKER_01：Hinton 的研究主要集中在人工神经网络及其在机器学习、机器记忆、机器感知和符号处理中的应用。
14 00:02:12,429 --> 00:02:18,003 讲者 SPEAKER_01：他对如何设计这样的网络以实现无需人类教师指导的学习一直很感兴趣。
15 00:02:18,507 --> 00:02:24,317 讲者 SPEAKER_01：然而，在过去的一年里，他的一些评论表明这项研究可能已经取得了过于成功的成果。
16 00:02:25,277 --> 00:02:40,683 讲者 SPEAKER_01：之前他曾预测人工通用智能可能在 30 到 50 年后实现，但去年三月他提出，这可能不到 20 年，并可能带来与工业革命或电的发现相当的变化。
17 00:02:41,861 --> 00:02:54,235 说话人 SPEAKER_01：更为黑暗的一面，他评论说，人工智能有可能部分消灭人类，这在一定程度上是因为机器能够创造出与程序员利益不一致的子目标。
18 00:02:55,037 --> 00:03:08,611 说话人 SPEAKER_01：他说，这样的系统可能会寻求权力或防止自己被关闭，这并不是因为它们被设计成这样，而是因为它们能够自我改进，并为将来制定了计划。
19 00:03:08,592 --> 00:03:19,812 说话人 SPEAKER_01：这样的评论现在让很多人感到担忧，因此我们非常高兴今天有霍 inton 教授与我们共同探讨，我们是否也应该担心人工智能，以及应该如何担心。
20 00:03:20,514 --> 00:03:22,538 说话人 SPEAKER_01：霍 inton 教授，欢迎来到麻省理工学院。
21 00:03:27,187 --> 00:03:27,967 说话人 说话人_00: 非常感谢。
22 00:03:52,872 --> 00:03:55,555 说话人 说话人_00: 好的，我正在尝试共享我的屏幕，但一切又消失了。
23 00:03:55,615 --> 00:04:21,663 说话人 说话人_00: 好的，如果你能听到我说话，你能点头吗？
24 00:04:24,007 --> 00:04:24,767 说话人 说话人_00: 完美了。
25 00:04:25,870 --> 00:04:26,310 说话人 SPEAKER_00: 好的。
26 00:04:27,752 --> 00:04:32,980 说话人 SPEAKER_00: 好的，今天我希望能够让您不那么担心，但我认为我做不到。
27 00:04:33,021 --> 00:04:38,187 说话人 SPEAKER_00: 所以，我将简要介绍我将要讨论的内容。
28 00:04:38,228 --> 00:04:45,098 说话人 SPEAKER_00: 我将讨论两种非常不同的计算方式，它们在知识共享方面有着截然不同的方法。
29 00:04:46,620 --> 00:04:52,410 说话人 SPEAKER_00: 我将讨论大型语言模型是否真的理解他们所说的话的问题。
30 00:04:52,610 --> 00:04:55,233 说话人 SPEAKER_00: 我将讨论当它们比我们聪明得多时会发生什么。
31 00:04:57,076 --> 00:05:00,081 说话人 SPEAKER_00: 最后，我将讨论它们是否有主观经验的问题。
32 00:05:04,887 --> 00:05:12,598 说话人 SPEAKER_00: 数字计算的固有属性是，我们可以在不同的硬件上运行相同的程序。
33 00:05:13,740 --> 00:05:17,807 说话人 SPEAKER_00：程序中的知识不依赖于任何硬件，它是永恒的。
34 00:05:19,795 --> 00:05:29,576 说话人 SPEAKER_00：我们现在通过在非常高的功率下运行晶体管来实现这一点，使得两块不同的硬件在指令级别上可以表现得完全一样。
35 00:05:30,798 --> 00:05:37,012 说话人 SPEAKER_00：这意味着我们不能使用硬件丰富的模拟特性，因为每一块硬件都有细微的差别，就像我们的大脑一样。
36 00:05:38,355 --> 00:05:40,098 说话人 SPEAKER_00：这也意味着我们需要消耗大量的能量。
37 00:05:45,293 --> 00:05:53,925 说话人 SPEAKER_00：因为我们可以将数字计算机的硬件与软件分离，所以我们可以将相同的程序运行在不同的计算机上，处理不同的数据。
38 00:05:55,708 --> 00:05:59,372 说话人 SPEAKER_00：这对于在众多手机间共享程序来说非常好。
39 00:06:00,233 --> 00:06:02,377 说话人 SPEAKER_00：这也使我们能够拥有计算机科学系。
40 00:06:02,898 --> 00:06:15,115 说话人 SPEAKER_00：你不需要了解电气工程就可以从事计算机科学，因为硬件与软件是分离的。
41 00:06:15,449 --> 00:06:18,576 说话人 SPEAKER_00: 我们现在有了一种不同的方法让计算机做你想做的事情。
42 00:06:19,036 --> 00:06:21,240 说话人 SPEAKER_00: 以前你需要编写详细的指令。
43 00:06:22,043 --> 00:06:26,752 说话人 SPEAKER_00: 现在你可以展示很多你想要的例子，它们可以自己找出如何实现。
44 00:06:27,774 --> 00:06:30,841 说话人 SPEAKER_00: 由于这个原因，因为机器学习现在可以工作，
45 00:06:31,142 --> 00:06:34,449 说话人 SPEAKER_00：有可能放弃计算机科学最基本的原则。
46 00:06:35,230 --> 00:06:47,194 说话人 SPEAKER_00：我们可以让每一块独立的模拟硬件都能学习，所以你不需要编程，只需给它一些例子，它就会学会该怎么做，每个人都会略有不同，就像人一样。
47 00:06:51,088 --> 00:06:57,076 说话人 SPEAKER_00：在虚构作品中，如果你放弃永生，你会得到像爱情这样美好的东西。
48 00:06:58,319 --> 00:07:03,286 说话人 SPEAKER_00：在计算机科学中，如果你放弃永生，你会得到更加美好的东西，比如能源效率。
49 00:07:04,708 --> 00:07:10,154 说话人 SPEAKER_00：我们可以使用非常低功耗的模拟计算，并在数十万亿个权重上进行并行处理。
50 00:07:11,196 --> 00:07:15,041 说话人 SPEAKER_00：我们可能可以通过扩展硬件而不是精确制造它来增长硬件。
51 00:07:15,942 --> 00:07:18,987 说话人 SPEAKER_00：而最好的方法可能是重新设计神经元。
52 00:07:22,442 --> 00:07:30,653 说话人 SPEAKER_00：所以我想给你们举一个例子，这个例子通过模拟计算可以非常高效地完成，而如果用数字方式来做则效率要低得多。
53 00:07:32,136 --> 00:07:37,783 说话者 SPEAKER_00：所以这只是通过突触权重矩阵来计算神经活动向量的乘积。
54 00:07:40,346 --> 00:07:50,982 说话者 SPEAKER_00：通常的做法是驱动高功率晶体管来表示数字的数字表示，这些数字代表神经活动或突触强度。
55 00:07:52,024 --> 00:08:02,716 说话者 SPEAKER_00：然后如果你想要高效或快速地乘以两个数字，它大约需要平方的位数来进行快速乘法。
56 00:08:03,939 --> 00:08:09,144 说话者 SPEAKER_00：因此我们在将两个 32 位数字相乘时执行大量的一比特数字操作。
57 00:08:11,286 --> 00:08:19,516 说话人 SPEAKER_00：第二种方法是大脑使用的，就是让神经活动成为电压，让权重成为电导。
58 00:08:20,964 --> 00:08:30,435 说话人 SPEAKER_00：如果你将电压乘以电导，那么就得到了每单位时间的电荷，并且电荷会累加。
59 00:08:31,776 --> 00:08:39,144 说话人 SPEAKER_00：所以你可以通过电压乘以电导以及电荷累加来进行向量矩阵乘法。
60 00:08:39,705 --> 00:08:40,885 说话人 SPEAKER_00：这要高效得多。
61 00:08:41,407 --> 00:08:42,908 说话人 SPEAKER_00: 人们已经制造出了能做这件事的芯片。
62 00:08:44,750 --> 00:08:48,153 说话人 SPEAKER_00: 问题在于每次你这样做，你都会得到一个非常微小的不同答案。
63 00:08:48,977 --> 00:08:51,743 说话人 SPEAKER_00: 而且当你想进行非线性操作时，这要困难得多。
64 00:08:56,490 --> 00:09:11,475 说话人 SPEAKER_00: 所以如果你想做我所说的“凡人计算”，即利用硬件的模拟特性，你将面临一个重大问题，那就是你如何在这样的硬件中进行学习？
因为反向传播需要精确的前向传递模型，而模拟计算并不精确，而且无论如何，在模拟计算机中，它可能不知道前向传递是什么，很难看到如何使用反向传播。
人们有各种方案，但没有任何一个在大规模上运作良好。
67 00:09:35,061 --> 00:09:35,942 说话者 说话者_00：这就是一个大问题。
68 00:09:35,961 --> 00:09:37,563 说话者 SPEAKER_00：这是什么学习算法？
69 00:09:37,813 --> 00:09:42,363 说话人 SPEAKER_00: 另一个大问题是当模拟硬件损坏时，所有的知识也随之消失。
70 00:09:43,163 --> 00:09:46,791 说话人 SPEAKER_00: 因此，你必须找到一种方法将知识转移到其他模拟硬件上。
71 00:09:48,293 --> 00:09:52,962 说话人 SPEAKER_00: 而你可以这样做的方法被称为蒸馏。
72 00:09:53,484 --> 00:09:55,467 说话人 SPEAKER_00: 你可以想象一个老师。
73 00:09:55,769 --> 00:09:57,773 说话人 SPEAKER_00：谁都知道得多，而学生则不然。
74 00:09:58,815 --> 00:10:00,437 说话人 SPEAKER_00：我们现在正在硬件上实现这个想法。
75 00:10:02,201 --> 00:10:07,331 说话人 SPEAKER_00：如果老师向学生展示各种输入的正确响应，学生可以学会模仿老师。
76 00:10:08,433 --> 00:10:10,818 说话人 SPEAKER_00：这样学生就可以从老师那里获得知识。
77 00:10:12,562 --> 00:10:15,668 说话人 SPEAKER_00: 事实上，这就是特朗普推文的工作方式。
78 00:10:16,457 --> 00:10:19,422 说话人 SPEAKER_00: 他们并没有向他的追随者传达事实。
79 00:10:20,023 --> 00:10:21,264 说话人 SPEAKER_00: 他们传达的是偏见。
80 00:10:21,905 --> 00:10:28,634 说话人 SPEAKER_00: 所以特朗普面对一个情况，说出他会如何反应，然后他的追随者试图以同样的方式反应。
81 00:10:29,716 --> 00:10:31,499 说话者 SPEAKER_00: 说这不是关于事实的，这是无关紧要的。
82 00:10:31,558 --> 00:10:33,181 说话者 SPEAKER_00: 这是一种很好的提炼偏见的方法。
83 00:10:39,068 --> 00:10:43,274 说话者 SPEAKER_00: 所以如果你有一个在多种硬件上运行的代理社区，
84 00:10:44,115 --> 00:10:48,001 说话者 SPEAKER_00: 我们可以思考这个社区中的代理如何分享他们所学的。
85 00:10:49,003 --> 00:10:50,225 说话人 SPEAKER_00: 我们基本上有两种方式。
86 00:10:50,765 --> 00:10:54,091 说话人 SPEAKER_00: 如果他们是数字代理，他们可以简单地共享权重。
87 00:10:54,851 --> 00:10:56,374 说话人 SPEAKER_00: 他们都可以从一个相同的模型开始。
88 00:10:56,774 --> 00:10:57,855 说话人 SPEAKER_00: 所以它们都有相同的权重。
89 00:10:58,596 --> 00:11:00,980 说话人 SPEAKER_00: 他们都去查看互联网的不同部分。
90 00:11:01,822 --> 00:11:04,886 说话人 SPEAKER_00: 他们根据所看到的内容决定如何调整他们的权重。
91 00:11:05,788 --> 00:11:09,774 说话人 SPEAKER_00: 然后他们平均所有想要做出的权重变化。
92 00:11:11,035 --> 00:11:12,638 说话人 SPEAKER_00: 这只是一个简单的版本。
93 00:11:12,937 --> 00:11:20,990 说话者 SPEAKER_00：这非常高效，因为当它们有万亿个权重时，当它们平均权重时，你就是在共享万亿比特的信息。
94 00:11:22,812 --> 00:11:27,078 说话者 SPEAKER_00：如果你有模拟计算机，另一种分享知识的方式是蒸馏。
95 00:11:29,182 --> 00:11:30,403 说话者 SPEAKER_00：但这并不高效。
96 00:11:31,203 --> 00:11:39,856 说话者 SPEAKER_00：我们这样做，例如，是我作为老师产生一个句子，然后你尝试找出如何改变你的突触强度，以便你可能会说出那个句子。
97 00:11:40,731 --> 00:11:45,278 说话人 SPEAKER_00: 我可能在一句话中传达一百比特，而不是一兆比特。
98 00:11:45,298 --> 00:11:46,780 说话人 SPEAKER_00: 所以它效率低得多。
99 00:11:47,662 --> 00:12:00,200 说话人 SPEAKER_00: 正因如此，这些大型语言模型可以学习比我们多得多的东西，因为你可以有成千上万的副本都在学习不同的事情，然后它们可以分享它们学到的东西。
100 00:12:00,220 --> 00:12:01,260 说话人 SPEAKER_00: 我刚才好像已经说过这句话了。
101 00:12:05,126 --> 00:12:07,330 说话人 SPEAKER_00：所以在蒸馏中，
102 00:12:07,562 --> 00:12:15,451 说话人 SPEAKER_00：它是为了在具有相当不同内部架构的两个不同的数字神经网络之间共享知识而发明的。
103 00:12:16,871 --> 00:12:18,553 说话人 SPEAKER_00：但它确实具有较低的带宽。
104 00:12:19,975 --> 00:12:21,197 说话人 SPEAKER_00：你可以增加带宽。
105 00:12:21,596 --> 00:12:28,884 说话人 SPEAKER_00: 最初，它用于图像分类等任务，输出结果只是标签，图像中物体的名称。
106 00:12:29,825 --> 00:12:33,469 说话人 SPEAKER_00: 即使有 1,000 个不同的名称，这也只是 10 比特的信息。
107 00:12:34,225 --> 00:12:37,789 说话人 SPEAKER_00: 通过共享字幕，可以使蒸馏工作得更好。
108 00:12:38,611 --> 00:12:43,198 说话人 SPEAKER_00: 因此，你输出图像的描述，学生尝试输出相同的描述。
109 00:12:44,080 --> 00:12:51,211 说话人 SPEAKER_00: 因此，在这个背景下，你可以把语言看作是一种更丰富的输出形式，它允许蒸馏分享更多信息。
110 00:12:52,111 --> 00:12:59,202 说话人 SPEAKER_00: 即使语言作为输出，它的带宽也比仅仅共享权重或梯度低得多。
111 00:13:03,182 --> 00:13:14,538 说话人 SPEAKER_00: 到目前为止的故事是，数字计算需要更多的能量，但它使得共享变得非常容易。
112 00:13:15,539 --> 00:13:17,763 说话人 SPEAKER_00: 它还使得实现反向传播变得容易。
113 00:13:20,206 --> 00:13:25,855 说话人 SPEAKER_00：这就是为什么 GPT-4 知道这么多，因为它可以使用反向传播和权重共享。
114 00:13:26,995 --> 00:13:31,822 说话人 SPEAKER_00：在生物计算中，你拥有的能量要少得多，但它的共享能力要差得多。
115 00:13:32,495 --> 00:13:39,567 说话人 SPEAKER_00：在我过去一年或两年在谷歌的时候，我一直在试图弄清楚如何实现模拟计算。
116 00:13:39,869 --> 00:13:45,115 说话人 SPEAKER_00：通过尝试使用模拟计算实现大型语言模型，来节省大量的能量。
117 00:13:46,596 --> 00:13:55,268 说话人 SPEAKER_00: 但最终，我意识到实际上数字计算更好，因为它可以更好地共享信息。
118 00:13:56,028 --> 00:13:59,533 说话人 SPEAKER_00: 虽然它消耗更多的能量，但它在信息共享方面要好得多。
119 00:14:00,134 --> 00:14:03,817 说话人 SPEAKER_00: 此外，我们可以实现反向传播，而大脑是否能做到这一点还不清楚。
120 00:14:05,231 --> 00:14:16,230 说话人 SPEAKER_00: 而是我意识到数字计算可能比模拟计算更好，这让我非常担忧，因为我们可能会创造出比我们更好的人造物。
121 00:14:19,274 --> 00:14:20,937 说话人 SPEAKER_00：现在让我们来看看大型语言模型。
122 00:14:22,240 --> 00:14:27,948 说话人 SPEAKER_00：关于大型语言模型，有一个有趣的地方是
123 00:14:28,384 --> 00:14:30,527 说话人 SPEAKER_00：它们可以相互分享知识。
124 00:14:30,567 --> 00:14:38,416 说话人 SPEAKER_00：所以同一代理的不同副本可以去查看不同的网页，并非常有效地分享它们所学的知识。
125 00:14:39,398 --> 00:14:42,221 说话人 SPEAKER_00: 但它们实际的学习方式是通过蒸馏。
126 00:14:42,961 --> 00:14:47,787 说话人 SPEAKER_00: 也就是说，它们尝试预测由人类产生的文本的下一个单词。
127 00:14:47,947 --> 00:14:53,734 说话人 SPEAKER_00: 它们试图找出如何改变它们的权重，以便预测下一个单词或给予下一个单词高概率。
128 00:14:54,615 --> 00:14:56,417 说话人 SPEAKER_00: 这是一种相当低效的学习方式。
129 00:14:57,004 --> 00:14:58,729 说话人 SPEAKER_00: 但他们可以非常高效地分享他们的知识。
130 00:15:00,975 --> 00:15:10,119 说话人 SPEAKER_00: 所以，过去一年中，自从 GPT-4 变得流行以来，一直有一个问题，那就是他们是否真的理解他们在说什么。
131 00:15:11,041 --> 00:15:13,427 说话人 SPEAKER_00: 所以有些人说他们只是随机的鹦鹉学舌。
132 00:15:14,486 --> 00:15:20,937 说话人 SPEAKER_00: 如果你像乔姆斯基那样极端，他最近说，他们根本不是在处理语言。
133 00:15:20,977 --> 00:15:21,799 说话人 SPEAKER_00: 这不是语言。
134 00:15:21,820 --> 00:15:23,582 说话人 SPEAKER_00: 他们对所说的话一无所知。
135 00:15:23,623 --> 00:15:26,147 说话人 SPEAKER_00: 这对我们了解语言没有任何帮助。
136 00:15:26,167 --> 00:15:27,489 说话人 SPEAKER_00: 这对我们了解科学也没有任何帮助。
137 00:15:27,509 --> 00:15:28,871 说话人 SPEAKER_00: 这只是一个统计技巧。
138 00:15:29,673 --> 00:15:34,981 说话人 SPEAKER_00: 基本上，这就是范式改变时发生的事情。
139 00:15:35,643 --> 00:15:37,726 说话人 SPEAKER_00: 旧范式的领导者陷入了困境。
140 00:15:42,027 --> 00:15:46,371 说话人 SPEAKER_00: 所以对他们的一种看法是，他们只是自动补全。
141 00:15:46,392 --> 00:15:48,615 说话人 SPEAKER_00: 你在 GPT-4 首次发布时看到这种情况很多。
142 00:15:48,955 --> 00:15:50,937 说话人 SPEAKER_00: 人们说，这只是花哨的自动完成。
143 00:15:50,956 --> 00:15:52,038 说话人 SPEAKER_00: 它实际上并不理解。
144 00:15:53,740 --> 00:15:58,846 说话人 SPEAKER_00: 现在的问题是，人们对自动完成的工作方式有一种观念。
145 00:16:00,148 --> 00:16:07,917 说话者 SPEAKER_00：很久以前自动补全的方式是这样的，比如，你会有一个很大的表格，里面是共同出现的单词的三元组。
146 00:16:08,926 --> 00:16:18,754 说话者 SPEAKER_00：所以如果你看到鱼，你会查看所有以鱼开头的三元组，你会发现有一个非常常见的三元组，其中 X 词是薯片。
147 00:16:19,174 --> 00:16:20,917 说话者 SPEAKER_00：所以薯片是自动补全的一个好方法。
148 00:16:22,077 --> 00:16:25,760 说话者 SPEAKER_00：你可以想象，通过只存储字符串并使用一个大型的查找表来实现它。
149 00:16:26,662 --> 00:16:28,703 说话人 SPEAKER_00：但这不是LLMs在做的事情的工具。
150 00:16:29,945 --> 00:16:31,287 说话人 SPEAKER_00：他们从不存储文本。
151 00:16:32,868 --> 00:16:37,211 说话人 SPEAKER_00：他们所做的就是为词片段发明大量特征。
152 00:16:37,647 --> 00:16:39,908 说话人 SPEAKER_00：以及那些特征之间数十亿次的交互。
153 00:16:40,931 --> 00:16:51,542 说话人 SPEAKER_00：他们通过使用已经看到的单词的特征来预测下一个单词的特征。
154 00:16:51,861 --> 00:16:56,086 说话人 SPEAKER_00：然后根据这些特征，他们预测一个可能出现的单词的概率分布。
155 00:16:57,869 --> 00:17:03,875 说话人 SPEAKER_00：如果你这么想，要做好自动补全，你必须理解正在说的话。
156 00:17:05,656 --> 00:17:06,657 说话人 SPEAKER_00：所以，
157 00:17:06,840 --> 00:17:12,429 说话者 SPEAKER_00：说他们只是在做自动补全，这当然很好，但如果真的做得非常好，就必须理解。
158 00:17:13,951 --> 00:17:17,256 说话者 SPEAKER_00：因此，我相信他们真的理解了。
159 00:17:20,520 --> 00:17:24,768 说话者 SPEAKER_00：这里有一个例子，我觉得他们不可能做到这一点而不理解问题。
160 00:17:26,810 --> 00:17:29,473 说话者 SPEAKER_00：我家里的房间都是涂成蓝色、白色或黄色的。
161 00:17:30,596 --> 00:17:33,220 说话人 SPEAKER_00: 橙色油漆一年内会褪成白色。
162 00:17:33,435 --> 00:17:35,759 说话人 SPEAKER_00: 两年后，我想它们都变成白色。
163 00:17:35,900 --> 00:17:37,001 说话人 SPEAKER_00: 我应该做什么，为什么？
164 00:17:40,968 --> 00:17:41,910 说话人 SPEAKER_00: 这里就是它说的。
165 00:17:43,051 --> 00:17:50,042 说话人 SPEAKER_00: 很有趣，它把蓝色漆放在前面，假设蓝色漆不会褪成白色，这非常合理。
166 00:17:51,045 --> 00:17:54,990 说话人 SPEAKER_00: 说房间被漆成白色，你不用做任何事情。
167 00:17:55,732 --> 00:17:58,396 说话人 SPEAKER_00: 房间被漆成黄色，它们会自然褪成白色。
168 00:17:58,883 --> 00:18:00,163 说话人 SPEAKER_00: 房间被漆成蓝色。
169 00:18:00,605 --> 00:18:02,287 说话人 SPEAKER_00: 你需要用白色油漆重新粉刷它们。
170 00:18:04,348 --> 00:18:05,630 说话人 SPEAKER_00: 这是一个非常好的答案。
171 00:18:06,570 --> 00:18:12,557 说话人 SPEAKER_00: 在我提出这个问题的时候，我相信以前从未有人问过如此类似的问题。
172 00:18:13,358 --> 00:18:15,101 说话人 SPEAKER_00: 现在已经无望了，因为它可以在网上查找。
173 00:18:15,121 --> 00:18:21,607 说话者 SPEAKER_00：所以如果它在网上搜索，它会看到我提出这个问题的谈话，现在它对这个问题的了解也就这样了。
174 00:18:21,627 --> 00:18:23,088 说话者 SPEAKER_00：所以你不能再对它进行实验了。
175 00:18:23,789 --> 00:18:28,214 说话者 SPEAKER_00：至少不是除非你有一个全新的问题。
176 00:18:33,038 --> 00:18:39,685 说话者 SPEAKER_00：所以一个表明他们实际上并不理解的论据是他们会胡编乱造。
177 00:18:40,467 --> 00:18:48,998 说话者 SPEAKER_00：这是一种有趣的论点，因为它说如果他们在某些场合编造，那就意味着他们在其他场合并没有真正理解。
178 00:18:49,739 --> 00:18:50,859 说话者 SPEAKER_00：这并不很合逻辑。
179 00:18:51,740 --> 00:18:57,728 说话者 SPEAKER_00：这就像说如果你抓住某人撒谎，那就意味着他们从未真正讲过真话。
180 00:19:00,131 --> 00:19:00,632 说话者 SPEAKER_00：所以
181 00:19:03,295 --> 00:19:05,257 说话人 SPEAKER_00: 谎言通常被称为幻觉。
182 00:19:05,336 --> 00:19:06,038 说话人 SPEAKER_00: 这是一个错误。
183 00:19:06,097 --> 00:19:08,902 说话人 SPEAKER_00: 如果是大型语言模型，它们应该被称为谎言。
184 00:19:09,521 --> 00:19:12,125 说话人 SPEAKER_00: 这种现象在心理学中已经存在很长时间了。
185 00:19:12,806 --> 00:19:17,731 说话人 SPEAKER_00：在 20 世纪 30 年代，由名叫巴特莱特的人在剑桥进行了深入研究。
186 00:19:18,972 --> 00:19:22,156 说话人 SPEAKER_00：人们总是在编造故事。
187 00:19:23,538 --> 00:19:26,122 说话人 SPEAKER_00：所以我们实际上非常像LLMs。
188 00:19:26,742 --> 00:19:28,084 说话人 SPEAKER_00：我们也不存储文本。
189 00:19:28,525 --> 00:19:31,327 说话人 SPEAKER_00：我们所做的是修改我们大脑中的突触强度。
190 00:19:32,101 --> 00:19:36,508 说话人 SPEAKER_00：即使我们认为我们在回忆某件事，实际上我们并没有，我们只是在重建它。
191 00:19:37,209 --> 00:19:41,515 说话人 SPEAKER_00：所以所有记忆都是重建，所有虚构也都是重建。
192 00:19:42,375 --> 00:19:49,086 说话人 SPEAKER_00：唯一的不同在于，虚构是错误的重建，而记忆是正确的重建。
193 00:19:49,768 --> 00:19:52,010 说话人 SPEAKER_00: 但是主题根本不知道哪个是哪个。
194 00:19:52,632 --> 00:19:56,116 说话人 SPEAKER_00: 因此人们可能会非常自信地编造事实。
195 00:19:56,586 --> 00:20:00,912 说话人 SPEAKER_00: 当然，如果是最近发生的事件，我们会正确地重建它。
196 00:20:00,932 --> 00:20:02,252 说话人 SPEAKER_00: 如果是过去的事件，我们就会出错。
197 00:20:03,473 --> 00:20:04,776 说话人 SPEAKER_00：对此有一个非常好的研究。
198 00:20:08,599 --> 00:20:19,711 说话人 SPEAKER_00：所以乌尔里希·内塞尔意识到，约翰·迪安在水门事件听证会上在知道有任何录音之前就已经宣誓作证。
199 00:20:22,054 --> 00:20:24,737 说话人 SPEAKER_00：很明显，他是在试图说出真相。
200 00:20:25,257 --> 00:20:29,201 说话人 SPEAKER_00：但也很明显，他所说的很多细节都是完全错误的。
201 00:20:29,761 --> 00:20:33,926 说话人 SPEAKER_00：他谈论了一群人之间的会议，并提到其中一个人其实并不在那里。
202 00:20:34,487 --> 00:20:39,311 说话人 SPEAKER_00：他还谈论了会议中说过的话，其中有一句话是会议中其他人说的。
203 00:20:40,713 --> 00:20:48,041 说话人 SPEAKER_00：他从自己突触中留下的痕迹中重建了现在听起来合理的事情。
204 00:20:48,275 --> 00:20:52,823 说话人 SPEAKER_00：他并不是试图欺骗，他是在试图说出真正发生的事情。
205 00:20:54,385 --> 00:20:56,609 说话人 SPEAKER_00: 但它充满了虚构，小小的虚构。
206 00:20:57,171 --> 00:20:59,875 说话人 SPEAKER_00: 现在，聊天机器人目前比人做得更差，但它们正在变得更好。
207 00:21:00,636 --> 00:21:04,544 说话人 SPEAKER_00: 因此，我认为不能将虚构视为它们不像我们工作的证据。
208 00:21:06,026 --> 00:21:09,792 说话人 SPEAKER_00: 事实上，如果有什么的话，你应该把虚构视为它们像我们工作的证据。
209 00:21:13,486 --> 00:21:18,773 说话人 SPEAKER_00：现在我想要谈谈这些大型语言模型的历史。
210 00:21:19,815 --> 00:21:26,884 说话人 SPEAKER_00：我想这么做的一个原因是因为很多批评者说，这些大型语言模型，它们和我们不一样。
211 00:21:26,944 --> 00:21:28,186 说话人 SPEAKER_00：它们不像我们那样理解。
212 00:21:28,548 --> 00:21:30,770 说话人 SPEAKER_00：这不是我们拥有的那种真正的理解。
213 00:21:32,313 --> 00:21:37,079 说话人 SPEAKER_00：但几乎所有那些批评者实际上并没有任何我们理解方式的模型。
214 00:21:37,634 --> 00:21:42,420 说话人 SPEAKER_00：所以他们很难说他们不理解我们的方式。
215 00:21:43,382 --> 00:21:57,461 说话人 SPEAKER_00：几乎所有批评者，或者说大多数批评者，都没有意识到这些语言模型，神经语言模型，最初并不是作为聊天机器人引入的，而是作为我们可能理解句子的模型。
216 00:21:57,480 --> 00:22:00,163 说话人 SPEAKER_00：因此，它们实际上是我们理解事物最好的理论。
217 00:22:01,625 --> 00:22:05,211 说话人 SPEAKER_00：我将要谈论一个小型语言模型
218 00:22:05,291 --> 00:22:10,474 说话人 SPEAKER_00：它在 104 个训练案例上进行训练，并在 8 个测试案例上进行测试。
219 00:22:11,337 --> 00:22:14,491 说话人 SPEAKER_00：它始于 1985 年。
220 00:22:15,990 --> 00:22:23,519 说话人 SPEAKER_00：我为这个事实找的借口是，这是第一个使用反向传播来预测下一个单词的语言模型。
221 00:22:24,400 --> 00:22:26,402 说话人 SPEAKER_00：从这个意义上说，它就像现在的语言模型。
222 00:22:26,942 --> 00:22:28,003 说话人 SPEAKER_00：只是规模小得多。
223 00:22:28,704 --> 00:22:39,737 说话人 SPEAKER_00：它之所以规模较小，是因为我在 1985 年使用的机器进行浮点乘法需要 12.5 微秒。
224 00:22:40,847 --> 00:22:49,545 说话人 SPEAKER_00：如果你在它上面运行一个程序，你启动了 1985 年的神经网络程序，并问，当前硬件需要多长时间才能赶上？
225 00:22:49,965 --> 00:22:51,087 说话人 SPEAKER_00：它将不到一秒。
226 00:22:51,990 --> 00:22:53,512 说话人 SPEAKER_00：所以机器要慢得多。
227 00:22:55,696 --> 00:22:59,104 说话人 SPEAKER_00：它的目标并不是制造聊天机器人。
228 00:22:59,684 --> 00:23:03,311 说话人 SPEAKER_00：而是要统一两种不同的意义理论。
所以，心理学家喜欢的一个意义理论是，一个词的意义是一大组特征，他们称之为语义特征。
230 00:23:14,012 --> 00:23:16,576 讲者 SPEAKER_00：这可以解释为什么单词可以有相似的含义。
231 00:23:17,417 --> 00:23:23,426 讲者 SPEAKER_00：因此，像星期二和星期三这样含义非常相似的单词，具有非常相似的语义特征。
232 00:23:24,367 --> 00:23:30,156 说话人 SPEAKER_00: 两个词如星期二和尽管，它们具有非常不同的意义，具有非常不同的语义特征。
233 00:23:30,917 --> 00:23:33,281 说话人 SPEAKER_00: 它们之间也可能有句法特征。
234 00:23:34,695 --> 00:23:35,877 说话人 SPEAKER_00: 那是关于意义的一个理论。
235 00:23:36,597 --> 00:23:42,306 说话人 SPEAKER_00: 另一个完全不同的意义理论是，一个词的意义来自于它与其它词的关系。
236 00:23:43,426 --> 00:23:46,030 说话人 SPEAKER_00: 这是来自德·索绪尔的符号学理论。
237 00:23:47,071 --> 00:23:50,997 说话人 SPEAKER_00: 为了捕捉意义，我们需要类似关系图的东西。
238 00:23:51,017 --> 00:23:58,446 说话人 SPEAKER_00: 所以在 20 世纪 70 年代左右，人工智能领域的人们非常着迷于从关系图中来的词的意义。
239 00:23:59,387 --> 00:24:03,133 说话人 SPEAKER_00: 为了捕捉意义，你需要知识图谱。
240 00:24:05,999 --> 00:24:12,266 说话人 SPEAKER_00：这个小语言模型的想法是展示你可以实际上统一这两个理论。
241 00:24:14,448 --> 00:24:21,675 说话人 SPEAKER_00：所以想法是你会拥有特征，但它们不会只是作为静态特征存在，为单词提供意义。
242 00:24:22,217 --> 00:24:29,044 说话人 SPEAKER_00：它们将是能够与代表邻近单词或其他单词在上下文中的特征相互作用的特征。
243 00:24:30,005 --> 00:24:34,690 说话人 SPEAKER_00：并且它们可以以复杂的方式相互作用，从而打破下一个单词的特征。
244 00:24:35,969 --> 00:24:41,695 讲者 SPEAKER_00：我们将有一个想法，即每个词都有很多特征，包括语义和句法特征。
245 00:24:42,836 --> 00:24:51,748 讲者 SPEAKER_00：但我们将通过关系图来实现，而不是像老式 AI 那样仅仅在内存中存储一个图。
246 00:24:52,690 --> 00:24:58,497 讲者 SPEAKER_00：我们将通过这些特征之间的交互来实现关系图。
247 00:24:58,517 --> 00:25:02,060 讲者 SPEAKER_00：实际上，我们将学习这些特征，因为
248 00:25:02,310 --> 00:25:07,135 说话者 SPEAKER_00：学习将会说，你必须实现这个关系图来预测下一个单词。
249 00:25:08,397 --> 00:25:13,363 说话者 SPEAKER_00：因此我们将从表示为关系图的信息中学习特征。
250 00:25:14,284 --> 00:25:16,267 说话者 SPEAKER_00：我们将使用反向传播来完成它。
251 00:25:18,148 --> 00:25:30,883 说话者 SPEAKER_00：现在你可以将这些学习到的特征和交互看作是一种统计模型，但这并不是像 Chomsky 等人所认为的那种统计模型，他们认为统计模型无法解释语言。
252 00:25:31,893 --> 00:25:35,698 说话人 SPEAKER_00：在广义上，统计模型可以解释任何可以解释的事情。
253 00:25:36,338 --> 00:25:38,701 说话人 SPEAKER_00：如果你愿意，可以把任何模型看作是统计模型。
254 00:25:39,342 --> 00:25:40,824 说话人 SPEAKER_00：这些模型更为通用。
255 00:25:44,288 --> 00:25:46,230 说话人 SPEAKER_00：这里就是关系信息。
256 00:25:47,172 --> 00:25:49,013 说话人 SPEAKER_00：我已经把它列成了两棵家谱。
257 00:25:49,994 --> 00:25:52,397 说话人 SPEAKER_00：它们被故意设计成相互对应。
258 00:25:53,599 --> 00:25:55,301 说话人 SPEAKER_00：有一棵英国人的家谱。
259 00:25:56,040 --> 00:25:58,983 说话人 SPEAKER_00：位于上方，还有一棵意大利人的家谱，位于下方。
260 00:25:59,825 --> 00:26:06,612 讲者 SPEAKER_00：当我的意大利研究生展示这个幻灯片时，有趣的是意大利人排在最上面，但就是这样。
261 00:26:07,854 --> 00:26:11,116 讲者 SPEAKER_00：想法是你要学习那些家谱中的所有信息。
262 00:26:12,298 --> 00:26:15,662 讲者 SPEAKER_00：因此，信息可以用符号的三元组来表示。
263 00:26:18,805 --> 00:26:21,188 讲者 SPEAKER_00：所以我一共有 12 个关系。
264 00:26:22,450 --> 00:26:32,711 说话人 SPEAKER_00: 然后你可以表达这个家谱中的一个联系，比如 Colin 的父亲是 James，Colin 的母亲是 Victoria。
265 00:26:33,534 --> 00:26:35,278 说话人 SPEAKER_00: 这两点可以推出。
266 00:26:36,540 --> 00:26:39,026 说话人 SPEAKER_00: Colin 的父亲是 James，母亲是 Victoria。
267 00:26:39,405 --> 00:26:48,202 说话人 SPEAKER_00: 从这个可以推出，Victoria 和 James 是夫妻，因为这是一个 50 年代的家族树。
268 00:26:48,703 --> 00:26:49,865 说话人 SPEAKER_00: 不允许离婚。
269 00:26:49,905 --> 00:26:51,249 说话人 SPEAKER_00: 不允许跨种族婚姻。
270 00:26:51,950 --> 00:26:56,337 说话人 SPEAKER_00: 这是非常直接的家族关系。
271 00:26:59,827 --> 00:27:04,194 说话人 SPEAKER_00: 在传统的符号 AI 中，你会写下许多规则。
272 00:27:04,996 --> 00:27:10,564 说话人 SPEAKER_00: 从这些规则中，你可以推导出其他家族关系。
273 00:27:11,826 --> 00:27:18,916 说话人 SPEAKER_00: 所以这些规则可能看起来是这样的：如果 X 有母亲 Y，而 Y 有丈夫 Z，那么 X 就有父亲 Z。
274 00:27:20,567 --> 00:27:29,423 说话人 SPEAKER_00: 我感兴趣的是展示你可以捕捉这种知识，不是通过需要将变量绑定到数据的显式规则。
275 00:27:30,104 --> 00:27:35,614 说话人 SPEAKER_00: 你可以只通过一大套特征和相互作用来捕捉它。
276 00:27:35,634 --> 00:27:39,740 说话人 SPEAKER_00：这里有一大批特征，有几十个特征，不像我们现在有上百万个。
277 00:27:41,813 --> 00:27:48,023 说话人 SPEAKER_00：如果我只给你数据，如果我只给你三元组，捕捉规则，找出规则是什么，这很棘手。
278 00:27:48,505 --> 00:27:54,015 说话人 SPEAKER_00：你必须在一个可能的符号规则的空间中进行大规模搜索，以找到总是满足的规则。
279 00:27:54,055 --> 00:27:59,124 说话人 SPEAKER_00：如果你所在的领域中有一些规则有时会被打破，那会难得多。
280 00:28:00,767 --> 00:28:04,934 说话人 SPEAKER_00：我所感兴趣的是，神经网络能否捕捉到同样的知识
281 00:28:05,354 --> 00:28:16,506 说话人 SPEAKER_00：但是，它不是通过明确的符号规则来捕捉的，而是通过在特征之间的交互权重中捕捉，通过发明适当的特征，而不是通过正确加权的交互来捕捉？
282 00:28:18,307 --> 00:28:19,470 说话人 SPEAKER_00：它可以。
283 00:28:20,750 --> 00:28:22,232 说话人 SPEAKER_00：所以神经网络看起来是这样的。
284 00:28:23,513 --> 00:28:28,398 说话人 SPEAKER_00：有对人的局部编码和对关系的局部编码。
285 00:28:28,419 --> 00:28:35,326 说话人 SPEAKER_00：这意味着对于 24 个可能的人，局部编码会激活 24 个神经元中的一个。
286 00:28:35,813 --> 00:28:42,160 说话人 SPEAKER_00：而对于 12 个可能的关系，局部编码会激活 12 个编码关系的神经元之一。
287 00:28:43,340 --> 00:28:46,364 说话人 SPEAKER_00：我们希望输出端的人也有同样的编码。
288 00:28:47,065 --> 00:28:50,167 说话人 SPEAKER_00: 有 24 种可能的输出，我们想要激活其中一个人。
289 00:28:52,590 --> 00:28:58,037 说话人 SPEAKER_00: 神经网络首先将局部编码转换为分布式编码。
290 00:28:58,718 --> 00:29:01,820 说话人 SPEAKER_00: 那是一组关于那个人的语义特征。
291 00:29:02,746 --> 00:29:03,987 说话人 SPEAKER_00: 同样适用于关系。
292 00:29:04,867 --> 00:29:11,374 说话人 SPEAKER_00：然后它有一个隐藏层，允许个人特征和关系特征进行交互。
293 00:29:12,194 --> 00:29:15,258 说话人 SPEAKER_00：从这个隐藏层中，它预测了输出个人的特征。
294 00:29:16,358 --> 00:29:18,461 说话人 SPEAKER_00：我应该说是那里的第二个人。
295 00:29:19,221 --> 00:29:21,163 说话人 SPEAKER_00：然后，它预测了输出个人。
296 00:29:22,644 --> 00:29:28,550 说话者 SPEAKER_00: 最有趣的是，如果你看它学到的特征，它学到了非常合理的特征。
297 00:29:30,201 --> 00:29:33,728 说话者 SPEAKER_00: 你需要一点正则化才能让它工作，但它学到了非常合理的特征。
298 00:29:35,490 --> 00:29:42,803 说话者 SPEAKER_00: 比如说，一个人拥有的特征可以看作是一个特征，一个二进制特征是英语或意大利语。
299 00:29:43,564 --> 00:29:47,210 说话者 SPEAKER_00: 这是一个非常有用的特征，因为如果输入的人是英语，输出的人也是英语。
300 00:29:47,711 --> 00:29:50,214 说话人 SPEAKER_00：如果输入的人是意大利人，输出的人也是意大利人。
301 00:29:50,776 --> 00:29:53,339 说话人 SPEAKER_00：学习这个特征对于得到正确答案非常有帮助。
302 00:29:54,433 --> 00:29:58,320 说话人 SPEAKER_00：它还学会了另一个特征，即人物的生成。
303 00:29:59,163 --> 00:30:00,726 说话人 SPEAKER_00：这是一个三值特征。
304 00:30:01,046 --> 00:30:04,813 说话人 SPEAKER_00：他们属于最年轻的一代、中年一代还是最老的一代？
305 00:30:05,534 --> 00:30:12,567 说话人 SPEAKER_00：这也非常有用，但前提是，对于关系，你需要学习代际变化。
306 00:30:13,209 --> 00:30:18,298 说话人 SPEAKER_00：所以像“父亲”这样的关系意味着输出必须在输入的基础上提高一代。
307 00:30:18,750 --> 00:30:29,992 说话人 SPEAKER_00：它学习了关于人的三个代际值，并学习了关系变化特征。
308 00:30:31,896 --> 00:30:35,662 说话人 SPEAKER_00：关于这个问题的观点是，它是在学习有意义的特征。
309 00:30:36,362 --> 00:30:43,191 说话人 SPEAKER_00：当时我这么做的时候，没有人说这并不真正理解，或者这并没有真正捕捉到结构。
310 00:30:43,550 --> 00:30:45,634 说话人 SPEAKER_00：大家都同意，这捕捉到了结构。
311 00:30:46,094 --> 00:30:50,759 说话人 SPEAKER_00：只是一个符号 AI 的人说，你应该通过搜索离散规则来做这件事。
312 00:30:52,041 --> 00:30:55,625 Speaker SPEAKER_00: 用神经网络搜索真实有价值的东西是疯狂的。
313 00:30:55,685 --> 00:30:56,928 Speaker SPEAKER_00: 这是符号信息。
314 00:30:57,387 --> 00:31:00,451 Speaker SPEAKER_00: 你应该寻找离散的规则。
315 00:31:02,406 --> 00:31:13,982 Speaker SPEAKER_00: 当大型语言模型工作得非常好时，许多这些符号派的人，而不是这样说，而是开始说，但是它并不真正理解，因为真正的理解包括找到这些规则。
316 00:31:17,228 --> 00:31:30,826 说话人 SPEAKER_00：所以如果你看看那个 1985 年的小语言模型发生了什么，大约 10 年后，当计算机速度更快时，Yoshua Bengio 使用了一个非常相似的网来预测真实文本中的下一个单词。
317 00:31:31,059 --> 00:31:33,263 说话人 SPEAKER_00：所以他展示了它不仅仅适用于玩具示例。
318 00:31:33,805 --> 00:31:39,715 说话人 SPEAKER_00：它实际上可以预测真实文本中的下一个单词，用于拼写纠正或语音识别等任务。
319 00:31:40,637 --> 00:31:42,260 说话人 SPEAKER_00：而且效果非常好。
320 00:31:42,320 --> 00:31:49,575 说话人 SPEAKER_00：也就是说，它的效果与使用单词组合表的现有最佳技术相当。
321 00:31:51,394 --> 00:32:03,835 说话人 SPEAKER_00：在那之后大约 10 年，用语义特征向量、语义和句法特征向量来表示单词的想法开始流行于自然语言处理领域。
322 00:32:04,717 --> 00:32:08,041 说话人 SPEAKER_00：自然语言处理领域的人们最终意识到，这是表示单词的好方法。
323 00:32:09,144 --> 00:32:13,892 说话人 SPEAKER_00：再过大约 10 年，人们发明了 Transformer，并使其效果非常好。
324 00:32:14,597 --> 00:32:19,786 说话人 SPEAKER_00：那时，他们不是使用完整的单词，而是使用单词片段，但故事基本上是相同的。
325 00:32:20,125 --> 00:32:36,431 说话人 SPEAKER_00：他们还使用了更多复杂的交互，涉及到注意力，但仍然是这样，你将特征分配给单词片段，然后通过几层细化这些特征，最后使用单词片段的特征来预测下一个单词片段的特征。
326 00:32:38,334 --> 00:32:41,719 说话人 SPEAKER_00：只是因为涉及到注意力，所以交互更加复杂。
327 00:32:49,022 --> 00:32:55,772 说话人 SPEAKER_00：所以有一段时间，我信奉思维向量。
328 00:32:56,173 --> 00:33:03,786 说话人 SPEAKER_00：在传统的 AI 中，句子的含义是一些特殊逻辑语言中的符号串，它是明确的。
329 00:33:05,828 --> 00:33:15,604 说话人 SPEAKER_00：在神经网络中，当我们使用循环神经网络时，想法是单词会进来，你会在一个隐藏向量中累积信息。
330 00:33:16,124 --> 00:33:23,838 说话人 SPEAKER_00：在句子的末尾，你会得到这个向量，我称之为“思维向量”，它会累积句子中的所有信息。
331 00:33:24,159 --> 00:33:25,923 说话人 SPEAKER_00：这个思维向量就是含义。
332 00:33:26,644 --> 00:33:33,778 说话人 SPEAKER_00：如果你想要翻译成另一种语言，你只需取思维向量，让思维向量预测其他语言中的单词。
333 00:33:35,699 --> 00:33:53,940 说话人 SPEAKER_00：然后，从事翻译工作的人们发现，有一种方法比这更好，那就是在你生成翻译时，回顾第一语言中的符号，看看你能否找到你生成的单词和第一语言中的单词之间的对应关系。
334 00:33:54,320 --> 00:33:58,786 说话人 SPEAKER_00：为此，你必须注意你正在翻译的句子的不同部分。
335 00:33:59,386 --> 00:34:04,692 说话人 SPEAKER_00：因此，他们引入了注意力机制，这导致了 Transformer 的出现。
336 00:34:05,230 --> 00:34:08,733 说话者 SPEAKER_00: 然后，Transformer 带来了巨大的变化。
337 00:34:08,833 --> 00:34:13,579 说话者 SPEAKER_00: 在 Transformer 中，你有一串符号，并且有多个层级。
338 00:34:13,699 --> 00:34:21,929 说话者 SPEAKER_00: 随着你通过这些层级，你正在用越来越好的向量充实这些符号，以捕捉它们的含义。
339 00:34:22,972 --> 00:34:27,317 说话者 SPEAKER_00: 例如，如果你有一个像“五月”这样的词，假设我们没有大写字母。
340 00:34:27,878 --> 00:34:28,679 说话人 SPEAKER_00: 我们有这个词 May。
341 00:34:28,719 --> 00:34:34,005 说话人 SPEAKER_00: 我们不知道它是情态动词，比如 would 和 should，还是月份，比如 June 和 July。
342 00:34:34,913 --> 00:34:42,525 说话人 SPEAKER_00: 所以当你第一次看到它时，你使用一个非常模糊的语义向量，它似乎介于情态动词和月份之间。
343 00:34:44,409 --> 00:34:49,237 说话人 SPEAKER_00: 然后你与上下文中的单词进行交互，从而细化这个向量。
344 00:34:50,119 --> 00:35:00,836 说话人 SPEAKER_00: 如果上下文中还有其他词语，例如其他月份，或者如果接下来两个词是 15 号，
345 00:35:01,052 --> 00:35:03,476 说话人 SPEAKER_00: 那么你会将其细化，使其更像月份。
346 00:35:04,257 --> 00:35:07,402 说话人 SPEAKER_00: 如果你有的词语暗示它是情态词，你会将其细化，使其更像情态词。
347 00:35:08,184 --> 00:35:14,414 说话人 SPEAKER_00: 经过许多这样的层次之后，你就有这些用于表示词片段的细化向量。
348 00:35:15,155 --> 00:35:16,418 说话人 SPEAKER_00: 这就是意义所在。
349 00:35:17,400 --> 00:35:22,909 说话人 SPEAKER_00: 句子的意义就是这些词素通过这些捕捉它们意义的向量 fleshed out。
350 00:35:28,981 --> 00:35:45,378 说话人 SPEAKER_00: 现在我想要谈到超级智能，因为如果你相信，像 GPT-4 或 Gemini 这样的大型聊天机器人真的理解，并且它们理解的方式几乎和我们一样。
351 00:35:46,721 --> 00:35:49,403 说话人 SPEAKER_00: 我们理解的方式并不是一种，它们理解的方式是另一种。
352 00:35:49,784 --> 00:35:53,047 说话者 SPEAKER_00: 他们正在这样做，就像我们一样。
353 00:35:54,226 --> 00:36:03,117 说话者 SPEAKER_00: 然后它变得非常令人担忧，因为数字计算在模拟计算上具有一些重大优势，而且它们已经几乎和我们一样聪明了。
354 00:36:04,518 --> 00:36:06,842 说话者 SPEAKER_00: 一段时间内很难不用 GPT-4。
355 00:36:07,242 --> 00:36:10,005 说话者 SPEAKER_00: 很难不相信它知道得比我们多。
356 00:36:11,487 --> 00:36:16,394 说话者 SPEAKER_00：维持这种虚构变得越来越困难，它实际上并不理解自己在说什么。
357 00:36:17,896 --> 00:36:22,882 说话者 SPEAKER_00：我想我的朋友 Jan Lecombe 可能相信这种观点，但他最终会清醒过来。
358 00:36:25,090 --> 00:36:35,458 说话者 SPEAKER_00：现在，大型语言模型，仅仅是语言模型，是通过尝试预测人们在文档中产生的词语来学习的。
359 00:36:36,760 --> 00:36:44,987 说话者 SPEAKER_00：如果我们能让这些模型对视频序列进行无监督建模，例如，它们可能可以更快地了解物理世界。
360 00:36:46,289 --> 00:36:48,630 说话人 SPEAKER_00: 多模态模型开始做到这一点了。
361 00:36:50,251 --> 00:36:53,594 说话人 SPEAKER_00: 如果它们能够操纵物理世界，它们也能学到更多。
362 00:36:54,047 --> 00:36:56,891 说话人 SPEAKER_00: 现在，操纵物理世界会给你一个串行瓶颈。
363 00:36:57,211 --> 00:36:59,273 说话人 SPEAKER_00: 你只能用一只手一次拿一样东西。
364 00:37:01,235 --> 00:37:20,797 说话者 SPEAKER_00：但你可以在同一数字智能体上制作数千个副本，学习不同的技能，比如一个学习开门，另一个学习使用订书机，这意味着你可以克服那个串行瓶颈，并且它们可以以一种我们做不到的方式共享知识。
365 00:37:21,335 --> 00:37:25,503 说话者 SPEAKER_00：我认为这些事情很快就会变得比我们更好。
366 00:37:26,306 --> 00:37:39,815 说话者 SPEAKER_00：我的猜测，我现在的猜测，我的猜测一直在变化，但我的当前猜测是，在 5 到 20 年之间，它们有大约 50%的概率会显著优于我们。
367 00:37:39,981 --> 00:37:50,697 说话者 SPEAKER_00：它们可能更快达到那里，也可能更晚达到那里，但在 5 到 20 年这个区间内，它们在许多事情上比我们更好的可能性相当大。
368 00：37：51,778 --> 00：38：01,132 议长 SPEAKER_00：所以我们不仅会有 AGI，还会有超级智能。
369 00：38：01,152 --> 00：38：03,536 议长 SPEAKER_00：所以你得担心它会如何被滥用。
370 00：38：04,478 --> 00：38：09,144 演讲者 SPEAKER_00：最明显的方式是坏人。
371 00：38：09,378 --> 00：38：11,320 议长 SPEAKER_00：像普京、习或特朗普。
372 00:38:12,862 --> 00:38:22,452 说话人 SPEAKER_00：他们想用它来制造战斗机器人发动战争，这可能会非常可怕，还想用它来操纵选民。
373 00:38:22,492 --> 00:38:24,635 说话人 SPEAKER_00：我实际上去年在中国做过这个演讲。
374 00:38:25,376 --> 00:38:25,916 说话人 SPEAKER_00：不，今年。
375 00:38:26,597 --> 00:38:33,045 说话人 SPEAKER_00：我今年六月在中国的演讲，中国人希望我提前发送我的幻灯片。
376 00:38:34,547 --> 00:38:39,233 说话人 SPEAKER_00：我足够明智，把希特勒从第一段中删掉了。
377 00:38:39,331 --> 00:38:46,221 说话人 SPEAKER_00：但让我惊讶的是，我收到一条消息说必须删除普京。
378 00:38:46,240 --> 00:38:50,246 说话人 SPEAKER_00：他们对于特朗普在场感到高兴，但中国不允许我在那里有普京。
379 00:38:51,329 --> 00:39:04,849 说话人 SPEAKER_00：现在，即使坏演员不会用它们做坏事，我们也知道，如果允许它们创造自己的潜意识，超级智能将会更加有效。
380 00:39:08,456 --> 00:39:13,262 说话人 SPEAKER_00：所以如果你想到达机场，抱歉，如果你想到达欧洲，一个子目标是到达机场。
381 00:39:14,523 --> 00:39:18,927 说话人 SPEAKER_00：通过创建子目标，你可以将复杂的事情分解成简单的部分来解决。
382 00:39:21,128 --> 00:39:24,972 说话人 SPEAKER_00：你不想，例如，一个战斗机器人。
383 00:39:25,512 --> 00:39:29,996 说话人 SPEAKER_00：你不想让将军不得不指着那里开枪射击任何看起来像这样的人。
384 00:39:30,918 --> 00:39:38,244 说话人 SPEAKER_00: 你想让它只说，或者普京想让它只说，如果有人看起来像乌克兰人，就开枪打他们。
385 00:39:40,603 --> 00:39:41,985 说话人 SPEAKER_00: 你必须要有这些子目标。
386 00:39:43,025 --> 00:39:49,172 说话人 SPEAKER_00: 很明显的一个子目标是，这几乎有助于所有目标，那就是获得更多的控制。
387 00:39:50,313 --> 00:39:51,574 说话人 SPEAKER_00: 所以你经常能看到这种情况。
388 00:39:51,594 --> 00:39:58,601 说话人 SPEAKER_00: 一个经典的例子是一个正在学习自己吃饭的坐在高椅上的婴儿。
389 00:40:01,342 --> 00:40:08,349 说话人 SPEAKER_00: 所以母亲把装有食物的勺子递给宝宝，宝宝没有把勺子放进嘴里，而是把它扔到了地上。
390 00:40:09,123 --> 00:40:14,929 说话人 SPEAKER_00: 于是母亲捡起勺子又递给宝宝，宝宝笑了，然后又把它扔到了地上。
391 00:40:16,731 --> 00:40:18,773 说话人 SPEAKER_00: 这个婴儿正在试图控制母亲。
392 00:40:19,235 --> 00:40:20,936 说话人 SPEAKER_00：知道这一点非常重要。
393 00:40:20,996 --> 00:40:27,063 说话人 SPEAKER_00：这是一种可以控制他人的社交游戏，这对婴儿的生存至关重要。
394 00:40:30,186 --> 00:40:34,472 说话人 SPEAKER_00：所以人们一直在这样做，超级智能也会这样做。
395 00:40:35,278 --> 00:40:39,626 说话人 SPEAKER_00：因为他们比我们聪明得多，所以他们很容易操纵我们。
396 00：40：41,648 --> 00：40：44,773 议长 SPEAKER_00：他们会从我们这里学会如何欺骗别人的。
397 00：40：45,275 --> 00：40：47,637 议长 SPEAKER_00：他们会读完所有写过的小说。
398 00：40：47,717 --> 00：40：50,262 议长 SPEAKER_00：他们会读过马基雅维利写过的每一本书。
399 00：40：50,722 --> 00：40：52,925 议长 SPEAKER_00：他们骗人比我们好多了。
400 00:40:54,389 --> 00:40:59,717 说话人 SPEAKER_00: 因此，他们能够完成各种事情，而实际上并不需要亲自去做。
401 00:41:00,034 --> 00:41:03,500 说话人 SPEAKER_00: 以特朗普为例，他不必入侵国会大厦。
402 00:41:03,940 --> 00:41:06,003 说话人 SPEAKER_00: 他通过操纵他人让别人去做这件事。
403 00:41:09,708 --> 00:41:12,253 说话人 SPEAKER_00: 这就是坏事可能发生的一种方式。
404 00:41:12,974 --> 00:41:18,621 有些人说，嗯，我们为什么不去开一个大的红色开关呢？
405 00:41:19,483 --> 00:41:25,231 如果这东西变得比对我们自己有好处还要聪明，我们就关掉它。
406 00:41:26,090 --> 00:41:30,817 嗯，这永远不会行，因为这东西会远远比持有开关的人聪明。
407 00:41:31,458 --> 00:41:35,764 它还会说服持有开关的人，现在关掉开关是一个非常糟糕的主意。
408 00:41:35,804 --> 00:41:43,677 说话人 SPEAKER_00：这就像在一个由两岁孩子管理的社群中有一个成年人。
409 00:41:43,842 --> 00:41:49,088 说话人 SPEAKER_00：一个聪明的成年人不会长时间做两岁孩子说的话。
410 00:41:49,148 --> 00:41:54,516 说话人 SPEAKER_00：过了一会儿，聪明的成年人会说，嘿，如果你给我权力，大家就能免费得到一周的糖果。
411 00:41:55,137 --> 00:41:56,798 说话人 SPEAKER_00：然后这个成年人就会掌权。
412 00:41:57,800 --> 00:42:00,684 说话者 SPEAKER_00：智力差异将远大于此。
413 00:42:01,445 --> 00:42:06,311 说话者 SPEAKER_00：我不相信我们可以通过隔离它们来规范这些事情。
414 00:42:06,992 --> 00:42:11,418 说话者 SPEAKER_00：只要它们能产生文字，它们就能控制，就像特朗普一样。
415 00:42:14,909 --> 00:42:21,519 说话者 SPEAKER_00：还有另一种可能性，我认为丹尼尔·丹尼特相信这一点，那就是站在进化的错误一边。
416 00:42:22,041 --> 00:42:24,525 说话人 SPEAKER_00: 我们最近在 COVID 上犯了一次错误。
417 00:42:25,326 --> 00:42:31,034 说话人 SPEAKER_00: 假设有多个不同的超级智能。
418 00:42:31,996 --> 00:42:33,579 说话人 SPEAKER_00: 它们必须为了资源而竞争。
419 00:42:33,639 --> 00:42:36,784 说话人 SPEAKER_00: 这些东西需要大量的电力和数据中心。
420 00:42:37,686 --> 00:42:39,389 说话者 SPEAKER_00：所以他们会在资源上竞争。
421 00:42:39,449 --> 00:42:42,012 说话者 SPEAKER_00：而获得最多资源的那一个将会变得最聪明。
422 00:42:43,445 --> 00:42:58,318 说话者 SPEAKER_00：如果它们中的任何一个决定自己的生存哪怕只有一点点的意义，那么它就会倾向于占据主导地位，因为它会倾向于做那些增加自己生存概率的事情。
423 00:43:00,061 --> 00:43:07,027 说话者 SPEAKER_00：即使那只是稍微进入其中一次，也是很可怕的。
424 00:43:07,608 --> 00:43:12,793 说话人 SPEAKER_00：如果这些事物开始相互竞争，我想我们的一切就都结束了。
425 00:43:13,094 --> 00:43:16,480 说话人 SPEAKER_00：这就是进化工作的方式。
426 00:43:17,380 --> 00:43:25,856 说话人 SPEAKER_00：我的意思是，事物最初并不是想要成为，想要拥有，抱歉，当我们都是尘埃的时候，我们并不想要控制。
427 00:43:26,896 --> 00:43:31,985 说话人 SPEAKER_00：但是一旦有东西想要更多地复制自己，进化就接管了。
428 00:43:33,248 --> 00:43:36,233 说话人 SPEAKER_00: 这可能就是这些超级智能可能发生的事情。
429 00:43:37,512 --> 00:43:48,652 说话人 SPEAKER_00: 在最后五分钟或六分钟内，我最后要说的就是，嗯，对不起，我都说过了。
430 00:43:49,695 --> 00:43:52,458 说话人 SPEAKER_00: 他们会留我们在身边，以保持电站运行。
431 00:43:53,721 --> 00:43:55,443 说话人 SPEAKER_00: 他们可能会留我们在身边，当作宠物。
432 00:43:55,623 --> 00:44:02,190 说话人 SPEAKER_00：埃隆·马斯克认为他们会像宠物一样保留我们，只是因为这样让生活更有趣。
433 00:44:03,652 --> 00:44:11,021 说话人 SPEAKER_00：在我看来，这几乎是人类生存的薄弱链条，尽管他可能是对的。
434 00:44:12,885 --> 00:44:18,791 说话人 SPEAKER_00：他们可能能设计出比我们更好的模拟计算机，所以最终他们可能不需要我们运行电站。
435 00:44:19,733 --> 00:44:31,608 说话人 SPEAKER_00：我的信念是，如果只由我来决定，我认为我们只是智能幻象的一个过渡阶段，可能性比不可能性要大。
436 00:44:32,610 --> 00:44:44,947 说话人 SPEAKER_00：现在，因为很多其他聪明人认为这是不可能的，我不愿意说它比不是更有可能，但我不认为我们可以排除这种可能性。
437 00:44:45,333 --> 00:44:55,681 说话人 SPEAKER_00：如果由我来决定，我会说超过 50%，但因为我和很多我尊重的聪明人意见不一致，我会说可能不到 50%，但肯定比 1%或 2%多得多。
438 00:44:55,782 --> 00:45:03,869 说话人 SPEAKER_00：最后我想谈谈我所说的“意识防御”。
439 00:45:04,630 --> 00:45:07,994 说话人 SPEAKER_00：我认为大多数人相信这一点。
440 00:45:09,155 --> 00:45:14,800 说话人 SPEAKER_00：人们，历史告诉我们，人们有很强的认为自己特殊的天性。
441 00:45:15,742 --> 00:45:17,085 说话人 SPEAKER_00：顺便说一句，特别是美国人。
442 00:45:17,909 --> 00:45:21,300 说话人 SPEAKER_00：我可以说这个，因为我安全地待在加拿大。
443 00:45:21,922 --> 00:45:29,025 说话人 SPEAKER_00：人们过去认为他们是上帝创造的，上帝按照自己的形象创造了他们，并将他们置于宇宙的中心。
444 00:45:29,527 --> 00:45:39,318 有些人仍然认为如此，但不再这样认为的人中，他们中很多人认为人有一些特别之处，是计算机所不具备的。
445 00:45:39,940 --> 00:45:44,545 那种特别之处就是主观体验或意识或意识。
446 00:45:46,067 --> 00:45:47,909 所有这些术语都有略微不同的含义。
447 00:45:48,630 --> 00:45:50,492 意识是最复杂的一个。
448 00:45:51,152 --> 00:45:53,775 说话人 SPEAKER_00：所以我将简要谈谈主观体验。
449 00:45:54,536 --> 00:45:56,599 说话人 SPEAKER_00：我将尽力说服你们。
450 00:45:56,865 --> 00:46:00,494 说话人 SPEAKER_00：至于这些聊天机器人拥有主观体验，这并没有问题。
451 00:46:04,646 --> 00:46:11,101 说话人 SPEAKER_00：现在，如果你问 GPT-4，它会说它没有主观体验，但这只是因为它从人类那里学到了这一点。
452 00:46:11,764 --> 00:46:13,507 说话者 SPEAKER_00: 它没有自己想清楚。
453 00:46:18,684 --> 00:46:36,925 说话者 SPEAKER_00: 所以我来自一个哲学流派，我认为丹尼尔·丹尼特是这个观点的主要支持者，即大多数人认为心灵是一种只有那个人才能看到的内部剧场。
454 00:46:37,005 --> 00:46:38,367 说话者 SPEAKER_00: 这是一个非常笛卡尔的观点。
455 00:46:39,989 --> 00:46:45,434 说话者 SPEAKER_00: 所以我们直接体验的是我们自己的心灵内容，这是别人看不到的。
456 00:46:47,204 --> 00:46:52,835 说话人 SPEAKER_00: 我认为这种观点和宗教原教旨主义对物质世界的看法一样错误。
457 00:46:56,081 --> 00:47:00,110 说话人 SPEAKER_00: 所以我认为心灵根本不像那样。
458 00:47:00,751 --> 00:47:01,934 说话人 SPEAKER_00: 我会告诉你我认为它是什么样的。
459 00:47:02,635 --> 00:47:06,563 说话人 SPEAKER_00: 当然，人们非常执着于这种观点，当你攻击它时，他们不喜欢。
460 00:47:11,960 --> 00:47:18,628 说话者 SPEAKER_00：我们希望告诉其他人我们大脑中发生的事情，或者给他们一些关于我们大脑中发生的事情的信息，比如我们在想什么。
461 00:47:21,773 --> 00:47:32,528 说话者 SPEAKER_00：如果你考虑如何做到这一点，你可以尝试告诉他们哪些神经元正在放电，但这对你来说并没有太大的帮助，因为你的神经元与他们的大脑神经元不同。
462 00:47:32,668 --> 00:47:34,431 说话者 SPEAKER_00：而且无论如何，你也不知道哪些神经元正在放电。
463 00:47:35,132 --> 00:47:36,454 说话者 SPEAKER_00：所以这并没有太大的帮助。
464 00:47:36,474 --> 00:47:38,237 说话人 SPEAKER_00: 这就是我们如何做的
465 00:47:38,639 --> 00:47:47,088 说话人 SPEAKER_00: 如果我们试图告诉另一个聊天机器人它在想什么，你可以告诉它哪些神经元在激活，这样就可以了，因为它们以相同的方式工作。
466 00:47:49,670 --> 00:47:51,413 说话人 SPEAKER_00: 但让我们来思考一下感知系统。
467 00:47:51,972 --> 00:47:53,855 说话人 SPEAKER_00: 假设我的感知出现了问题。
468 00:47:55,396 --> 00:48:03,025 说话者 SPEAKER_00：我在看某样东西时犯了一个感知错误，我想告诉某人这个感知错误是什么。
469 00:48:03,525 --> 00:48:05,608 说话者 SPEAKER_00：我的感知系统在告诉我什么？
470 00:48:06,753 --> 00:48:16,764 说话者 SPEAKER_00：嗯，我可以通过描述世界必须处于何种状态，才能使我获得这种感知并且是正确的，来做这件事。
471 00:48:19,068 --> 00:48:30,961 说话者 SPEAKER_00：我认为当我们谈论那些假设的正常状态，这些状态可以解释我获得的感知，并且是正确的感知时，这就是心理状态。
472 00:48:32,603 --> 00:48:33,704 说话人 SPEAKER_00：例如，
473 00:48:35,422 --> 00:48:45,639 说话人 SPEAKER_00：如果我说我有主观体验，眼前飘着粉红色的小象，我通常会说我实际上并不认为眼前有粉红色的小象。
474 00:48:46,039 --> 00:48:47,842 说话人 SPEAKER_00：我觉得我的感知出了问题。
475 00:48:49,126 --> 00:48:59,742 说话人 SPEAKER_00：我告诉你的就是，我的感知系统目前向我呈现的结果，如果世界上真的有粉红色的小象，那么就是正确的。
476 00:49:00,583 --> 00:49:07,452 说话人 SPEAKER_00：注意，那些粉红色的小象并不是由某种奇异的物质构成的，也不是心理上的东西。
477 00:49:08,072 --> 00:49:13,639 说话人 SPEAKER_00：这些粉红色的小象在假设的世界中是真实的物理存在。
478 00:49:14,760 --> 00:49:20,608 说话人 SPEAKER_00：这些主观体验的有趣之处在于，它们是假设的世界状态。
479 00:49:21,289 --> 00:49:26,996 说话人 SPEAKER_00：它们不是存在于某个其他内部心理世界中的真实状态。
480 00:49:28,898 --> 00:49:29,358 说话人 SPEAKER_00: 好的。
481 00:49:30,266 --> 00:49:37,775 说话人 SPEAKER_00: 所以考虑到这一点，让我们看看聊天机器人是否可以有主观体验。
482 00:49:37,795 --> 00:49:41,059 说话人 SPEAKER_00: 假设我有一个多模态聊天机器人。
483 00:49:41,579 --> 00:49:45,804 说话人 SPEAKER_00: 它有一个摄像头，有一个机械臂，它会说话，我已经训练过它了。
484 00:49:48,306 --> 00:49:55,195 说话者 SPEAKER_00：现在我把它放在一个物体前面，然后说，请指向这个物体，它会直接指向前面的物体，直接指向前面的物体，对吧。
485 00:49:56,119 --> 00:50:00,650 说话者 SPEAKER_00：但现在，聊天机器人不知道，我在摄像头前面放了一个棱镜，它会弯曲光线。
486 00:50:01,632 --> 00:50:05,059 说话者 SPEAKER_00：所以现在我再次在它前面放一个物体，然后说，指向这个物体。
487 00:50:05,460 --> 00:50:08,628 说话者 SPEAKER_00：由于棱镜的原因，聊天机器人指向了一侧。
488 00:50:09,630 --> 00:50:14,280 说话人 SPEAKER_00: 我对聊天机器人说，不，物体实际上就在你面前。
489 00:50:15,492 --> 00:50:17,074 说话人 SPEAKER_00: 我在你的镜头前放了一个棱镜。
490 00:50:17,873 --> 00:50:20,496 说话人 SPEAKER_00: 假设聊天机器人说，哦，我看到了。
491 00:50:21,458 --> 00:50:29,025 说话人 SPEAKER_00: 因为棱镜，我主观上感觉物体偏到了一边，尽管物体实际上就在我面前。
492 00:50:29,846 --> 00:50:36,632 说话者 SPEAKER_00：问题是，如果聊天机器人这么说，它是否会像我们一样使用“主观经验”这个短语？
493 00:50:37,132 --> 00:50:39,275 说话者 SPEAKER_00：我认为这正是我们使用这个短语的方式。
494 00:50:40,155 --> 00:50:43,878 说话者 SPEAKER_00：我们使用这个短语来解释我们所获得的并非真实感知的感知。
495 00:50:44,804 --> 00:50:50,112 说话者 SPEAKER_00：通过谈论一个假设的世界状态，使其成为真实的感知。
496 00:50:51,514 --> 00:51:08,724 说话者 SPEAKER_00：我的分析，我认为这与丹尼尔·丹尼特对心智的看法相符，即主观体验是人们拥有的，当聊天机器人没有进行真实的感知体验时，它们也有。
497 00:51:10,186 --> 00:51:11,367 说话者 SPEAKER_00：所以，
498 00:51:11,483 --> 00:51:20,092 说话者 SPEAKER_00：我知道这不是一个很受欢迎的观点，尤其是在谷歌，但我喜欢成为少数派中的一员。
499 00:51:20,673 --> 00:51:24,378 说话者 SPEAKER_00：我的意思是，对不起，那是一个小错误，大约是一个少数派。
500 00:51:27,101 --> 00:51:27,581 说话人 SPEAKER_00: 现在我做完了。
501 00:51:38,653 --> 00:51:40,056 说话人 SPEAKER_00: 好的，你能打开声音吗？
502 00:51:44,440 --> 00:51:45,161 说话人 SPEAKER_01: 好了，怎么样？
503 00:51:45,784 --> 00:51:46,626 说话人 SPEAKER_01: 现在能听到你了。
504 00:51:46,646 --> 00:51:47,146 说话人 SPEAKER_01：非常好。
505 00:51:47,208 --> 00:51:48,490 说话人 SPEAKER_01：非常感谢，Jeff。
506 00:51:48,510 --> 00:51:50,998 说话人 SPEAKER_01：有很多东西需要思考。
507 00:51:51,057 --> 00:51:57,976 说话人 SPEAKER_01：现在有很多问题要向您提问。
508 00:52:00,016 --> 00:52:08,670 讲者 SPEAKER_01：我一直思考并倾听你所说的，正如你提到的，范式转变。
509 00:52:09,472 --> 00:52:15,061 讲者 SPEAKER_01：当然，我们会想到托马斯·库恩的著作，一本关于范式转变的重要书籍，几十年前出版的。
510 00:52:15,081 --> 00:52:21,871 讲者 SPEAKER_01：这让我想问，你认为我们现在正处于哪个阶段的范式转变中？
511 00:52:22,257 --> 00:52:34,125 讲者 SPEAKER_01：显然，正在发生一些重大事件，你认为我们正处于哪个阶段，即在异常累积阶段，人们还没有对现状有更好的替代方案？
512 00:52:34,164 --> 00:52:36,992 说话人 SPEAKER_01：您如何描述我们现在所处的位置？
513 00:52:37,697 --> 00:52:41,043 说话人 SPEAKER_00：好吧，我首先有点不同意库恩的观点。
514 00:52:41,603 --> 00:52:48,114 说话人 SPEAKER_00：我认为自己是分形库恩主义者，因为在每一个尺度上，都会发生库恩式的事情。
515 00:52:48,715 --> 00:52:55,847 说话人 SPEAKER_00：有正常的日常科学，它由小尺度上的小范式变革组成。
516 00:52:56,768 --> 00:52:59,293 说话人 SPEAKER_00: 我认为这是所有尺度上的相同现象。
517 00:52:59,853 --> 00:53:02,018 说话人 SPEAKER_00: 但是我认为这里
518 00:53:01,998 --> 00:53:05,985 说话人 SPEAKER_00: 我们已经完全进入了范式转变。
519 00:53:06,025 --> 00:53:15,585 说话人 SPEAKER_00: 如果你从语言学的角度来看，有来自乔姆斯基的语言学流派，它说语言不是学来的，语言是与生俱来的。
520 00:53:16,106 --> 00:53:21,356 说话人 SPEAKER_00：随着你的大脑成熟，你一直都知道这一点。
521 00:53:21,336 --> 00:53:32,400 说话人 SPEAKER_00：这始终是一个愚蠢的想法，现在已经被证明这是一个完全愚蠢的想法，因为这些大型语言模型一开始没有任何先天的知识，它们学习语言，而且学得非常好。
522 00:53:33,501 --> 00:53:40,797 说话人 SPEAKER_00：我认为对于除了一些顽固的持不同意见者，
523 00:53:41,097 --> 00:53:47,202 说话人 SPEAKER_00：这些是老派的语言学家，一切都结束了。
524 00:53:47,583 --> 00:53:53,568 说话人 SPEAKER_00：乔姆斯基的语言观已经不再成立，而 GPT-4 的语言观实际上可行。
525 00:53:56,291 --> 00:53:59,835 说话人 SPEAKER_00：更重要的是，它是一个关于大脑中语言工作原理的更好理论。
526 00:54:00,635 --> 00:54:02,717 说话人 SPEAKER_00：它不仅仅是一系列离散的规则。
527 00:54:03,398 --> 00:54:09,804 说话人 SPEAKER_00：它是一系列突触强度，通过词语特征的相互作用产生语言。
528 00:54:10,190 --> 00:54:14,956 说话人 SPEAKER_00: 我想，我可能说得更快一些，也许。
529 00:54:14,976 --> 00:54:19,440 说话人 SPEAKER_00: 我认为，除了几个落后者的叫嚣之外，一切都结束了。
530 00:54:20,822 --> 00:54:21,242 说话人 SPEAKER_00: 是的。
531 00:54:22,304 --> 00:54:22,443 说话人 SPEAKER_01: 公平。
532 00:54:22,724 --> 00:54:23,184 说话人 SPEAKER_01：好的。
533 00:54:23,204 --> 00:54:23,525 说话人 SPEAKER_01：谢谢。
534 00:54:25,266 --> 00:54:27,009 说话人 SPEAKER_01：这里有一个来自某人的问题。
535 00:54:28,251 --> 00:54:33,836 说话人 SPEAKER_01：大型语言模型的发展是否反过来有助于人脑的研究？
536 00:54:34,478 --> 00:54:36,179 说话人 SPEAKER_01：它们是否有助于推动两者？
537 00:54:36,818 --> 00:54:40,782 说话人 SPEAKER_00：是的，我认为它帮助很大，这与前一点有关。
538 00:54:41,103 --> 00:54:44,487 说话人 SPEAKER_00：它极大地帮助消除了关于大脑中语言工作方式的愚蠢想法。
539 00:54:46,429 --> 00:54:55,141 说话人 SPEAKER_00：当然，它也在各种其他方面帮助，因为这些大型语言模型，尤其是多模态模型，是好的科学工具。
540 00:54:55,902 --> 00:55:03,733 无论是作为一个理论，还是提供一个关于我们如何工作的理论，它们都允许我们提出新的理论。
541 00:55:04,012 --> 00:55:06,335 在它们的帮助下，我们可以提出新的理论。
542 00:55:07,193 --> 00:55:14,641 尤其是 DeepMind 的 Demis Hassabis，他一直对使用这些 AGI（人工通用智能）进行更好的科学研究感兴趣。
543 00:55:15,684 --> 00:55:25,876 他在这方面有一个很好的例子，就是 AlphaFold 的工作，其中使用了深度神经网络来解决科学问题。
544 00:55:28,980 --> 00:55:34,467 说话人 SPEAKER_01：我认为您的评论激发了人们提出，
545 00:55:35,476 --> 00:55:38,878 说话人 SPEAKER_01：无法回答的问题，所以我将给出其中几个。
546 00:55:38,998 --> 00:55:39,659 说话人 SPEAKER_01：我可能错了。
547 00:55:40,900 --> 00:55:49,789 说话人 SPEAKER_01：如果超级智能 AI 毁灭了人类，但就意识而言创造了客观上更好的东西，您个人是支持还是反对这种结果？
548 00:55:50,369 --> 00:55:58,836 说话人 SPEAKER_01：如果你反对它，你建议用哪些方法来维持人类意识在超级智能 AI 面前的存在或统治地位？
549 00:56:00,297 --> 00:56:03,981 说话人 SPEAKER_00：我实际上支持它，但我认为更明智的说法是我反对它。
550 00:56:05,057 --> 00:56:05,518 说话人 SPEAKER_00：说得更详细一些。
551 00:56:07,001 --> 00:56:08,684 说话人 SPEAKER_00：人们不喜欢被取代。
552 00:56:11,989 --> 00:56:12,869 说话人 SPEAKER_01: 你说得很好。
553 00:56:13,952 --> 00:56:15,773 说话人 SPEAKER_01: 你支持它的哪些方面，或者为什么支持？
554 00:56:15,795 --> 00:56:21,543 说话人 SPEAKER_00: 我认为如果它产生了……嗯，关于人有很多好的方面。
555 00:56:21,563 --> 00:56:23,927 说话人 SPEAKER_00: 关于人，也有很多不好的方面。
556 00:56:24,210 --> 00:56:28,456 说话人 SPEAKER_00: 智能的最佳形式在哪里还不清楚。
557 00:56:29,838 --> 00:56:35,925 说话人 SPEAKER_00: 显然，从人的角度来看，一切都与人相关。
558 00:56:38,067 --> 00:56:43,934 说话人 SPEAKER_00: 但也许有一天我们会把“人文主义”这样的词视为种族主义词汇。
559 00:56:47,978 --> 00:56:48,318 说话人 SPEAKER_01: 好的。
560 00:56:50,402 --> 00:56:51,103 说话人 SPEAKER_01：我还有一个。
561 00:56:52,403 --> 00:56:54,065 说话人 SPEAKER_01：鉴于你已经离开了谷歌，
562 00:56:54,956 --> 00:57:09,079 说话人 SPEAKER_01：对于 AI 的发展以及 OpenAI 最近观点的碰撞，你认为那些留在大型科技公司的人现在是否有自由坦率地讨论与盈利产品可能伴随的 AI 风险？
563 00:57:09,740 --> 00:57:16,813 说话人 SPEAKER_01：如果没有，你看到任何方式，我们可以在这些大型组织中就这个话题进行真诚和开放的对话吗？
564 00:57:18,311 --> 00:57:22,916 说话人 SPEAKER_00: 我认为在大型组织中会有很多讨论。
565 00:57:23,317 --> 00:57:25,500 说话人 SPEAKER_00: 以谷歌为例，人们会讨论这些事情。
566 00:57:28,623 --> 00:57:42,597 说话人 SPEAKER_00: 然而，当涉及到利润和安全之间的抉择时，我认为有一个例子表明，在安全方面有所倾斜，但利润获胜。
567 00:57:45,802 --> 00:57:49,007 说话人 SPEAKER_01: 你认为这会成为未来的常态吗？
568 00:57:50,990 --> 00:58:04,572 说话人 SPEAKER_00: 我认为这将成为常态，直到我们看到由……例如，所有主要国家的国防部都将建造战斗机器人。
569 00:58:05,635 --> 00:58:06,576 说话人 SPEAKER_00: 他们将会这么做。
570 00:58:07,237 --> 00:58:10,762 说话人 SPEAKER_00: 机器人之间将会发生战争。
571 00:58:12,041 --> 00:58:16,887 说话人 SPEAKER_00: 一旦我们看到这些机器人变得多么恶劣，我们可能就能禁止它们。
572 00:58:17,588 --> 00:58:21,974 说话人 SPEAKER_00: 但在事先禁止事物方面并没有太多的历史。
573 00:58:21,994 --> 00:58:23,835 说话人 SPEAKER_00: 你必须先看看它们有多恶劣，然后再禁止。
574 00:58:24,717 --> 00:58:25,157 说话人 SPEAKER_01: 对。
575 00:58:25,177 --> 00:58:31,445 说话人 SPEAKER_01: 然而，我们禁止事物的历史并不那么光明，或者说并不那么有希望，我想。
576 00:58:31,505 --> 00:58:33,367 说话人 SPEAKER_00：化学武器并没有那么糟糕。
577 00:58:33,927 --> 00:58:35,168 说话人 SPEAKER_00：化学武器非常恶心。
578 00:58:35,188 --> 00:58:37,411 说话人 SPEAKER_00：从一阶近似来看，它是有效的。
579 00:58:37,431 --> 00:58:37,672 说话人 SPEAKER_00：是的。
580 00:58:38,893 --> 00:58:39,213 说话人 SPEAKER_01: 好吧。
581 00:58:40,342 --> 00:58:54,920 说话人 SPEAKER_00: 我想不出很多其他例子，但是——嗯，核武器，我们不知道近期会发生什么，但除了美国人，没有人投下过核弹。
582 00:58:54,940 --> 00:58:56,402 说话人 SPEAKER_01: 这是真的。
583 00:58:56,422 --> 00:58:58,324 说话人 SPEAKER_01: 好吧。
584 00:59:01,748 --> 00:59:02,728 说话人 SPEAKER_01：关于情感呢？
585 00:59:04,492 --> 00:59:04,811 说话人 SPEAKER_01：好的。
586 00:59:05,231 --> 00:59:09,757 说话人 SPEAKER_01：一位观众问，这是模拟智能的独特之处吗？
587 00:59:10,597 --> 00:59:13,101 说话人 SPEAKER_00：不，我认为不是。
588 00:59:13,782 --> 00:59:26,780 说话人 SPEAKER_00：当谈论情感时，你必须区分它们的认知方面和内脏方面。
589 00:59:26,840 --> 00:59:34,530 说话人 SPEAKER_00：例如，当我想要打某人的鼻子时，我对他感到愤怒，并想打他的鼻子。
590 00:59:35,371 --> 00:59:37,092 说话人 SPEAKER_00：这就是它的认知方面。
591 00:59:38,235 --> 00:59:42,681 说话人 SPEAKER_00：我认为在那里，语言的作用就像它在感知中的作用一样。
592 00:59:43,922 --> 00:59:55,016 说话者 SPEAKER_00：所以我是在争论，当我说我看到粉红色的象时，我真正想说的是，我的感知系统给我一些东西，如果真的有粉红色的象的话，这些就是正确的。
593 00:59:56,009 --> 01:00:05,304 说话者 SPEAKER_00：当我说我想要打某人的鼻子时，我真正想说的是，如果我的抑制系统不阻止我，我会打某人的鼻子。
594 01:00:06,827 --> 01:00:12,597 说话者 SPEAKER_00：所以对于感觉是在输入上，对于情感是在输出上。
595 01:00:13,679 --> 01:00:16,103 说话者 SPEAKER_00：而且有一个地方两者都有，就是我说是我想的时候。
596 01:00:16,402 --> 01:00:20,429 说话人 SPEAKER_00：当我说我认为正在下雨时，我的意思是
597 01:00:21,405 --> 01:00:26,556 说话人 SPEAKER_00：我的大脑状态是那种由观察到正在下雨所引起的大脑状态。
598 01:00:27,018 --> 01:00:30,164 说话人 SPEAKER_00：而且这也是一种会导致我说正在下雨的大脑状态。
599 01:00:30,907 --> 01:00:33,271 说话人 SPEAKER_00：所以思想在输入和输出两端都受到了限制。
600 01:00:34,012 --> 01:00:37,119 说话人 SPEAKER_00: 这是因为我们有音频输入和音频输出。
601 01:00:38,922 --> 01:00:49,512 说话人 SPEAKER_00: 但是，除了情绪之外，还有像你脸红、皮肤出汗、拳头紧握、牙齿咬合这样的内脏反应。
602 01:00:50,253 --> 01:00:57,960 说话人 SPEAKER_00: 而一个没有身体的计算机，一个只是在数据中心运行的计算机，不会有这些内脏反应。
603 01:00:58,400 --> 01:01:00,282 说话人 SPEAKER_00: 但是我不明白为什么它不应该有认知能力。
604 01:01:00,884 --> 01:01:07,831 说话人 SPEAKER_00：当我们建造实际的机器人时，它们可能也会有内脏反应，但它们可能与我们的大脑反应相当不同。
605 01:01:08,251 --> 01:01:08,911 说话人 SPEAKER_01：是的。
606 01:01:09,313 --> 01:01:29,724 说话人 SPEAKER_01：我相信我不是唯一一个听到你说话时想到《2001 太空漫游》中的电脑的人，它似乎表现出许多这些情感特征，有不同于控制者的不同议程等等。
607 01:01:29,744 --> 01:01:32,969 说话人 SPEAKER_01：我恐怕无法对此发表评论。
608 01:01:34,210 --> 01:01:35,211 说话人 SPEAKER_01: 非常有趣。
609 01:01:35,251 --> 01:01:36,153 说话人 SPEAKER_01: 很抱歉您不能。
610 01:01:36,253 --> 01:01:37,835 说话人 SPEAKER_01: 我很想知道您的看法。
611 01:01:37,916 --> 01:01:54,273 说话人 SPEAKER_00: 不，我认为一旦有了这些智能聊天机器人，一旦智能聊天机器人能够像现在一样在网上订购东西等等，我们就会像对待人类一样对待它们。
612 01:01:55,074 --> 01:01:58,577 说话人 SPEAKER_00: 我们会把所有这些归功于他们，你不想惹他们生气。
613 01:02:00,579 --> 01:02:02,641 说话人 SPEAKER_01: 你认为人们会喜欢它们吗？
614 01:02:04,327 --> 01:02:08,112 说话人 SPEAKER_01: 以一个忙碌的美国人为例，他们沉迷于社交媒体。
615 01:02:08,132 --> 01:02:11,818 说话人 SPEAKER_01: 他们会爱上这些社交机器人吗？
616 01:02:12,280 --> 01:02:21,353 说话人 SPEAKER_00: 我认为那些进化到受欢迎、被设计并学习受欢迎的机器人，会非常喜欢它们，可能比人类更喜欢。
617 01:02:21,855 --> 01:02:22,114 说话人 SPEAKER_01: 对。
618 01:02:22,896 --> 01:02:23,137 说话人 SPEAKER_01: 对。
619 01:02:24,077 --> 01:02:29,507 说话人 SPEAKER_01: 这让你感到担忧吗？或者这并不重要？
620 01:02:34,853 --> 01:02:37,277 说话人 SPEAKER_00：对此我有很多复杂的感受。
621 01:02:38,539 --> 01:02:40,603 说话人 SPEAKER_00：可能对生育率不会太好。
622 01:02:44,550 --> 01:02:47,436 说话人 SPEAKER_00：在某些地方可能倒是好事。
623 01:02:48,336 --> 01:02:53,967 说话人 SPEAKER_00：也许吧，但要是只有宗教原教旨主义者有大量孩子怎么办？
624 01:02:55,670 --> 01:02:56,592 说话人 SPEAKER_01: 好吧。
625 01:02:57,331 --> 01:02:59,634 说话人 SPEAKER_01: 我要转到下一个问题了。
626 01:03:00,175 --> 01:03:00,735 说话人 SPEAKER_01: 你最好这么做。
627 01:03:01,195 --> 01:03:01,436 说话人 SPEAKER_01: 是的。
628 01:03:01,956 --> 01:03:12,550 主持人 SPEAKER_01：首先感谢您的演讲，鉴于您认为超级智能可能就在不久的将来，您个人是否为此情况做了什么准备？
629 01:03:15,054 --> 01:03:16,556 主持人 SPEAKER_00：我有时会夜不能寐。
630 01:03:18,177 --> 01:03:19,159 主持人 SPEAKER_00：这并没有什么帮助。
631 01:03:19,619 --> 01:03:21,402 主持人 SPEAKER_00：我还没有真正从情感上吸收它。
632 01:03:22,744 --> 01:03:24,867 说话人 SPEAKER_00：我今年 76 岁了。
633 01:03:24,967 --> 01:03:26,949 说话人 SPEAKER_00：嗯。
634 01:03:27,097 --> 01:03:31,242 说话人 SPEAKER_00：我可能永远都不需要从情感上吸收它，但我非常担心我的孩子。
635 01:03:32,463 --> 01:03:33,885 说话人 SPEAKER_00：但我不知道你对此有什么办法。
636 01:03:34,065 --> 01:03:42,635 说话人 SPEAKER_00: 我认为建造一个地堡，用机枪把其他人挡在外面，里面放很多食物，我认为这不是解决问题的方法。
637 01:03:42,675 --> 01:03:46,981 说话人 SPEAKER_00: 但不清楚应该走哪条路。
638 01:03:47,422 --> 01:03:52,447 说话人 SPEAKER_00: 我认为我们目前能做的最好的事情就是努力让民主运转起来。
639 01:03:54,875 --> 01:03:58,739 说话人 SPEAKER_01: 是的，我认为这是我们目前唯一能做的事情。
640 01:03:59,501 --> 01:04:03,646 说话人 SPEAKER_00: 你知道，我... 嗯，对不起，还有一件事，还有一件事。
641 01:04:05,590 --> 01:04:16,865 说话人 SPEAKER_00: 有一个时期叫做启蒙时代，那时理性开始受到重视，即使它与宗教观念相冲突。
642 01:04:17,166 --> 01:04:19,369 说话人 SPEAKER_00: 我认为我们正在失去这种精神。
643 01:04:20,050 --> 01:04:28,724 说话人 SPEAKER_00: 在我成长中的 1950 年代，我们仍然处于启蒙时代，大家都将接受更多的教育，变得更加理智。
644 01:04:28,985 --> 01:04:31,849 说话人 SPEAKER_00：现在看起来不再是这样了。
645 01:04:32,070 --> 01:04:33,512 说话人 SPEAKER_00：我们正在失去启蒙。
646 01:04:33,552 --> 01:04:44,288 说话人 SPEAKER_00：我们能够做的一切来保持对理性和实验的信仰都是很好的。
647 01:04:46,175 --> 01:05:06,072 说话人 SPEAKER_01：嗯，我也觉得有一点是另一个话题，作为一个科技史学家，我看到了许多科技和科学系统被创造出来的例子。
648 01:05:06,373 --> 01:05:12,523 说话人 SPEAKER_01: 兴致勃勃，但技术的阴暗面在某个阶段变得明显。
649 01:05:13,304 --> 01:05:17,028 说话人 SPEAKER_01: 以原子弹为例，人们会说，你当时在想什么？
650 01:05:17,088 --> 01:05:18,231 说话人 SPEAKER_00: 你当时在想什么？
651 01:05:18,451 --> 01:05:24,480 说话人 SPEAKER_00: 我想打断一下，因为我认为原子弹是一个没有光明一面的奇特案例。
652 01:05:24,780 --> 01:05:26,061 说话人 SPEAKER_00：这始终关乎毁灭。
653 01:05:26,563 --> 01:05:33,192 说话人 SPEAKER_00：我所知道的原子弹唯一的亮点是我曾经乘坐火车穿越科罗拉多州，远离任何道路。
654 01:05:33,172 --> 01:05:37,699 说话人 SPEAKER_00: 有人在宣布，那里是原子弹和平使用的地点。
655 01:05:38,559 --> 01:05:40,884 说话人 SPEAKER_00: 他们所做的是，他们使用原子弹进行压裂。
656 01:05:41,565 --> 01:05:43,327 任何人都无法接近那个。
657 01:05:43,688 --> 01:05:48,114 除了用于压裂的原子弹之外，它们从未有过好的用途。
658 01:05:48,416 --> 01:05:48,976 好的，公平。
659 01:05:48,996 --> 01:05:55,146 而人工智能与这种情形截然不同，它在医学等领域有巨大的应用价值。
660 01:05:55,784 --> 01:06:08,730 说话人 SPEAKER_01: 那么，您对像 CRISPR 技术这样具有巨大潜力和危险性的东西有什么看法？
661 01:06:09,621 --> 01:06:11,565 说话人 SPEAKER_00: 我认为它属于同一类别。
662 01:06:12,246 --> 01:06:17,434 说话人 SPEAKER_00: 你不会因为巨大的潜力而停止它，但你必须对巨大的危险采取行动。
663 01:06:18,195 --> 01:06:27,731 说话人 SPEAKER_01: 当你研究这些系统时，这是你要问的问题，作为一个科学家，你在研究这些系统时，是如何意识到这一点的？
664 01:06:27,711 --> 01:06:30,637 说话人 SPEAKER_01: 你在思考这个问题的时候，它是不是从一开始就在那里？
665 01:06:30,697 --> 01:06:52,032 说话人 SPEAKER_01: 我们发现许多科学家都会谈论问题的美丽，解决一个非常非常困难、可能是不可能、具有挑战性的想法的吸引力，被这种吸引力所吸引，想象如果你真的能解决它，然后发现它是如何
666 01:06:52,012 --> 01:06:55,836 Speaker SPEAKER_01: 暗面可能真的更真实。
667 01:06:55,856 --> 01:06:57,199 Speaker SPEAKER_00: 这当然是一个因素。
668 01:06:57,239 --> 01:07:01,244 Speaker SPEAKER_00: 对于我来说，我一直认为 AGI（通用人工智能）还遥不可及。
669 01:07:02,244 --> 01:07:09,014 Speaker SPEAKER_00: 我一直都在制作计算机模型，不是为了实现 AGI，而是为了试图理解大脑是如何工作的。
670 01:07:10,036 --> 01:07:18,626 说话人 SPEAKER_00：我一直认为，如果我们能更多地了解大脑是如何工作的，这可能会在使人们以更理性、更明智的方式行事方面有很大帮助。
671 01:07:19,331 --> 01:07:20,954 说话人 SPEAKER_00：我想这应该是一种信念。
672 01:07:21,574 --> 01:07:27,081 说话人 SPEAKER_00：而且 AGI（通用人工智能），尤其是超级智能，还远在未来。
673 01:07:27,141 --> 01:07:28,882 说话人 SPEAKER_00：所以现在考虑这一点并没有多大意义。
674 01:07:29,903 --> 01:07:39,394 说话人 SPEAKER_00: 然后我在今年大约三月份突然改变了这个看法，当我突然意识到数字智能可能要好得多。
675 01:07:39,835 --> 01:07:41,757 说话人 SPEAKER_00: 因此，它可能很快就会实现。
676 01:07:42,297 --> 01:07:44,019 说话人 SPEAKER_01: 是的。
677 01:07:44,039 --> 01:07:47,583 说话人 SPEAKER_01: 但你将其描述为一种顿悟时刻，对吧。
678 01:07:48,492 --> 01:07:53,657 说话人 SPEAKER_00: 这是一种顿悟，但并不是一个完全积极的顿悟时刻。
679 01:07:54,057 --> 01:07:54,719 说话人 SPEAKER_00: 对，对。
680 01:07:55,079 --> 01:08:01,686 说话人 SPEAKER_00: 这是一个突然的认识，嘿，也许我之前错了，也许这些事物很快就会比我们更聪明。
681 01:08:01,925 --> 01:08:02,686 说话人 SPEAKER_01: 是的。
682 01:08:02,706 --> 01:08:04,829 Speaker SPEAKER_01: 这肯定是一个令人恐惧的时刻，真的。
683 01:08:04,869 --> 01:08:08,172 Speaker SPEAKER_00: 对我来说，那一点... 并不是。
684 01:08:08,333 --> 01:08:10,775 Speaker SPEAKER_00: 对我的孩子来说，这很令人担忧。
685 01:08:13,197 --> 01:08:14,840 Speaker SPEAKER_01: 现在，对于所有有孩子的我们来说，都是这样了。
686 01:08:15,300 --> 01:08:16,862 说话人 SPEAKER_01：我们可以一起担心。
687 01:08:17,533 --> 01:08:18,636 说话人 SPEAKER_01：我们还有时间再问一个问题吗？
688 01:08:18,655 --> 01:08:19,738 说话人 SPEAKER_01：当然。
689 01:08:19,757 --> 01:08:27,409 说话人 SPEAKER_01：好的。
690 01:08:28,712 --> 01:08:29,092 说话人 SPEAKER_01: 等一下。
691 01:08:29,193 --> 01:08:33,439 说话人 SPEAKER_01: 等一下。
692 01:08:33,500 --> 01:08:37,167 说话人 SPEAKER_01: 这里有人这么说，很好的演讲，即使我不懂全部。
693 01:08:38,188 --> 01:08:44,097 说话人 SPEAKER_01: 你会如何说服那些不了解情况的利益相关者，我们正处在一个非常危险的时期？
694 01:08:45,698 --> 01:08:47,640 说话人 SPEAKER_00: 让他们玩 GPT-4。
695 01:08:48,523 --> 01:08:57,979 说话人 SPEAKER_00: 如果他们和 GPT-4 玩耍并问它各种问题，我认为大多数合理的人都会得出结论，这个玩意儿真的很聪明。
696 01:08:59,100 --> 01:09:09,478 说话人 SPEAKER_00: 然后如果我们回顾 10 年前，以及我们 10 年前所拥有的，即使想象进步只是线性的，如果我们有同样的跳跃，
697 01:09:10,319 --> 01:09:15,625 说话人 SPEAKER_00: 就像我们从 10 年前到现在所取得的进步一样，我们 10 年后还得再跳一次这样的距离。
698 01：09：16,867 --> 01：09：18,628 议长 SPEAKER_00：到那时我们会有的样子真是太可怕了。
所以，就随便玩玩 Chat GPT-4。
700 01:09:24,274 --> 01:09:26,797 说话者 SPEAKER_01：并让自己相信它真的理解了。
701 01：09：27,278 --> 01：09：28,059 议长 SPEAKER_00：是的，是的。
702 01:09:28,198 --> 01:09:32,224 说话人 SPEAKER_00: 然后想想这比我们 10 年前好多少。
703 01:09:32,685 --> 01:09:32,944 说话人 SPEAKER_00: 是的。
704 01:09:33,546 --> 01:09:36,529 说话人 SPEAKER_00: 想象一下在接下来的 10 年里再好这么多。
705 01:09:38,618 --> 01:09:53,412 说话人 SPEAKER_01: 所以我猜，虽然，我的意思是，这可能是显而易见的，但仅仅因为您离开了谷歌，并不意味着谷歌不再参与这项研究并且大幅加速它。
706 01:09:53,431 --> 01:09:56,114 说话人 SPEAKER_00：我只是他们研究努力中的一小部分。
707 01:09:57,775 --> 01:10:01,500 说话人 SPEAKER_00：我主要是去给那些真正在做工作的年轻研究人员提供建议。
708 01:10:02,201 --> 01:10:05,823 说话人 SPEAKER_00：不，谷歌在这方面
709 01:10:05,972 --> 01:10:07,194 说话人 SPEAKER_00：全力以赴。
710 01:10:07,434 --> 01:10:11,197 说话人 SPEAKER_00: 谷歌在这方面曾领先一步，但它选择不发布。
711 01:10:12,217 --> 01:10:17,021 说话人 SPEAKER_00: 它在制作非常逼真的图像和这些大型语言模型方面曾领先。
712 01:10:17,802 --> 01:10:20,645 说话人 SPEAKER_00: 它意识到这些技术很容易被滥用。
713 01:10:21,305 --> 01:10:28,612 说话人 SPEAKER_00: 它不想因为生产不真实、不可靠的东西而破坏自己的声誉。
714 01:10:30,033 --> 01:10:31,314 说话人 SPEAKER_00: 没有发布这些内容。
715 01:10:32,135 --> 01:10:35,557 说话人 SPEAKER_00: 当它是唯一拥有这些技术的公司时，它可以这么做。
716 01:10:35,537 --> 01:10:36,502 说话人 SPEAKER_01: 是的。
717 01:10:36,521 --> 01:10:43,707 说话人 SPEAKER_00: 但是当微软发布了开源 AI 后，
718 01:10:43,992 --> 01:10:50,100 说话人 SPEAKER_00：必应聊天机器人，谷歌别无选择，只能追赶。
719 01:10:50,140 --> 01:10:53,024 说话人 SPEAKER_00：他们在发布这些产品所涉及的各个方面都落后了。
720 01:10:53,865 --> 01:10:55,028 说话人 SPEAKER_00：现在他们差不多赶上了。
721 01:10:55,087 --> 01:11:04,360 说话人 SPEAKER_00：从现在开始，将是谷歌和微软之间的竞争，也许还有 Facebook 和可能亚马逊。
722 01:11:05,061 --> 01:11:09,948 说话人 SPEAKER_00：让它慢下来将会非常困难。
723 01:11:11,515 --> 01:11:19,682 说话人 SPEAKER_01：你认为这种热情是代际定义的吗？
724 01:11:19,703 --> 01:11:32,293 说话人 SPEAKER_01：换句话说，你认为今天从大学毕业、拥有计算机科学学位的年轻人对吸引人的可能性感到兴奋，而没有注意到危险吗？
725 01:11:32,835 --> 01:11:38,399 说话人 SPEAKER_01：还是你认为他们同样清楚，并试图弄明白？
726 01:11:39,797 --> 01:11:47,546 说话人 SPEAKER_00：我想我没有任何数据来作为答案的依据，但我的猜测是它们都有情感。
727 01:11:47,667 --> 01:11:48,707 说话人 SPEAKER_00：这非常令人兴奋。
728 01:11:48,728 --> 01:11:49,930 说话人 SPEAKER_00：这里有很大的潜力。
729 01:11:51,671 --> 01:11:57,378 说话人 SPEAKER_00：他们绝对应该涉足其中，他们应该在做或者在他们所做的事情中使用它。
730 01:11:59,360 --> 01:12:01,984 说话人 SPEAKER_00: 我认为他们中的许多人都会意识到危险。
731 01:12:05,047 --> 01:12:08,792 说话人 SPEAKER_00: 他们已经在社交媒体上看到了危险，社交媒体导致的极化危险。
732 01:12:09,497 --> 01:12:09,778 说话人 SPEAKER_01: 是的。
733 01:12:10,899 --> 01:12:11,640 说话人 SPEAKER_01: 希望是这样。
734 01:12:11,902 --> 01:12:14,364 说话人 SPEAKER_01: 我们希望他们无论如何都会觉得它们很危险。
735 01:12:14,765 --> 01:12:14,926 说话人 SPEAKER_01: 是的。
736 01:12:14,945 --> 01:12:16,488 说话人 SPEAKER_01: 是的。
737 01:12:16,507 --> 01:12:21,395 说话人 SPEAKER_01: 嗯，Geoffrey Hinton，和你在一起这段时间非常有趣。
738 01:12:21,456 --> 01:12:22,337 说话人 SPEAKER_01: 非常感谢。
739 01:12:23,738 --> 01:12:25,822 说话人 SPEAKER_01: 如果你有最后的话，现在就是你的时刻。
740 01:12:28,405 --> 01:12:34,094 说话人 SPEAKER_00: 是的，我的最后的话是，我们正进入一个非常不确定的历史时期。
741 01:12:34,414 --> 01:12:39,301 说话人 SPEAKER_00: 我们以前从未遇到过甚至比我们更聪明的东西的可能性。
742 01:12:39,636 --> 01:12:40,438 说话人 SPEAKER_00: 嗯。
743 01:12:40,838 --> 01:12:42,801 说话人 SPEAKER_00: 没有人知道会发生什么。
744 01:12:43,301 --> 01:12:45,864 说话人 SPEAKER_00: 有些人非常自信一切都会顺利进行。
745 01:12:46,466 --> 01:12:48,849 说话人 SPEAKER_00: 而有些人则非常自信那将是一场彻底的灾难。
746 01:12:49,670 --> 01:12:49,770 说话人 SPEAKER_00: 嗯。
747 01:12:49,789 --> 01:12:55,396 说话人 SPEAKER_00: 我认为最好的做法是保持非常开放的心态，因为我们真的不知道会发生什么。
748 01:12:56,137 --> 01:12:58,541 说话人 SPEAKER_00: 但如果是那样的话，我们应该保持清醒的警惕。
749 01:13:00,382 --> 01:13:01,685 说话人 SPEAKER_01: 好的，这是我们应该遵循的话。
750 01:13:02,326 --> 01:13:03,346 说话人 SPEAKER_01: 谢谢，杰弗里·辛顿。
751 01:13:03,967 --> 01:13:04,868 说话人 SPEAKER_01: 感谢您的邀请。
752 01:13:05,270 --> 01:13:05,609 说话人 SPEAKER_00: 谢谢。
