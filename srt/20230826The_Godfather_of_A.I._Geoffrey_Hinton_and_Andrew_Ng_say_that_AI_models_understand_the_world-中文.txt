1 00:00:00,031 --> 00:00:03,278 说话人 SPEAKER_00: 好的，所以我们决定总结一下我们之前讨论的内容。
2 00:00:04,801 --> 00:00:06,905 说话人 SPEAKER_00: 提出了两个主要观点。
3 00:00:09,430 --> 00:00:18,850 说话人 SPEAKER_00: 其中一个是我们需要人工智能研究人员达成共识。
4 00:00:19,420 --> 00:00:32,304 说话人 SPEAKER_00: 就像气候科学家在气候变化问题上达成共识一样，因为政治家和决策者将寻求人工智能研究人员的专业技术意见。
5 00:00:32,884 --> 00:00:41,682 说话人 SPEAKER_00: 如果人工智能研究人员有各种各样的意见，那么他们就能挑选出适合他们的任何东西。
6 00:00:42,909 --> 00:00:49,060 说话人 SPEAKER_00: 目前意见分歧很大，在一定程度上，阵营内部存在冲突。
7 00:00:49,981 --> 00:01:10,031 说话人 SPEAKER_00: 如果我们能克服这个阶段，达到人们大致同意人工智能的主要威胁是什么，或者至少同意一些主要威胁，并且也同意它们的紧迫性和危险性，那就太好了。
8 00:01:12,373 --> 00:01:14,237 说话人 SPEAKER_01: 这就是一个问题。
9 00:01:14,980 --> 00:01:16,903 说话人 SPEAKER_01：我想插一句，我完全同意。
10 00:01:17,484 --> 00:01:23,638 说话人 SPEAKER_01：我从未见过 AI 社区像现在这样呈现出分裂的趋势。
11 00:01:23,677 --> 00:01:32,576 说话人 SPEAKER_01：包括美国在内的许多国家，都出现了极端的分化，不同的阵营相互喊叫，而不是进行对话。
12 00:01:32,557 --> 00:01:38,444 说话人 SPEAKER_01：我认为 AI 社区并没有那么糟糕，但它的某些迹象确实令人担忧，可能会走向那个方向。
13 00:01:38,504 --> 00:01:55,745 说话人 SPEAKER_01：如果我们能集体弄清楚科学和我们对风险的最好评估，从灾难性的到像灭绝一样糟糕的一切，有一个共同的观点，进行对话，让我们都达成共识，我们就可以更好地引导，帮助政策制定者。
14 00:01:55,906 --> 00:01:56,126 说话人 SPEAKER_00：没错。
15 00:01:57,128 --> 00:02:00,572 说话人 SPEAKER_00：所以这将是研究人员要追求的一个目标。
16 00:02:00,552 --> 00:02:19,623 说话人 SPEAKER_00：然后第二个观点是，我认为研究人员就这些大型聊天机器人如 GPT-4 或 BARD 是否真正理解他们所说的话达成共识是非常紧迫的。
17 00:02:21,088 --> 00:02:25,355 说话人 SPEAKER_00: 很明显，有些人认为他们确实如此，有些人认为它们只是随机的鹦鹉。
18 00:02:26,557 --> 00:02:35,551 说话人 SPEAKER_00: 只要我们存在这些差异，我们就无法就危险达成共识。
19 00:02:35,572 --> 00:02:45,527 说话人 SPEAKER_00: 因此，我认为研究界迫切需要解决这个问题，即他们是否真的理解。
20 00:02:46,408 --> 00:02:48,953 说话人 SPEAKER_00: 我认为我们都认为他们确实理解。
21 00:02:49,050 --> 00:02:52,820 说话人 SPEAKER_00: 我们非常尊敬的人，比如 Jan，认为他们实际上并不真正理解。
22 00:02:52,860 --> 00:02:58,156 说话人 SPEAKER_00: 解决这个问题至关重要。
23 00:02:58,256 --> 00:03:03,550 说话人 SPEAKER_00: 我们可能无法在其他问题上达成共识，除非我们解决了那个问题。
24 00:03:04,862 --> 00:03:12,735 说话人 SPEAKER_01: 术语理解的一个挑战是，没有向我们展示测试系统是否理解测试。
25 00:03:13,235 --> 00:03:24,271 说话人 SPEAKER_01：我认为我的观点是，我相信大型语言模型和其他大型 AI 模型正在构建一个世界模型。
26 00:03:24,252 --> 00:03:26,795 说话人 SPEAKER_01：或者说正在构建一个看起来很像世界模型的东西。
27 00:03:26,876 --> 00:03:34,068 说话人 SPEAKER_01：所以我的直觉是，我相信它在构建世界模型的过程中，确实在传达对世界的某种理解。
28 00:03:35,210 --> 00:03:37,173 说话人 SPEAKER_01：但这只是我现在的看法。
29 00:03:37,574 --> 00:03:47,289 说话人 SPEAKER_01：我认为这正如你所说，Jeff，是研究界需要更多讨论和辩论，并达成共识的一个话题。
30 00:03:47,741 --> 00:03:59,939 说话人 SPEAKER_01：我认为这将是如果我们在这方面达成一致，可能会让我们以更一致的方式进行推理，并可能作为社区在 AI 风险方面获得更好的共识的问题之一。
31 00:04:00,600 --> 00:04:01,241 说话人 SPEAKER_00：没错。
32 00:04:01,262 --> 00:04:06,889 说话人 SPEAKER_00：这个话题的一个方面是，它只是统计学。
33 00:04:06,909 --> 00:04:09,854 说话人 说话人_00: 我们都同意在某种程度上这必须是纯粹的数据统计。
34 00:04:10,314 --> 00:04:14,661 说话人 说话人_00: 所有这些事物所拥有的只是它们输入的数据统计。
35 00:04:15,247 --> 00:04:23,319 说话人 说话人_00: 认为这仅仅是数据统计的许多人，是在诸如三元模型或计算词语共现频率等事物上思考的。
36 00:04:24,360 --> 00:04:25,903 说话人 说话人_00: 而不仅仅如此。
37 00:04:26,122 --> 00:04:37,959 说话人 SPEAKER_00: 我们认为，这个过程，即创建嵌入特征以及特征之间的交互，实际上就是理解。
38 00:04:39,822 --> 00:04:40,463 说话人 SPEAKER_00: 一旦你
39 00:04:41,944 --> 00:05:04,569 说话人 SPEAKER_00: 一旦你获得了符号字符串的原始数据，你现在可以预测下一个符号，不是通过像三联词这样的方法，而是通过大量特征以非常复杂的方式相互作用来预测下一个单词的特征，并据此预测下一个单词的概率。
40 00:05:04,589 --> 00:05:07,033 说话人 SPEAKER_00: 关键在于，那才是理解。
41 00:05:07,173 --> 00:05:08,795 说话人 SPEAKER_00：至少我相信那是理解。
42 00:05:08,814 --> 00:05:11,057 说话人 SPEAKER_00：我相信这也是我们大脑在做的事情。
43 00:05:11,627 --> 00:05:23,257 说话人 SPEAKER_00：但这是一个需要由研究界讨论的问题，如果能说服人们他们不是仅仅是无序的鹦鹉，那就太好了。
44 00:05:24,199 --> 00:05:40,892 说话人 SPEAKER_01：我认为，可能有一系列问题，关于 AI 系统是否真正理解世界，这导致不同的人对 AI 的灾难性或甚至灭绝风险的类型和性质得出不同的合理结论。
45 00:05:40,913 --> 00:05:41,954 说话人 SPEAKER_01：我认为
46 00:05:42,526 --> 00:05:46,891 说话人 SPEAKER_01：更好地理解 AI 是否理解，这将是其中之一。
47 00:05:47,473 --> 00:05:55,362 说话人 SPEAKER_01：可能还有一些其他值得提出的问题，这些问题可能会让我们作为一个社区得出更相似的结论。
48 00:05:56,244 --> 00:05:57,204 说话人 SPEAKER_01：是的，那会很好。
49 00:05:58,447 --> 00:06:01,190 说话人 说话人_00：好的，感谢这次对话。
50 00:06:01,350 --> 00:06:06,997 说话人 说话人_01：是的，我期待继续对话，我们也是，也希望和每个人。
51 00:06:07,017 --> 00:06:07,478 说话人 说话人_01：谢谢，杰夫。
52 00:06:07,718 --> 00:06:09,141 说话人 说话人_00：好的，再见。
