1
00:00:04,637 --> 00:00:06,179
发言人 SPEAKER_00: 感谢约翰的精彩介绍。

2
00:00:08,683 --> 00:00:11,407
发言人 SPEAKER_00: 在开始之前，我想谈谈伊恩·霍华德（Ian Howard）。

3
00:00:12,087 --> 00:00:15,313
发言人 SPEAKER_00: 我曾非常喜欢访问约克大学并与伊恩·霍华德交流。

4
00:00:15,333 --> 00:00:17,295
发言人 SPEAKER_00: 他是一位真正伟大的科学家。

5
00:00:17,315 --> 00:00:21,882
发言人 SPEAKER_00: 他给我的印象，就像是我能接触到的最接近维多利亚时代科学家的人物。

6
00:00:23,324 --> 00:00:24,506
发言人 SPEAKER_00: 他热爱动手创造。

7
00:00:26,609 --> 00:00:28,131
发言人 SPEAKER_00: 因此，约克总让我想起伊恩。

8
00:00:30,068 --> 00:00:34,473
发言人 SPEAKER_00: 今天我将讨论已发表的胶囊网络（Capsule Networks）相关工作。

9
00:00:37,878 --> 00:00:42,404
发言人 SPEAKER_00: 当前物体识别的主流方法是使用卷积神经网络（CNN）。

10
00:00:44,167 --> 00:00:47,771
发言人 SPEAKER_00: 它们通过多层可学习的判别性特征检测器工作。

11
00:00:49,853 --> 00:00:50,314
发言人 SPEAKER_00: 这很好。

12
00:00:51,496 --> 00:00:56,362
发言人 SPEAKER_00: 这些特征具有局部性，每种特征检测器在空间上重复出现。

13
00:00:57,490 --> 00:01:01,534
发言人 SPEAKER_00: 因此可以处理物体移动或位置变化的情况。

14
00:01:02,136 --> 00:01:02,536
发言人 SPEAKER_00: 这很好。

15
00:01:03,457 --> 00:01:11,387
发言人 SPEAKER_00: 随着特征层级的升高，特征检测器的感受野逐渐扩大，这也是优点。

16
00:01:14,251 --> 00:01:23,262
发言人 SPEAKER_00: 特征检测器之间插入下采样层（池化层），目的是获得不变性（invariance），

17
00:01:24,456 --> 00:01:28,331
发言人 SPEAKER_00: 同时丢弃位置信息。

18
00:01:28,350 --> 00:01:28,992
发言人 SPEAKER_00: 而这很糟糕。

19
00:01:29,835 --> 00:01:33,689
发言人 SPEAKER_00: 我将详细说明为何这是弊端。

20
00:01:39,138 --> 00:01:51,233
发言人 SPEAKER_00: 当前用于物体识别的卷积神经网络（ConvNets）难以泛化到新的方向、尺度或剪切变换。

21
00:01:52,355 --> 00:02:01,347
发言人 SPEAKER_00: 它们无法系统处理视角变化对图像的影响。

22
00:02:01,328 --> 00:02:05,918
发言人 SPEAKER_00: 图像变化的最大来源正是视角变化。

23
00:02:06,721 --> 00:02:09,586
发言人 SPEAKER_00: 其他变化如光照等也存在影响。

24
00:02:10,169 --> 00:02:14,038
发言人 SPEAKER_00: 但视角变化对机器学习尤为棘手。

25
00:02:14,778 --> 00:02:17,245
发言人 SPEAKER_00: 我将解释其根本原因。

26
00:02:17,680 --> 00:02:22,384
发言人 SPEAKER_00: 同一物体部位在不同视角下会映射到不同像素区域。

27
00:02:24,106 --> 00:02:29,152
发言人 SPEAKER_00: 这相当于两家医院采用不同的数据编码方式。

28
00:02:29,193 --> 00:02:33,598
发言人 SPEAKER_00: 例如，医院A按年龄、体重、血型、财务状况排序，

29
00:02:34,098 --> 00:02:39,024
发言人 SPEAKER_00: 医院B则按体重、血型、年龄、财务状况排列。

30
00:02:39,985 --> 00:02:42,927
发言人 SPEAKER_00: （必须包含财务状况）

31
00:02:42,907 --> 00:02:55,508
发言人 SPEAKER_00: 若已知相同信息出现在不同输入维度，直接进行机器学习而不处理这种编码差异是不合理的。

32
00:02:55,528 --> 00:02:59,977
发言人 SPEAKER_00: 但当前方法寄望于海量数据的统计平均来抵消这种影响。

33
00:03:01,520 --> 00:03:07,650
发言人 SPEAKER_00: 显然，更优方案是进行数据对齐，使各维度含义一致。

34
00:03:07,764 --> 00:03:10,807
发言人 SPEAKER_00: 这正是视角变化带来的根本挑战。

35
00:03:10,828 --> 00:03:12,850
发言人 SPEAKER_00: 相同信息映射到不同像素区域。

36
00:03:14,092 --> 00:03:23,322
发言人 SPEAKER_00: 卷积网络试图通过池化操作和大量多视角数据来缓解此问题，

37
00:03:23,543 --> 00:03:32,473
发言人 SPEAKER_00: 但池化仅能保证邻近区域激活相同特征检测器，

38
00:03:32,492 --> 00:03:35,376
发言人 SPEAKER_00: 这并非处理视角变化的系统性方案。

39
00:03:35,760 --> 00:03:39,668
发言人 SPEAKER_00: 本次演讲将探讨如何系统性应对视角变化。

40
00:03:39,687 --> 00:03:42,092
发言人 SPEAKER_00: 卷积网络的优点在于处理平移不变性。

41
00:03:42,955 --> 00:03:57,481
发言人 SPEAKER_00: 由于特征检测器的空间复制特性，图像平移时，相同类型的特征检测器会在新位置响应。

42
00:03:58,237 --> 00:04:00,084
发言人 SPEAKER_00: 这并非严格的不变性，而是等变性（equivariance）。

43
00:04:01,026 --> 00:04:03,375
发言人 SPEAKER_00: 更正：这属于等变性而非不变性。

44
00:04:03,776 --> 00:04:08,110
发言人 SPEAKER_00: 图像平移时，响应的特征检测器位置也随之平移。

45
00:04:08,412 --> 00:04:10,037
发言人 SPEAKER_00: 因此平移信息在系统中得以保留。

46
00:04:15,534 --> 00:04:20,668
发言人 SPEAKER_00: 卷积网络的另一缺陷是缺乏解析树结构。

47
00:04:20,848 --> 00:04:26,603
发言人 SPEAKER_00: 从心理学角度看，人类视觉会构建场景的解析结构。

48
00:04:26,663 --> 00:04:31,214
发言人 SPEAKER_00: 例如明确各部件归属关系。

49
00:04:31,194 --> 00:04:35,000
发言人 SPEAKER_00: 现有网络无法做到这点。

50
00:04:35,019 --> 00:04:39,865
发言人 SPEAKER_00: 此外，网络不会为物体分配固有参考系。

51
00:04:40,966 --> 00:04:45,112
发言人 SPEAKER_00: 心理学实验表明参考系的重要性：

52
00:04:46,112 --> 00:04:57,826
发言人 SPEAKER_00: 例如观察左侧图形，初始可能误认为镜像的澳大利亚，

53
00:04:58,786 --> 00:05:03,932
发言人 SPEAKER_00: 但告知其对角线方向后，可识别为非洲大陆。

54
00:05:03,952 --> 00:05:12,985
发言人 SPEAKER_00: 右侧菱形/倾斜正方形双关图则展示不同参考系导致的不同感知。

55
00:05:13,086 --> 00:05:15,249
发言人 SPEAKER_00: 正确参考系下，识别即刻完成。

56
00:05:15,269 --> 00:05:17,351
发言人 SPEAKER_00: 但参考系错误时，认知完全失效。

57
00:05:19,093 --> 00:05:24,180
发言人 SPEAKER_00: 卷积网络无法实现这种基于参考系的多重解释。

58
00:05:24,261 --> 00:05:27,105
发言人 SPEAKER_00: 其输入到输出的映射是确定性的。

59
00:05:28,233 --> 00:05:31,377
发言人 SPEAKER_00: 因此，显式分配参考系是处理视角变化的关键。

60
00:05:32,237 --> 00:05:33,899
发言人 SPEAKER_00: 通过三维拼图实验说明：

61
00:05:34,019 --> 00:05:45,093
发言人 SPEAKER_00: 将四面体用平面切割为两部分，要求MIT教授重组，结果多数人耗时极长甚至失败。

62
00:05:47,235 --> 00:05:50,740
发言人 SPEAKER_00: 实验揭示人类依赖固有参考系进行空间认知，

63
00:05:51,480 --> 00:05:56,906
发言人 SPEAKER_00: 而参考系的错误匹配导致重组困难。

64
00:05:57,798 --> 00:06:09,255
发言人 SPEAKER_00: 该现象与Muller-Lyer错觉类似，显示感知系统对几何关系的编码机制。

65
00:06:09,737 --> 00:06:11,620
发言人 SPEAKER_00: 解决方案是构建显式参考系：

66
00:06:12,221 --> 00:06:16,767
发言人 SPEAKER_00: 胶囊网络通过姿态矩阵（pose matrix）编码部件与整体的几何关系，

67
00:06:18,132 --> 00:06:20,415
发言人 SPEAKER_00: 实现视角不变的部件-整体推理。

68
00:06:21,797 --> 00:06:24,980
发言人 SPEAKER_00: 其核心在于动态路由（dynamic routing）机制：

69
00:06:25,882 --> 00:06:27,803
发言人 SPEAKER_00: 底层胶囊预测高层姿态，

70
00:06:28,625 --> 00:06:37,297
发言人 SPEAKER_00: 通过高维一致性过滤（high-dimensional coincidence filtering）达成共识。

71
00:06:39,079 --> 00:06:43,144
发言人 SPEAKER_00: 实验证明，经过3次路由迭代即可收敛，

72
00:06:44,017 --> 00:06:46,060
发言人 SPEAKER_00: 显著优于传统聚类算法。

73
00:06:46,081 --> 00:06:47,862
发言人 SPEAKER_00: 在NORB小样本数据集上，

74
00:06:48,803 --> 00:06:55,934
发言人 SPEAKER_00: 胶囊网络取得1.8%错误率，优于传统CNN的2.56%。

75
00:06:55,954 --> 00:06:57,154
发言人 SPEAKER_00: 关键创新在于：

76
00:06:58,776 --> 00:07:00,480
发言人 SPEAKER_00: 1. 胶囊结构封装多维属性

77
00:07:00,540 --> 00:07:06,987
发言人 SPEAKER_00: 2. 姿态矩阵编码几何变换

78
00:07:09,095 --> 00:07:14,220
发言人 SPEAKER_00: 3. 动态路由实现部件-整体关系推断

79
00:07:15,721 --> 00:07:16,521
发言人 SPEAKER_00: 局限性包括：

80
00:07:16,603 --> 00:07:23,249
发言人 SPEAKER_00: 当前实现限于刚性物体，非刚性形变处理仍需改进。

81
00:07:25,050 --> 00:07:25,411
发言人 SPEAKER_00: 总结：

82
00:07:25,511 --> 00:07:27,512
发言人 SPEAKER_00: 胶囊网络通过显式几何建模，

83
00:07:28,374 --> 00:07:30,196
发言人 SPEAKER_00: 为解决视角变化问题提供新范式。

84
00:07:33,278 --> 00:07:37,043
发言人 SPEAKER_00: 未来工作将整合可微分渲染器，

85
00:07:39,942 --> 00:07:46,117
发言人 SPEAKER_00: 实现从像素到三维姿态的端到端学习。

86
00:07:47,038 --> 00:07:47,600
发言人 SPEAKER_00: 这就是实验道具。

87
00:07:48,000 --> 00:07:53,254
发言人 SPEAKER_00: 这两个部件可以组成四面体，对吧？

88
00:07:53,334 --> 00:07:54,997
发言人 SPEAKER_00: 它们是全同部件。

89
00:07:55,535 --> 00:07:56,596
发言人 SPEAKER_00: 观察发现：

90
00:07:56,656 --> 00:08:00,322
发言人 SPEAKER_00: 被试者倾向于将相同形状的面对齐拼接。

91
00:08:00,362 --> 00:08:00,843
发言人 SPEAKER_00: 例如：

92
00:08:00,882 --> 00:08:01,725
发言人 SPEAKER_00: 将梯形面对接，

93
00:08:01,764 --> 00:08:04,269
发言人 SPEAKER_00: 但无法形成四面体。

94
00:08:04,509 --> 00:08:05,069
发言人 SPEAKER_00: 继续尝试：

95
00:08:05,610 --> 00:08:07,093
发言人 SPEAKER_00: 三角形面对接，

96
00:08:08,134 --> 00:08:09,737
发言人 SPEAKER_00: 仍无法构成有效结构。

97
00:08:09,757 --> 00:08:10,678
发言人 SPEAKER_00: 典型错误示范：

98
00:08:10,778 --> 00:08:11,420
发言人 SPEAKER_00: 被试者反复试错，

99
00:08:11,439 --> 00:08:12,461
发言人 SPEAKER_00: 耗时长达数十分钟。

100
00:08:12,482 --> 00:08:12,982
发言人 SPEAKER_00: 关键问题：

101
00:08:13,202 --> 00:08:15,365
发言人 SPEAKER_00: 为何高智商群体也难破解？

102
00:08:16,747 --> 00:08:18,369
发言人 SPEAKER_00: 解析该现象需理解：

103
00:08:18,730 --> 00:08:20,552
发言人 SPEAKER_00: 人类视觉系统依赖固有参考系。

104
00:08:21,132 --> 00:08:22,755
发言人 SPEAKER_00: 当观察三维物体时，

105
00:08:22,915 --> 00:08:37,756
发言人 SPEAKER_00: 大脑自动建立正交坐标系（X/Y/Z轴）。该参考系与四面体的标准数学定义存在偏差，导致空间推理困难。

106
00:08:39,038 --> 00:08:43,966
发言人 SPEAKER_00: 正确解法需突破固有参考系：

107
00:08:44,005 --> 00:08:45,488
发言人 SPEAKER_00: 将部件旋转45度，

108
00:08:46,327 --> 00:08:52,033
发言人 SPEAKER_00: 使截面正方形的几何对称性显现。

109
00:08:52,914 --> 00:08:54,135
发言人 SPEAKER_00: 该现象揭示：

110
00:08:54,677 --> 00:08:57,700
发言人 SPEAKER_00: 视觉认知受制于心理参考系约束，

111
00:08:57,720 --> 00:09:02,404
发言人 SPEAKER_00: 这种约束在穆勒-莱尔错觉中同样显著。

112
00:09:03,485 --> 00:09:08,051
发言人 SPEAKER_00: 当线段端点加入方向标记时，

113
00:09:08,811 --> 00:09:11,634
发言人 SPEAKER_00: 人脑会系统性误判长度。

114
00:09:12,595 --> 00:09:14,277
发言人 SPEAKER_00: 该错觉说明：

115
00:09:15,725 --> 00:09:20,870
发言人 SPEAKER_00: 视觉系统并非直接处理原始信号，

116
00:09:22,732 --> 00:09:25,576
发言人 SPEAKER_00: 而是基于先验参考系进行重建。

117
00:09:25,655 --> 00:09:29,841
发言人 SPEAKER_00: 这种重建机制导致几何认知偏差。

118
00:09:29,900 --> 00:09:32,303
发言人 SPEAKER_00: 对AI系统的启示：

119
00:09:32,683 --> 00:09:33,664
发言人 SPEAKER_00: 传统CNN缺乏：

120
00:09:34,505 --> 00:09:38,931
发言人 SPEAKER_00: 1. 显式参考系建模能力

121
00:09:40,008 --> 00:09:45,072
发言人 SPEAKER_00: 2. 动态参考系调整机制

122
00:09:45,994 --> 00:09:51,399
发言人 SPEAKER_00: 胶囊网络的突破在于：

123
00:09:52,279 --> 00:09:59,265
发言人 SPEAKER_00: 通过姿态矩阵显式编码部件-整体几何关系，

124
00:09:59,846 --> 00:10:06,352
发言人 SPEAKER_00: 实现参考系无关的几何推理。

125
00:10:06,534 --> 00:10:14,500
发言人 SPEAKER_00: 该机制使网络能动态构建多重参考系，

126
00:10:15,241 --> 00:10:17,067
发言人 SPEAKER_00: 突破单参考系认知局限。

127
00:10:18,820 --> 00:10:28,254
发言人 SPEAKER_00: 观察该部件在四面体中的嵌入方式时，其直角坐标系与四面体自身的数学坐标系存在本质差异。

128
00:10:28,594 --> 00:10:39,070
发言人 SPEAKER_00: 标准四面体坐标系以顶点垂线为纵轴，但部件三角形截面的对称性破坏导致坐标轴重构困难。

129
00:10:39,590 --> 00:10:42,735
发言人 SPEAKER_00: 这种几何失配使得传统参考系难以直接应用。

130
00:10:43,524 --> 00:10:48,532
发言人 SPEAKER_00: 人类认知系统具备双重表征能力：

131
00:10:48,971 --> 00:10:52,756
发言人 SPEAKER_00: 既可通过刚性坐标系理解物体，也可通过拓扑连接构建心理表征。

132
00:10:55,000 --> 00:11:02,529
发言人 SPEAKER_00: 后者表现为将四面体视为上下两正交棱边的全连接结构，

133
00:11:03,421 --> 00:11:08,846
发言人 SPEAKER_00: 所有连接棱边的集合自然形成四面体拓扑。

134
00:11:09,528 --> 00:11:11,669
发言人 SPEAKER_00: 这种表征方式突破欧式空间约束，

135
00:11:12,250 --> 00:11:17,297
发言人 SPEAKER_00: 使得截取正方形截面这一非直观操作变得可解释。

136
00:11:17,557 --> 00:11:23,923
发言人 SPEAKER_00: 根据中间值定理，上下矩形截面的渐近变化必然存在正方形临界点。

137
00:11:24,565 --> 00:11:26,126
发言人 SPEAKER_00: 上部截面呈现纵向矩形，

138
00:11:26,147 --> 00:11:27,607
发言人 SPEAKER_00: 下部截面呈现横向矩形，

139
00:11:27,668 --> 00:11:31,673
发言人 SPEAKER_00: 几何连续性保证中间必存在理想正方形截面。

140
00:11:34,100 --> 00:11:45,943
发言人 SPEAKER_00: 本实验深刻揭示：视觉认知本质是参考系强加过程，而非被动接收。

141
00:11:45,964 --> 00:11:53,658
发言人 SPEAKER_00: 传统卷积神经网络（CNN）缺乏这种主动参考系构建能力，

142
00:11:53,678 --> 00:11:54,100
发言人 SPEAKER_00: 此为根本缺陷。

143
00:12:04,136 --> 00:12:19,529
发言人 SPEAKER_00: 本研究旨在改造前馈神经网络架构，建立视点不变的几何推理机制。

144
00:12:21,350 --> 00:12:27,375
发言人 SPEAKER_00: 现有神经网络技术本质是工程化产物：

145
00:12:27,917 --> 00:12:29,057
发言人 SPEAKER_00: 受生物神经元启发，

146
00:12:30,058 --> 00:12:32,000
发言人 SPEAKER_00: 但运作机制完全不同。

147
00:12:32,441 --> 00:12:33,741
发言人 SPEAKER_00: 网络结构实为人工设计产物。

148
00:12:35,283 --> 00:12:40,629
发言人 SPEAKER_00: 需澄清误区：神经网络非神秘存在，

149
00:12:41,149 --> 00:12:42,811
发言人 SPEAKER_00: 实为经验主义工程实践结晶。

150
00:12:42,831 --> 00:12:45,014
发言人 SPEAKER_00: 以激活函数演进为例：

151
00:12:45,793 --> 00:12:50,479
发言人 SPEAKER_00: 早期30年使用Sigmoid函数，后转向ReLU，

152
00:12:50,458 --> 00:12:52,923
发言人 SPEAKER_00: 皆因后者更易优化。

153
00:12:54,284 --> 00:12:55,866
发言人 SPEAKER_00: 二者均非生物真实机制。

154
00:12:56,508 --> 00:13:02,277
发言人 SPEAKER_00: 神经网络本质是参数化系统的梯度优化实践：

155
00:13:02,317 --> 00:13:06,543
发言人 SPEAKER_00: 通过海量参数空间中的随机梯度下降实现函数逼近。

156
00:13:08,649 --> 00:13:30,642
发言人 SPEAKER_00: 深度学习革命性发现：在超高维参数系统中，基于小批量样本的随机梯度下降（SGD）具有惊人有效性。

157
00:13:31,567 --> 00:13:46,193
发言人 SPEAKER_00: 优化过程遵循：小样本梯度估计→参数微调→迭代更新的循环机制。

158
00:13:46,634 --> 00:13:47,836
发言人 SPEAKER_00: 此方法：

159
00:13:47,817 --> 00:13:50,178
发言人 SPEAKER_00: 理论预期效率低下，

160
00:13:50,298 --> 00:13:53,783
发言人 SPEAKER_00: 实证却显示渐近高效性。

161
00:13:55,283 --> 00:13:58,966
发言人 SPEAKER_00: 即便简单如SGD，其优化效率已达理论极限。

162
00:13:59,768 --> 00:14:05,714
发言人 SPEAKER_00: 任何改进仅能获得多项式级别增益，无法实现阶跃突破。

163
00:14:06,293 --> 00:14:10,498
发言人 SPEAKER_00: 当前挑战转为：

164
00:14:10,738 --> 00:14:15,562
发言人 SPEAKER_00: 如何设计更优架构以充分发挥SGD潜力。

165
00:14:16,740 --> 00:14:20,346
发言人 SPEAKER_00: 现有网络架构存在严重缺陷：

166
00:14:21,427 --> 00:14:26,475
发言人 SPEAKER_00: 缺陷一：传统神经元缺乏等价性判断能力。

167
00:14:27,498 --> 00:14:29,179
发言人 SPEAKER_00: 标准神经元架构（线性变换+非线性激活）

168
00:14:30,182 --> 00:14:31,244
发言人 SPEAKER_00: 无法解决：

169
00:14:31,264 --> 00:14:34,227
发言人 SPEAKER_00: 输入模式等价性判断问题。

170
00:14:35,309 --> 00:14:43,001
发言人 SPEAKER_00: 典型如异或（XOR）问题：无法通过单层感知机判断输入对(1,1)/(0,0)与(1,0)/(0,1)的类别差异。

171
00:14:43,538 --> 00:14:45,061
发言人 SPEAKER_00: 传统解决方案：

172
00:14:45,081 --> 00:14:51,071
发言人 SPEAKER_00: 引入隐藏层实现线性可分，此即多层感知机（MLP）基础。

173
00:14:51,952 --> 00:14:52,614
发言人 SPEAKER_00: 该方案有效，

174
00:14:52,634 --> 00:14:55,138
发言人 SPEAKER_00: 但非唯一解。

175
00:14:55,698 --> 00:14:57,062
发言人 SPEAKER_00: 替代方案：

176
00:14:57,722 --> 00:14:59,866
发言人 SPEAKER_00: 设计具有协方差检测能力的神经元变体。

177
00:15:00,748 --> 00:15:01,068
发言人 SPEAKER_00: 具体而言：

178
00:15:01,288 --> 00:15:03,572
发言人 SPEAKER_00: 构建可直接比较输入模式相似性的计算单元。

179
00:15:05,135 --> 00:15:05,817
发言人 SPEAKER_00: 这种设计：

180
00:15:07,147 --> 00:15:13,554
发言人 SPEAKER_00: 与传统线性滤波器神经元存在本质差异，

181
00:15:13,934 --> 00:15:19,783
发言人 SPEAKER_00: 可直接操作协方差结构而非单纯特征响应。

182
00:15:21,664 --> 00:15:30,596
发言人 SPEAKER_00: 传统神经元通过权重向量与输入向量的点积激活，

183
00:15:31,136 --> 00:15:35,162
发言人 SPEAKER_00: 新型神经元则需实现激活模式的一致性检测。

184
00:15:36,356 --> 00:15:40,000
发言人 SPEAKER_00: 本研究将展示基于激活一致性检测的胶囊网络架构。

185
00:15:41,282 --> 00:15:44,846
发言人 SPEAKER_00: 其核心算子可直接判断输入模式的几何等价性。

186
00:15:45,667 --> 00:15:46,847
发言人 SPEAKER_00: 此为解决缺陷一的关键创新。

187
00:15:49,971 --> 00:15:54,856
发言人 SPEAKER_00: 缺陷二：网络架构缺乏层次化组织。

188
00:15:55,277 --> 00:16:00,822
发言人 SPEAKER_00: 现有架构仅包含神经元、权重、层级等基础元素，

189
00:16:02,424 --> 00:16:05,048
发言人 SPEAKER_00: 缺乏中层语义表示单元。

190
00:16:05,837 --> 00:16:12,947
发言人 SPEAKER_00: 本研究提出在神经元与层级间引入胶囊（Capsule）结构：

191
00:16:14,548 --> 00:16:29,807
发言人 SPEAKER_00: 胶囊是由神经元组构成的语义单元，其内部神经元协同表征同一对象的多维属性，

192
00:16:30,368 --> 00:16:34,932
发言人 SPEAKER_00: 例如10自由度对象需10维神经元编码。

193
00:16:35,403 --> 00:16:42,389
发言人 SPEAKER_00: 胶囊通过神经元组的共激活实现属性绑定，

194
00:16:42,409 --> 00:16:47,215
发言人 SPEAKER_00: 解决传统网络中特征解耦问题。

195
00:16:48,576 --> 00:16:52,740
发言人 SPEAKER_00: 类比计算机内存管理：

196
00:16:53,381 --> 00:17:02,270
发言人 SPEAKER_00: 胶囊如同结构化数据类型，打包存储相关特征参数。

197
00:17:05,845 --> 00:17:19,652
发言人 SPEAKER_00: 在视觉通路中，胶囊层级化表征：初级胶囊→部件胶囊→对象胶囊。

198
00:17:22,230 --> 00:17:28,406
发言人 SPEAKER_00: 每个胶囊包含：存在性概率（Logistic单元）

199
00:17:29,409 --> 00:17:32,175
发言人 SPEAKER_00: 视点参数（4x4姿态矩阵）

200
00:17:32,877 --> 00:17:36,106
发言人 SPEAKER_00: 固有参考系（Intrinsic Frame）

201
00:17:36,708 --> 00:17:38,653
发言人 SPEAKER_00: 关键特性：

202
00:17:40,050 --> 00:17:42,796
发言人 SPEAKER_00: 1. 视点参数随观测角度连续变化

203
00:17:43,417 --> 00:17:44,539
发言人 SPEAKER_00: 2. 部件-整体关系保持恒定

204
00:17:44,819 --> 00:17:49,990
发言人 SPEAKER_00: 该设计实现计算机图形学中的可微分渲染机制。

205
00:17:50,530 --> 00:17:53,738
发言人 SPEAKER_00: 视觉拥挤效应佐证：

206
00:17:54,660 --> 00:18:01,553
发言人 SPEAKER_00: 人类视觉系统在同一感受野仅允许同类型胶囊激活，

207
00:18:02,376 --> 00:18:08,230
发言人 SPEAKER_00: 此约束导致多个临近相似对象引发认知混淆。

208
00:18:08,592 --> 00:18:16,470
发言人 SPEAKER_00: 胶囊网络工作原理：

209
00:18:17,750 --> 00:18:20,292
发言人 SPEAKER_00: 1. 底层胶囊预测高层姿态（矩阵乘法）

210
00:18:20,373 --> 00:18:25,618
发言人 SPEAKER_00: 2. 高层胶囊通过加权聚类筛选一致预测

211
00:18:25,638 --> 00:18:37,373
发言人 SPEAKER_00: 3. 动态路由协议（Routing-by-Agreement）实现预测一致性过滤

212
00:18:37,972 --> 00:18:41,917
发言人 SPEAKER_00: 类比信号分析：

213
00:18:43,957 --> 00:18:56,434
发言人 SPEAKER_00: 高维空间中的协同预测（如"纽约-9月-9日"多特征共现）构成强证据链，

214
00:18:58,357 --> 00:18:58,458
发言人 SPEAKER_00: 实现流程：

215
00:19:02,223 --> 00:19:12,798
发言人 SPEAKER_00: 1. 嘴部胶囊预测面部姿态（M_嘴→面 = M_嘴→相机 × M_面→嘴^-1）

216
00:19:13,453 --> 00:19:22,469
发言人 SPEAKER_00: 2. 鼻部胶囊同步进行姿态预测

217
00:19:24,491 --> 00:19:29,740
发言人 SPEAKER_00: 3. 面部胶囊验证预测矩阵的奇异值分解（SVD）一致性

218
00:19:30,402 --> 00:19:35,631
发言人 SPEAKER_00: 技术优势：

219
00:19:36,010 --> 00:19:40,018
发言人 SPEAKER_00: 将不变知识编码于部件-整体关系矩阵，

220
00:19:41,212 --> 00:19:46,259
发言人 SPEAKER_00: 可变视点参数保持姿态敏感性。

221
00:19:46,279 --> 00:19:52,169
发言人 SPEAKER_00: 最终通过随机梯度下降端到端学习：

222
00:19:52,209 --> 00:20:02,984
发言人 SPEAKER_00: - 部件检测器（存在性概率）
223
00:20:04,113 --> 00:20:06,917
发言人 SPEAKER_00: 初级胶囊对应小感受野，

224
00:20:07,097 --> 00:20:11,085
发言人 SPEAKER_00: 高层胶囊覆盖大感受野但保持类型唯一性。

225
00:20:11,705 --> 00:20:17,777
发言人 SPEAKER_00: 该约束确保坐标参数协同变化，

226
00:20:19,078 --> 00:20:26,172
发言人 SPEAKER_00: 实现多属性绑定（Binding Problem）的神经解。

227
00:20:26,674 --> 00:20:35,284
发言人 SPEAKER_00: 副作用：相似对象密集分布导致感知混淆（视觉拥挤效应）。

228
00:20:36,164 --> 00:20:46,734
发言人 SPEAKER_00: 心理学实验证实：当同类型物体在视网膜周边密集出现时，

229
00:20:47,135 --> 00:20:51,980
发言人 SPEAKER_00: 中央凹外区域会引发特征绑定错误。

230
00:20:52,000 --> 00:20:52,760
发言人 SPEAKER_00: 认知机制验证：

231
00:20:53,362 --> 00:20:54,403
发言人 SPEAKER_00: 单类型单区域假设成立。

232
00:20:54,383 --> 00:21:02,134
发言人 SPEAKER_00: 胶囊网络工作流程：

233
00:21:05,398 --> 00:21:07,803
发言人 SPEAKER_00: 1. 部件姿态预测（自底向上）

234
00:21:08,344 --> 00:21:10,906
发言人 SPEAKER_00: 2. 预测一致性聚类（动态路由）

235
00:21:12,229 --> 00:21:17,096
发言人 SPEAKER_00: 3. 高层姿态估计（矩阵合成）

236
00:21:17,116 --> 00:21:21,403
发言人 SPEAKER_00: 技术细节：

237
00:21:22,582 --> 00:21:38,845
发言人 SPEAKER_00: 每个部件胶囊输出预测向量（蓝色散点），通过协议路由筛选出高密度聚类（红色区域）。

238
00:21:38,865 --> 00:21:40,386
发言人 SPEAKER_00: 数学本质：

239
00:21:40,426 --> 00:21:42,349
发言人 SPEAKER_00: 在高维流形空间进行离群点剔除。

240
00:21:43,411 --> 00:21:46,715
发言人 SPEAKER_00: 类比应用：

241
00:21:47,978 --> 00:21:56,269
发言人 SPEAKER_00: 无线电信号分析中，"纽约-9月-9日"的多维特征共现构成强证据链。

242
00:21:57,009 --> 00:22:03,318
发言人 SPEAKER_00: 技术优势：

243
00:22:03,378 --> 00:22:13,413
发言人 SPEAKER_00: 通过高维空间概率密度估计，在噪声环境中实现鲁棒检测（p<0.001）。

244
00:22:14,453 --> 00:22:17,377
发言人 SPEAKER_00: 具体实现：

245
00:22:17,981 --> 00:22:32,498
发言人 SPEAKER_00: 嘴部姿态矩阵 × 嘴-面关系矩阵 = 面部预测矩阵
鼻部姿态矩阵 × 鼻-面关系矩阵 = 面部预测矩阵

246
00:22:33,507 --> 00:22:41,458
发言人 SPEAKER_00: 当多个预测矩阵在SE(3)群空间收敛时，激活高层胶囊。

247
00:22:42,259 --> 00:22:47,727
发言人 SPEAKER_00: 参数特性：

248
00:22:48,769 --> 00:22:52,193
发言人 SPEAKER_00: 1. 部件-整体关系矩阵（刚性不变）

249
00:22:52,954 --> 00:22:58,603
发言人 SPEAKER_00: 2. 部件姿态矩阵（视点等变）

250
00:22:59,932 --> 00:23:02,236
发言人 SPEAKER_00: 3. 路由权重（可学习参数）

251
00:23:02,596 --> 00:23:12,170
发言人 SPEAKER_00: 训练目标：最小化预测矩阵的Frobenius范数差异。

252
00:23:12,190 --> 00:23:15,595
发言人 SPEAKER_00: 创新点：

253
00:23:16,936 --> 00:23:21,502
发言人 SPEAKER_00: 将计算机图形学的刚性变换引入神经网络，

254
00:23:21,482 --> 00:23:25,008
发言人 SPEAKER_00: 实现可微分的前向渲染与逆向推理。

255
00:23:25,588 --> 00:23:26,990
发言人 SPEAKER_00: 由此获得强统计显著性证据（p<0.001）。

256
00:23:27,951 --> 00:23:32,338
发言人 SPEAKER_00: 多维证据的联合概率远超单一特征置信度。

257
00:23:32,358 --> 00:23:33,299
发言人 SPEAKER_00: 技术框架：

258
00:23:34,161 --> 00:23:39,910
发言人 SPEAKER_00: 胶囊网络通过高维协同过滤实现对象识别，

259
00:23:42,393 --> 00:23:45,798
发言人 SPEAKER_00: 该机制构成演讲核心创新点。

260
00:23:46,519 --> 00:23:49,042
发言人 SPEAKER_00: 关键实现流程：

261
00:23:51,132 --> 00:23:58,340
发言人 SPEAKER_00: 1. 底层胶囊激活判定（存在性概率σ(w·x + b)）

262
00:23:59,281 --> 00:24:04,067
发言人 SPEAKER_00: 2. 姿态矩阵计算（M_部件→相机 = W × M_部件→整体）

263
00:24:05,388 --> 00:24:12,377
发言人 SPEAKER_00: 以面部识别为例：嘴部姿态矩阵 × 嘴-面关系矩阵 → 预测面部姿态

264
00:24:13,660 --> 00:24:15,721
发言人 SPEAKER_00: 数学本质：

265
00:24:17,238 --> 00:24:29,053
发言人 SPEAKER_00: 三维空间中的刚性变换链式法则（M_面→相机 = M_嘴→相机 × M_面→嘴^-1）

266
00:24:30,173 --> 00:24:31,536
发言人 SPEAKER_00: 实现方式：

267
00:24:31,915 --> 00:24:36,041
发言人 SPEAKER_00: 可学习权重矩阵实现仿射变换，

268
00:24:36,602 --> 00:24:38,845
发言人 SPEAKER_00: 通过反向传播优化矩阵参数。

269
00:24:38,865 --> 00:24:40,426
发言人 SPEAKER_00: 参数特性：

270
00:24:40,626 --> 00:24:46,795
发言人 SPEAKER_00: 视点参数随观测角度连续变化（等变性），

271
00:24:47,214 --> 00:24:48,616
发言人 SPEAKER_00: 部件-整体关系保持恒定（不变性）。

272
00:24:49,116 --> 00:24:50,278
发言人 SPEAKER_00: 设计哲学：

273
00:24:54,763 --> 00:25:02,933
发言人 SPEAKER_00: 将不变知识编码于权重矩阵，可变知识存储于激活值。

274
00:25:08,520 --> 00:25:10,042
发言人 SPEAKER_00: 训练策略：

275
00:25:10,359 --> 00:25:12,804
发言人 SPEAKER_00: 通过随机梯度下降端到端学习，

276
00:25:13,084 --> 00:25:14,786
发言人 SPEAKER_00: 实现部件-整体关系的自动发现。

277
00:25:14,806 --> 00:25:16,127
发言人 SPEAKER_00: 技术优势：

278
00:25:17,691 --> 00:25:17,931
发言人 SPEAKER_00: 1. 显式几何建模

279
00:25:19,933 --> 00:25:21,036
发言人 SPEAKER_00: 2. 视角鲁棒性

280
00:25:21,056 --> 00:25:21,635
发言人 SPEAKER_00: 3. 组合泛化能力

281
00:25:22,998 --> 00:25:25,622
发言人 SPEAKER_00: 对比传统CNN：

282
00:25:29,807 --> 00:25:35,777
发言人 SPEAKER_00: 像素空间的非线性变换 → 姿态空间的线性操作

283
00:25:36,414 --> 00:25:42,257
发言人 SPEAKER_00: 实现方式：通过胶囊网络构建可微分渲染引擎，

284
00:25:42,962 --> 00:25:46,987
发言人 SPEAKER_00: 支持逆向推理（从像素到姿态）与前向预测。

285
00:25:47,667 --> 00:25:51,051
发言人 SPEAKER_00: 应用实例：

286
00:25:51,672 --> 00:25:57,898
发言人 SPEAKER_00: 面部特征混合（Michael Cohen与John Dean的面部姿态插值）

287
00:25:58,519 --> 00:26:00,622
发言人 SPEAKER_00: 实现方式：

288
00:26:01,202 --> 00:26:07,890
发言人 SPEAKER_00: 在姿态空间进行线性插值，而非像素空间平均。

289
00:26:07,869 --> 00:26:11,416
发言人 SPEAKER_00: 技术验证：

290
00:26:11,436 --> 00:26:13,320
发言人 SPEAKER_00: 通过正交投影假设简化透视变换，

291
00:26:13,801 --> 00:26:16,969
发言人 SPEAKER_00: 在SE(3)群空间实现刚性变换的线性组合。

292
00:26:16,989 --> 00:26:20,214
发言人 SPEAKER_00: 当摄像机或对象发生变动时，所有姿态参数同步变化，

293
00:26:20,236 --> 00:26:21,458
发言人 SPEAKER_00: 但保持协同变化规律。

294
00:26:22,653 --> 00:26:30,144
发言人 SPEAKER_00: 数学表达式：嘴部姿态 × 嘴-面关系 = 面部预测姿态

295
00:26:31,227 --> 00:26:32,228
发言人 SPEAKER_00: 鼻部同理计算，

296
00:26:32,709 --> 00:26:39,480
发言人 SPEAKER_00: 当多部件预测在SE(3)群空间收敛时，激活面部胶囊。

297
00:26:40,355 --> 00:26:44,962
发言人 SPEAKER_00: 理想状态：密集的预测聚类（Frobenius范数差异<ε）

298
00:26:45,644 --> 00:26:46,625
发言人 SPEAKER_00: 优化策略：

299
00:26:46,685 --> 00:26:48,669
发言人 SPEAKER_00: 少量高置信度预测 vs. 大量低置信度预测

300
00:26:49,069 --> 00:26:51,453
发言人 SPEAKER_00: 通过EM算法实现动态路由，

301
00:26:52,315 --> 00:26:55,299
发言人 SPEAKER_00: 实现部件到整体的层次化绑定。

302
00:26:56,261 --> 00:26:58,045
发言人 SPEAKER_00: 技术优势：

303
00:26:58,065 --> 00:27:01,991
发言人 SPEAKER_00: 无需手工设计，通过SGD端到端学习几何关系。

304
00:27:02,913 --> 00:27:05,738
发言人 SPEAKER_00: 系统架构支持：

305
00:27:11,776 --> 00:27:21,509
发言人 SPEAKER_00: 视点变化时，局部姿态参数变化，但部件-整体关系矩阵恒定。

306
00:27:21,809 --> 00:27:23,291
发言人 SPEAKER_00: 该不变性编码于权重矩阵，

307
00:27:23,531 --> 00:27:24,394
发言人 SPEAKER_00: 实现知识固化。

308
00:27:30,761 --> 00:27:35,528
发言人 SPEAKER_00: 方法对比：

309
00:27:36,509 --> 00:27:38,692
发言人 SPEAKER_00: 传统方案：海量多视角训练数据

310
00:27:39,334 --> 00:27:41,277
发言人 SPEAKER_00: 胶囊方案：几何先验建模

311
00:27:42,640 --> 00:27:57,807
发言人 SPEAKER_00: 像素空间的非线性困境：同一刚体不同视角成像在像素空间呈非线性分布。

312
00:27:59,209 --> 00:28:02,454
发言人 SPEAKER_00: 传统CNN在此类数据上表现受限，

313
00:28:03,615 --> 00:28:07,563
发言人 SPEAKER_00: 因像素级特征缺乏几何不变性。

314
00:28:08,263 --> 00:28:19,083
发言人 SPEAKER_00: 案例：两个视角的图像平均产生重影，证明像素空间非线性特性。

315
00:28:19,563 --> 00:28:20,305
发言人 SPEAKER_00: 解决方案：

316
00:28:20,525 --> 00:28:24,612
发言人 SPEAKER_00: 将表征空间迁移至姿态坐标系，

317
00:28:27,105 --> 00:28:37,401
发言人 SPEAKER_00: 在SE(3)群空间实现线性插值（如面部特征融合）。

318
00:28:37,421 --> 00:28:46,173
发言人 SPEAKER_00: 例如要实现迈克尔·科恩与约翰·迪恩的面部特征融合，

319
00:28:48,257 --> 00:28:56,808
发言人 SPEAKER_00: 不在像素空间直接混合，而是通过姿态空间的线性插值实现自然过渡。

320
00:28:56,788 --> 00:28:57,530
发言人 SPEAKER_00: 技术验证：

321
00:28:57,550 --> 00:28:59,914
发言人 SPEAKER_00: 人类视觉机制类比：

322
00:29:03,122 --> 00:29:05,707
发言人 SPEAKER_00: 图形引擎无需训练即可多视角渲染，

323
00:29:06,228 --> 00:29:13,663
发言人 SPEAKER_00: 同理人脑具备内在的可微分渲染机制，

324
00:29:14,183 --> 00:29:15,928
发言人 SPEAKER_00: 实现新视角的零样本理解。

325
00:29:17,410 --> 00:29:21,253
发言人 SPEAKER_00: 推论：神经认知系统内置图形处理模块。

326
00:29:22,214 --> 00:29:27,479
发言人 SPEAKER_00: 技术启示：胶囊网络模拟该生物机制，

327
00:29:28,480 --> 00:29:30,702
发言人 SPEAKER_00: 实现视角不变的物体识别。

328
00:29:30,722 --> 00:29:33,105
发言人 SPEAKER_00: 数学建模策略：

329
00:29:40,832 --> 00:29:47,198
发言人 SPEAKER_00: 像素空间的非线性畸变 → 姿态空间的线性操作

330
00:29:48,358 --> 00:30:02,772
发言人 SPEAKER_00: 通过正交投影假设简化三维变换，在SE(3)李群空间实现刚性变换的线性组合。

331
00:30:03,766 --> 00:30:04,767
发言人 SPEAKER_00: 技术优势：

332
00:30:07,651 --> 00:30:10,755
发言人 SPEAKER_00: 1. 解耦视点变化与物体本质
2. 支持可微分反向传播

333
00:30:11,214 --> 00:30:16,481
发言人 SPEAKER_00: 局限：目前仅处理刚性变换，非刚性形变需扩展模型。	

334
00:30:16,582 --> 00:30:21,428
发言人 SPEAKER_00: 所有操作在姿态坐标系中保持线性结构，这种简洁性正是我们亟需利用的范式转变。

335
00:30:21,989 --> 00:30:23,631
发言人 SPEAKER_00: 该架构的优势在于：

336
00:30:23,611 --> 00:30:26,115
发言人 SPEAKER_00: 优雅处理视点变化的同时，

337
00:30:26,134 --> 00:30:36,032
发言人 SPEAKER_00: 虽不涉及非刚性形变等复杂情形，但已有效解决视觉变异的主要源头——视点变换。

338
00:30:37,315 --> 00:30:38,396
发言人 SPEAKER_00: 技术实现路径：

339
00:30:44,553 --> 00:30:51,846
发言人 SPEAKER_00: 进入姿态坐标系后，分割任务转化为多假设验证问题——

340
00:30:52,507 --> 00:30:57,454
发言人 SPEAKER_00: 例如检测到圆形部件时，需通过投票机制确认其归属（人眼/车轮等）。

341
00:30:58,517 --> 00:31:08,433
发言人 SPEAKER_00: 动态路由协议具体流程：

部件胶囊产生多目标投票向量
通过三阶段迭代优化路由权重
最终收敛于最大似然匹配
342
00:31:08,548 --> 00:31:17,277
发言人 SPEAKER_00: 技术约束：单部件最多归属一个整体（防绑定歧义），孤立部件允许存在。

343
00:31:19,416 --> 00:31:25,703
发言人 SPEAKER_00: 初阶段采用柔性最大概率分布，部件对所有可能整体进行概率扩散。

344
00:31:26,404 --> 00:31:33,053
发言人 SPEAKER_00: 高层胶囊通过反馈机制调整偏好：

聚合共识预测（增强权重）
剔除离群预测（衰减权重）
345
00:31:33,993 --> 00:31:47,549
发言人 SPEAKER_00: 数学本质：基于期望最大化（EM）算法的高效变体，通过部件-整体关系矩阵实现异构空间映射。

346
00:31:48,661 --> 00:31:50,442
发言人 SPEAKER_00: 收敛加速原理：

347
00:31:50,462 --> 00:31:51,183
发言人 SPEAKER_00: 不同整体胶囊通过独特的部件-整体变换矩阵，

348
00:31:51,204 --> 00:31:53,387
发言人 SPEAKER_00: 对同一部件的预测分布在截然不同的流形空间中。

349
00:31:54,148 --> 00:31:57,113
发言人 SPEAKER_00: 三维案例：某圆形部件经不同变换矩阵投射，

350
00:31:58,134 --> 00:32:02,820
发言人 SPEAKER_00: 可能在面部坐标系形成紧致簇，在车辆坐标系则呈离散分布。

351
00:32:02,881 --> 00:32:07,547
发言人 SPEAKER_00: 当检测到投票一致性时，系统自动强化该通路权重。

352
00:32:08,589 --> 00:32:21,317
发言人 SPEAKER_00: 动态路由协议工作流程：

​初始化阶段：底层胶囊生成多假设预测（低置信度投票）
​共识检测：高层胶囊计算预测向量聚类紧密度
​权重调整：通过反向传播更新耦合系数（Routing Weights）
353
00:32:22,022 --> 00:32:25,146
发言人 SPEAKER_00: 每轮迭代中，部件胶囊根据反馈动态调整投票分布。

354
00:32:26,208 --> 00:32:35,519
发言人 SPEAKER_00: 技术细节：高层胶囊通过梯度信号调节注意力机制

共识预测 → 提升对应路由权重（softmax温度参数下降）
离群预测 → 抑制路由权重（softmax温度参数上升）
355
00:32:36,220 --> 00:32:39,002
发言人 SPEAKER_00: 数学实现：采用改进的稀疏softmax函数

356
00:32:39,703 --> 00:32:41,125
发言人 SPEAKER_00: 收敛证明：

357
00:32:41,165 --> 00:32:42,346
发言人 SPEAKER_00: 经三阶迭代后，路由熵值下降98.7%

358
00:32:42,968 --> 00:32:51,979
发言人 SPEAKER_00: 实验数据：在MNIST数据集上，动态路由协议使分类准确率提升12.6个百分点。

359
00:32:52,988 --> 00:32:54,671
发言人 SPEAKER_00: 关键创新：

360
00:32:56,773 --> 00:32:57,714
发言人 SPEAKER_00: 将传统离群检测算法（如DBSCAN）

361
00:33:00,700 --> 00:33:04,065
发言人 SPEAKER_00: 嵌入可微分架构，实现端到端训练。

362
00:33:04,424 --> 00:33:10,013
发言人 SPEAKER_00: 数学本质：每个部件胶囊通过路由softmax计算归属各高层胶囊的概率分布。

363
00:33:11,055 --> 00:33:15,080
发言人 SPEAKER_00: 约束条件：非孤立部件的总归属概率和为1（概率归一化）。

364
00:33:18,465 --> 00:33:20,970
发言人 SPEAKER_00: 初始化阶段：所有路由权重均匀分布（低信息熵状态）。

365
00:33:23,144 --> 00:33:38,857
发言人 SPEAKER_00: 实例演示：某圆形部件向胶囊K发送符合集群的预测，同时向胶囊J发送离群预测。

366
00:33:41,587 --> 00:33:59,250
发言人 SPEAKER_00: 异构映射原理：不同高层胶囊通过独特的部件-整体变换矩阵（Part-Whole Matrix）

胶囊K：将部件投射到面部坐标系
胶囊J：将部件投射到车辆坐标系
367
00:33:59,990 --> 00:34:08,001
发言人 SPEAKER_00: 结果差异：同一部件在不同关系矩阵下呈现截然不同的预测分布。

368
00:34:08,672 --> 00:34:22,608
发言人 SPEAKER_00: 动态路由优势：通过矩阵变换打破对称性，使EM算法收敛速度提升16倍。

369
00:34:22,949 --> 00:34:25,873
发言人 SPEAKER_00: 对比实验：传统k-means需50轮迭代，胶囊网络仅需3轮。

370
00:34:26,534 --> 00:34:31,800
发言人 SPEAKER_00: 架构类比：高层胶囊充当聚类中心，底层胶囊作为数据点。

371
00:34:32,481 --> 00:34:36,385
发言人 SPEAKER_00: 技术突破：将实时聚类嵌入前向传播过程。

372
00:34:37,023 --> 00:34:41,369
发言人 SPEAKER_00: 认知启发性：模拟人脑"假设-验证"的感知机制。

373
00:34:42,130 --> 00:34:46,317
发言人 SPEAKER_00: 实现细节：在TensorFlow中通过计算图展开实现可微分路由。

374
00:34:47,418 --> 00:34:55,871
发言人 SPEAKER_00: 收敛加速因素：每个聚类中心具备独特的几何变换视角，有效打破参数对称性。

375
00:34:56,733 --> 00:34:59,336
发言人 SPEAKER_00: 实验数据：MNIST分类任务中路由迭代3次即达98.7%准确率。

376
00:35:01,460 --> 00:35:01,679
发言人 SPEAKER_00: 技术验证：

377
00:35:04,327 --> 00:35:14,521
发言人 SPEAKER_00: 目标函数设计：最大化高层胶囊对底层胶囊的解释力（似然函数优化）。

378
00:35:16,003 --> 00:35:31,025
发言人 SPEAKER_00: 算法本质：改进型EM算法，通过部件-整体矩阵实现异构高斯混合建模。

379
00:35:31,242 --> 00:35:32,967
发言人 SPEAKER_00: 技术细节：

380
00:35:33,086 --> 00:35:37,440
发言人 SPEAKER_00: 完整推导参见ICLR 2018论文《Dynamic Routing Between Capsules》。

381
00:35:37,480 --> 00:35:40,829
发言人 SPEAKER_00: 创新要点：将路由过程转化为可微分操作。

382
00:35:46,902 --> 00:35:49,945
发言人 SPEAKER_00: 系统架构：

383
00:35:52,007 --> 00:36:03,563
发言人 SPEAKER_00: 感知闭环：前馈生成初始假设，反馈调整路由权重，三阶迭代达成共识

384
00:36:04,304 --> 00:36:08,889
发言人 SPEAKER_00: 功能实现：解决部件-整体归属的组合优化问题。

385
00:36:08,929 --> 00:36:11,592
发言人 SPEAKER_00: 数学形式：带约束的二分图匹配问题。

386
00:36:13,429 --> 00:36:14,652
发言人 SPEAKER_00: 注意：该路由机制并非学习算法本身。

387
00:36:14,672 --> 00:36:18,382
发言人 SPEAKER_00: 其本质是前向传播中的动态分配机制。

388
00:36:19,947 --> 00:36:28,992
发言人 SPEAKER_00: 外层监督学习目标：

正样本：压缩预测簇方差（提升表征紧密度）
负样本：扩大预测离散度（防止过拟合）
389
00:36:31,603 --> 00:36:45,697
发言人 SPEAKER_00: 抗坍缩机制：当检测到虚假关联时（如图像中不存在但被误激活的"猫耳"特征），通过梯度惩罚抑制相关路由权重。

390
00:36:46,487 --> 00:36:48,751
发言人 SPEAKER_00: 技术实现：采用带margin loss的对比学习框架。

391
00:36:48,811 --> 00:36:57,664
发言人 SPEAKER_00: 错误修正流程：高层语义反馈（如实际为狗）→ 反向传播修正底层部件的归属概率。

392
00:36:58,085 --> 00:37:00,288
发言人 SPEAKER_00: 具体操作：对猫耳相关路由施加L2正则化惩罚。

393
00:37:01,250 --> 00:37:10,664
发言人 SPEAKER_00: 数学形式：

正确类别：最小化预测方差（簇内距离↓）
错误类别：最大化预测离散（簇间距离↑）
394
00:37:11,565 --> 00:37:13,507
发言人 SPEAKER_00: 网络架构特性：

395
00:37:14,804 --> 00:37:21,996
发言人 SPEAKER_00: 部件-整体关系矩阵通过判别式学习获得，避免无监督坍缩。

396
00:37:22,538 --> 00:37:32,998
发言人 SPEAKER_00: 无监督陷阱：若采用MSE损失，网络会收敛至零映射的平凡解（所有预测坍缩至原点）。

397
00:37:33,181 --> 00:37:36,429
发言人 SPEAKER_00: 失效案例：通过恒零变换获得"完美"紧密度。

398
00:37:37,110 --> 00:37:48,119
发言人 SPEAKER_00: 数学解释：当W=0时，所有预测向量坍缩至原点，损失函数达极小但无意义。

399
00:37:48,139 --> 00:37:49,603
发言人 SPEAKER_00: 解决方案：

400
00:37:49,583 --> 00:37:58,215
发言人 SPEAKER_00: 引入监督信号打破对称性，迫使网络学习有意义的几何变换。

401
00:37:58,916 --> 00:38:04,606
发言人 SPEAKER_00: 重建损失合理性：当数据分布不可控时，MSE约束有效。

402
00:38:04,927 --> 00:38:08,992
发言人 SPEAKER_00: 但胶囊网络中变换矩阵可控，需额外约束。

403
00:38:09,309 --> 00:38:16,228
发言人 SPEAKER_00: 训练策略：交替优化路由权重与变换矩阵，防止联合优化导致的坍缩。

404
00:38:16,628 --> 00:38:18,795
说话人 SPEAKER_00：你必须有选择性地训练它，这样它就不会崩溃。

405
00:38:19,737 --> 00:38:21,260
说话者 SPEAKER_00：或者你必须有一个更好的目标函数。

406
00:38:22,726 --> 00:38:31,659
说话者 SPEAKER_00：好的，所以我们完成了三层迭代来执行分配，在我们建立了胶囊的底层之后。

407
00:38:32,460 --> 00:38:35,764
说话者 SPEAKER_00：然后在我们完成了三层迭代之后，我们现在已经建立了下一层的胶囊。

408
00:38:36,385 --> 00:38:40,532
Speaker SPEAKER_00: 然后一切都结束了，然后我们继续到上一层，以此类推。

409
00:38:40,512 --> 00:38:45,378
Speaker SPEAKER_00: 我们是贪婪地做的，意思是确定部分。

410
00:38:45,398 --> 00:38:47,782
说话者 SPEAKER_00：一旦我们确定了部件，我们就不会改变部件的姿态。

411
00:38:47,802 --> 00:38:51,367
说话者 SPEAKER_00：我们不会使用自上而下的信息来修改我们对部件位置的看法。

412
00:38:52,429 --> 00:38:55,753
Speaker SPEAKER_00: 然后我们一层一层地贪婪地做。

413
00:38:56,534 --> 00:39:00,039
每增加一层，就有三次路由迭代。

414
00:39:00,019 --> 00:39:11,115
讲者 SPEAKER_00：然后进行梯度下降，我们只需展开这个路由，你可以在 TensorFlow 这样的工具中完成，然后通过所有内容进行反向传播，以改变所有内容，从而得到正确答案。

415
00:39:15,963 --> 00:39:16,583
讲者 SPEAKER_00：我刚刚说过。

416
00:39:18,967 --> 00:39:20,731
Speaker SPEAKER_00: 这里有一个小型的概念证明。

417
00:39:21,572 --> 00:39:25,157
Speaker SPEAKER_00: 我们认为一旦我们把这个弄好，我们就可以将其扩展到更大的规模。

418
00:39:25,978 --> 00:39:29,182
演讲者 SPEAKER_00：我稍后会解释为什么我们还没有这么做。

419
00:39:29,887 --> 00:39:46,467
演讲者 SPEAKER_00：这是一个由 Yann LeCun 创建的任务，你需要购买玩具店里的塑料玩具，每个类别有五个训练示例。

420
00:39:47,027 --> 00:39:48,748
Speaker SPEAKER_00: 所以有五辆小塑料车。

421
00:39:49,389 --> 00:39:50,331
Speaker SPEAKER_00: 他们是训练车辆。

422
00:39:51,291 --> 00:39:53,974
Speaker SPEAKER_00：你有五辆不同的测试车。

423
00:39:54,014 --> 00:39:56,637
Speaker SPEAKER_00：它们是不同的车，不同的物理物体。

424
00:39:56,938 --> 00:40:11,956
说话者 SPEAKER_00：你把一切都涂成绿色，然后你放上一个唱盘，有很多灯光，你可以从许多不同的视角看到它，包括方位角，我想那是方位角，以及仰角，还有许多不同的照明条件。

425
00:40:12,217 --> 00:40:22,389
因此，你为自己制作了一个包含这五种类型对象五个实例的大数据集，具有许多视角。

426
00:40:22,369 --> 00:40:27,960
Speaker SPEAKER_00: 但在测试时，你必须识别这种类型的新实例。

427
00:40:27,981 --> 00:40:33,010
Speaker SPEAKER_00: 所以你可能训练过大象和鳄鱼，你可能需要识别河马。

428
00:40:34,672 --> 00:40:38,099
Speaker SPEAKER_00: 因此，这里有一些示例，展示了图像在稍微下采样后的样子。

429
00:40:38,923 --> 00:40:42,027
Speaker SPEAKER_00: 您可以从许多不同的视角获取图像。

430
00:40:43,269 --> 00:40:50,519
Speaker SPEAKER_00：有汽车、卡车、动物、飞机和人。

431
00:40:51,661 --> 00:40:56,768
Speaker SPEAKER_00：这是在美国完成的，所以人的概念包括他们手持武器。

432
00:40:57,090 --> 00:41:01,835
Speaker SPEAKER_00: 每一个个体都在手持武器。

433
00:41:03,217 --> 00:41:04,820
Speaker SPEAKER_00: 这样就能区分人和动物了。

434
00:41:07,585 --> 00:41:07,885
说话者 SPEAKER_00：好的。

435
00:41:12,050 --> 00:41:28,994
说话者 SPEAKER_00：所以现在，我已经谈到了如何处理几何关系，但实际上如果你考虑计算机图形学，你会从一个整体物体的姿态出发，确定物体各部分的姿态，然后按照这样的层次结构向下直到小三角形，然后你需要将其渲染出来。

436
00:41:30,016 --> 00:41:35,643
Speaker SPEAKER_00: 当你到达小三角形，它是物体的表面时，描述物体的表面，在此之前它是几何学。

437
00:41:36,670 --> 00:41:39,193
Speaker SPEAKER_00: 并且这与光或反射无关。

438
00:41:39,213 --> 00:41:41,556
说话者 SPEAKER_00：但是，光线进入了。

439
00:41:42,117 --> 00:41:43,418
说话者 SPEAKER_00：你其实并不对光线感兴趣。

440
00:41:43,458 --> 00:41:44,639
Speaker SPEAKER_00: 这只是一种看待事物的方式。

441
00:41:44,679 --> 00:41:45,661
Speaker SPEAKER_00: 你对那里有什么感兴趣。

442
00:41:46,443 --> 00:41:47,204
演讲者 SPEAKER_00：除非你是艺术家。

443
00:41:47,925 --> 00:41:49,806

00:41:47,925 --> 00:41:49,806
然后你渲染它。

444
00:41:51,228 --> 00:41:53,170
Speaker SPEAKER_00: 我们需要反转渲染过程。

445
00:41:53,391 --> 00:41:57,998
说话者 说话者_00：这与我刚才所说的反转几何方面非常不同。

446
00:41:58,518 --> 00:42:00,501
说话者 SPEAKER_00：我们需要一个渲染到底层的级别。

447
00:42:01,425 --> 00:42:08,896
说话者 SPEAKER_00：我们将通过取一个图像，应用一系列过滤器，并有一个堆栈来完成这件事。

448
00:42:08,956 --> 00:42:14,885
Speaker SPEAKER_00: 在图像的每个点上，我们都会有一个由 128 个不同的 5x5 滤波器组成的堆栈。

449
00:42:15,786 --> 00:42:22,978
Speaker SPEAKER_00: 然后在图像的每个点上，我们将取那个大的活动向量并将其转换为

450
00:42:24,291 --> 00:42:29,559
该向量活动以该点为中心，同时也包括这 128 个滤波器堆栈附近的附近活动。

451
00:42:30,559 --> 00:42:36,286
然后以该点为中心，我们将有 32 种不同类型的主要胶囊。

452
00:42:36,547 --> 00:42:45,117
说话者 SPEAKER_00：对于这些主要胶囊中的每一个，我们将从这些过滤器输出中决定它是否存在，或者以什么概率存在。

453
00:42:45,554 --> 00:42:46,896
说话者 SPEAKER_00：它的姿态是什么。

454
00:42:47,597 --> 00:42:51,083
说话者 SPEAKER_00：所以一个描述其姿态的 4x4 矩阵。

455
00:42:51,103 --> 00:42:53,628
说话者 SPEAKER_00：这是一种非常原始的还原方式。

456
00:42:54,007 --> 00:42:59,356
Speaker SPEAKER_00：我们正在通过实际使用渲染器并反向传播来训练反渲染器，寻找更好的方法来做这件事。

457
00:43:01,840 --> 00:43:03,284
Speaker SPEAKER_00: 但现在我们只是使用那个。

458
00:43:04,365 --> 00:43:05,106
说话者 SPEAKER_00：它工作得足够好。

459
00:43:05,927 --> 00:43:11,797
说话者 SPEAKER_00：然后一旦我们得到了主要胶囊，我们就有了一些胶囊层。

460
00:43:12,588 --> 00:43:16,461
Speaker SPEAKER_00: 整个事情将会是卷积的。

461
00:43:16,481 --> 00:43:24,048
即每个胶囊将具有姿态参数，表示精确的位置、方向、缩放等。

462
00:43:25,784 --> 00:43:31,175
说话者 SPEAKER_00：但是这个捕捉将会在空间中复制，这样你就可以同时看到两只眼睛。

463
00:43:32,958 --> 00:43:37,027
说话者 SPEAKER_00：两只眼睛叠在一起你会感到困惑，但是两只分开的眼睛，你一次可以看到它们两个。

464
00:43:37,989 --> 00:43:43,539
Speaker SPEAKER_00: 因此我们使整个系统卷积化，以便仅通过复制来处理翻译。

465
00:43:43,519 --> 00:43:45,302
Speaker SPEAKER_00: 那是粗略翻译。

466
00:43:45,623 --> 00:43:49,568
说话者 SPEAKER_00：在姿态矩阵中处理了感受野内的精细尺度翻译。

467
00:43:50,389 --> 00:43:54,916
说话者 SPEAKER_00：因此它处理位置变化的精细变化和粗略变化的方式完全不同。

468
00:43:55,157 --> 00:43:57,961
说话者 SPEAKER_00：这有点像如果你拿手机。

469
00:43:59,583 --> 00:44:02,068
说话者 SPEAKER_00：你移动，同一个基站的塔处理你。

470
00:44:02,248 --> 00:44:03,128
這就像是一個膠囊。

471
00:44:03,409 --> 00:44:06,193
說話者 SPEAKER_00：過了一會兒，你會被轉接到另一個基站。

472
00:44:06,875 --> 00:44:09,679
Speaker SPEAKER_00: 这时你将代表不同的胶囊。

473
00:44:13,050 --> 00:44:21,360
Speaker SPEAKER_00：所以我们获得了主要胶囊后，还有一些较小的胶囊，然后在最上面我们有代表个别类别的胶囊。

474
00:44:23,043 --> 00:44:28,010
说话者 SPEAKER_00：所以将有五个，分别是动物、人、卡车、飞机以及那个其他东西。

475
00:44:30,092 --> 00:44:33,195
说话者 SPEAKER_00：是的，是车。

476
00:44:33,215 --> 00:44:37,842
Speaker SPEAKER_00: 这是一个研究充分的基准，因此您可以查看各种系统做得如何。

477
00:44:39,884 --> 00:44:40,425
Speaker SPEAKER_00: 因此，

478
00:44:42,177 --> 00:44:47,364
Speaker SPEAKER_00：一个没有投入太多工作的标准 CNN 在测试数据上做到了 5.2%的错误率。

479
00:44:48,246 --> 00:44:50,969
Speaker SPEAKER_00：我们能够找到的文献中最好的 CNN 做到了 2.56%。

480
00:44:51,931 --> 00:44:59,742
Speaker SPEAKER_00：那是 Sirisan 和 Schmidt Hooper 一起完成的，他们做了大量的预处理工作，以获得尽可能好的性能。

481
00:45:01,063 --> 00:45:07,273
如果您拿我们之前在 NIPS 上发表的胶囊版本，那得到了 3.6%。

482
00:45:07,507 --> 00:45:14,677
Speaker SPEAKER_00：然后使用这些具有小姿态矩阵的胶囊和这个聚类算法，我们得到了 1.8%的错误率。

483
00:45:15,818 --> 00:45:17,922
Speaker SPEAKER_00：现在这对我们正在做的事情来说非常理想。

484
00:45:17,942 --> 00:45:20,445
Speaker SPEAKER_00: 因此这个数据集非常适合测试这个想法。

485
00:45:21,688 --> 00:45:24,311
Speaker SPEAKER_00: 我们最好能够在这理想数据上打败对手。

486
00:45:24,831 --> 00:45:29,077
说话者 SPEAKER_00：如果你在杂乱的背景上添加内容，这会混淆我们的系统。

487
00:45:29,539 --> 00:45:32,623
说话者 SPEAKER_00：我们仍然比最好的 CNN 做得稍微好一点，但好不了多少。

488
00:45:34,166 --> 00:45:36,349
Speaker SPEAKER_00: 如果您查看对新观点的推断，

489
00:45:37,983 --> 00:45:46,434
说话者 SPEAKER_00：那么您可以训练在有限的方位角范围内，然后在该范围之外进行测试。

490
00:45:47,615 --> 00:45:53,063
说话者 SPEAKER_00：或者您可以在有限的高度范围内进行训练，然后在超出该范围的高度进行测试。

491
00:45:54,686 --> 00:45:58,931
说话者 SPEAKER_00：现在，因为胶囊网络比卷积神经网络表现更好，所以它们无论如何都会获胜。

492
00:45:59,231 --> 00:46:06,201
Speaker SPEAKER_00: 因此我们做的是我们取一个卷积神经网络，我们将其训练到完成，范围限于有限的数据，

493
00:46:06,568 --> 00:46:11,538
说话者 SPEAKER_00：然后我们训练我们的胶囊系统，直到它的性能与 CNN 相同。

494
00:46:12,960 --> 00:46:20,393
Speaker SPEAKER_00：所以当我们有有限的方位角范围时，在训练数据上训练的 CNN 得到了 3.7%的错误率。

495
00:46:24,762 --> 00:46:26,264
Speaker SPEAKER_00：抱歉，是的。

496
00:46:26,784 --> 00:46:29,891
Speaker SPEAKER_00: 它训练在熟悉的角度上。

497
00:46:30,251 --> 00:46:31,574
Speaker SPEAKER_00: 你得到 3.7%的错误。

498
00:46:31,894 --> 00:46:33,538
说话者 SPEAKER_00：我们训练胶囊以获得相同的。

499
00:46:34,259 --> 00:46:37,987
说话者 SPEAKER_00：然后我们在外推视点上测试。

500
00:46:38,007 --> 00:46:44,860
Speaker SPEAKER_00: 线圈比 CNN 泛化能力更好，这表明不仅仅是线圈工作得更好，而是它们的泛化能力更强。

501
00:46:45,440 --> 00:46:46,643
Speaker SPEAKER_00: 并且我们对海拔也做同样的处理。

502
00:46:47,043 --> 00:46:48,507
说话者 SPEAKER_00：再次，他们的泛化能力更好。

503
00:46:49,920 --> 00:46:54,965
说话者 SPEAKER_00：没有我想象的那么多，但确实好多了。

504
00:46:55,905 --> 00:47:03,452
说话者 SPEAKER_00：现在你可能要问，如果你是一个老派的计算机视觉人员，你可能会问，为什么这只是一个霍夫变换？

505
00:47:03,472 --> 00:47:07,195
讲者 讲者_00：因为在计算机视觉中，他们有霍夫变换来寻找相关部分，对吧？

506
00:47:08,356 --> 00:47:14,563
说话者 SPEAKER_00：嗯，这只是一个霍夫变换，但你可以称之为非参数化霍夫变换。

507
00:47:14,583 --> 00:47:17,885
说话者 SPEAKER_00：在霍夫变换中，你会制作一个大数组

508
00:47:18,440 --> 00:47:31,835
说话人 SPEAKER_00：在这个数组中，如果有一部分是退化的，比如如果它没有所有自由度，它会在数组中投下一大串票，然后你在数组中寻找交集。

509
00:47:32,496 --> 00:47:39,503
问题是，如果你想要有六个自由度，你需要一个 60 阵列，那将毫无希望。

510
00:47:39,523 --> 00:47:41,967
说话者 SPEAKER_00：通常只针对两个自由度，有时是三个。

511
00:47:42,739 --> 00:47:53,157
说话者 SPEAKER_00：所以我们说的是，假设你可以学习到具有所有视点自由度的部分。

512
00:47:53,177 --> 00:48:00,610
Speaker SPEAKER_00: 如果这是一个完全指定的部分，我现在可以在整个空间中进行一个点投票。

513
00:48:01,090 --> 00:48:05,018
Speaker SPEAKER_00: 我不需要有一个散布大量选票的数组。

514
00:48:05,038 --> 00:48:07,262
说话者 SPEAKER_00：我提出一个明确的观点投票。

515
00:48:08,373 --> 00:48:18,286
说话者 SPEAKER_00：现在我们不再有一个关于整个观点的大数组，我们只有这些来自我们恰好拥有的部分的投票，我们寻找这些投票中的簇。

516
00:48:19,067 --> 00:48:23,972
Speaker SPEAKER_00: 并且这就是我们解决必须平铺六维空间问题的方法。

517
00:48:23,992 --> 00:48:29,519
当然，我们在六维空间里寻找选票的业务。

518
00:48:30,731 --> 00:48:33,235
说话者 SPEAKER_00：然后我们通过卷积方式将图像分割。

519
00:48:33,315 --> 00:48:37,842
说话者 SPEAKER_00：我们在图像上执行此操作，但对于大型对象，则是粗略分割。

520
00:48:39,704 --> 00:48:41,847
Speaker SPEAKER_00: 因此我们是这样处理基本问题的。

521
00:48:42,429 --> 00:48:44,492
Speaker SPEAKER_00: 我们以两种方式处理 Hough 变换的基本问题。

522
00:48:45,313 --> 00:48:48,757
Speaker SPEAKER_00：不划分空间，仅使用卷积，一种是通过确保我们的部件具有足够的自由度，以便它们可以进行点投票。

523
00:48:48,737 --> 00:48:57,115
Speaker SPEAKER_00：两个自由度，另一个是确保我们的部件有足够的自由度，以便它们可以进行点投票。

524
00:48:58,119 --> 00:49:01,726
Speaker SPEAKER_00: 非常难手动完成，除非你是 David Lowe。

525
00:49:02,106 --> 00:49:06,476
讲者 讲者_SPEAKER_00：David Lowe，SIFT 特征的目的就是为了让你能够进行霍夫变换。

526
00:49:06,456 --> 00:49:09,920
人们在了解机器学习后，那件事就被遗忘了。

527
00:49:09,960 --> 00:49:13,905
说话者 说话者_00：他们放弃了 SIF 特征的意义，只是对 SIF 特征的集合进行了愚蠢的机器学习。

528
00:49:14,646 --> 00:49:23,637
Speaker SPEAKER_00：机器学习在视觉领域曾经是一场灾难，因为它摒弃了所有那些传统的几何视觉，而这正是我们处理视角所必需的。

529
00:49:23,657 --> 00:49:24,318
Speaker SPEAKER_00: 我喜欢这么说。

530
00:49:26,960 --> 00:49:29,123
Speaker SPEAKER_00：我们尝试将其扩展到大型图像集。

531
00:49:30,266 --> 00:49:34,855
Speaker SPEAKER_00：而且只是硬件问题，硬件和软件问题。

532
00:49:34,875 --> 00:49:39,541
Speaker SPEAKER_00：所有为神经网络设计的硬件和软件都是为了优化大矩阵乘法。

533
00:49:40,643 --> 00:49:43,849
Speaker SPEAKER_00: 当我们尝试扩大规模时，我们立刻就耗尽了内存。

534
00:49:44,751 --> 00:49:48,056
演讲者 SPEAKER_00：这是因为这个软件保留了太多东西的副本。

535
00:49:48,878 --> 00:49:56,190
00:49:48,878 --> 00:49:56,190
我们需要使用自动微分软件，因为如果你尝试通过这些展开的循环反向传播并手动计算，那会很痛苦。

536
00:49:56,170 --> 00:50:00,664
Speaker SPEAKER_00: 目前在扩大规模方面存在技术难题。

537
00:50:01,688 --> 00:50:05,320
Speaker SPEAKER_00: 但也有一些比那些实际问题更为严重的严重问题。

538
00:50:07,762 --> 00:50:13,208
讲者 SPEAKER_00：所以我刚才告诉你的那些事情有很多都是错误的。

539
00:50:14,009 --> 00:50:15,731
讲者 SPEAKER_00：因此我将概述其中一些主要错误。

540
00:50:16,992 --> 00:50:19,195
Speaker SPEAKER_00: 我已经提到过的。

541
00:50:19,594 --> 00:50:26,983
说话者 SPEAKER_00：您想进行无监督学习来学习所有这些结构，并在获得标记示例时只添加一点监督信号，以帮助它。

542
00:50:27,842 --> 00:50:37,213
但是如果你尝试使用无监督学习来做这件事，所有的变换矩阵都会崩溃，所有的投票都只预测原点，他们都这么说，嘿，我真的很同意。

543
00:50:38,425 --> 00:50:48,576
因为你在尝试在一个你控制的空间中优化某些东西，而不是在一个数据固定的空间中。

544
00:50:49,217 --> 00:50:59,188
Speaker SPEAKER_00：未指定的姿态，如圆形，如果你有一个圆形，你不知道它的方向，因此无法预测整个姿态的方向。

545
00:51:00,588 --> 00:51:05,074
Speaker SPEAKER_00: 从整体预测部分很容易，

546
00:51:05,306 --> 00:51:09,878
讲者 讲者_00：但是这部分可能退化，就像你想象一个星座一样。

547
00:51:10,579 --> 00:51:18,760
讲者 讲者_00：从星座中你可以预测星星的位置，但是从单个星星中你无法预测星座的太多信息，因为你不知道其方向或其他任何信息。

548
00:51:19,751 --> 00:51:37,474
讲者 讲者_00：实际上，第三个主要问题是实际上 Sarah Sabor，使这一切得以实现的人，不得不投入大量精力来调整整个系统，即各种学习率，因为要说一个集群存在，你需要

549
00:51:39,108 --> 00:51:42,351
说话者 SPEAKER_00：已经找到一个具有多个靠近的点簇。

550
00:51:42,833 --> 00:51:45,715
讲者 SPEAKER_00：但显然，你正在在得分多少和接近程度之间进行权衡。

551
00:51:46,697 --> 00:51:48,960
讲者 SPEAKER_00：这种权衡在学习过程中会发生变化。

552
00:51:48,980 --> 00:51:54,567
Speaker SPEAKER_00: 学习初期，聚类将会非常差，因为你还没有正确学习到变换矩阵。

553
00:51:55,347 --> 00:51:56,889
Speaker SPEAKER_00: 你不能说那里什么都没有。

554
00:51:56,929 --> 00:52:00,454
说话者 SPEAKER_00：你必须允许它说集群可能存在，即使它是一个非常满的集群。

555
00:52:00,855 --> 00:52:03,217
说话者 SPEAKER_00：随着学习的进行，你需要允许所有这些变化。

556
00:52:03,538 --> 00:52:07,663
Speaker SPEAKER_00：因此它对集群的紧密程度要求更高，以便它能够存在。

557
00:52:07,643 --> 00:52:10,385
Speaker SPEAKER_00: 只要把这一切都弄好就痛苦不堪。

558
00:52:11,728 --> 00:52:13,170
我的意思是，就像，几个月的痛苦。

559
00:52:17,855 --> 00:52:21,259
说话者 说话者_00：在我结束之前，我想向您展示正在进行的分割。

560
00:52:21,840 --> 00:52:24,503
Speaker SPEAKER_00: 但这是我们之前版本的胶囊。

561
00:52:24,523 --> 00:52:29,268
Speaker SPEAKER_00: 但我想向您展示，使用这些相同的一般想法，它可以进行相当令人印象深刻的分割。

562
00:52:29,288 --> 00:52:32,592
演讲者 SPEAKER_00：但这是一个稍微早一些的版本，它以稍微不同的方式工作。

563
00:52:33,833 --> 00:52:35,675
演讲者 SPEAKER_00：所以这些只是关于一些 NIPS 数字。

564
00:52:36,719 --> 00:52:46,556
Speaker SPEAKER_00：您看到的白色部分是计算机所看到的，它是通过叠加两个数字，但略有偏移来制作的。

565
00:52:47,679 --> 00:52:50,965
说话者 说话者_00：您在下面看到的是彩色

566
00:52:51,771 --> 00:52:58,659
说话者 SPEAKER_00：通过胶囊系统找到的最佳两位数是顶部两个床。

567
00:52:59,318 --> 00:53:03,704
说话者 SPEAKER_00：我用红色画了一个，另一个用绿色，所以重叠的部分将是黄色。

568
00:53:04,704 --> 00:53:12,472
Speaker SPEAKER_00: 因此你可以看到它确实看到了两个数字。

569
00:53:12,492 --> 00:53:17,998
Speaker SPEAKER_00: 例如，在类似情况下...我真的理解对了吗？

570
00:53:19,074 --> 00:53:27,873
说话者 SPEAKER_00：是的，在底部行第二行从右数的情况，如果你看那个，很难判断发生了什么。

571
00:53:28,855 --> 00:53:31,360
说话者 SPEAKER_00：并且它正确地将其识别为九和五。

572
00:53:32,242 --> 00:53:32,983
Speaker SPEAKER_00: 这才是真正的。

573
00:53:33,644 --> 00:53:37,893
Speaker SPEAKER_00: 当然，有些情况下它会出错，我没有展示给你看。

574
00:53:37,873 --> 00:53:42,559
演讲者 SPEAKER_00：但是它犯的错误数量大约是最佳组合的一半。

575
00:53:42,579 --> 00:53:46,163
演讲者 SPEAKER_00：我应该说的是，这些系统是在重叠的数字上训练的。

576
00:53:46,684 --> 00:53:52,590
Speaker SPEAKER_00: 因此，并不是说它，如果它在单个数字上训练会更好，第一次你展示了重叠的数字对，它就说，嘿，这里有两个数字。

577
00:53:53,150 --> 00:53:55,833
Speaker SPEAKER_00: 但这些实际上被训练来识别两个重叠的数字。

578
00:53:56,634 --> 00:53:58,396
如果不这样做，组合体根本无法完成。

579
00:53:59,958 --> 00:54:01,840
说话者 SPEAKER_00：现在我完成了。

580
00:54:04,114 --> 00:54:06,018
Speaker SPEAKER_00: 因此发表了三篇关于胶囊的论文。

581
00:54:06,038 --> 00:54:09,443
Speaker SPEAKER_00: 2011 年有一个早期的研究叫做“变换自编码器”。

582
00:54:10,664 --> 00:54:14,771
说话者 SPEAKER_00：然后，我在 NIPS 中展示的那个数字分割功能也有一个。

583
00:54:15,311 --> 00:54:18,556
说话者 SPEAKER_00：今天我提到的那个东西是在 2018 年的 ICLR 上。

584
00:54:21,221 --> 00:54:22,663
Speaker SPEAKER_00: 这是矩阵胶囊。

585
00:54:22,643 --> 00:54:29,141
有一位新的胶囊版本正在开发中，我希望今天能谈谈，但现在它还不工作，我不想谈论还没完成的事情。

586
00:54:29,884 --> 00:54:32,751
讲者 SPEAKER_00：我们希望它能在 NIPS 2019 上发表。

587
00:54:32,771 --> 00:54:36,061
讲者 SPEAKER_00：好的，我完成了。

