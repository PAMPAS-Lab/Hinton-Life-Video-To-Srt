1 00:00:00,031 --> 00:00:14,067 讲者 SPEAKER_06：他同样也激励了像我这样的学者、教授以及许多人，因为他对于研究和科学的坚定观点以及追求重大问题，真正重大的问题。
2 00:00:15,628 --> 00:00:23,878 讲者 SPEAKER_06：他还激励了许多公司，包括谷歌，进行开创性的研究，并设定长期的大目标。
3 00:00:27,841 --> 00:00:33,911 那个人可以站在这里，可以明确地说，他已经激励了数百万人。
4 00:00:34,993 --> 00:00:36,837 讲者 SPEAKER_06：并不是每天都能遇到这样的人。
5 00:00:37,618 --> 00:00:43,268 说话人 SPEAKER_06：如果还没有被他启发，那就看看这个演讲吧。
6 00:00:43,287 --> 00:00:47,115 说话人 SPEAKER_07：嗯，感谢介绍，之后只会让人失望。
7 00:00:49,423 --> 00:00:54,350 说话人 SPEAKER_07：这是我准备在温哥华的 ICASP 上发表的演讲。
8 00:00:55,091 --> 00:00:56,893 说话人 SPEAKER_07：他们说服我再次在这里发表。
9 00:00:57,613 --> 00:01:06,605 讲者 SPEAKER_07：它包含了一些相当基础的内容关于深度神经网络，其中一些内容你们可能非常熟悉，但希望其他人也能从中受益。
10 00:01:06,625 --> 00:01:13,573 讲者 SPEAKER_07：我将简要谈谈神经网络研究的历史，特别是具有许多特征层的网络。
11 00:01:14,614 --> 00:01:18,840 讲者 SPEAKER_07：以及它们现在在语音系统中的应用，我将非常简要地介绍。
12 00:01:19,748 --> 00:01:30,040 讲者 SPEAKER_07：我将介绍我们如何将这项工作扩展到物体识别，以及为了实现出色的物体识别所需的技巧。
13 00:01:31,683 --> 00:01:34,227 说话人 SPEAKER_07：接下来，我将谈谈深度神经网络的一些其他成功案例。
14 00:01:35,227 --> 00:01:42,817 说话人 SPEAKER_07：然后，我会对未来语音识别系统进行一些推测，我认为它们将非常不同于现在的系统。
15 00:01:46,441 --> 00:01:47,123 说话人 SPEAKER_07：所以。
16 00:01:48,688 --> 00:01:50,733 说话人 SPEAKER_07：如果你想要识别模式，显然有办法做到。
17 00:01:50,893 --> 00:01:58,686 说话人 SPEAKER_07：从图像或输入中获取一些特征，然后学习将这些特征与哪些权重关联起来，以决定它属于哪个类别。
18 00:01:59,447 --> 00:02:02,533 说话人 SPEAKER_07：这被称为模式识别或统计模式识别。
19 00:02:03,594 --> 00:02:06,359 说话人 SPEAKER_07：问题在于特征从何而来？
20 00:02:06,379 --> 00:02:08,604 说话人 SPEAKER_07：你可以做的一件事是手动设计特征。
21 00:02:09,445 --> 00:02:10,747 说话人 SPEAKER_07：人们已经做了很多这样的事情。
22 00:02:11,622 --> 00:02:23,199 说话人 SPEAKER_07：你可以这样做，你可以定义一个特征，比如说，我会选择我看到的一些输入模式，并且我会有一种方法来衡量测试案例与这些输入的相似度。
23 00:02:24,161 --> 00:02:30,510 说话人 SPEAKER_07：然后我会有一种巧妙的方法来选择我应该使用哪些输入模式，以及如何为选中的那些模式分配权重。
24 00:02:31,332 --> 00:02:32,955 说话人 SPEAKER_07：这被称为支持向量机。
25 00:02:34,082 --> 00:02:43,859 说话人 SPEAKER_07：如果支持向量机真的在反向传播之前被发明出来，这个故事就会简单得多，因为这是事物发展的自然顺序。
26 00:02:43,919 --> 00:02:46,102 说话人 SPEAKER_07：不幸的是，我们过早地发明了反向传播。
27 00:02:47,463 --> 00:02:49,647 说话人 SPEAKER_07：但假设我们在支持向量机之后发明了它。
28 00:02:49,668 --> 00:02:50,489 说话人 SPEAKER_07：故事就会更美好。
29 00:02:51,491 --> 00:02:54,816 说话人 SPEAKER_07：当然，最后一种方法就是学习特征应该是什么。
30 00:02:57,721 --> 00:02:58,622 说话人 SPEAKER_07：嗯。
31 00:02:58,719 --> 00:03:05,269 说话人 SPEAKER_07：20 世纪 80 年代中期，实际上在 70 年代，保罗·沃布斯提出了反向传播算法，但未能说服任何人。
32 00:03:06,030 --> 00:03:12,079 说话人 SPEAKER_07：然后在 80 年代中期，包括杨立昆、大卫·罗梅尔哈特、我和罗恩·威廉姆斯等多人对其进行了发展。
33 00:03:13,100 --> 00:03:17,606 讲者 SPEAKER_07：反向传播是通过说，我们将有一个前馈神经网络。
34 00:03:19,796 --> 00:03:26,926 讲者 SPEAKER_07：我们将比较当我们给它一个图像进行分类时，网络输出的结果与我们想要得到的结果之间的差异。
35 00:03:27,788 --> 00:03:29,711 讲者 SPEAKER_07：我们将采取一些差异的度量。
36 00:03:30,192 --> 00:03:31,993 讲者 SPEAKER_07：我们将把这个差异反向传递到网络中。
37 00:03:33,056 --> 00:03:41,907 说话人 SPEAKER_07：我们将使用链式法则，以便计算网络中每个权重的变化如何影响与正确答案的差异。
38 00:03:42,669 --> 00:03:46,935 说话人 SPEAKER_07：然后我们只需稍微更新一下权重，使其朝着减少差异的方向发展。
39 00:03:47,084 --> 00:03:50,288 说话人 SPEAKER_07：这就是所谓的随机在线梯度下降。
40 00:03:51,048 --> 00:03:53,991 说话人 SPEAKER_07：事实证明，它是一种非常原始的优化方法。
41 00:03:54,491 --> 00:04:00,258 说话人 SPEAKER_07：对于非常大的数据集，经过一些调整后，它比我们知道的任何花哨的优化方法都要好。
42 00:04:01,118 --> 00:04:06,324 说话人 SPEAKER_07：因此我们对反向传播非常兴奋，因为我们认为我们终于解决了特征来源的问题。
43 00:04:06,966 --> 00:04:09,389 说话人 SPEAKER_07：你只需要一个多层神经网络，就可以学习所有特征。
44 00:04:10,008 --> 00:04:12,953 说话人 SPEAKER_07：我们使这些非线性函数变得平滑，以便我们得到很好的导数。
45 00:04:13,492 --> 00:04:15,235 说话人 SPEAKER_07：问题解决了。
46 00:04:15,467 --> 00:04:17,269 说话人 SPEAKER_07：实际上，这有点令人失望。
47 00:04:20,053 --> 00:04:23,257 说话人 SPEAKER_07：所以人们发展了一个关于为什么反向传播不起作用的故事。
48 00:04:23,978 --> 00:04:27,144 说话人 SPEAKER_07：这个故事，我从我之前的一张幻灯片中得到的。
49 00:04:27,163 --> 00:04:29,346 说话人 SPEAKER_07：这就是我要讲的故事。
50 00:04:29,387 --> 00:04:34,733 说话人 SPEAKER_07：它不起作用，因为你需要太多的标记训练数据。
51 00:04:35,774 --> 00:04:38,538 说话人 SPEAKER_07：而且你几乎可以轻易获取的所有数据都是未标记的。
52 00:04:39,598 --> 00:04:41,822 说话人 SPEAKER_07：因为你必须知道正确的答案来训练这些网络。
53 00:04:41,862 --> 00:04:45,129 说话人 SPEAKER_07：你最好训练一个不需要知道正确答案的生成模型。
54 00:04:47,372 --> 00:04:50,740 说话人 SPEAKER_07：第二个问题是学习时间扩展性不好。
55 00:04:51,000 --> 00:04:52,642 说话人 SPEAKER_07：如果你只有一个隐藏层，它工作得相当好。
56 00:04:52,944 --> 00:04:55,387 说话人 SPEAKER_07：但是一旦你有多个隐藏层，它学习速度就会变得非常慢。
57 00:04:56,509 --> 00:05:02,822 说话人 SPEAKER_07：然后正常情况下，它可能会陷入局部最优解，而这些解可能并不像它们可能的那样好。
58 00:05:03,122 --> 00:05:06,208 说话人 SPEAKER_07：在高维空间中，很难弄清楚真正发生的事情。
59 00:05:06,728 --> 00:05:15,223 说话人 SPEAKER_07：你不知道你是否陷入了局部最优解，直到你开发出一个更好的优化器，并发现你之前认为的局部最优解都有向下的方向倾斜。
60 00:05:15,242 --> 00:05:16,625 说话人 SPEAKER_07：所以它们根本不是局部最优解。
61 00:05:18,908 --> 00:05:20,672 说话人 SPEAKER_07：但这个故事实际上是无稽之谈。
62 00:05:21,733 --> 00:05:23,697 说话人 SPEAKER_07：问题不在于那个传播。
63 00:05:24,132 --> 00:05:27,975 说话人 SPEAKER_07：问题在于反向传播，我们没有足够多的标记数据，但语音处理人员有。
64 00:05:29,137 --> 00:05:33,141 说话人 SPEAKER_07：我们没有足够快的计算机，也没有一个合理的初始化权重的方法。
65 00:05:35,124 --> 00:05:37,646 说话人 SPEAKER_07：如果解决了这三个问题，效果就非常好。
66 00:05:39,228 --> 00:05:40,228 说话人 SPEAKER_07：所以这确实是答案。
67 00:05:41,589 --> 00:05:45,694 说话人 SPEAKER_07：至少这是关于特征从何而来，或者是否存在某种合理的获取特征的方法的答案。
68 00:05:46,214 --> 00:05:49,819 说话人 SPEAKER_07：这可能不是我们大脑中特征的来源，但它在计算机上会有效。
69 00:05:50,879 --> 00:05:58,348 说话人 SPEAKER_07：自 80 年代中期以来，我们获得了更大的标记数据集，首先是语音，最近是视觉。
70 00:05:59,310 --> 00:06:02,415 说话人 SPEAKER_07：计算机速度大幅提升，尤其是在图形处理单元方面。
71 00:06:02,454 --> 00:06:05,819 说话人 SPEAKER_07：我们突然提高了 30 倍，这对差异产生了巨大影响。
72 00:06:05,839 --> 00:06:09,625 说话人 SPEAKER_07：我们找到了更好的方法来初始化权重，而不使用标记数据。
73 00:06:11,827 --> 00:06:14,831 说话人 SPEAKER_07：因此，神经网络在某些方面变得更好。
74 00:06:14,932 --> 00:06:18,557 说话人 SPEAKER_07：特别是，它们在语音识别的声学建模方面变得更好。
75 00:06:18,891 --> 00:06:25,862 说话人 SPEAKER_07：在语音识别中，您有用于音素的隐藏马尔可夫模型，它们表示这个音素处于这种状态，然后是这种状态，然后是这种状态。
76 00:06:26,384 --> 00:06:31,252 说话人 SPEAKER_07：然后您需要观察声波，并说，声波的这一部分可能对应于这个音素的这种状态。
77 00:06:32,134 --> 00:06:39,285 说话者 SPEAKER_07：因此，你需要将声音波或从声音波中提取的系数与隐藏马尔可夫模型的各个状态关联起来。
78 00:06:39,665 --> 00:06:40,706 说话者 SPEAKER_07：当然，你并不完全确定。
79 00:06:40,747 --> 00:06:45,355 说话者 SPEAKER_07：所以你需要从声音波中提取一些系数，并说，
80 00:06:45,334 --> 00:06:49,562 说话者 SPEAKER_07：有大约 0.3 的概率，这是这个音素的这一部分，有 0.4 的概率，这是那个音素的这一部分，等等。
81 00:06:50,262 --> 00:06:54,029 说话人 SPEAKER_07：这就是深度神经网络现在常规使用的用途。
82 00:06:54,050 --> 00:06:57,254 说话人 SPEAKER_07：它们正在取代之前的方法，即高斯混合模型。
83 00:06:59,858 --> 00:07:02,584 说话人 SPEAKER_07：所以我将简要谈谈初始化权重的问题。
84 00:07:02,850 --> 00:07:11,446 说话人 SPEAKER_07：在历史上，这对于克服这些深度神经网络不好且无法训练的信念非常重要。
85 00:07:11,466 --> 00:07:12,728 说话人 SPEAKER_07：这真是一个非常坚定的信念。
86 00:07:13,569 --> 00:07:17,956 说话人 SPEAKER_07：不久前，我的一个朋友向 ICML 提交了一篇论文。
87 00:07:17,937 --> 00:07:24,824 说话人 SPEAKER_07：审稿人说这篇论文不应该被 ICML 接受，因为它涉及神经网络，这在 ICML 上并不合适。
88 00:07:24,845 --> 00:07:29,571 说话人 SPEAKER_07：实际上，如果你回顾去年的 ICML，没有标题中包含“神经网络”的论文被接受。
89 00:07:29,990 --> 00:07:34,536 讲者 SPEAKER_07：所以 ICML 不应该接受关于神经网络的论文。
90 00:07:34,557 --> 00:07:35,557 讲者 SPEAKER_07：那只是几年前的事。
91 00:07:36,598 --> 00:07:43,286 讲者 SPEAKER_07：IEEE 期刊实际上有一项官方政策，据我们所知，就是不对神经网络论文进行评审，直接退回。
92 00:07:46,101 --> 00:07:51,086 讲者 SPEAKER_07：所以这是一种强烈的信念，并且并非完全没有证据支持。
93 00:07:54,689 --> 00:07:59,774 说话人 SPEAKER_07：这就是如何在不需要标签的情况下初始化这些网络中的权重。
94 00:07:59,793 --> 00:08:14,067 说话人 SPEAKER_07：您首先学习输入变量的结构生成模型，而实现这一目标的一种方法就是使用一种具有输入变量的生成模型。
95 00:08:14,468 --> 00:08:16,574 说话人 SPEAKER_07：它包含一层潜在变量。
96 00:08:17,658 --> 00:08:19,043 说话人 SPEAKER_07：它具有对称连接。
97 00:08:19,543 --> 00:08:22,894 说话人 SPEAKER_07：这实际上就像一个二部图马尔可夫随机场。
98 00:08:23,877 --> 00:08:27,550 说话人 SPEAKER_07：它没有潜在变量之间的任何连接，这使得事情变得容易得多。
99 00:08:28,237 --> 00:08:32,202 说话人 SPEAKER_07：而这个的最大似然训练算法相当复杂。
100 00:08:33,544 --> 00:08:38,090 说话人 SPEAKER_07：但是有一个近似方法，一个非常粗略的近似，称为对比散度。
101 00:08:38,110 --> 00:08:38,770 说话人 SPEAKER_07：非常简单。
102 00:08:39,130 --> 00:08:42,335 说话人 SPEAKER_07：我不打算深入那个话题，因为我想说这是如何融入更大的故事中的。
103 00:08:42,394 --> 00:08:43,015 说话人 SPEAKER_07：我没有时间。
104 00:08:43,797 --> 00:08:48,643 说话人 SPEAKER_07：但是，根据一些数据，训练这些网络（称为受限玻尔兹曼机）有一个非常简单的方法。
105 00:08:49,062 --> 00:08:53,650 说话人 SPEAKER_07：这不是最大似然，也不是最优，但它速度快，而且能做一份合理的工作。
106 00:08:53,671 --> 00:08:55,315 说话人 SPEAKER_07：对我们来说已经足够好了。
107 00:08:56,096 --> 00:09:03,551 说话人 SPEAKER_07：这意味着你可以向它展示一些像素，你可以快速训练它，并且你将得到一些特征检测器，它们能够捕捉像素之间的相关性。
108 00:09:03,571 --> 00:09:06,496 说话人 SPEAKER_07：所以你会得到像边缘检测器、角检测器这样的东西。
109 00:09:08,501 --> 00:09:17,095 说话人 SPEAKER_07：真正的技巧是，在你做了这些之后，你可以将这些隐藏单元的活动向量作为数据再次进行处理。
110 00:09:17,956 --> 00:09:21,903 说话人 SPEAKER_07：现在我们可以把这些作为数据来学习第二层。
111 00:09:21,923 --> 00:09:23,264 说话人 SPEAKER_07：然后你可以再次这样做。
112 00:09:23,304 --> 00:09:24,787 说话人 SPEAKER_07：你可以随心所欲地做很多次。
113 00:09:25,849 --> 00:09:31,977 说话人 SPEAKER_07：这个模型的关键特性是，如果你训练一整个这样的模型堆栈，
114 00:09:32,937 --> 00:09:35,318 说话人 SPEAKER_07：你可以证明可以将它们组合成一个大的模型。
115 00:09:36,039 --> 00:09:43,868 说话人 SPEAKER_07：每次你训练一个额外的隐藏层，你都会得到数据对数概率的不同界限。
116 00:09:44,508 --> 00:09:46,831 说话人 SPEAKER_07：随着模型变得更深，这个界限会变得更好。
117 00:09:48,011 --> 00:09:55,538 说话人 SPEAKER_07：换句话说，在训练数据的对数概率的下界方面，你绝对可以通过添加一个额外的隐藏层来获胜。
118 00:09:56,559 --> 00:09:58,282 说话人 SPEAKER_07：从这个意义上说，这是正确的事情。
119 00:09:58,302 --> 00:09:59,602 说话人 SPEAKER_07：你正在取得进步。
120 00:10:00,240 --> 00:10:08,450 说话人 SPEAKER_07：现在，证明当然需要各种条件，比如你为每个小限制玻尔兹曼机进行了最大似然学习，并且确保层不会变窄。
121 00:10:09,311 --> 00:10:12,953 说话人 SPEAKER_07：所以我们一直在肆无忌惮地违反证明的条件。
122 00:10:13,634 --> 00:10:20,883 说话人 SPEAKER_07：但证明仍然非常重要，因为它表明在特定情况下，一次学习一层的事情在学术上是值得尊敬的。
123 00:10:21,602 --> 00:10:24,807 说话人 SPEAKER_07：有一些频段正在改善，所以这样做是合理的。
124 00:10:24,866 --> 00:10:26,048 说话人 SPEAKER_07：这并非纯粹的启发式方法。
125 00:10:26,589 --> 00:10:29,792 说话人 SPEAKER_07：这个证明为你提供了足够的掩护，让你可以继续进行研究。
126 00:10:30,649 --> 00:10:33,332 说话人 SPEAKER_07：并且不会使论文常规性地被拒绝。
127 00:10:36,356 --> 00:10:39,600 说话人 SPEAKER_07：这就是我们在语音识别器中使用它的方法。
128 00:10:42,104 --> 00:10:47,289 说话人 SPEAKER_07：这里每种绿色的列都是一个从声音波形中提取的系数帧。
129 00:10:48,150 --> 00:10:51,054 说话人 SPEAKER_07：实际上，最好的使用方式就是滤波器组输出。
130 00:10:51,827 --> 00:10:56,692 说话人 SPEAKER_07：在语音处理中，他们开发了更复杂的东西，称为梅尔齐德系数。
131 00:10:56,711 --> 00:11:07,221 说话人 SPEAKER_07：但他们主要发展是为了去相关和降维，以便一个被称为高斯混合模型的无脑方法，基本上是平滑的表查找，可以模拟这些数据。
132 00:11:08,363 --> 00:11:16,269 说话人 SPEAKER_07：一旦在这里使用受限玻尔兹曼机，那么你可以接受输入的较少处理版本。
133 00:11:16,309 --> 00:11:19,253 说话人 SPEAKER_07：换句话说，它可以决定它想要提取哪些特征。
134 00:11:19,451 --> 00:11:22,177 说话人 SPEAKER_07：你可以查看更多的系数窗口。
135 00:11:22,197 --> 00:11:24,000 说话人 SPEAKER_07：你可以查看更长的时间段。
136 00:11:25,524 --> 00:11:27,386 说话人 SPEAKER_07：对于输入，这些将是真实值。
137 00:11:27,827 --> 00:11:29,831 说话人 SPEAKER_07：稍后，我们将使用二进制值单位。
138 00:11:30,493 --> 00:11:37,866 说话人 SPEAKER_07：因此，您将使用一种特殊的玻尔兹曼机来处理输入，称为高斯限制玻尔兹曼机，其中这些是真实的，这些是二进制随机变量。
139 00:11:38,908 --> 00:11:42,134 说话人 SPEAKER_07：然后一旦您在未标记的数据上学习了此模型，
140 00:11:42,773 --> 00:11:47,821 发言人 SPEAKER_07：你可以考虑将这些活动向量复制到那里，将其作为训练数据，然后学习另一个模型。
141 00:11:48,402 --> 00:11:50,104 发言人 SPEAKER_07：那你就把它复制过来，学习另一个模型。
一旦你学会了所有这些模型，你现在想将它们组合成一个大的模型，这将是一个数据生成模型。
143 00:11:58,157 --> 00:12:00,860 发言人 SPEAKER_07：换句话说，它仍然只是输入的一个模型。
144 00:12:01,402 --> 00:12:06,489 说话人 SPEAKER_07：我的意思是，使用这个生成模型，如果你从模型中生成，你会得到看起来像数据的东西。
145 00:12:07,791 --> 00:12:11,397 说话人 SPEAKER_07：而且从这么大的模型中生成的方式，非常令人惊讶，
146 00:12:11,798 --> 00:12:14,970 说话人 SPEAKER_07：就是你将取前两层，永远向前向后。
147 00:12:16,636 --> 00:12:22,821 说话人 SPEAKER_07：然后你在这里永远向前向后之后，就会变成一块一块的。
148 00:12:24,251 --> 00:12:28,258 说话人 SPEAKER_07：换句话说，这些都是自上而下的连接，但这些是对称连接。
149 00:12:28,677 --> 00:12:36,409 说话人 SPEAKER_07：这真是个巨大的惊喜，因为你可能会想，如果你把这么多对称的东西放在一起，那么你将得到一个巨大的玻尔兹曼机。
150 00:12:36,429 --> 00:12:36,951 说话人 SPEAKER_07：但你不会。
151 00:12:37,490 --> 00:12:39,234 说话人 SPEAKER_07：你可以去读读关于为什么不会的论文。
152 00:12:39,695 --> 00:12:40,916 说话人 SPEAKER_07：我现在不想尝试解释它。
153 00:12:41,197 --> 00:12:45,383 说话人 SPEAKER_07：我已经解释过很多次了，但我从未说服过任何人。
154 00:12:46,307 --> 00:12:47,710 说话人 SPEAKER_07：所以，阅读论文。
155 00:12:48,230 --> 00:12:49,072 说话人 SPEAKER_07：这就是你得到的结果。
156 00:12:49,092 --> 00:13:07,624 说话人 SPEAKER_07：那么我们现在知道如何做的是，我们可以一层一层地学习特征，而不需要知道任何标签，然后将它们全部组合成一个具有多层特征的庞大生成模型，这个模型的生成能力比单独的最低层模型要好。
157 00:13:08,261 --> 00:13:12,730 说话人 SPEAKER_07：完成这一切之后，我们就可以说，现在让我们把所有理论都抛开。
158 00:13:13,731 --> 00:13:19,162 说话人 SPEAKER_07：那么我们就反过来使用权重矩阵，而不是像这样使用。
159 00:13:19,182 --> 00:13:20,825 说话人 SPEAKER_07：让我们把它当作一个庞大的神经网络来处理。
160 00:13:21,725 --> 00:13:23,830 说话人 SPEAKER_07：我们将在上面添加一些类别标签。
161 00:13:25,011 --> 00:13:28,177 说话人 SPEAKER_07：我们将在这里学到的知识来初始化权重。
162 00:13:28,764 --> 00:13:32,230 说话人 SPEAKER_07：然后我们将使用反向传播算法来训练这个模型。
163 00:13:32,250 --> 00:13:39,124 说话人 SPEAKER_07：与之前使用反向传播的不同之处在于，我们使用了未标记的数据来初始化所有的特征检测器。
164 00:13:40,086 --> 00:13:43,892 说话人 SPEAKER_07：因此，在未标记数据上解决特征发现的问题。
165 00:13:44,293 --> 00:13:46,636 说话人 SPEAKER_07：你找到了好的特征检测器，以及它们的多个层次。
166 00:13:47,097 --> 00:13:52,528 说话人 SPEAKER_07：所以在高层，你得到了相当复杂的特征检测器，所有这些都是在没有使用任何标记数据的情况下发现的。
167 00:13:52,508 --> 00:13:58,356 说话人 SPEAKER_07：如果你只有少量标记数据，你现在可以将反向传播释放到这个网络中，并对其进行训练。
168 00:13:58,878 --> 00:14:04,164 说话人 SPEAKER_07：与您用那一点标注数据训练整个网络相比，它将工作得更好。
169 00:14:04,785 --> 00:14:08,392 说话人 SPEAKER_07：因为标注数据只是略微改变了您在无监督学习中找到的特征。
170 00:14:08,952 --> 00:14:10,475 说话人 SPEAKER_07：无需设计特征。
171 00:14:12,357 --> 00:14:17,905 说话人 SPEAKER_07：然而，这个故事中不幸的是，如果您有很多标注数据，您就无需这些了。
172 00:14:18,647 --> 00:14:21,350 说话人 SPEAKER_07：你只需要正确初始化权重的尺度。
173 00:14:21,888 --> 00:14:26,913 说话人 SPEAKER_07：但直到我们做了所有这些事情并发现实际上可以学习这些深度网络之前，我们并没有发现这一点。
174 00:14:26,933 --> 00:14:32,298 说话人 SPEAKER_07：直到那时，人们认为你根本无法学习它们，因为它们会错误地初始化权重，然后就无法学习。
175 00:14:33,520 --> 00:14:42,289 说话人 SPEAKER_07：在我们完成所有这些工作，即将提交论文之前，我让学生检查了一下，也许如果我们继续探索所有可能的权重尺度，它就能学习。
176 00:14:42,309 --> 00:14:45,374 说话人 SPEAKER_07：因为我们有一个美妙的图表，我们的系统学习得非常漂亮。
177 00:14:45,394 --> 00:14:49,177 说话人 SPEAKER_07：如果你随机初始化权重，它根本学不到任何东西。
178 00:14:49,158 --> 00:14:58,845 说话人 SPEAKER_07：但我们探索了所有权重的尺度，我们发现了一个可怕的事情，那就是如果你把尺度调整得恰到好处，你实际上可以很好地学习这些深度网络。
179 00:14:58,865 --> 00:15:01,071 说话人 SPEAKER_07：不如预训练那样好，但几乎一样好。
180 00:15:01,091 --> 00:15:05,142 说话人 SPEAKER_07：只要有足够的标注数据，这已经足够好了。
181 00:15:06,893 --> 00:15:12,759 说话人 SPEAKER_07：这种生成式预训练之所以有意义，是因为你可以训练所有这些特征检测器。
182 00:15:12,779 --> 00:15:15,163 说话人 SPEAKER_07：你可以在未标注的数据上设计你的特征检测器。
183 00:15:16,404 --> 00:15:19,288 说话人 SPEAKER_07：在你将这些模型组合在一起之后，推理过程变得非常简单。
184 00:15:19,347 --> 00:15:20,489 说话人 SPEAKER_07：这只是一个前馈网络。
185 00:15:21,029 --> 00:15:27,518 说话人 SPEAKER_07：它正在进行近似推理，但这是准确的近似推理。
186 00:15:31,125 --> 00:15:43,600 说话人 SPEAKER_07：这意味着你可以取数据，你可以非常快地推断出所有的特征检测器，比使用正常的有向图模型快得多，在有向图模型中，存在一种称为解释消除的现象，这使得推理变得非常复杂。
187 00:15:48,524 --> 00:16:05,865 说话人 SPEAKER_07：不幸的是，尽管预训练使得优化网络变得容易并减少了过拟合，但现在我们知道了如何初始化权重，如果你有大量的标记数据，你只需将权重初始化到适当的尺度，然后在标记数据上训练反向传播，效果就很好。
188 00:16:05,885 --> 00:16:09,049 说话人 SPEAKER_07：如果你进行预训练，效果会好一点，但只是好一点。
189 00:16:09,811 --> 00:16:14,397 说话人 SPEAKER_07：然而，如果你没有太多标记数据，一次训练所有这些预训练层仍然非常值得。
190 00:16:16,250 --> 00:16:21,259 说话人 SPEAKER_07：所以，第一次真正成功使用这个技术是在声学模型和语音识别器中。
191 00:16:21,940 --> 00:16:28,129 说话人 SPEAKER_07：而且，在我不在的时候，我的两个学生探索了这个技术在声学模型中的应用。
192 00:16:28,831 --> 00:16:35,863 有一位非常优秀的演讲学生名叫阿卜杜拉曼·穆罕默德，另一位是非常优秀的神经网络和学习学生名叫乔治·达尔。
193 00:16:36,565 --> 00:16:39,809 他们使用一个非常深的网络，具有八个隐藏层，效果非常好。
194 00:16:40,549 --> 00:16:46,879 他们随后去了 IBM 和微软实习，还有一位学生去了谷歌。
195 00:16:48,020 --> 00:16:54,230 在这些公司，他们将技术应用于非常大的数据集和大型词汇量，效果非常好。
196 00:16:55,130 --> 00:16:57,254 说话人 SPEAKER_07：现在它已经替换了所有那些。
197 00:16:57,495 --> 00:17:01,039 说话人 SPEAKER_07：在谷歌、微软和 IBM，他们不再使用高斯混合模型了。
198 00:17:01,059 --> 00:17:03,283 说话人 SPEAKER_07：他们使用这些大型深度网络，因为它们效果更好。
199 00:17:03,753 --> 00:17:08,019 说话人 SPEAKER_07：并且词错误率的降低相当显著。
200 00:17:08,059 --> 00:17:10,403 说话人 SPEAKER_07：这大约是 30%的词错误率降低。
201 00:17:12,346 --> 00:17:14,028 说话人 SPEAKER_07：这意味着 30%的错误消失了。
202 00:17:15,711 --> 00:17:19,597 说话人 SPEAKER_07：关于这一点，有一篇由所有四个参与该项目的团队撰写的优秀综述论文。
203 00:17:21,480 --> 00:17:28,191 说话人 SPEAKER_07：今天我想主要谈谈如何将这一成功应用于物体识别。
204 00:17:29,233 --> 00:17:32,317 说话人 SPEAKER_07：识别物体和图像似乎要困难得多。
205 00:17:32,636 --> 00:17:38,603 说话人 SPEAKER_07：这是一个更大的问题，因为在语音的声学模型中，声学模型不需要知道那么多。
206 00:17:38,682 --> 00:17:46,671 说话人 SPEAKER_07：可能几百万个连接就能从声音波中获取足够的信息，来对音素片段进行下注。
207 00:17:47,191 --> 00:17:49,353 说话人 SPEAKER_07：那里的知识量并不多。
208 00:17:49,373 --> 00:17:58,261 说话人 SPEAKER_07：而如果你想要一个能够以某种通用方式识别物体和图像的系统，它需要对物体外观有大量的知识。
209 00:17:59,001 --> 00:18:01,489 说话人 SPEAKER_07：在语音系统中，这被称为语言模型。
210 00:18:02,250 --> 00:18:08,167 说话人 SPEAKER_07：我们没有触及，只是替换了前端。
211 00:18:08,721 --> 00:18:18,401 说话人 SPEAKER_07：因此，计算机视觉社区普遍认为，这些深度神经网络无法与他们的方法竞争，尽管他们的方法在多年中逐渐变得糟糕。
212 00:18:18,902 --> 00:18:29,643 讲者 SPEAKER_07：他们一开始采用了非常好的方法，就像 David Lowe 在他的论文中所做的那样，这种方法尊重几何形状，试图通过找到与该物体相关的一系列特征来识别物体。
213 00:18:29,663 --> 00:18:30,965 讲者 SPEAKER_07：有些合理的事情。
214 00:18:30,945 --> 00:18:32,929 讲者 SPEAKER_07：这种做法考虑了三维几何。
215 00:18:32,949 --> 00:18:47,049 讲者 SPEAKER_07：由于这种方法没有达到预期的效果，他们最终退回到了最简单的机器学习方法，即将图像视为一个视觉词汇的集合，忽略了它们的空间关系，只是有些词汇在这里，有些词汇在那里。
216 00:18:48,010 --> 00:18:50,114 说话人 SPEAKER_07：结果证明效果更好。
217 00:18:50,153 --> 00:18:56,143 说话人 SPEAKER_07：他们并没有说，嗯，我不在乎它效果更好，这是错的，他们说，好吧，我们都换成那个。
218 00:18:56,123 --> 00:18:58,827 说话人 SPEAKER_07：我认为那是一个大错误。
219 00:18:59,909 --> 00:19:00,711 说话人 SPEAKER_07：他们都换成了那个。
220 00:19:00,891 --> 00:19:01,992 说话人 SPEAKER_07：他们说，这就是做的方法。
221 00:19:02,032 --> 00:19:04,195 说话人 SPEAKER_07：而且你的深度神经网络不好，因为我们这样能做得更好。
222 00:19:05,459 --> 00:19:08,824 说话人 SPEAKER_07：结果证明他们做得更好，因为他们有非常小的训练集。
223 00:19:09,305 --> 00:19:13,050 说话人 SPEAKER_07：他们所需要做的只是提取他们手工设计的特征。
实际上，拿 David Lowe 手工设计的特征，稍作修改，使它们有不同的名称
225 00:19:21,232 --> 00:19:22,817 发言人 SPEAKER_07：然后调整一些参数。
226 00:19:23,638 --> 00:19:26,746 说话者 SPEAKER_07：为了做到这一点，你只需要有一个小数据集。
227 00:19:27,488 --> 00:19:29,251 发言人 SPEAKER_07：但最终，他们制作出了大数据集。
228 00:19:30,654 --> 00:19:34,845 说话人 SPEAKER_07：因此他们产生了一个包含 120 万张高分辨率训练图像的数据集。
229 00:19:35,666 --> 00:19:39,174 说话人 SPEAKER_07：任务是识别 1000 个不同的物体类别。
230 00:19:39,761 --> 00:19:41,844 说话人 SPEAKER_07：每张图像都已标注。
231 00:19:42,905 --> 00:19:44,547 说话人 SPEAKER_07：现在，这些图像包含了好几样东西。
232 00:19:44,807 --> 00:19:47,069 说话人 SPEAKER_07：所以你并不能确定它会有什么标签。
233 00:19:47,931 --> 00:19:50,493 说话人 SPEAKER_07：游戏规则是你有五次下注的机会。
234 00:19:51,035 --> 00:19:54,458 说话人 SPEAKER_07：如果与图片相关联的人的标签在你前五次下注中，你就赢了。
235 00:19:54,478 --> 00:19:55,078 说话人 SPEAKER_07：否则，你就输了。
236 00:19:56,160 --> 00:20:09,414 说话人 SPEAKER_07：在这个比赛中，包括一些非常优秀的团队，如牛津大学的安德鲁·齐斯曼小组和法国国家研究实验室 INRIA，与 Zero2Europe 合作。
237 00:20:09,461 --> 00:20:21,436 说话人 SPEAKER_07：如果你看看他们的结果，那么所有这些计算机视觉系统，这些都是好的计算机视觉系统，它们的准确率都在 26%或 27%，或者稍低一些。
238 00:20:22,898 --> 00:20:25,080 说话人 SPEAKER_07：而我们用同样的数据得到了 16%。
239 00:20:25,121 --> 00:20:26,643 说话人 SPEAKER_07：如果我们使用更多的数据，我们得到了 15%。
240 00:20:26,884 --> 00:20:28,865 说话人 SPEAKER_07：这些人无法使用更多数据。
241 00:20:29,446 --> 00:20:30,969 说话人 SPEAKER_07：但我刚刚在相同的数据集上做了。
242 00:20:30,989 --> 00:20:31,509 说话人 SPEAKER_07：我们得到了 16%。
243 00:20:31,670 --> 00:20:34,272 说话人 SPEAKER_07：所以这相当于 10%的差距，非常大。
244 00:20:34,333 --> 00:20:39,199 说话人 SPEAKER_07：这个差距比我们最初处理语音时大得多。
245 00:20:41,743 --> 00:20:43,667 说话人 SPEAKER_07：然后我们把它卖给了谷歌，谈话就结束了。
246 00:20:48,557 --> 00:20:50,863 说话人 SPEAKER_07：哦，我应该继续吗？
247 00:20:50,883 --> 00:20:51,063 说话人 SPEAKER_07：好的。
248 00:20:52,185 --> 00:20:56,294 说话人 SPEAKER_07：这里有一些测试集的例子。
249 00:20:57,236 --> 00:21:03,127 说话人 SPEAKER_07：那么，看看这个激光笔，谁有能用的激光笔？
250 00:21:04,255 --> 00:21:05,916 说话人 SPEAKER_07：把它吓跑了。
251 00:21:06,458 --> 00:21:10,544 说话人 SPEAKER_07：你看那里，你可以看到一个摩托车，但图像中不止这一样东西。
252 00:21:10,564 --> 00:21:11,605 说话人 SPEAKER_07：图片中还有很多其他东西。
253 00:21:12,247 --> 00:21:15,270 说话人 SPEAKER_07：现在，标签中没有包含人的标签。
254 00:21:15,310 --> 00:21:19,237 说话人 SPEAKER_07：所以你通常会关注人，但这些图片中没有给他们标注。
255 00:21:20,538 --> 00:21:22,662 说话人 SPEAKER_07：但它仍然，它识别出了摩托车，对吧？
256 00:21:22,701 --> 00:21:25,806 说话人 SPEAKER_07：你不能说这东西无法处理分割。
257 00:21:25,826 --> 00:21:27,729 说话人 SPEAKER_07：我的意思是，它在那里找到了摩托车。
258 00:21:27,749 --> 00:21:32,675 说话人 SPEAKER_07：在这里，我会说正确答案是一种大红色的敞篷车。
259 00:21:33,667 --> 00:21:36,210 说话人 SPEAKER_07：正确答案是烧烤架，它将其作为第二个答案给出。
260 00:21:36,730 --> 00:21:38,392 说话人 SPEAKER_07：它得到的其他答案都很合理。
261 00:21:39,453 --> 00:21:45,058 说话人 SPEAKER_07：如果你看最后一个，愚蠢的网络说达尔马提犬，显然答案是樱桃。
262 00:21:46,759 --> 00:21:52,185 说话人 SPEAKER_07：网络还有其他一些猜测，比如斯塔福德郡斗牛犬，或者葡萄，或者接骨木，或者醋栗。
263 00:21:52,566 --> 00:21:55,087 说话人 SPEAKER_07：如果你认为红醋栗，那些看起来很像红醋栗。
264 00:21:55,689 --> 00:21:57,590 说话人 SPEAKER_07：但这只是一个网络出错示例。
265 00:21:59,553 --> 00:22:02,055 说话人 SPEAKER_07：这是一个选择得当的错误示例。
266 00:22:05,848 --> 00:22:11,556 说话人 SPEAKER_07：所以问题是，这种物体识别技术何时才能实际应用？
267 00:22:12,436 --> 00:22:15,621 说话人 SPEAKER_07：答案是，它上周已经上线。
268 00:22:16,361 --> 00:22:19,545 说话人 SPEAKER_07：所以如果你去 Google+，你可以上传你自己的照片。
269 00:22:20,846 --> 00:22:24,790 说话人 SPEAKER_07：你可以搜索关键词。
270 00:22:26,012 --> 00:22:27,413 说话人 SPEAKER_07：你可以搜索很多关键词。
271 00:22:28,556 --> 00:22:33,882 说话人 SPEAKER_07：它会在你的未标记照片中找到这些关键词的示例。
272 00:22:35,650 --> 00:22:39,354 说话人 SPEAKER_07：我从网上找到这些，所以我没有泄露任何东西。
273 00:22:39,374 --> 00:22:40,315 说话人 SPEAKER_07：这些已经在网上了。
274 00:22:42,877 --> 00:22:45,601 说话人 SPEAKER_07：所以这是在某个人的照片收藏中搜索珠宝。
275 00:22:46,501 --> 00:22:53,088 说话人 SPEAKER_07：那里所有的东西实际上都是珠宝，包括显然是由小珠宝制成的摩托车。
276 00:22:53,789 --> 00:22:57,614 说话人 SPEAKER_07：右边的是给蛇的，它们都是蛇。
277 00:22:58,474 --> 00:22:59,596 说话人 SPEAKER_07：所以它工作得相当不错。
278 00:23:00,857 --> 00:23:01,478 说话人 SPEAKER_07：足够好了。
279 00:23:02,378 --> 00:23:05,623 说话人 SPEAKER_07：正如艾伦·麦克莱所说，这是消费级水平。
280 00:23:05,788 --> 00:23:08,012 说话人 SPEAKER_07：我认为那意味着它是好的。
281 00:23:10,036 --> 00:23:12,140 说话人 SPEAKER_07：现在，需要很多技巧才能让它工作。
282 00:23:13,701 --> 00:23:20,133 说话人 SPEAKER_07：第一个技巧是让 Yann LeCun 工作 20 年，找出让它工作起来的方法。
283 00:23:20,693 --> 00:23:21,635 说话人 SPEAKER_07：这是一个非常巧妙的技巧。
284 00:23:22,837 --> 00:23:28,708 说话人 SPEAKER_07：他找到了很多关于如何使卷积神经网络工作得更好和更好的方法，我们使用了所有这些方法。
285 00:23:29,801 --> 00:23:43,384 说话人 SPEAKER_07：另一个标准的技巧是将图像取一个大块，这个大块几乎占据了整个图像，然后移动这个块，这样我们只需通过移动数据来处理平移。
286 00:23:44,065 --> 00:23:46,669 说话人 SPEAKER_07：现在这样做真的很愚蠢，这肯定是不对的。
287 00:23:46,709 --> 00:23:49,093 说话人 SPEAKER_07：这几乎和视觉词袋一样愚蠢。
288 00:23:50,086 --> 00:23:58,336 说话人 SPEAKER_07：你真的希望通过理解视角如何影响事物，就像计算机图形学中那样，来处理视角变化的影响。
289 00:23:58,715 --> 00:24:02,601 说话人 SPEAKER_07：认为仅通过从所有可能的角度看问题就能处理视角问题，这真的很愚蠢。
290 00:24:03,541 --> 00:24:04,923 说话人 SPEAKER_07：但这就是这些网络目前所做的事情。
291 00:24:05,484 --> 00:24:06,045 说话人 SPEAKER_07：而且它有效。
292 00:24:06,445 --> 00:24:10,009 说话人 SPEAKER_07：这仅仅表明我们能够使这项工作做得更好。
293 00:24:11,892 --> 00:24:12,512 说话人 SPEAKER_07：好的。
294 00:24:12,532 --> 00:24:17,358 另一个技巧是不使用标准的逻辑神经元。
295 00:24:19,364 --> 00:24:23,048 神经网络使用具有某种逻辑输入输出的非线性神经元。
296 00:24:23,650 --> 00:24:26,753 说话人 SPEAKER_07：大多数人只是自然而然地了解到神经网络就是这样使用的。
297 00:24:27,314 --> 00:24:28,916 说话人 SPEAKER_07：我记得我们当时是这么定的。
298 00:24:29,436 --> 00:24:31,159 说话人 SPEAKER_07：所以我明白当时并没有什么合理的理由。
299 00:24:34,443 --> 00:24:35,404 说话人 SPEAKER_07：所以我们尝试了其他方法。
300 00:24:36,125 --> 00:24:38,528 说话人 SPEAKER_07：而且，Jan LeCun 也尝试了其他事情。
301 00:24:39,230 --> 00:24:43,836 说话人 SPEAKER_07：事实上，你可以尝试一件事，如果我们有一大堆逻辑单元呢？
302 00:24:44,643 --> 00:24:48,586 说话人 SPEAKER_07：它们都有相同的输入和输出权重，但阈值略有不同。
303 00:24:49,367 --> 00:24:50,189 说话人 SPEAKER_07：我稍后会提到这一点。
304 00:24:55,354 --> 00:24:56,414 说话人 SPEAKER_07：我稍后会解释这一点。
305 00:24:56,714 --> 00:25:04,442 说话人 SPEAKER_07：而且，我们还提出了一种更好的正则化器，允许您使用具有太多参数的大隐藏层而不会过拟合。
306 00:25:05,584 --> 00:25:07,826 说话人 SPEAKER_07：所以，我将解释修正线性单元和 dropout。
307 00:25:09,508 --> 00:25:14,413 说话人 SPEAKER_07：但首先，我想简要介绍一下卷积网络，因为这是这里最重要的东西。
308 00:25:14,848 --> 00:25:20,838 说话人 SPEAKER_07：想法是您将学习特征检测器。
309 00:25:20,878 --> 00:25:22,662 说话人 SPEAKER_07：它们查看输入图像。
310 00:25:23,564 --> 00:25:27,790 说话人 SPEAKER_07：但对于任何给定的特征检测器，您将在输入图像中复制它。
311 00:25:27,810 --> 00:25:31,175 说话人 SPEAKER_07：因此它有一个核，一组权重，并将这些权重应用于各个地方。
312 00:25:31,195 --> 00:25:34,561 说话人 SPEAKER_07：所以你在进行卷积之后跟着非线性变换。
313 00:25:35,048 --> 00:25:39,193 说话人 SPEAKER_07：所以在那张图片中，你可以看到三个相同的特征检测器的副本。
314 00:25:39,614 --> 00:25:43,700 说话人 SPEAKER_07：所以所有的红色权重值都相同，所有的绿色权重值都相同，所有的蓝色权重值都相同。
315 00:25:44,540 --> 00:25:48,046 说话人 SPEAKER_07：实际上你有一系列不同的图，每个图都有一个不同的核。
316 00:25:48,886 --> 00:25:50,388 说话人 SPEAKER_07：您可以为多层这样做。
317 00:25:52,010 --> 00:25:54,755 说话人 SPEAKER_07：卷积神经网络还有其他组成部分，但这是主要的一个。
318 00:25:55,134 --> 00:26:00,442 说话人 SPEAKER_07：我不打算描述池化，因为我不认为这是正确的做法，但它有效。
319 00:26:02,365 --> 00:26:03,807 说话人 SPEAKER_07：这就是卷积神经网络。
320 00:26:05,643 --> 00:26:09,208 说话人 SPEAKER_07：实际上，你可以将卷积网络应用于语音。
321 00:26:09,228 --> 00:26:14,935 说话人 SPEAKER_07：实际上，我在 80 年代就做了这件事，那时我们有一些看起来像时间的小滤波器。
322 00:26:14,996 --> 00:26:16,598 说话人 SPEAKER_07：然后你将滤波器复制到时间上。
323 00:26:17,400 --> 00:26:19,863 说话人 SPEAKER_07：实际上，只有一个滤波器在那里，让数据通过。
324 00:26:19,903 --> 00:26:22,227 说话人 SPEAKER_07：这就是所说的时延神经网络。
325 00:26:22,988 --> 00:26:25,672 说话人 SPEAKER_07：实际上，Jan 就是从这里得到了卷积神经网络的想法。
326 00:26:25,771 --> 00:26:27,954 说话人 SPEAKER_07：他将这个概念推广到了二维。
327 00:26:27,934 --> 00:26:30,298 说话人 SPEAKER_07：但后来我发现我所做的是愚蠢的。
328 00:26:30,317 --> 00:26:33,101 说话人 SPEAKER_07：我正在使用时间过滤器。
329 00:26:33,161 --> 00:26:36,285 说话人 SPEAKER_07：而在语音方面，使用频率过滤器会更好。
330 00:26:37,065 --> 00:26:40,128 说话人 SPEAKER_07：因为时间是由隐马尔可夫模型来处理的。
331 00:26:40,528 --> 00:26:43,992 说话人 SPEAKER_07：它们可以处理不同的起始时间和不同的速率。
332 00:26:45,134 --> 00:26:51,182 说话人 SPEAKER_07：但在频率上，由于声迹长度的变化，可以得到共振峰的变化。
333 00:26:52,282 --> 00:26:55,967 说话人 SPEAKER_07：在频率上局部进行卷积
334 00:26:56,115 --> 00:26:58,558 说话人 SPEAKER_07：在语音识别方面带来了显著的提升。
335 00:26:59,359 --> 00:27:02,344 说话人 SPEAKER_07：加拿大的一些学生发现了这一点。
336 00:27:03,204 --> 00:27:06,028 说话人 SPEAKER_07：IBM 已经证明它工作得非常好。
337 00:27:08,732 --> 00:27:10,454 说话人 SPEAKER_07：所以这里是修正线性单元。
338 00:27:11,056 --> 00:27:15,741 说话人 SPEAKER_07：我们取一个逻辑单元，然后取一大堆具有不同偏置的单元。
339 00:27:16,163 --> 00:27:24,874 说话人 SPEAKER_07：所以您有一个学习到的偏置 B，但您还有一个略小于那个的偏置，B 减去 0.5，B 减去 1.5，B 减去 2.5。
340 00:27:25,816 --> 00:27:29,221 说话人 SPEAKER_07：因此，您有一系列具有递增阈值的功能检测器。
341 00:27:30,541 --> 00:27:32,826 说话人 SPEAKER_07：它们的输入和输出权重都相同。
342 00:27:32,865 --> 00:27:35,730 说话人 SPEAKER_07：所以唯一的问题是，当您给它们一些输入时，会有多少个被激活？
343 00:27:37,070 --> 00:27:46,805 说话人 SPEAKER_07：如果您查看被激活的数量，那么您会对所有这些带有步偏置的对数求和感兴趣。
344 00:27:47,546 --> 00:27:54,355 说话人 SPEAKER_07：这个和几乎与 1 加上 e 的 x 的对数相同，这在黑色曲线上有显示。
345 00:27:55,076 --> 00:27:59,761 说话人 SPEAKER_07：逻辑分布属于指数族，而 1 加上 e 的 x 的对数不属于。
346 00:28:01,423 --> 00:28:20,865 说话人 SPEAKER_07：但结果是，如果你取这个和的极限并使其成为积分，它就正好是 1 加上 e 的 x 的对数。所以我们知道 1 加上 e 的 x 的对数的行为就像很多逻辑分布，但它比一个逻辑分布更强大，因为它不会在顶部饱和，因此它具有更大的动态范围。
347 00:28:21,435 --> 00:28:26,544 说话人 SPEAKER_07：看到这一点后，你说，我真的需要这个对数和 x 吗？
348 00:28:26,663 --> 00:28:31,311 说话人 SPEAKER_07：也许我可以直接取输入的最大值和 0 的最大值，这样就可以正常工作。
349 00:28:34,435 --> 00:28:35,698 说话人 SPEAKER_07：这并不完全合理。
350 00:28:35,759 --> 00:28:40,526 说话人 SPEAKER_07：我的意思是，我喜欢从逻辑单元推导出来的结果，但最终还是要放弃推导，直接进行下去。
351 00:28:41,166 --> 00:28:44,471 说话人 SPEAKER_07：这比逻辑单元学习得快得多。
352 00:28:45,192 --> 00:28:46,836 说话人 SPEAKER_07：它的容量稍微大一些。
353 00:28:47,103 --> 00:28:54,612 说话人 SPEAKER_07：所以现在做这些深度神经网络的多数人都转向使用这些修正线性单元了。
354 00:28:54,711 --> 00:28:56,694 说话人 SPEAKER_07：你可能会问接下来会是什么类型的单元。
355 00:28:57,796 --> 00:29:04,183 说话人 SPEAKER_07：蒙特利尔的人尝试过，修正线性单元是一个线性单元或零，取两者中较大的。
356 00:29:05,365 --> 00:29:12,874 说话人 SPEAKER_07：那么我们可以推广到，为什么我们不把一大堆不同的线性单元放在一个池子里，而是取输出最大的那个呢？
357 00:29:13,900 --> 00:29:15,470 说话人 SPEAKER_07：这是一个有趣的非线性。
358 00:29:15,791 --> 00:29:18,830 说话人 SPEAKER_07：他们已经证明在某些情况下，这样做稍微好一些。
359 00:29:19,199 --> 00:29:23,663 说话人 SPEAKER_07：我仍然不知道这是否通常更好，或者只是有时更好，但这样做是有道理的。
360 00:29:24,744 --> 00:29:44,147 说话人 SPEAKER_07：我认为我们多年来一直使用逻辑单元，而有些简单的方法效果更好，或者显著更好，以及存在许多变体效果甚至更好，这强烈地暗示我们设计这些网络时过于保守，我们应该考虑所有各种复杂但合理的函数。
361 00:29:44,587 --> 00:29:46,911 说话人 SPEAKER_07：也许我们甚至可以从大脑中汲取一些灵感，
362 00:29:47,869 --> 00:29:51,253 说话人 SPEAKER_07：所以我们在神经网络中称之为层的实际上是对应的皮层区域。
363 00:29:52,336 --> 00:29:54,377 说话人 SPEAKER_07：而在每个皮层区域中，你都有微型柱。
364 00:29:54,878 --> 00:29:59,724 说话人 SPEAKER_07：这些微型列在发送到下一个区域之前会进行一些相当复杂的计算。
365 00:30:00,526 --> 00:30:05,813 说话人 SPEAKER_07：我认为我们可能更适合使用神经网络进入下一个层次。
366 00:30:05,893 --> 00:30:08,696 说话人 SPEAKER_07：在下一个层次，你会进行一些相当复杂的计算。
367 00:30:08,737 --> 00:30:11,800 说话人 SPEAKER_07：这涉及到一些递归，可能需要几次迭代。
368 00:30:12,501 --> 00:30:14,163 说话人 SPEAKER_07：然后你将其发送到下一级。
369 00:30:15,005 --> 00:30:17,688 说话人 SPEAKER_07：你可以通过循环神经网络进行反向传播。
370 00:30:17,708 --> 00:30:19,289 说话人 SPEAKER_07：所以你可以通过所有这些进行反向传播。
371 00:30:19,589 --> 00:30:27,598 说话人 SPEAKER_07：反向传播所需的就是你有一个模块，并且你知道如果输入一些东西，之后会输出什么东西。
372 00:30:28,359 --> 00:30:29,320 说话人 SPEAKER_07：所以你有了前向函数。
373 00:30:29,622 --> 00:30:36,809 说话人 SPEAKER_07：你也知道，如果你发送误差函数相对于什么的导数，你可以在顶部得到导数。
374 00:30:37,009 --> 00:30:39,193 说话人 SPEAKER_07：这是反向传播所需的所有内容。
375 00:30:39,674 --> 00:30:41,878 说话人 SPEAKER_07：这就是反向传播所需的所有内容。
376 00:30:41,898 --> 00:30:45,265 说话人 SPEAKER_07：我们应该在探索模块的种类上更加雄心勃勃。
377 00:30:45,285 --> 00:30:46,488 说话人 SPEAKER_07：Jan 已经说了很多年了。
378 00:30:48,832 --> 00:30:51,175 说话人 SPEAKER_07：所以我认为我们可能更接近皮质柱。
379 00:30:52,038 --> 00:30:57,027 说话人 SPEAKER_07：而我喜欢的神经启发是当
380 00:30:57,849 --> 00:31:00,253 说话人 SPEAKER_07：让它更像大脑，这样能让它工作得更好。
381 00:31:00,753 --> 00:31:02,896 说话人 SPEAKER_07：很多人都说，你应该让它更像大脑。
382 00:31:02,916 --> 00:31:04,259 说话人 SPEAKER_07：比如亨利·马克拉姆。
383 00:31:04,920 --> 00:31:07,544 说话人 SPEAKER_07：他说，给我十亿美元，我就做出类似大脑的东西。
384 00:31:07,584 --> 00:31:09,707 说话人 SPEAKER_07：但他实际上不知道如何让它工作。
385 00:31:09,727 --> 00:31:12,510 说话人 SPEAKER_07：他只知道如何让它越来越像大脑，但实际上并没有工作。
386 00:31:13,333 --> 00:31:16,096 说话人 SPEAKER_07：在我看来，这不是正确的做法。
387 00:31:16,176 --> 00:31:19,761 说话人 SPEAKER_07：我们应该坚持那些真正有效的方法，并尝试使它们更接近大脑。
388 00:31:19,981 --> 00:31:23,126 说话人 SPEAKER_07：特别是要注意，使其更接近大脑是有帮助的。
389 00:31:23,607 --> 00:31:26,592 说话人 SPEAKER_07：如果这样做只是让工作变得更糟，那么让它更接近大脑就没有什么意义了。
390 00:31:30,384 --> 00:31:34,548 说话人 SPEAKER_07：这里有一件事，我们直到最近都无法用神经网络做到。
391 00:31:35,329 --> 00:31:42,857 说话人 SPEAKER_07：任何参加过这些机器学习竞赛的人都知道，如果你想赢得比赛，你必须训练很多不同的模型并将它们平均。
392 00:31:42,877 --> 00:31:43,878 说话人 SPEAKER_07：而且，不同的模型越多越好。
393 00:31:45,401 --> 00:31:49,044 说话人 SPEAKER_07：但不同模型的平均是一种非常有效的避免过拟合的方法。
394 00:31:50,526 --> 00:31:51,787 说话人 SPEAKER_07：这基本上是一个委员会。
395 00:31:52,788 --> 00:31:56,291 说话人 SPEAKER_07：在大学里，它可以避免任何事情都做不成。
396 00:31:57,300 --> 00:32:00,247 说话人 SPEAKER_07：但实际上，经济学家现在都知道这一点。
397 00:32:00,287 --> 00:32:08,462 说话人 SPEAKER_07：当一位明智的经济学家想要预测经济接下来会发生什么时，你会得到 15 位专家，然后平均他们的说法。
398 00:32:09,384 --> 00:32:11,328 说话人 SPEAKER_07：这样比随机选择一个专家要好。
399 00:32:12,391 --> 00:32:16,338 说话人 SPEAKER_07：可能比选择最好的专家还要差，但你不知道谁是最好的专家。
400 00:32:17,585 --> 00:32:21,387 说话人 SPEAKER_07：所以直到最近，平均多个模型的方法是使用决策树。
401 00:32:21,929 --> 00:32:24,070 说话人 SPEAKER_07：这是一种来自 Leo Breiman 的技术。
402 00:32:24,832 --> 00:32:31,396 说话人 SPEAKER_07：决策树对数据的拟合非常快，在测试时使用也非常快。
403 00:32:31,416 --> 00:32:38,263 说话人 SPEAKER_07：因此我们可以拟合很多决策树，也可以在测试时运行很多决策树。
404 00:32:38,284 --> 00:32:39,944 说话人 SPEAKER_07：决策树是一个相对较弱的模型。
405 00:32:40,045 --> 00:32:42,307 说话人 SPEAKER_07：它远不如神经网络强大。
406 00:32:42,326 --> 00:32:44,788 说话人 SPEAKER_07：但是你可以快速地拟合很多，你可以在测试时运行它们。
407 00:32:44,990 --> 00:32:47,592 说话人 SPEAKER_07：这就叫做随机森林，而且效果相当不错。
408 00:32:47,842 --> 00:32:51,371 说话人 SPEAKER_07：我们想要做的是用神经网络来实现随机森林的等效功能。
409 00:32:51,912 --> 00:32:56,162 说话人 SPEAKER_07：我们想要拟合大量的神经网络，并在测试时对它们进行平均。
410 00:32:56,663 --> 00:32:58,627 说话人 SPEAKER_07：问题是计算量太大。
411 00:32:59,569 --> 00:33:03,095 说话人 SPEAKER_07：所以如果你用我们中的一个网络，训练它需要很长时间。
412 00:33:03,115 --> 00:33:05,298 说话人 SPEAKER_07：在 GPU 上训练这样一个网络需要大约一周时间。
413 00:33:06,239 --> 00:33:07,882 说话人 SPEAKER_07：这是一个很大的网络，是物体识别网络。
414 00:33:08,782 --> 00:33:12,788 说话人 SPEAKER_07：在测试时，你不想运行这么多大型网络。
415 00:33:13,088 --> 00:33:14,069 说话人 SPEAKER_07：这将会非常昂贵。
416 00:33:14,730 --> 00:33:17,796 说话人 SPEAKER_07：所以看起来你无法用神经网络进行这种模型平均。
417 00:33:18,517 --> 00:33:19,617 说话人 SPEAKER_07：但结果证明这是错误的。
418 00:33:19,637 --> 00:33:21,180 说话人 SPEAKER_07：有一种非常简单的方法来做这件事。
419 00:33:21,560 --> 00:33:22,863 说话人 SPEAKER_07：这是一种模型平均的形式。
420 00:33:25,105 --> 00:33:28,851 说话人 SPEAKER_07：在我向您展示如何做之前，我想区分两种模型平均的方法。
421 00:33:28,982 --> 00:33:30,144 说话人 SPEAKER_07：它们都工作得很好。
422 00:33:30,684 --> 00:33:33,887 说话人 SPEAKER_07：它们在 callback-Libla 距离上都有很好的保证。
423 00:33:34,327 --> 00:33:38,192 说话人 SPEAKER_07：也就是说，它们表明模型平均的效果比随机选择一个模型要好。
424 00:33:40,192 --> 00:33:51,124 说话人 SPEAKER_07：第一种是最明显的方法，就是简单地说，如果我有两个模型 A 和 B，并且我有三个类别，我就简单地平均每个模型预测的概率分布。
425 00:33:52,484 --> 00:33:55,867 说话人 SPEAKER_07：所以当我们结合模型时，我们只是平均它们的输出概率。
426 00:33:57,400 --> 00:34:00,503 说话人 SPEAKER_07：第二个是取输出概率的几何平均值。
427 00:34:00,544 --> 00:34:01,645 说话人 SPEAKER_07：你只需要将它们相乘。
428 00:34:01,685 --> 00:34:04,789 说话人 SPEAKER_07：现在，当你这样做的时候，你会得到一些数字，它们的和不再是 1 了。
429 00:34:05,351 --> 00:34:09,916 说话人 SPEAKER_07：所以你必须通过除以总和来重新归一化它们。
430 00:34:09,936 --> 00:34:13,402 说话人 SPEAKER_07：这两种平均模型的方法之间有一些重要的区别。
431 00:34:14,384 --> 00:34:19,751 说话人 SPEAKER_07：例如，在第一种方法中，平均模型总是比单个模型模糊。
432 00:34:21,813 --> 00:34:26,260 说话人 SPEAKER_07：平均模型永远不能比单个模型中最精确的更精确。
433 00:34:26,476 --> 00:34:29,079 说话人 SPEAKER_07：你必须这样获得更高的熵。
434 00:34:29,099 --> 00:34:32,302 说话人 SPEAKER_07：当你计算几何平均数时，可以得到更高的熵或更低的熵。
435 00:34:34,887 --> 00:34:37,068 说话人 SPEAKER_07：从这个意义上说，你可能认为它更强大。
436 00:34:37,088 --> 00:34:38,690 说话人 SPEAKER_07：但无论如何，这只是两种平均方式。
437 00:34:41,335 --> 00:34:44,898 说话人 SPEAKER_07：现在，我将向您展示如何非常高效地使用神经网络进行几何平均。
438 00:34:46,101 --> 00:34:48,423 说话人 SPEAKER_07：我们所做的，让我们用一个只有一个隐藏层的神经网络为例。
439 00:34:49,545 --> 00:34:54,170 说话人 SPEAKER_07：每次我们展示一个训练示例时，我们会省略一半的隐藏单元。
440 00:34:56,141 --> 00:34:58,864 说话人 SPEAKER_07：所以我们所做的是从不同的模型架构中进行采样。
441 00:35:01,349 --> 00:35:07,356 说话人 SPEAKER_07：但我们保留的单元在保留时总是具有相同的权重。
442 00:35:07,376 --> 00:35:15,525 说话人 SPEAKER_07：所以你可以把它想象成我们有 H 个隐藏单元，我们从 2 的 H 次方可能的架构中随机采样。
443 00:35:15,726 --> 00:35:16,907 说话人 SPEAKER_07：但我们中的大多数都不会进行采样。
444 00:35:17,409 --> 00:35:20,192 说话人 SPEAKER_07：但这些架构正在进行大量的权重共享。
445 00:35:26,364 --> 00:35:28,967 说话人 SPEAKER_07：所以只有少数这些架构会被训练。
446 00:35:29,708 --> 00:35:30,751 说话人 SPEAKER_07：每个训练示例一个。
447 00:35:31,931 --> 00:35:36,277 说话人 SPEAKER_07：但是这种大规模权重共享比 L2 和 L1 等要更好地正则化。
448 00:35:36,918 --> 00:35:41,985 说话人 SPEAKER_07：因为权重不是被拉向零，而是被拉向其他模型希望它们所在的位置。
449 00:35:42,264 --> 00:35:43,847 说话人 SPEAKER_07：它们被拉向合理的值。
450 00:35:44,507 --> 00:35:45,528 说话人 SPEAKER_07：所以这不仅仅是缩小。
451 00:35:46,971 --> 00:35:54,280 说话人 SPEAKER_07：因此，拥有这个庞大的、指数级增长的模型集，以及所有这些权重共享，结果证明效果非常好。
452 00:35:56,369 --> 00:35:58,192 说话人 SPEAKER_07：一个问题是我们测试时该怎么做？
453 00:35:58,211 --> 00:35:59,833 说话人 SPEAKER_07：我们是否需要运行指数级多的模型？
454 00:36:00,355 --> 00:36:01,195 说话人 SPEAKER_07：这里有一个小技巧。
455 00:36:02,518 --> 00:36:09,608 说话人 SPEAKER_07：在测试时，你不需要以一半的概率省略单位，你只需将输出权重减半。
456 00:36:11,271 --> 00:36:17,300 说话人 SPEAKER_07：因此，在测试时，你得到相同的期望值输出，没有方差。
457 00:36:17,320 --> 00:36:20,844 说话人 SPEAKER_07：所以你使用了所有的单元，但只使用了强度的一半。
458 00:36:21,565 --> 00:36:24,891 说话人 SPEAKER_07：结果恰好计算了平均值，
459 00:36:24,989 --> 00:36:26,871 说话人 SPEAKER_07：计算了所有 2 到 H 个模型的平均值。
460 00:36:26,891 --> 00:36:29,532 说话人 SPEAKER_07：它计算了几何平均值。
461 00:36:29,552 --> 00:36:31,494 说话人 SPEAKER_07：所以你几乎可以免费得到它。
462 00:36:32,576 --> 00:36:35,358 说话人 SPEAKER_07：所以我们只运行了一个测试网络的测试时间。
463 00:36:35,378 --> 00:36:38,762 说话人 SPEAKER_07：它的大小是我们在训练期间运行的任何单个网络的两倍。
464 00:36:39,302 --> 00:36:43,266 说话人 SPEAKER_07：现在我们已经计算了几何平均值。
465 00:36:43,286 --> 00:36:49,092 说话人 SPEAKER_07：这使得在训练时间高效地训练大量不同的模型，并在测试时间高效地组合它们成为可能。
466 00:36:50,773 --> 00:36:53,697 说话人 SPEAKER_07：如果你有更多的隐藏层，你就继续做 dropout。
467 00:36:53,980 --> 00:37:05,213 说话人 SPEAKER_07：你每层都去掉 50%的单元。
468 00:37:05,233 --> 00:37:16,005 说话人 SPEAKER_07：你每层都去掉 50%的单元。
469 00:37:16,507 --> 00:37:19,652 说话人 SPEAKER_07：那么在测试时你就有所有的空气动力学。
470 00:37:19,672 --> 00:37:29,889 发言人 SPEAKER_07：它不再与计算所有模型的几何平均值完全相同，但它是一个接近的近似值，而且效果很好。
471 00:37:29,909 --> 00:37:32,833 发言人 SPEAKER_07：您还可以在输入中省略一些内容，这也有帮助。
472 00:37:33,574 --> 00:37:40,626 发言人 SPEAKER_07：这项技术已经由帕斯卡·文森特、蒙特利尔大学及其合作者发明，他们通过不同的途径获得了它。
473 00:37:40,646 --> 00:37:44,371 发言人 SPEAKER_07：但是省去输入，随机输入，也是一种很好的方法。
474 00:37:45,297 --> 00:37:50,083 说话人 SPEAKER_07：了解机器学习的人对那种技术非常熟悉。
475 00:37:50,103 --> 00:37:57,251 说话人 SPEAKER_07：如果你将朴素贝叶斯与逻辑回归进行比较，在逻辑回归中，你使用所有输入来获取输出。
476 00:37:57,271 --> 00:37:59,153 说话人 SPEAKER_07：在朴素贝叶斯中，你只留下其中一个。
477 00:38:01,817 --> 00:38:11,288 说话人 SPEAKER_07：结果发现，如果你数据不多，最好是通过只留下其中一个来训练，然后训练大量不同的模型并取平均值。
478 00:38:11,307 --> 00:38:15,253 说话人 SPEAKER_07：在朴素贝叶斯中，这是一种非常简单的输入 dropout 形式。
479 00:38:18,170 --> 00:38:19,411 说话人 SPEAKER_07：dropout 工作得非常好。
480 00:38:23,735 --> 00:38:30,581 说话人 SPEAKER_07：如果大多数神经网络存在过拟合，它将大大减少错误。
481 00:38:30,822 --> 00:38:33,865 说话人 SPEAKER_07：如果没有过拟合，你应该使用更大的神经网络。
无论你有多少数据，我都一直向谷歌解释这一点，无论你有多少数据，你都可以使用一个神经网络，这样它就会过拟合。
483 00:38:42,373 --> 00:38:43,315 说话者 SPEAKER_07：这就是你应该做的。
484 00:38:43,675 --> 00:38:44,735 发言人 SPEAKER_07：然后你应该对其进行正则化。
485 00:38:45,416 --> 00:38:47,298 说话者 SPEAKER_07：如果你看看人们所处的体制，
486 00:38:48,393 --> 00:38:53,543 发言人 SPEAKER_07：统计学家生活在这样一种境况中：你的主要正则化因素就是你没有足够的参数。
所以对于统计学家来说，默认的设置是有1,000个训练样本和50个参数。
488 00:39:00,217 --> 00:39:01,038 发言人 SPEAKER_07：然后他们就很高兴了。
489 00:39:01,077 --> 00:39:01,780 发言人 SPEAKER_07：这很熟悉。
490 00:39:02,380 --> 00:39:05,447 说话人 SPEAKER_07：如果你说，关于有 1,000 个训练样本和一百万个参数怎么办？
491 00:39:05,987 --> 00:39:08,393 说话人 SPEAKER_07：他们说，别傻了。
492 00:39:09,672 --> 00:39:10,893 说话人 SPEAKER_07：但是使用 Dropout，你可以做到这一点。
493 00:39:11,554 --> 00:39:13,416 说话人 SPEAKER_07：如果你想，人们通常会怎么做？
494 00:39:14,777 --> 00:39:17,521 说话人 SPEAKER_07：嗯，人们，你们活着的时间是 10 的 9 次方秒。
495 00:39:18,442 --> 00:39:20,744 说话人 SPEAKER_07：假设你每秒有 10 个训练样本。
496 00:39:21,364 --> 00:39:23,608 说话人 SPEAKER_07：这并不是一个很好的视频模型，但暂时可以。
497 00:39:24,268 --> 00:39:26,710 说话人 SPEAKER_07：你得到 10 的 10 次方个训练样本。
498 00:39:29,353 --> 00:39:31,876 说话人 SPEAKER_07：但你有了 10 的 14 次方或 10 的 15 次方个参数。
499 00:39:32,757 --> 00:39:37,282 说话人 SPEAKER_07：所以每个训练样本有 10,000 或 100,000 个参数。
500 00:39:37,853 --> 00:39:42,338 说话人 SPEAKER_07：所以我们处于参数数量远多于训练样本的状态。
501 00:39:42,818 --> 00:39:46,023 说话人 SPEAKER_07：这是因为突触比经验便宜得多。
502 00:39:46,664 --> 00:39:52,230 说话人 SPEAKER_07：一秒钟的经验需要消耗大量能量，而与一生中一个突触相比，几乎微不足道。
503 00:39:53,371 --> 00:39:55,673 说话人 SPEAKER_07：所以我们与统计学家处于完全不同的领域。
504 00:40:01,460 --> 00:40:05,346 讲者 SPEAKER_07：关于 dropout 的另一种思考方式是，它就像性行为。
505 00:40:05,764 --> 00:40:15,418 讲者 SPEAKER_07：在有性繁殖中有一个谜题，就是你拥有所有这些完美适应的基因，然后与某人交配，生下后代，你一半的完美适应基因就消失了。
506 00:40:15,458 --> 00:40:18,023 讲者 SPEAKER_07：这似乎是一件坏事。
507 00:40:18,563 --> 00:40:20,306 讲者 SPEAKER_07：看起来你最好是克隆自己。
508 00:40:21,407 --> 00:40:27,177 说话人 SPEAKER_07：的确，如果环境一点都没有变化，我想你最好是克隆自己。
509 00:40:27,197 --> 00:40:30,641 说话人 SPEAKER_07：但是假设环境可能会突然变化。
510 00:40:31,972 --> 00:40:35,456 说话人 SPEAKER_07：那么拥有大量共适应基因是一个非常糟糕的想法。
511 00:40:36,277 --> 00:40:40,844 说话人 SPEAKER_07：因为如果环境发生变化，它们就不会很好地一起工作。
512 00:40:41,264 --> 00:40:44,208 说话人 SPEAKER_07：拥有许多小套共适应基因是一个更好的主意。
513 00:40:45,009 --> 00:40:52,038 说话人 SPEAKER_07：例如，如果你为基地组织工作，拥有许多小阴谋比一个大阴谋要好。
514 00:40:52,599 --> 00:40:55,822 说话人 SPEAKER_07：因为在测试时，条件可能和训练时不同。
515 00:40:56,403 --> 00:40:58,907 说话人 SPEAKER_07：如果你有许多小阴谋，其中一些仍然会起作用。
516 00:41:01,164 --> 00:41:04,469 说话人 SPEAKER_07：我在加拿大，对吧？
517 00:41:08,293 --> 00:41:08,632 说话人 SPEAKER_07：好的。
518 00:41:11,076 --> 00:41:12,958 说话人 SPEAKER_07：那么让我给你讲几个其他案例。
519 00:41:13,097 --> 00:41:13,958 说话人 SPEAKER_07：我时间掌握得怎么样？
520 00:41:18,784 --> 00:41:19,844 说话人 SPEAKER_07: 好的。
521 00:41:19,864 --> 00:41:24,050 说话人 SPEAKER_07: 让我告诉你几个我们现在已经有了食谱的案例。
522 00:41:24,550 --> 00:41:27,172 说话人 SPEAKER_07: 那个食谱就是有一个深度网络。
523 00:41:28,688 --> 00:41:30,849 说话人 SPEAKER_07: 如果你没有很多标记的训练数据，就先进行预训练。
524 00:41:30,869 --> 00:41:33,213 说话人 SPEAKER_07：但是如果你有很多标记的训练数据，那就不用费心了。
525 00:41:33,793 --> 00:41:39,099 说话人 SPEAKER_07：初始化权重为合理的值，以便在反向传播导数时，不会消亡或爆炸。
526 00:41:40,079 --> 00:41:41,661 说话人 SPEAKER_07：使用修正线性单元。
527 00:41:42,702 --> 00:41:47,047 说话人 SPEAKER_07：使用 dropout 进行正则化，这样你就可以使用比训练样本更多的参数。
528 00:41:47,967 --> 00:41:51,992 说话人 SPEAKER_07：如果数据有空间结构，就在前端使用卷积。
529 00:41:52,012 --> 00:41:52,833 说话人 SPEAKER_07：这就是我们的方法。
530 00:41:53,414 --> 00:41:57,057 说话人 SPEAKER_07：现在这个方法将解决所有问题。
531 00:41:58,152 --> 00:42:03,101 说话人 SPEAKER_07：所以如果你去嘉吉，那里有机器学习竞赛。
532 00:42:03,541 --> 00:42:09,032 说话人 SPEAKER_07：直到最近，所有的比赛都是由业余爱好者赢得的，这对机器学习专业人士来说应该非常尴尬。
533 00:42:09,914 --> 00:42:16,987 说话人 SPEAKER_07：大型机器学习团队并没有参与这些比赛，尽管有丰厚的奖金。
534 00:42:18,824 --> 00:42:21,788 说话人 SPEAKER_07：其中一个原因是随机森林一直在获胜。
535 00:42:22,650 --> 00:42:24,853 说话人 SPEAKER_07：随机森林在这些比赛中表现相当不错。
536 00:42:25,353 --> 00:42:30,802 说话人 SPEAKER_07：但最近我们展示了我们的配方打败了随机森林，并且它做得相当一致。
537 00:42:33,266 --> 00:42:39,135 说话人 SPEAKER_07：所以一个很好的例子是从分子的描述符预测分子的活性。
538 00:42:39,155 --> 00:42:45,945 说话人 SPEAKER_07：因此默克举办了一场竞赛，其中包含大约 11,000 个分子的描述符。
539 00:42:47,916 --> 00:42:55,347 说话人 SPEAKER_07：并且每个特定的任务都需要使用 3,000 到 9,000 个这些描述符。
540 00:42:55,487 --> 00:42:57,329 说话人 SPEAKER_07：但是这些都是从同一个描述符池中提取的。
541 00:42:58,731 --> 00:43:04,259 说话人 SPEAKER_07：然后你需要预测分子是否能够很好地与某物结合。
542 00:43:05,260 --> 00:43:07,143 说话人 SPEAKER_07：他们已经为大量分子进行了测量。
543 00:43:08,123 --> 00:43:10,166 说话人 SPEAKER_07：但通常情况下，他们只测量了数千个。
544 00:43:10,788 --> 00:43:15,273 说话人 SPEAKER_07：您有一个问题，输入的维度几乎与训练样本的数量相当。
545 00:43:16,586 --> 00:43:19,349 说话人 SPEAKER_07：乔治尝试在这个问题上训练标准的反向传播网络。
546 00:43:20,550 --> 00:43:27,318 说话人 SPEAKER_07：问题是，一旦您使用超过 30 个隐藏单元，即使使用强大的 L2 正则化，模型也会严重过拟合。
547 00:43:28,059 --> 00:43:32,503 说话人 SPEAKER_07：因为现在您的参数数量比数据点多了 50 倍。
548 00:43:33,764 --> 00:43:38,208 说话人 SPEAKER_07：但是如果你在这个地方使用 dropout，你可以使用大约 500 个隐藏单元和多层。
549 00:43:38,730 --> 00:43:42,132 说话人 SPEAKER_07：所以你可以使用比训练样本数量多出数百倍的参数。
550 00:43:42,813 --> 00:43:46,036 说话人 SPEAKER_07：而且效果非常好。
551 00:43:46,456 --> 00:43:53,045 说话人 SPEAKER_07：另外一件事是，你可以将许多不同的任务合并起来，训练一个网络来解决所有这些问题。
552 00:43:53,445 --> 00:43:55,949 说话人 SPEAKER_07：那么牛奶比赛，有 15 个目标。
553 00:43:56,369 --> 00:43:59,574 说话人 SPEAKER_07：然后你给他们一组分子，问它们与这个目标结合得怎么样？
554 00:43:59,634 --> 00:44:01,615 说话人 SPEAKER_07：再给另一组，问它们与那个目标结合得怎么样？
555 00:44:02,217 --> 00:44:03,858 说话人 SPEAKER_07：然后你只训练一个大的网络来完成所有这些。
556 00:44:06,623 --> 00:44:09,947 说话人 SPEAKER_07：对于缺失的描述符，你只需将这些视为输入上的丢弃。
557 00:44:11,228 --> 00:44:11,989 说话人 SPEAKER_07：这实际上已经完成了。
558 00:44:12,010 --> 00:44:14,673 说话人 SPEAKER_07：你只需在 GPU 上训练它。
559 00:44:15,092 --> 00:44:21,025 说话人 SPEAKER_07：如果乔治训练它，它确实做得很好，因为他非常擅长训练这类东西。
560 00:44:21,847 --> 00:44:26,458 说话人 SPEAKER_07：就那样，神经网络本身就能赢得比赛。
561 00:44:26,577 --> 00:44:35,396 说话人 SPEAKER_07：他实际上与其他东西平均了，但之后他回过头来，在赢得比赛之后，发现神经网络本身就能赢得比赛。
562 00:44:38,565 --> 00:44:40,268 说话人 SPEAKER_07：这里还有另一场这样的比赛。
563 00:44:40,467 --> 00:44:43,710 说话人 SPEAKER_07：你得到了英国一份招聘广告的标题。
564 00:44:44,311 --> 00:44:46,735 说话人 SPEAKER_07：你得到了描述的主体。
565 00:44:47,355 --> 00:44:48,757 说话人 SPEAKER_07：并且你得到了位置信息。
566 00:44:48,836 --> 00:44:51,539 说话人 SPEAKER_07：然后你必须预测薪水。
567 00:44:52,260 --> 00:44:59,248 说话人 SPEAKER_07：我的另一个学生 Vlad Ni 也使用了同样的技术并赢得了比赛。
568 00:44:59,347 --> 00:45:00,188 说话人 SPEAKER_07：赢得比赛相当轻松。
569 00:45:00,548 --> 00:45:02,811 说话人 SPEAKER_07：第二名的人也在使用神经网络。
570 00:45:03,773 --> 00:45:07,797 说话人 SPEAKER_07：所以我们现在有一种技术，至少可以赢得这些愚蠢的比赛。
571 00:45:08,586 --> 00:45:15,733 说话人 SPEAKER_07：可能很快就会有更好的东西出现，但就目前而言，这已经很好了。
572 00:45:17,434 --> 00:45:20,237 说话人 SPEAKER_07：我想以谈谈语音识别结束。
573 00:45:21,838 --> 00:45:25,900 说话人 SPEAKER_07：所以当前的语音识别系统有很多不同的组件。
574 00:45:25,942 --> 00:45:29,525 说话人 SPEAKER_07：它们有一个语言模型，试图预测下一个单词。
575 00:45:30,766 --> 00:45:33,728 说话人 SPEAKER_07：如果你听不清楚，预测将会有帮助。
576 00:45:35,750 --> 00:45:38,492 说话人 SPEAKER_07：他们有隐藏马尔可夫模型来模拟音素。
577 00:45:38,978 --> 00:45:45,728 说话人 SPEAKER_07：他们有一个声学模型，将您从声波中提取的系数映射到马尔可夫模型的比特概率。
578 00:45:46,869 --> 00:45:49,853 说话人 SPEAKER_07：所有这些最初都是分开训练的，然后它们都被组合在一起。
579 00:45:50,054 --> 00:45:55,362 说话人 SPEAKER_07：如果您想要真正好的性能，现在您尝试在最后有区别地将整个系统一起训练。
580 00:45:55,382 --> 00:45:58,425 说话人 SPEAKER_07：但这是一个大杂烩，包含了不同的方法。
581 00:45:58,447 --> 00:46:03,653 说话人 SPEAKER_07：现在我们已经取得了一些成功，我们的帝国主义倾向变得明显了。
582 00:46:04,434 --> 00:46:08,360 说话人 SPEAKER_07：我们希望做一个整个语音系统，它就是一个大型的循环神经网络。
583 00:46:09,202 --> 00:46:17,074 说话人 SPEAKER_07：也就是说，我们的任务是让声音波变成文本。
584 00:46:17,235 --> 00:46:18,096 说话人 SPEAKER_07：什么是转录？
585 00:46:18,376 --> 00:46:22,222 说话人 SPEAKER_07：它只是一串包含空格的字符。
586 00:46:22,822 --> 00:46:32,137 说话人 SPEAKER_07：所以我们想做的就是在这里取声音波，在那里取字符，至于你们的所有技术，我们只训练一个巨大的神经网络来完成它。
587 00:46:32,556 --> 00:46:35,079 说话人 SPEAKER_07：现在有很多理由让你相信这是徒劳的。
588 00:46:35,179 --> 00:46:42,909 说话人 SPEAKER_07：有一个非常好的理由是语言模型必须对词汇有深入了解，并且能够预测接下来出现的词汇。
589 00:46:43,550 --> 00:46:46,574 说话人 SPEAKER_07：我们提出用一种仅在字符级别上工作的方法来实现这一点。
590 00:46:48,135 --> 00:46:50,137 说话人 SPEAKER_07：这似乎是不合理的。
591 00:46:51,860 --> 00:46:53,882 说话人 SPEAKER_07：我们不会有一个单独的发音词典。
592 00:46:53,922 --> 00:46:55,324 说话人 SPEAKER_07：我们将学习所有这些。
593 00:46:55,911 --> 00:47:02,219 说话人 SPEAKER_07：我们不会用强制对齐声学目标来训练它，这是正常神经网络所做的事情。
594 00:47:02,280 --> 00:47:11,311 说话人 SPEAKER_07：所以通常在训练这些深度网络时，你首先训练一个愚蠢的老式模型，该模型将 HMM 与输入数据对齐。
595 00:47:11,610 --> 00:47:13,773 说话人 SPEAKER_07：然后你用这个来启动你的花哨的神经网络。
596 00:47:14,213 --> 00:47:16,157 说话人 SPEAKER_07：就像用原子弹启动氢弹。
597 00:47:16,597 --> 00:47:18,099 说话人 SPEAKER_07：没有原子弹就无法制造氢弹。
598 00:47:18,880 --> 00:47:20,501 说话人 SPEAKER_07：我认为。
599 00:47:22,864 --> 00:47:24,686 说话人 SPEAKER_07：我希望国土安全部在监听。
600 00:47:25,612 --> 00:47:28,396 说话人 SPEAKER_07: 好吧。
601 00:47:29,496 --> 00:47:31,840 说话人 SPEAKER_07: 所以 Alex Graves 花了很多时间在这上面。
602 00:47:32,780 --> 00:47:36,204 说话人 SPEAKER_07: 他已经有一个在读取在线手写文本方面表现最好的系统。
603 00:47:37,626 --> 00:47:39,510 说话人 SPEAKER_07: 这是一个循环神经网络。
604 00:47:40,250 --> 00:47:43,855 说话人 SPEAKER_07：他通过采用具有多个隐藏层的循环神经网络进一步发展了它。
605 00:47:44,356 --> 00:47:49,442 说话人 SPEAKER_07：因此它在时间上很深，因为它具有循环性，但在空间上也很深，因为它有这些多个隐藏层。
606 00:47:50,197 --> 00:47:53,981 说话人 SPEAKER_07：在 TIMIT 数据库上，之前最好的结果是大约 18.9%。
607 00:47:54,222 --> 00:47:56,786 说话人 SPEAKER_07：现在他们已经将其降低到 18.7%。
608 00:47:56,905 --> 00:47:59,548 说话人 SPEAKER_07：这已经是经过大量工作后的结果了。
609 00:48:00,650 --> 00:48:01,610 说话人 SPEAKER_07：他进步了很多。
610 00:48:01,630 --> 00:48:04,434 说话人 SPEAKER_07：17.7% 的提升是非常大的，非常出乎意料。
611 00:48:07,057 --> 00:48:09,621 说话人 SPEAKER_07：你无法去听他的演讲来了解细节，因为那是在 ICASP 上。
612 00:48:11,623 --> 00:48:13,204 说话人 SPEAKER_07：但是你可以在网上查一下。
613 00:48:13,425 --> 00:48:15,867 说话人 SPEAKER_07：所以他有一篇论文发表在 ICASP 上。
614 00:48:17,333 --> 00:48:20,960 说话人 SPEAKER_07：现在在 Timit 上，它的词汇量很小，不是大词汇量。
615 00:48:20,980 --> 00:48:25,528 说话人 SPEAKER_07：所以你避免了循环神经网络学习语言模型的问题。
616 00:48:26,170 --> 00:48:27,893 说话人 SPEAKER_07：看一个语言模型就像是对象识别。
617 00:48:27,914 --> 00:48:32,282 说话人 SPEAKER_07：要成为一个真正优秀的语言模型，它必须知道你所知道的一切。
618 00:48:32,943 --> 00:48:38,514 说话人 SPEAKER_07：这有点雄心勃勃，但要想成为一个相当好的语言模型，它仍然需要知道很多。
619 00:48:39,068 --> 00:48:41,791 说话人 SPEAKER_07：它必须知道人名。
620 00:48:41,871 --> 00:48:43,034 说话人 SPEAKER_07：它必须了解地点。
621 00:48:43,094 --> 00:48:45,378 说话人 SPEAKER_07：它必须了解各种有趣的异国他乡的词汇。
622 00:48:45,958 --> 00:48:53,990 说话人 SPEAKER_07：似乎不太可能让一个小循环神经网络，甚至一个大循环神经网络，在字符级别上工作来模拟语言。
623 00:48:54,512 --> 00:48:58,659 说话人 SPEAKER_07：所以我要以展示一些东西来结束，这会让你觉得这不太不可能。
624 00:48:59,860 --> 00:49:05,329 说话人 SPEAKER_07: 伊利亚·索茨基瓦训练了
625 00:49:05,815 --> 00:49:12,423 说话人 SPEAKER_07: 一个大约有 800 万个参数的循环神经网络，这不算多，用于预测某些文本中的下一个字符。
626 00:49:12,563 --> 00:49:20,833 说话人 SPEAKER_07: 他从维基百科中获取的文本，去掉了所有非常奇怪的字符，比如我们去掉所有的法式重音，这有点不道德。
627 00:49:21,434 --> 00:49:31,467 说话人 SPEAKER_07: 他将其缩减到 86 个字符，即数字和字母，大写字母和小写字母是不同的，等等。
628 00:49:31,920 --> 00:49:37,228 说话人 SPEAKER_07：然后他把维基百科的一半亿个字符分成了 100 个字符串，每个字符串 100 个字符长。
629 00:49:37,730 --> 00:49:38,952 说话人 SPEAKER_07：还有 500 万个这样的字符串。
630 00:49:39,893 --> 00:49:43,619 说话人 SPEAKER_07：然后循环神经网络会看到前 11 个字符，并需要开始预测它们。
631 00:49:45,121 --> 00:49:48,186 说话人 SPEAKER_07：然后他只训练它来预测下一个字符。
632 00:49:48,206 --> 00:49:51,172 说话人 SPEAKER_07：关于如何做这件事，还有一些小技巧，我就不详细介绍了。
633 00:49:51,592 --> 00:49:53,695 说话人 SPEAKER_07：这基本上是一个拥有 800 万个参数的循环神经网络。
634 00:49:53,755 --> 00:49:55,177 说话人 SPEAKER_07：它被训练来预测下一个字符。
635 00:49:56,304 --> 00:49:57,847 说话人 SPEAKER_07：问题是，这疯狂吗？
636 00:49:58,007 --> 00:50:01,650 说话人 SPEAKER_07：因为我们知道语言自然是由单词组成的，或者说至少是由词素组成的。
637 00:50:02,052 --> 00:50:03,793 说话人 SPEAKER_07：但是，将语言降低到字符级别似乎很疯狂。
638 00:50:04,414 --> 00:50:09,920 说话人 SPEAKER_07：当然，这对像芬兰语这样的粘着语来说非常好，因为单词由 15 个词素组成。
639 00:50:10,461 --> 00:50:12,123 说话人 SPEAKER_07：你不想在那里尝试建模单词。
640 00:50:13,606 --> 00:50:15,248 说话人 SPEAKER_07：令人惊奇的是它工作得非常好。
641 00:50:16,588 --> 00:50:22,936 说话人 SPEAKER_07：他的循环神经网络在字符识别方面与最先进的技术相当，略逊一筹。
642 00:50:23,557 --> 00:50:27,903 说话人 SPEAKER_07：但它可以做到像 30 个字符后还能平衡括号这样的功能。
643 00:50:28,405 --> 00:50:31,588 说话人 SPEAKER_07：因为循环神经网络会记住我有一个开括号，我最好把它关闭。
644 00:50:32,289 --> 00:50:36,675 说话人 SPEAKER_07：事实上，如果你给它两个开括号，它会稍微有点担心，然后很快就会关闭一个。
645 00:50:38,418 --> 00:50:40,942 说话人 SPEAKER_07：我们确定的循环神经网络可以计算括号。
646 00:50:41,001 --> 00:50:43,144 说话人 SPEAKER_07：它可以计算零个、一个、两个或多个。
647 00:50:43,704 --> 00:50:46,068 说话人 SPEAKER_07：如果你给它三个或更多，它会很快关闭一个。
648 00:50:48,831 --> 00:50:50,815 说话人 SPEAKER_07：这不一定能关闭正确的数字。
649 00:50:51,976 --> 00:50:54,398 说话人 SPEAKER_07：好的，所以他长时间在 GPU 上训练了它。
650 00:50:54,418 --> 00:50:55,239 说话人 SPEAKER_07：那么它工作得怎么样？
651 00:50:56,081 --> 00:50:58,385 说话人 SPEAKER_07：首先，他没有告诉它关于单词的事情。
652 00:50:58,625 --> 00:50:59,786 说话人 SPEAKER_07：那么它会学习英语单词吗？
653 00:50:59,806 --> 00:51:01,989 说话人 SPEAKER_07：还是它会产出乱码？
654 00:51:02,010 --> 00:51:03,210 说话人 SPEAKER_07：那么这里有一些生成的文本。
655 00:51:04,052 --> 00:51:09,539 说话人 SPEAKER_07：从模型中生成文本的方式是给它一些字符以启动。
656 00:51:09,780 --> 00:51:12,784 说话人 SPEAKER_07：然后你说，给我下一个字符的分布。
657 00:51:12,804 --> 00:51:20,193 说话人 SPEAKER_07：如果显示有 1/100 的概率是 x，那么以 1/100 的概率，你采样一个 x。
658 00:51:20,257 --> 00:51:24,789 说话人 SPEAKER_07：生成这个作为你的输出，并告诉语言模型，下一个字符是 X，你预测下一个是什么？
659 00:51:25,652 --> 00:51:27,677 说话人 SPEAKER_07：它可以逐步给出预测。
660 00:51:28,760 --> 00:51:32,849 说话人 SPEAKER_07：那么这里有一些它逐个字符生成的文本。
661 00:51:33,826 --> 00:51:36,548 说话人 SPEAKER_07：有趣的是，这里没有非单词字符。
662 00:51:37,070 --> 00:51:45,340 说话人 SPEAKER_07：这意味着，一旦它生成足够的英语单词，只有一个完成，它永远不会假设任何不一致的字符。
663 00:51:46,282 --> 00:51:47,043 说话人 SPEAKER_07：几乎从不。
664 00:51:47,063 --> 00:51:52,369 说话人 SPEAKER_07：它确实会产生非词，这些非词就像 ephemerable 或 continged。
665 00:51:53,030 --> 00:51:54,831 说话人 SPEAKER_07：所以 continged 不是英语单词。
666 00:51:55,492 --> 00:51:58,436 说话人 SPEAKER_07：但是如果你知道网络是这样做的，它就可以是。
667 00:51:58,456 --> 00:52:00,880 说话人 SPEAKER_07：好的。
668 00:52:02,277 --> 00:52:07,664 说话人 SPEAKER_07：您会注意到这一点，它也有幽默感，它喜欢地中海地区的爱尔兰情报机构。
669 00:52:10,027 --> 00:52:16,036 说话人 SPEAKER_07：您会发现它句子之间没有连贯性，但它有很多语法，有很多语义。
670 00:52:16,818 --> 00:52:24,909 说话人 SPEAKER_07：其中很多语义相当浅显，但它没有在学习单词是什么方面遇到任何问题，也没有在学习短距离语法方面遇到任何问题。
671 00:52:24,929 --> 00:52:29,735 说话人 SPEAKER_07：所以它真的可以，这个循环神经网络真的可以学习到一个相当好的语言模型。
672 00:52:30,155 --> 00:52:36,862 发言人 SPEAKER_07：虽然还没有全词语言模型那么好，但是已经足够好到让你怀疑我们或许可以把所有内容都放入一个循环网络中。
因此，我将通过向您展示来结束，如果您从维基百科中阅读了五亿个字符而没有先验知识，也就是说，先验知识包括它是一个有八百万个连接的神经网络，并且它做这件事，对吧？
674 00:52:52,481 --> 00:52:53,181 说话者 SPEAKER_07：那是先验。
675 00:52:53,822 --> 00:52:55,985 发言人 SPEAKER_07：哦，你要用梯度下降法来训练它。
676 00:52:56,965 --> 00:52:59,148 说话者 SPEAKER_07：那么，这里有一个哲学问题给你。
677 00:52:59,585 --> 00:53:06,152 说话者 SPEAKER_07：如果那是你的先验，你看到了来自维基百科的 50 亿个字符的字符串，你会知道生命的意义吗？
678 00:53:08,634 --> 00:53:12,478 说话者 SPEAKER_07：现在，如果你认为生命的意义是 42，那会很无聊，因为这在维基百科上，对吧？
679 00:53:13,278 --> 00:53:19,445 说话者 SPEAKER_07：如果你认为生命的意义是你自己阅读了维基百科后所创造的，那就更有趣了。
680 00:53:20,266 --> 00:53:20,806 说话人 SPEAKER_07：那么，我们开始了。
681 00:53:21,288 --> 00:53:22,068 说话人 SPEAKER_07：希望这能行。
682 00:53:22,789 --> 00:53:23,070 说话人 SPEAKER_07：好的。
683 00:53:23,309 --> 00:53:27,855 说话人 SPEAKER_07：你所做的是说出生命的意义，然后让它继续产生字符。
684 00:53:28,014 --> 00:53:29,135 说话人 SPEAKER_07：这是一个有趣的游戏。
685 00:53:29,655 --> 00:53:32,460 说话人 SPEAKER_07：我们本来希望它会说出 42，然后我们觉得，这样的希望不是很理智，对吧？
686 00:53:32,480 --> 00:53:33,422 说话人 SPEAKER_07：因为这太简单了。
687 00:53:35,063 --> 00:53:43,657 说话人 SPEAKER_07：所以在我们对模型的第一版进行训练时，那版模型并不好，大约在第三次尝试时，它说，生命的意义就是字面上的认识。
688 00:53:45,079 --> 00:53:48,184 说话人 SPEAKER_07：我想，哎呀，我们搞定了。
689 00:53:49,666 --> 00:53:53,172 说话人 SPEAKER_07：然后伊利亚又训练了一个月，我们得到了一个更好的模型。
690 00:53:53,952 --> 00:53:55,695 说话人 SPEAKER_07：然后他运行了模型 10 次。
691 00:53:56,257 --> 00:53:58,380 说话人 SPEAKER_07：然后你一直运行模型，直到它完全停止。
692 00:53:59,456 --> 00:54:02,400 说话人 SPEAKER_07：然后我们挑选最好的 10 个。
693 00:54:03,141 --> 00:54:08,088 说话人 SPEAKER_07：所以有一些选择，但这里的选择并不多。
694 00:54:09,228 --> 00:54:26,409 说话人 SPEAKER_07：所以这就是它完成生命意义的方式。
695 00:54:40,750 --> 00:54:41,990 说话人 SPEAKER_07：所以它几乎完成了。
696 00:54:42,010 --> 00:54:43,472 说话人 SPEAKER_07：快到了。
697 00:54:45,074 --> 00:54:46,715 说话人 SPEAKER_07：好的。
698 00:54:46,735 --> 00:54:47,117 说话人 SPEAKER_07：我完成了。
699 00:55:02,452 --> 00:55:04,275 说话人 SPEAKER_06：好的，所以我们有时间问几个问题。
700 00:55:07,838 --> 00:55:07,938 未知说话人：是的。
701 00:55:09,438 --> 00:55:17,010 说话人 SPEAKER_01：您最初做的无监督部分和无监督降维之间有相似之处吗？
702 00:55:17,550 --> 00:55:18,210 说话人 SPEAKER_01：无监督？
703 00:55:18,271 --> 00:55:20,414 说话人 SPEAKER_01：降维，比如 PCA。
704 00:55:20,936 --> 00:55:22,257 说话人 SPEAKER_01：嗯，这里有什么平行关系吗？
705 00:55:24,722 --> 00:55:28,306 说话人 SPEAKER_07：不多。
706 00:55:29,536 --> 00:55:37,045 说话人 SPEAKER_07：在许多系统中，你会尝试降低输入的维度，因为你不想有太多的参数，或者不想进行太多的计算。
707 00:55:37,646 --> 00:55:39,889 说话人 SPEAKER_07：因此主成分分析（PCA）正在丢弃信息。
708 00:55:40,630 --> 00:55:44,257 说话人 SPEAKER_07：通常情况下，如果你很幸运，这些信息就是次要成分中的噪声。
709 00:55:46,318 --> 00:55:50,224 说话人 SPEAKER_07：但通常情况下，如果扩展输入，这些网络工作得更好。
710 00:55:51,326 --> 00:55:55,391 说话人 SPEAKER_07：所以对于图像来说，例如，第一隐藏层的尺寸将大于像素数。
711 00:55:56,434 --> 00:56:02,393 发言人 SPEAKER_07：所以我们并不是要通过降低维度来实现正则化。
712 00:56:04,521 --> 00:56:09,617 说话人 SPEAKER_07：可以使用相同的降维方法，但这并不是它主要的工作方式。
713 00:56:13,545 --> 00:56:13,885 说话人 SPEAKER_00：是的。
714 00:56:14,567 --> 00:56:17,711 说话人 SPEAKER_00：我知道你可能不知道答案，但我只是想听听你的最佳猜测。
715 00:56:17,771 --> 00:56:25,282 说话人 SPEAKER_00：你认为这些模型与人类大脑皮层处理所用的方法相似吗？
716 00:56:26,103 --> 00:56:28,927 说话人 SPEAKER_00: 或者存在很大的差异吗？
717 00:56:28,947 --> 00:56:32,771 说话人 SPEAKER_00: 我们会在接下来的 20 年内知道答案吗？
718 00:56:32,791 --> 00:56:34,474 说话人 SPEAKER_07: 我认为大概有这么多差异。
719 00:56:40,630 --> 00:56:43,773 说话人 SPEAKER_07: 我认为我们很可能在接下来的 20 年内知道答案。
我认为，现在我已经持续思考这个问题很长时间了，但我认为在接下来的5到10年里，我们将对大脑如何进行这类计算有更多的了解。
721 00:56:57,693 --> 00:57:00,376 说话者 SPEAKER_07：最好在接下来的 10 年内。
722 00:57:01,690 --> 00:57:03,692 说话人 SPEAKER_07：我们最终会明白大脑是如何做到这一点的。
723 00:57:04,413 --> 00:57:05,675 说话人 SPEAKER_07：这将非常令人兴奋。
724 00:57:05,855 --> 00:57:07,036 说话人 SPEAKER_07：这将有助于技术的发展。
725 00:57:07,076 --> 00:57:08,677 说话人 SPEAKER_07：甚至可能有助于教育等方面。
726 00:57:09,679 --> 00:57:10,940 说话人 SPEAKER_07：但它肯定是以某种方式做到的。
727 00:57:12,001 --> 00:57:13,844 说话人 SPEAKER_07：大脑所做的是相当有效的。
728 00:57:14,445 --> 00:57:19,170 说话人 SPEAKER_07：随着这些技术越来越好，看起来理解大脑的活动是一个越来越好的选择。
729 00:57:19,831 --> 00:57:27,900 说话人 SPEAKER_07：我希望我们能够坚持那些有效的方法，并通过使它们越来越像大脑来不断提高它们的效果。
730 00:57:28,048 --> 00:57:32,574 说话人 SPEAKER_07：如果我们能这样做，我认为我们就能了解到大脑实际上在做什么。
731 00:57:32,594 --> 00:57:36,159 说话人 SPEAKER_07：我认为我们会在亨利·马克汉姆之前快 1000 年达到那里。
732 00:57:40,204 --> 00:57:43,228 说话人 SPEAKER_04：是的。
733 00:57:43,248 --> 00:57:51,280 说话人 SPEAKER_04：所以我感兴趣的是使用无监督学习构建的生成模型的潜力。
734 00:57:51,300 --> 00:57:52,842 说话人 SPEAKER_07：顺便说一句，这正是我所坚信的。
735 00:57:53,202 --> 00:57:57,128 说话人 SPEAKER_07：所有这些有歧视性的训练内容，它竟然能工作，真是令人尴尬。
736 00:57:58,626 --> 00:58:05,784 说话人 SPEAKER_04：我真的希望我知道你是否认真。
737 00:58:06,237 --> 00:58:17,489 说话人 SPEAKER_04：在演示中相当早的时候，您展示了使用无监督数据进行初始化，并且达到了我们现在正在生成方向上运行的深度叶网。
738 00:58:17,829 --> 00:58:29,721 说话人 SPEAKER_04：我在想，您认为这是否是一个实现新颖且逼真生成的良好模型，您能告诉我们关于该方向当前研究趋势的哪些信息吗？
739 00:58:29,880 --> 00:58:30,942 说话人 SPEAKER_07：是的，我认为是这样的。
740 00:58:31,682 --> 00:58:33,644 说话人 SPEAKER_07：我认为这是最终的方向。
741 00:58:34,536 --> 00:58:38,603 说话人 SPEAKER_07：但你知道，你应该让结果来引导你。
742 00:58:39,443 --> 00:58:43,610 说话人 SPEAKER_07：目前，我们可以充分利用判别方法效果非常好的事实。
743 00:58:45,632 --> 00:58:47,615 说话人 SPEAKER_07：但对于人类来说，我们得不到大量数据集。
744 00:58:48,076 --> 00:58:50,500 说话人 SPEAKER_07：我们得到的是，我们在输入中得到了很大的相关性。
745 00:58:50,519 --> 00:58:55,666 说话人 SPEAKER_07：你得到的是单词和物体，但它们只是输入中的相关性。
746 00:58:56,659 --> 00:59:02,335 说话人 SPEAKER_07：最终，我完全相信生成式方法会更好，并且要实现视觉，你需要进行逆向计算机图形学。
747 00:59:02,815 --> 00:59:04,400 说话人 SPEAKER_07：你需要有一个合适的图形模型在其中。
748 00:59:04,641 --> 00:59:07,288 说话人 SPEAKER_07：一旦你做到了这一点，你就能处理视角及其问题。
749 00:59:08,831 --> 00:59:10,094 说话人 SPEAKER_07：这就是我们要走的方向。
750 00:59:15,070 --> 00:59:16,775 说话人 SPEAKER_03：我的问题与那有一点关系。
751 00:59:16,855 --> 00:59:24,998 说话人 SPEAKER_03：所以你展示的模型学习某种形式的抽象或领域结构，不管它是如何做到的。
752 00:59:25,097 --> 00:59:30,092 说话人 SPEAKER_03：当然，从网络中提取这种结构是困难的。
753 00:59:30,072 --> 00:59:43,893 说话人 SPEAKER_03：但如果它真的在学习正确的抽象，比如名词和动词，那么你应该能够做到像单次学习这样的事情。
754 00:59:43,954 --> 00:59:54,612 说话人 SPEAKER_03：如果我说这是一个 floopy，那么我就不需要像谷歌那样，你知道的，包含很多包含 floopy 这个词的文本来学习如何使用它。
755 00:59:54,672 --> 00:59:56,534 说话人 SPEAKER_03：那么你对此有什么看法？
756 00:59:56,514 --> 01:00:00,021 说话人 SPEAKER_03：关于如何使用这个进行单子学习？
757 01:00:00,782 --> 01:00:02,206 说话人 SPEAKER_07：这与上一个问题有关。
758 01:00:02,266 --> 01:00:10,902 说话人 SPEAKER_07：如果你能构建好的生成模型，那么你将得到内部表示，从某种意义上说，这就是计算机图形学家所描述的正确。
759 01:00:11,923 --> 01:00:18,556 说话人 SPEAKER_07：它们是物体的有趣部分，并且你有这些部分与其他部分或与整个物体之间的空间关系。
760 01:00:18,739 --> 01:00:25,271 说话人 SPEAKER_07：然后从一次拍摄中，你将能够看到，哦，这是一个具有这些熟悉部分以这种方式排列的物体。
761 01:00:26,192 --> 01:00:30,619 说话人 SPEAKER_07：哦，还有一个以完全不同的视角，但却是以相同方式排列的相同部分。
762 01:00:31,760 --> 01:00:38,030 说话人 SPEAKER_07：我认为这是在视角或光照发生大幅变化的情况下进行一次性行为泛化的唯一希望。
763 01:00:38,010 --> 01:00:45,621 说话人 SPEAKER_03：做到这一点的方法是...你看到它是被学习到的吗？或者那被...首先以手工方式注入，然后...不，我看到它是被学习到的。
764 01:00:46,083 --> 01:00:56,677 说话人 SPEAKER_07：但我认为你可以通过手工方式注入的知识是，例如，坐标变换是线性操作。
765 01:00:57,333 --> 01:01:03,547 说话人 SPEAKER_07：因此，你可以在网络中放入一个大的先验知识，即学习通过一系列线性操作来处理这些内容。
766 01:01:04,510 --> 01:01:08,699 说话人 SPEAKER_07：这是一个非常、非常强的约束，因为大多数事情都不是线性操作。
767 01:01:09,141 --> 01:01:14,092 说话人 SPEAKER_07：我们使用这些多层非线性操作是完全疯狂的行为。
768 01:01:14,072 --> 01:01:20,706 说话人 SPEAKER_07：处理可以建模的内容，如果你去正确的计算机图形表示，就像线性运算一样。
769 01:01:20,887 --> 01:01:21,608 说话人 SPEAKER_07：这有点疯狂。
770 01:01:21,949 --> 01:01:25,336 说话人 SPEAKER_07：因为只有线性事物你才能沿着这条路外推。
771 01:01:25,356 --> 01:01:31,050 说话人 SPEAKER_07：除非你能找到所有事物都位于其上的线性流形，否则你永远无法外推到完全不同的观点。
772 01:01:32,413 --> 01:01:34,376 说话人 SPEAKER_07: 这就是我们必须要做的。
773 01:01:38,304 --> 01:01:51,840 说话人 SPEAKER_05: 所以我认为这是公平的，但另一方面，这也是一个观点，你可以也许在模型上做实验，看看禁用这里或那里的某个部分。
774 01:01:52,601 --> 01:01:55,905 说话人 SPEAKER_05: 此外，有些部分也很重要。
775 01:01:55,925 --> 01:02:02,472 说话人 SPEAKER_05: 所以我在想，如果你有一个拥有数百万个节点的网络，
776 01:02:02,639 --> 01:02:11,269 说话人 SPEAKER_05：或者成千上万的节点，我们是否可以看看这些权重实际上代表了什么？
777 01:02:11,349 --> 01:02:12,371 说话人 SPEAKER_07：在某种程度上。
778 01:02:12,590 --> 01:02:23,684 说话人 SPEAKER_07：我的意思是，Jeff Dean、Andrew Ng 和 Kwok Lee 在谷歌进行的从 YouTube 视频帧中进行无监督学习的工作，
779 01:02:24,239 --> 01:02:32,375 说话人 SPEAKER_07：他们展示了在网络中通过无监督学习，可以有几层神经元真正代表了猫。
780 01:02:33,036 --> 01:02:42,875 说话人 SPEAKER_07：我的意思是，如果你像线性系统一样将所有权重相乘，尽管它并不是线性系统，那么你就可以看到感受野像猫一样。
781 01:02:42,894 --> 01:02:46,382 说话人 SPEAKER_07：为了更好地，你可以做的是，你可以取系统深处的神经元，
782 01:02:46,480 --> 01:02:54,034 说话人 SPEAKER_07：然后你可以取一个输入，并且可以说，现在让我们改变输入的方向，让这个神经元越来越高兴。
783 01:02:54,757 --> 01:02:58,304 说话人 SPEAKER_07：因此你可以优化输入图像，以使这个神经元能够触发。
784 01:02:59,385 --> 01:03:03,675 说话人 SPEAKER_07: 然后你可以看到它最喜欢的东西，至少是从你开始的地方最喜欢的东西。
785 01:03:04,597 --> 01:03:06,159 说话人 SPEAKER_07: 它是一只猫。
786 01:03:06,646 --> 01:03:07,989 说话人 SPEAKER_07: 它是一只非常令人信服的猫。
787 01:03:08,009 --> 01:03:08,951 说话人 SPEAKER_07: 其他的是人。
788 01:03:09,813 --> 01:03:13,141 说话人 SPEAKER_07：您可以在工作中做一些事情，找出这些内部事物的一些情况。
789 01:03:13,561 --> 01:03:21,320 说话人 SPEAKER_07：这一点非常明确，他们的大规模无监督网络拥有数十亿个连接，正在学习识别熟悉的物体类别。
790 01:03:22,342 --> 01:03:24,047 说话人 SPEAKER_07：至少有一些神经元正在做这件事。
791 01:03:27,907 --> 01:03:32,054 说话人 SPEAKER_04：最后一个问题。
792 01:03:32,074 --> 01:03:43,813 说话人 SPEAKER_04：你提到了既是循环又是非循环的神经网络，我想问一下，对于循环神经网络，它们在堆叠方向上也是深度吗？这是否很重要？
793 01:03:44,353 --> 01:03:45,375 说话人 SPEAKER_07：好的，好问题。
794 01:03:45,956 --> 01:03:47,958 说话人 SPEAKER_07：所以直到最近，
795 01:03:48,293 --> 01:03:55,346 说话人 SPEAKER_07：我们通常认为，如果一个当前网络在堆叠方向上是深度的，那只是缺少了一些连接，对吧？
796 01:03:55,425 --> 01:04:06,025 说话人 SPEAKER_07：如果你有一个隐藏状态并且与下一个隐藏状态有完整的矩阵连接，那么如果你开始省略块，那么你将得到一个分层系统。
797 01:04:07,827 --> 01:04:09,411 说话人 SPEAKER_07：所以，我们认为，为什么不直接使用完整的呢？
798 01:04:10,132 --> 01:04:11,313 说话人 SPEAKER_07：结果证明，
799 01:04:12,407 --> 01:04:17,735 说话人 SPEAKER_07：在处理语音时，不直接使用完整的有两个原因。
一个是，为了让语音识别在循环神经网络中工作良好，亚历克斯不得不使用双向网络。
801 01:04:26,865 --> 01:04:27,867 说话人 SPEAKER_07：所以它是离线的。
802 01:04:28,027 --> 01:04:31,811 说话人 SPEAKER_07：他会向前走，也会向后走。
803 01:04:33,434 --> 01:04:35,956 说话人 SPEAKER_07：他在每一层都这样做。
804 01:04:36,717 --> 01:04:40,001 说话人 SPEAKER_07：所以他在四层网络中前后走了四次。
805 01:04:40,657 --> 01:04:44,101 说话人 SPEAKER_07：这就是从未来和过去传播信息，这非常有帮助。
806 01:04:44,802 --> 01:04:55,516 说话人 SPEAKER_07：所以实际上是在每一层进行全正向反向，不是 HMM 意义上的正向反向，而是在两个方向上运行循环网络，这非常有帮助。
807 01:04:55,576 --> 01:04:58,059 说话人 SPEAKER_07：这就是让他从 24%降到 17.7%的原因。
808 01:04:58,280 --> 01:05:04,588 说话人 SPEAKER_07：结果证明，这其中一个创新点就是将这些层叠加起来。