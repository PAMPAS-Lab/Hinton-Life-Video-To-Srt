1 00:00:00,908 --> 00:00:02,549 演讲者 演讲者_06: 大家好。
2 00:00:03,111 --> 00:00:09,941 演讲者 演讲者_00: 我们非常激动能够举办这次活动，向图灵奖获得者致敬和庆祝。
3 00:00:11,141 --> 00:00:15,528 演讲者 演讲者_00: 如你所知，他们的故事是一段非凡的坚韧和毅力。
4 00:00:16,388 --> 00:00:28,045 演讲者 演讲者_00: 今天很难想象，但杰夫、简和约书亚在做出许多关键贡献时，神经网络是一个极其不受欢迎的研究课题。
5 00:00:28,486 --> 00:00:29,768 说话人 说话人_00：看看我们现在在哪里。
6 00:00:30,489 --> 00:00:37,679 说话人 说话人_00：他们的贡献是现代计算机视觉、自然语言处理、语音识别等领域的核心。
7 00:00:38,621 --> 00:00:43,268 说话人 说话人_00：这一点不仅反映在 AAAI 的程序中，也反映在我们的日常生活中。
8 00:00:44,069 --> 00:00:49,417 说话人 说话人_00：我们与手机交谈，我们拍摄外文文本的照片，并立即获得翻译。
9 00:00:50,378 --> 00:00:55,826 讲者 SPEAKER_00: 他们的故事是追随你的科学之心而不是追随当下流行的东西的榜样。
10 00:00:57,008 --> 00:00:59,451 讲者 SPEAKER_00: 请和我一起欢迎图灵奖获得者。
11 00:01:15,918 --> 00:01:20,088 讲者 SPEAKER_00: 他们的演讲将是 30 分钟的讲座形式。
12 00:01:20,308 --> 00:01:21,692 讲者 SPEAKER_00: 在那个时刻不会有提问。
13 00:01:22,134 --> 00:01:25,281 主持人 主持人_00：最后，我们将有一个圆桌讨论，然后也会接受提问。
14 00:01:25,843 --> 00:01:29,352 主持人 主持人_00：同时，如果您想在线提交问题，请查看屏幕上的说明。
15 00:01:31,932 --> 00:01:34,715 主持人 主持人_03：好的，我很高兴介绍 Geoff Hinton。
16 00:01:35,176 --> 00:01:42,406 主持人 主持人_03：Geoff 曾担任多伦多大学计算机科学教授和谷歌研究科学家。
17 00:01:43,027 --> 00:01:56,825 讲者 SPEAKER_03：杰夫因其在人工智能领域的根本性贡献而闻名，并与他的合作者发现了反向传播，发明了 AlexNet、玻尔兹曼机、胶囊网络以及许多我们现在使用的模型和算法。
18 00:01:58,021 --> 00:02:03,728 讲者 SPEAKER_03：我本想讲一个关于杰夫的小笑话和一件关于他的私事，希望这不会冒犯到你们。
19 00:02:06,031 --> 00:02:20,771 讲者 SPEAKER_03：杰夫曾经告诉我，也许很久以前还告诉过别人，当他告诉他的女儿他发现了大脑的工作原理时，她的反应是，哦，爸爸，又是这样。
20 00:02:22,591 --> 00:02:29,489 讲者 SPEAKER_03：有趣的是，我相信他们每五年或三年，或者可能是五十年，都会进行同样的对话。
21 00:02:29,889 --> 00:02:30,251 说话人 SPEAKER_03: 我不知道。
22 00:02:30,692 --> 00:02:32,597 说话人 SPEAKER_03: 我想知道 Jeff 今天能告诉我们什么。
23 00:02:32,637 --> 00:02:35,604 说话人 SPEAKER_03: 现在，很高兴地欢迎 Jeff。
24 00:02:51,245 --> 00:02:57,237 说话人 SPEAKER_07: 好的，今天我将谈谈与 Adam Kosoriak、Sarah Saboy 在 UIT 上的最新合作研究。
25 00:02:58,259 --> 00:03:04,492 讲者 SPEAKER_07：我不会谈论哲学问题或者为什么我不再来参加 AAAI 会议之类的任何事情。
26 00:03:05,314 --> 00:03:07,919 讲者 SPEAKER_07：我只想谈谈这项工作。
27 00:03:09,300 --> 00:03:11,246 讲者 SPEAKER_07：所以物体识别有两种方法。
28 00:03:11,447 --> 00:03:19,990 讲者 SPEAKER_07：有一种是传统的基于部件的方法，其中包含合理的模块化表示，但通常需要大量的人工设计。
29 00:03:20,651 --> 00:03:23,580 说话人 SPEAKER_07：它们通常没有深度层次的结构，这些都是通过学习得到的。
30 00:03:25,062 --> 00:03:26,843 说话人 SPEAKER_07：然后是卷积神经网络。
31 00:03:27,364 --> 00:03:30,848 说话人 SPEAKER_07：卷积神经网络是端到端学习的。
32 00:03:31,687 --> 00:03:36,233 说话人 SPEAKER_07：通过将一个特征检测器在一个地方做得很好，它可以在其他地方也做得很好，从而获得了巨大的优势。
33 00:03:37,253 --> 00:03:40,896 演讲者 SPEAKER_07：这使得他们能够结合证据并在位置上很好地推广。
34 00:03:41,318 --> 00:03:42,919 演讲者 SPEAKER_07：但他们与人类感知非常不同。
35 00:03:43,719 --> 00:03:51,086 演讲者 SPEAKER_07：演讲的第一部分完全针对 Jan，内容是关于 CNN 的问题以及为什么它们很糟糕。
36 00:03:54,356 --> 00:03:57,120 演讲者 SPEAKER_07：因此，CNN 被设计用来处理翻译。
37 00:03:57,520 --> 00:04:03,605 讲者 SPEAKER_07：它们在处理视角变化的其他影响方面并不擅长，比如旋转和缩放，尽管比你想的要好一些。
38 00:04:05,747 --> 00:04:11,574 讲者 SPEAKER_07：一个明显的办法是使用 4D 或 6D 地图来代替 2D 地图，但这只会变得极其昂贵。
39 00:04:12,875 --> 00:04:20,483 讲者 SPEAKER_07：所以通常，CNNs 会在许多不同的视角上进行训练，以便它们能够跨视角泛化，但这并不高效。
40 00:04:21,576 --> 00:04:25,024 讲者 SPEAKER_07：我们希望神经网络能够轻松地泛化到新的视角。
41 00:04:25,485 --> 00:04:34,642 讲者 SPEAKER_07：如果它们学会了识别某个东西，然后你把它放大 10 倍，再旋转 60 度，这不应该给它们带来任何问题。
42 00:04:36,567 --> 00:04:40,394 讲者 SPEAKER_07：我们知道计算机图形学就是这样，我们希望神经网络更像这样。
43 00:04:41,995 --> 00:04:44,437 讲者 SPEAKER_07：所以首先让我区分等变性（equivariance）和不变性（invariance）。
44 00:04:45,399 --> 00:04:52,228 讲者 SPEAKER_07：在卷积神经网络中，尤其是当你进行池化操作时，目标是得到对视点变化不变（invariant）的表示。
45 00:04:53,129 --> 00:04:55,954 演讲者 SPEAKER_07：这与获得等变表示不同。
46 00:04:56,274 --> 00:05:01,422 等变的想法是，当视角改变时，表示中的某些内容也会改变。
47 00:05:02,295 --> 00:05:22,120 所以我认为在我们的感知系统中，当你的视角改变时，神经活动的模式会改变，但代表标签的模式不会改变，显然你希望它保持不变，但代表你感知的模式会改变很多，而不会随着视角改变的是权重，以及编码事物之间关系的权重。
48 00:05:22,139 --> 00:05:23,240 这将在稍后变得清晰。
49 00:05:25,060 --> 00:05:26,882 讲者 SPEAKER_07：卷积神经网络也无法解析图像。
50 00:05:27,461 --> 00:05:36,470 讲者 SPEAKER_07：当卷积神经网络识别图像时，如果你只进行一次遍历，它不会进行任何明确的解析，说明这个属于那个，这个不属于那个。
51 00:05:37,230 --> 00:05:49,480 讲者 SPEAKER_07：相反，你可以将卷积神经网络想象为以各种像素位置为中心，你得到越来越丰富的关于该像素位置发生情况的描述，这取决于越来越多的上下文。
52 00:05:49,802 --> 00:05:53,564 讲者 SPEAKER_07：最终，你得到如此丰富的描述，以至于你知道图像中有什么物体。
53 00:05:56,026 --> 00:05:57,817 演讲者 SPEAKER_07：但他们并没有明确解析图像。
54 00:06:00,142 --> 00:06:13,235 演讲者 SPEAKER_07：卷积神经网络（CNN）在识别物体方面与人类的方式截然不同，因为我可以拿一张图片，添加一点噪声，CNN 会将其识别为完全不同的东西，而我几乎看不到它有任何变化。
55 00:06:14,357 --> 00:06:16,298 演讲者 SPEAKER_07：这看起来真的很奇怪。
56 00:06:17,060 --> 00:06:22,665 演讲者 SPEAKER_07：我认为这是 CNN 实际上使用与我们非常不同的信息来识别图像的证据。
57 00:06:23,105 --> 00:06:29,711 讲者 SPEAKER_07：这并不是说它错了，他们只是以非常不同的方式来做，他们的方式在泛化方面有一些差异。
58 00:06:33,067 --> 00:06:44,144 对 CNN 的另一个抱怨是它们通过取下层活动与某些权重的标量积来激活事物，这提供了证据，并将证据相加。
59 00:06:44,165 --> 00:06:45,646 如果它们有足够的证据，事物就会激活。
60 00:06:46,988 --> 00:06:50,535 有一种非常不同的方式来激活事物，那就是寻找巧合。
61 00:06:51,291 --> 00:07:00,598 讲者 SPEAKER_07：巧合真的很重要，就像物理学的大部分内容都是关于你可以进行的两种不同测量的巧合，方程式的两边。
62 00:07:01,420 --> 00:07:03,968 讲者 SPEAKER_07：理论和实验之间存在巧合。
63 00:07:04,201 --> 00:07:08,369 讲者 SPEAKER_07：在高维度中，如果你得到一个高维度的巧合，那是非常有意义的。
64 00:07:08,709 --> 00:07:24,658 讲者 SPEAKER_07：如果你在过滤无线电交通时看到 9 月 9 日，纽约，然后在另一条信息中看到 9 月 9 日，纽约，只有少数几个这样的，如果它们都是 9 月 9 日和纽约，那是非常有意义的，因为这是一个高维度的巧合。
65 00:07:25,819 --> 00:07:27,963 讲者 SPEAKER_07：现在我们使用的神经元类型
66 00:07:29,108 --> 00:07:30,550 讲者 SPEAKER_07：不要做巧合。
67 00:07:31,170 --> 00:07:33,553 讲者 SPEAKER_07：这不再成立了，因为我们开始使用 Transformer。
68 00:07:33,613 --> 00:07:36,738 讲者 SPEAKER_07：Transformer 确实会做一些巧合，我稍后会解释。
69 00:07:37,600 --> 00:07:42,146 演讲者 SPEAKER_07：通过两个活动向量的标量积来激活事物会更好。
70 00:07:42,206 --> 00:07:43,687 演讲者 SPEAKER_07：这些活动向量匹配吗？
71 00:07:43,767 --> 00:07:44,910 演讲者 SPEAKER_07：如果是这样，就激活。
72 00:07:45,511 --> 00:07:46,632 演讲者 SPEAKER_07：这就是变压器所做的事情。
73 00:07:47,473 --> 00:07:49,315 演讲者 演讲者_07：这使得过滤器更好。
74 00:07:50,117 --> 00:07:53,341 演讲者 演讲者_07：这也使得对协方差结构响应更好的事物。
75 00:07:53,843 --> 00:07:57,747 演讲者 演讲者_07：在图像中，重要的是协方差结构，像素的协方差结构。
76 00:08:00,091 --> 00:08:03,437 演讲者 演讲者_07：CNNs 的最后一个也是最糟糕的问题是它们不使用坐标系。
77 00:08:04,399 --> 00:08:09,548 演讲者 SPEAKER_07：所以当你看到任何东西时，你会看到一个形状，你会施加一个坐标系。
78 00:08:09,928 --> 00:08:11,952 演讲者 SPEAKER_07：这是人类感知的基本方面。
79 00:08:12,514 --> 00:08:13,836 演讲者 SPEAKER_07：我将尝试说服你们这一点。
80 00:08:14,336 --> 00:08:17,783 演讲者 SPEAKER_07：由于时间不多，我将快速说服你们这一点。
81 00:08:18,345 --> 00:08:22,752 演讲者 SPEAKER_07：我有一些美丽的演示可以让你信服，但我没有时间展示它们。
82 00:08:22,773 --> 00:08:23,954 演讲者 SPEAKER_07：这个差距还不够大。
83 00:08:25,875 --> 00:08:30,923 演讲者 SPEAKER_07：所以，你会在那里看到一个国家，这个国家看起来有点像澳大利亚。
84 00:08:32,664 --> 00:08:38,553 演讲者 SPEAKER_07：当我告诉你它不是垂直的，它是倾斜的，你可以把它看作是非洲。
85 00:08:38,594 --> 00:08:43,660 讲者 SPEAKER_07：一旦你把它看作是非洲，它看起来就与当你把它看作是一种镜面翻转的澳大利亚时完全不同。
86 00:08:44,822 --> 00:08:50,230 讲者 SPEAKER_07：但人们最初并不把它看作是非洲，他们会把它看作是一个他们不认识的国度，如果他们被告知这是一个国度的话。
87 00:08:50,210 --> 00:08:57,716 讲者 SPEAKER_07：如果你看右边的例子，你可以看到它要么是一个直立钻石，要么是一个倾斜的方形。
88 00:08:58,879 --> 00:09:02,312 讲者 SPEAKER_07：你对它的感知完全不同，取决于你从哪个角度看它。
89 00:09:03,236 --> 00:09:09,903 讲者 SPEAKER_07：如果你把它看作一个直立钻石，你会非常清楚左下角和右下角是否完全处于同一高度。
90 00:09:10,222 --> 00:09:11,764 讲者 SPEAKER_07：你会注意到一个微小的差距。
91 00:09:12,706 --> 00:09:15,488 讲者 SPEAKER_07：但实际上你并不清楚这些角是否是直角。
92 00:09:15,888 --> 00:09:16,708 讲者 SPEAKER_07：你只是没有注意到。
93 00:09:17,649 --> 00:09:25,037 演讲者 SPEAKER_07：所以如果我把两个角垂直拉开，角度就不会是直角，但它仍然看起来像一颗完美的钻石。
94 00:09:25,937 --> 00:09:30,562 演讲者 SPEAKER_07：然而，如果你把它看作是一个倾斜的方形，你会非常清楚角度是否是直角。
95 00:09:30,621 --> 00:09:33,244 演讲者 SPEAKER_07：如果我将它们改变两度，你就会注意到。
96 00:09:33,224 --> 00:09:37,388 演讲者 SPEAKER_07：但你根本不会意识到两侧的两个角是否在同一高度。
97 00:09:38,428 --> 00:09:42,732 演讲者 SPEAKER_07：所以你根据所施加的坐标系不同，会有完全不同的内部感知。
98 00:09:44,033 --> 00:09:46,436 演讲者 SPEAKER_07：卷积神经网络实际上无法解释这一点。
99 00:09:47,177 --> 00:09:51,941 演讲者 SPEAKER_07：你给他们一个输入，他们有一个感知，而这个感知并不依赖于施加坐标系。
100 00:09:52,761 --> 00:10:00,109 演讲者 SPEAKER_07：我想这与对抗样本有关，并且与卷积神经网络以与人类完全不同的方式进行感知的事实有关。
101 00:10:02,047 --> 00:10:06,620 讲者 SPEAKER_07：我认为将计算机视觉视为逆向计算机图形学是一个非常不错的办法。
102 00:10:06,639 --> 00:10:07,501 讲者 SPEAKER_07：这绝非新观点。
103 00:10:07,523 --> 00:10:09,226 讲者 SPEAKER_07：我想这可以追溯到伯特奥尔·霍恩。
104 00:10:09,869 --> 00:10:12,275 讲者 SPEAKER_07：实际上，可能还要早得多。
105 00:10:14,567 --> 00:10:27,187 讲者 SPEAKER_07：所以图形程序使用层次模型，通过矩阵来模拟空间结构，这些矩阵将整个嵌入的坐标系与部分嵌入的坐标系联系起来。
106 00:10:27,207 --> 00:10:30,712 讲者 SPEAKER_07：所以你必须选择一个整体对象，嵌入一个坐标系，你必须选择它是什么。
107 00:10:31,114 --> 00:10:32,755 讲者 SPEAKER_07：对于部分，你必须嵌入一个坐标系。
108 00:10:33,076 --> 00:10:37,803 讲者 SPEAKER_07：一旦我完成了这个，我就可以说部分与整体之间的关系，这只是一个矩阵运算。
109 00:10:38,304 --> 00:10:39,746 讲者 SPEAKER_07: 我们现在先考虑刚性物体。
110 00:10:40,589 --> 00:10:42,751 讲者 SPEAKER_07: 这意味着它是一个线性关系。
111 00:10:43,288 --> 00:10:53,341 讲者 SPEAKER_07: 所以存在一个非常简单的线性结构，这就是计算机图形学所使用的，这也是为什么在计算机图形学中，如果你说，你能从另一个角度展示给我吗？
112 00:10:53,701 --> 00:10:58,707 讲者 SPEAKER_07: 他们不会说，哦，我想，但是我们没有从那个角度训练，所以我们不能从另一个角度展示给你。
113 00:10:58,727 --> 00:11:04,014 演讲者 SPEAKER_07：我们可以把它旋转 15 度给你看，但这也就这样了。
114 00:11:04,972 --> 00:11:15,586 演讲者 SPEAKER_07：他们只是从另一个角度展示给你，因为他们有一个真实的 3D 模型，并且他们通过部件和孔的关系来建模空间结构，这些关系根本不依赖于视角。
115 00:11:16,969 --> 00:11:17,249 演讲者 SPEAKER_07：好的。
116 00:11:18,691 --> 00:11:23,616 演讲者 SPEAKER_07：我认为在处理 3D 物体的图像时不利用这种美丽的结构是疯狂的。
117 00:11:24,658 --> 00:11:26,660 讲者 SPEAKER_07：其中一个原因是
118 00:11:28,581 --> 00:11:34,048 我们知道，你可以推广到长距离的东西，你可以真正外推的线性模型。
119 00:11:34,467 --> 00:11:37,311 如果它比线性更高阶，就很难很好地外推。
120 00:11:37,552 --> 00:11:39,234 但是线性模型，你可以外推得很远。
121 00:11:40,254 --> 00:11:43,057 演讲者 SPEAKER_07：我们一直在寻找线性的潜在流形。
122 00:11:43,457 --> 00:11:45,000 演讲者 SPEAKER_07：在计算机视觉中，我们知道它们是什么。
123 00:11:45,740 --> 00:11:48,302 演讲者 SPEAKER_07：视角是影响图像的最重要因素。
124 00:11:49,323 --> 00:11:52,648 演讲者 SPEAKER_07：在这之下有一个线性结构，但我们没有充分利用它。
125 00:11:55,462 --> 00:12:00,571 讲者 SPEAKER_07: 好的，现在我将要谈论一个特定的系统，称为堆叠胶囊自动编码器。
126 00:12:01,312 --> 00:12:08,745 讲者 SPEAKER_07: 对于阅读过任何关于胶囊内容的人来说，我想尝试澄清这是胶囊的不同版本。
127 00:12:08,904 --> 00:12:11,970 讲者 SPEAKER_07: 每年都会有全新的胶囊版本。
128 00:12:11,950 --> 00:12:16,956 讲者 SPEAKER_07: 所以在 2017 年的 NIPS 会议中有一个版本实现了路由功能。
129 00:12:17,456 --> 00:12:22,322 演讲者 SPEAKER_07：然后还有一个 2018 年在 ICLR 上使用的 EM 算法版本。
130 00:12:23,024 --> 00:12:28,270 演讲者 SPEAKER_07：还有 2019 年在 EURIPS 上的这个新版本，我现在就讲这个。
131 00:12:29,852 --> 00:12:32,196 演讲者 SPEAKER_07：所以，忘记你之前所知道的所有版本。
132 00:12:32,255 --> 00:12:38,143 演讲者 SPEAKER_07：它们都是错误的，但这个是对的。
133 00:12:39,861 --> 00:12:43,666 讲者 SPEAKER_07：之前的版本使用了判别性学习，我知道这是一个坏主意。
134 00:12:43,686 --> 00:12:45,547 讲者 SPEAKER_07：我一直知道无监督学习是正确的做法。
135 00:12:45,888 --> 00:12:47,909 讲者 SPEAKER_07：所以之前的模型是心怀叵测的。
136 00:12:49,431 --> 00:12:52,293 讲者 SPEAKER_07：它们还使用了部分-整体关系，这非常可疑。
137 00:12:53,034 --> 00:12:56,437 讲者 SPEAKER_07：使用整体-部分关系会更好。
138 00:12:56,498 --> 00:13:07,548 讲者 SPEAKER_07：如果你尝试使用部分-整体关系，如果部分比整体自由度少，比如它是一个点，而你正在寻找星座，仅知道一个点的位置是无法预测星座的姿态的。
139 00:13:07,568 --> 00:13:08,889 讲者 SPEAKER_07：你需要使用很多这样的点。
140 00:13:08,870 --> 00:13:11,297 讲者 SPEAKER_07：所以单个部分不能为整体做出预测。
141 00:13:12,740 --> 00:13:18,336 讲者 SPEAKER_07：在这个新版本中，我们正在进行无监督学习，并使用整体-部分关系。
142 00:13:20,160 --> 00:13:23,149 讲者 SPEAKER_07：胶囊网络的想法是...
143 00:13:25,052 --> 00:13:30,557 讲者 SPEAKER_07：为了在神经网络中构建更多结构，并希望这种额外的结构能帮助您更好地泛化。
144 00:13:30,817 --> 00:13:32,419 讲者 SPEAKER_07：这受到了卷积神经网络（CNN）的启发。
145 00:13:33,179 --> 00:13:36,803 讲者 SPEAKER_07：在 CNN 中，Jan 只增加了一点点结构。
146 00:13:37,283 --> 00:13:38,345 讲者 SPEAKER_07：非常简单的结构。
147 00:13:38,966 --> 00:13:42,609 讲者 SPEAKER_07：让你的特征检测器在翻译中重复使用。
148 00:13:43,169 --> 00:13:44,270 讲者 SPEAKER_07：这是一个巨大的胜利。
149 00:13:45,871 --> 00:13:48,134 演讲者 SPEAKER_07：我们能否再进一步？
150 00:13:48,594 --> 00:13:52,477 演讲者 SPEAKER_07：也许我们还能加入一些模块化结构，以便获取解析树等？
151 00:13:53,099 --> 00:14:06,302 所以胶囊将代表，它将学习应该代表什么实体，并将具有该实体的某些参数。
152 00:14:08,144 --> 00:14:14,735 在2019版本的胶囊中，这是最终和正确的版本，
153 00:14:15,796 --> 00:14:26,307 演讲者 SPEAKER_07：将有一个逻辑单元，那是一个浅蓝色的小东西，表示这个实体是否存在于当前图像中，无论这个胶囊覆盖的位置在哪里。
154 00:14:26,327 --> 00:14:28,211 演讲者 SPEAKER_07：所以胶囊本身也可以是卷积的。
155 00:14:30,113 --> 00:14:42,246 演讲者 SPEAKER_07：它将有一个矩阵，那是一个红色的小东西，表示被这个胶囊表示的实体或该实体的嵌入固有坐标系与相机之间的空间关系。
156 00:14:42,868 --> 00:14:45,650 演讲者 SPEAKER_07：所以它告诉你它是怎么放置的，有多大，在哪里等等。
157 00:14:46,508 --> 00:14:51,397 演讲者 SPEAKER_07：它将具有一系列其他属性，其中包括关于变形的内容。
158 00:14:51,437 --> 00:14:59,392 演讲者 SPEAKER_07：如果你处理视频，它们将包括关于速度、颜色等内容。
159 00:14:59,412 --> 00:15:05,562 演讲者 SPEAKER_07：再次强调，因为这是重点，它们擅长捕捉内在几何形状。
160 00:15:07,230 --> 00:15:18,644 演讲者 SPEAKER_07：因此，代表一个物体的胶囊可以从其姿态预测各个部分的姿态，并且当改变视角时，其姿态与部分姿态之间的关系不会改变。
161 00:15:19,144 --> 00:15:22,607 讲者 SPEAKER_07：如果我旋转整个物体，整体与部分之间的关系保持不变。
162 00:15:23,448 --> 00:15:26,272 讲者 SPEAKER_07：这就是你想要放入神经网络权重中的内容。
163 00:15:26,832 --> 00:15:33,120 讲者 SPEAKER_07：这就是你想要存储的知识，然后你想要使用这种知识进行识别，这种知识不依赖于视角。
164 00:15:39,479 --> 00:15:41,869 讲者 SPEAKER_07：所以这是你需要尝试理解的幻灯片。
165 00:15:41,909 --> 00:15:44,200 讲者 SPEAKER_07：如果您理解这张幻灯片，您就理解了新的模型。
166 00:15:45,345 --> 00:15:49,523 讲者 SPEAKER_07：我们的想法是会有一种自动编码器。
167 00:15:50,852 --> 00:15:55,159 讲者 SPEAKER_07：我们最初将贪婪地做，即取一些像素。
168 00:15:55,221 --> 00:15:56,863 讲者 SPEAKER_07：从一些像素中，您可以得到一些部分。
169 00:15:57,224 --> 00:15:58,706 演讲者 SPEAKER_07：从某些部分，你可以得到更大的部分。
170 00:15:58,726 --> 00:16:00,328 演讲者 SPEAKER_07：从更大的部分，你可以得到更大的部分。
171 00:16:01,511 --> 00:16:08,844 演讲者 SPEAKER_07：这将是一个贪婪的过程，因为一旦你从像素中提取出部分，你就不会自上而下地修正你对这些部分估计。
172 00:16:09,345 --> 00:16:10,226 演讲者 SPEAKER_07：你将接受这个结果。
173 00:16:10,768 --> 00:16:15,054 演讲者 SPEAKER_07：在更高一级别，你将尝试找出如何将这些部分组合成一个更熟悉的整体。
174 00:16:17,025 --> 00:16:25,835 演讲者 SPEAKER_07：所以，我向你展示的是两层自编码器中的一层解码器。
175 00:16:26,775 --> 00:16:29,499 演讲者 SPEAKER_07：但我们使用的单元不再是神经元了。
176 00:16:29,519 --> 00:16:32,280 演讲者 SPEAKER_07：它们是更复杂的东西，称为胶囊。
177 00:16:32,301 --> 00:16:37,066 演讲者 SPEAKER_07：在底层，我们已经从图像中推断出了一些胶囊。
178 00:16:37,787 --> 00:16:39,128 演讲者 SPEAKER_07：这是归纳步骤。
179 00:16:39,148 --> 00:16:42,932 演讲者 SPEAKER_07：我们已经有一些低层胶囊了。
180 00:16:44,735 --> 00:16:46,038 演讲者 SPEAKER_07：你知道，这相当令人厌恶。
181 00:16:46,360 --> 00:16:55,048 演讲者 SPEAKER_07：你知道它们是否存在，它们的属性向量是什么，它们的姿态是什么，它们与摄像机的相对位置如何。
182 00:16:56,091 --> 00:17:08,336 演讲者 SPEAKER_07：提取这些信息后，你现在想要学习下一层，或者想要推断下一层，这将是某些高级胶囊，而且最好有一个高级胶囊可以解释多个低级胶囊。
183 00:17:08,857 --> 00:17:11,061 演讲者 SPEAKER_07：这时候你就知道你正在取得进展。
184 00:17:11,102 --> 00:17:15,130 演讲者 SPEAKER_07：你已经用整个胶囊解释了看到的几个胶囊，即部分胶囊。
185 00:17:16,577 --> 00:17:26,452 演讲者 SPEAKER_07：好的，在生成模型中，我们实际上并不是生成低级数据，而是在生成低级数据应该是什么的预测。
186 00:17:27,614 --> 00:17:29,155 演讲者 SPEAKER_07：从高级胶囊中。
187 00:17:30,057 --> 00:17:45,176 演讲者 SPEAKER_07：我们首先做的是取胶囊中的参数向量，那些点状的绿色线条表示，使用我们为这个实体提取的参数，我们预测特定部分与整体的空间关系将是什么。
188 00:17:45,798 --> 00:17:48,280 演讲者 SPEAKER_07：如果是刚性实体，你不需要点状的绿色线条。
189 00:17:48,320 --> 00:17:52,145 演讲者 SPEAKER_07：那里的绿色矩阵可以是常数。
190 00:17:52,165 --> 00:17:54,229 演讲者 SPEAKER_07：但对于灵活的东西，你需要那些带点的绿色线条。
191 00:17:56,133 --> 00:18:10,574 演讲者 SPEAKER_07：然后每个高级胶囊，我稍后会解释它们是如何实例化的，但每个实例化的高级胶囊都会为从图像中提取的每个低级胶囊的姿势做出预测。
192 00:18:11,815 --> 00:18:23,592 演讲者 SPEAKER_07：所以那种有三个红色方框的垂直椭圆内，那是三个不同高级胶囊对特定低级胶囊姿势的预测。
193 00:18:25,141 --> 00:18:28,930 演讲者 SPEAKER_07：我们感兴趣的是，这些人中有一个应该能够解释它。
194 00:18:29,711 --> 00:18:30,835 演讲者 SPEAKER_07：所以我们使用混合模型。
195 00:18:31,236 --> 00:18:36,888 演讲者 SPEAKER_07：混合模型的基本假设是其中之一是解释，但通常我不知道是哪一个。
196 00:18:39,586 --> 00:18:54,232 演讲者 SPEAKER_07：现在我们有一个目标函数，我们希望最大化在混合模型下，由高级胶囊产生的混合模型对已经观察到的姿态的日志概率。
197 00:18:55,174 --> 00:18:58,641 演讲者 SPEAKER_07：在这种混合模型下，你可以计算对数概率。
198 00:19:00,561 --> 00:19:07,670 演讲者 SPEAKER_07：我们将通过反向传播来训练整个系统，以便学习实例化哪些高级胶囊。
199 00:19:08,431 --> 00:19:17,821 演讲者 SPEAKER_07：当你通过混合模型进行反向传播时，那些无法很好地解释数据的混合元素基本上没有后验责任。
200 00:19:17,922 --> 00:19:22,007 演讲者 SPEAKER_07：当你进行反向传播时，修复它们是没有意义的，因为它们没有帮助。
201 00:19:22,647 --> 00:19:26,231 演讲者 SPEAKER_07：通常来说，做最好解释的元素在调整后会有最大的导数。
202 00:19:27,105 --> 00:19:32,319 演讲者 SPEAKER_07：好吧，如果不小心的话，我的时间就要用完了，但这是生成模型。
203 00:19:32,641 --> 00:19:35,087 演讲者 SPEAKER_07：注意，生成模型有两个内置的东西。
204 00:19:35,568 --> 00:19:42,027 演讲者 SPEAKER_07：它有这样一个观点，即每个低级胶囊正好由一个高级胶囊解释。
205 00:19:42,344 --> 00:19:44,086 讲者 SPEAKER_07：这就是分析树的概念，对吧？
206 00:19:44,366 --> 00:19:47,451 讲者 SPEAKER_07：在分析树中，每个元素只有一个祖先。
207 00:19:50,074 --> 00:20:08,317 讲者 SPEAKER_07：它还包含了一个概念，即低级胶囊的姿态是通过矩阵乘法从高级胶囊到相机的关系以及部分到整体的关系推导出来的，这将给出部分到相机的关系。
208 00:20:09,614 --> 00:20:17,092 讲者 SPEAKER_07：因此，我们在视觉中加入了两个最重要的东西，即处理视角和推导分析树。
209 00:20:19,017 --> 00:20:22,243 演讲者 SPEAKER_07: 但是我们还没有做，我还没有做的是向您展示如何在这里进行编码。
210 00:20:22,726 --> 00:20:24,209 演讲者 SPEAKER_07: 当然，这就是感知。
211 00:20:24,269 --> 00:20:25,412 演讲者 SPEAKER_07: 感知就是编码器。
212 00:20:28,548 --> 00:20:30,250 演讲者 SPEAKER_07: 因此我们面临着一个艰难的推理问题。
我们尝试在胶囊的先前版本中，通过为高级胶囊的姿势投票来设计编码器，并查看这些投票是否一致。
214 00：20：42,625 --> 00：20：43,787 议长 SPEAKER_07：这真的很挑剔。
215 00：20：43,807 --> 00：20：44,989 演讲者 SPEAKER_07：真的很难说对。
Sarah Sabor 付出了很多努力，她确实让它成功了。
217 00:20:49,534 --> 00:20:50,494 演讲者 SPEAKER_07: 但这很困难。
218 00:20:52,157 --> 00:20:56,563 演讲者 SPEAKER_07: 幸运的是，当我们这样做的时候，变压器技术出现了。
219 00:20:56,694 --> 00:20:57,715 演讲者 SPEAKER_07: 它们被用于语言。
220 00:20:57,916 --> 00:20:59,198 演讲者 SPEAKER_07: 变压器技术真的很棒。
221 00:21:00,400 --> 00:21:04,925 演讲者 SPEAKER_07: 我们要做的就是简单地说，我们有一个棘手的推理问题。
222 00:21:05,506 --> 00:21:06,426 演讲者 SPEAKER_07: 你有一些部分。
223 00:21:06,928 --> 00:21:07,949 演讲者 SPEAKER_07: 你想要推断出空洞。
224 00:21:08,871 --> 00:21:13,656 演讲者 SPEAKER_07: 我为什么不把所有部分都给一个转换器，然后让它去处理呢？
225 00:21:14,377 --> 00:21:16,019 演讲者 SPEAKER_07：让我们将其变成一个多层变换器。
226 00:21:16,601 --> 00:21:20,506 演讲者 SPEAKER_07：所以我们将有一个简单的生成模型，但一个复杂的编码模型。
227 00:21:21,086 --> 00:21:25,571 演讲者 SPEAKER_07：这个多层变换器将决定如何组织协议和其他事物。
228 00:21:25,551 --> 00:21:27,453 演讲者 SPEAKER_07：你只需要能够训练它。
229 00:21:27,854 --> 00:21:31,438 演讲者 SPEAKER_07：为了训练它，你需要知道正确答案是什么。
230 00:21:31,458 --> 00:21:32,878 演讲者 SPEAKER_07：实际上，你不需要正确答案。
231 00:21:32,939 --> 00:21:34,820 演讲者 SPEAKER_07：你只需要训练它的导数。
232 00:21:34,881 --> 00:21:38,423 演讲者 SPEAKER_07：你需要看到它给出的答案，并告诉它如何给出一个更好的答案。
233 00:21:39,605 --> 00:21:43,429 演讲者 SPEAKER_07: 这就是从生成模型中得到的结果。
234 00:21:44,869 --> 00:21:48,153 演讲者 SPEAKER_07: 因此，我们取所有已经提取的胶囊。
235 00:21:48,594 --> 00:21:52,857 演讲者 SPEAKER_07: 我们将它们输入到多层次集合转换器中。
236 00:21:53,125 --> 00:22:11,523 演讲者 SPEAKER_07: 集合转换器基本上是接受每个低级胶囊的向量描述，并随着通过集合转换器向上进行，使用其他胶囊的描述上下文来不断修订这个向量描述。
237 00:22:12,484 --> 00:22:22,795 讲者 SPEAKER_07：一旦这些部件描述被修订得足够好，那么你将有一个最终层，它将这些描述转换为预测整个物体应该是什么。
238 00:22:25,019 --> 00:22:31,547 讲者 SPEAKER_07：因此，集合变换器很容易训练，因为我们有一个生成模型。
239 00:22:32,086 --> 00:22:34,650 讲者 SPEAKER_07：生成模型为我们提供了集合变换器的导数。
240 00:22:35,471 --> 00:22:48,086 讲者 SPEAKER_07：它的目标与训练生成模型相同，即简单地最大化给定高级胶囊的存在和姿态的观察到的部件姿态的对数概率。
241 00:22:49,126 --> 00:22:53,372 讲者 SPEAKER_07：我们还加入了一个稀疏性先验，以鼓励它只激活少数几个高级胶囊。
242 00:22:54,195 --> 00:23:01,212 讲者 SPEAKER_07：这是关于集合转换器的论文的引用。
243 00:23:01,252 --> 00:23:03,498 讲者 SPEAKER_07：我不会详细介绍它们是如何工作的。
244 00:23:04,820 --> 00:23:07,969 讲者 SPEAKER_07：我想你们很多人都知道转换器是如何工作的。
245 00:23:08,152 --> 00:23:11,856 讲者 SPEAKER_07：我没有太多时间，所以我会非常、非常快地讲解 transformer 的工作原理。
246 00:23:14,019 --> 00:23:15,240 讲者 SPEAKER_07：这是针对句子的，对吧？
247 00:23:15,701 --> 00:23:30,700 讲者 SPEAKER_07：处理句子的方法是获取一系列词向量，并应用卷积神经网络，以便每个词向量根据其邻居进行修订，然后你可以无监督地训练整个系统，以便在删除一些词向量后能够重建它们。
248 00:23:30,680 --> 00:23:36,411 讲者 SPEAKER_07：这将是一种卷积方式的自动编码器，一个深度自动编码器。
249 00:23:37,011 --> 00:23:39,917 演讲者 SPEAKER_07：Transformer 基本上就是这样，只是稍微详细一些。
250 00:23:39,958 --> 00:23:51,759 演讲者 SPEAKER_07：所以不是 WordVec 直接影响上面的 WordVec，也不是这些直接影响在某一层的 WordVec 和下一层的 WordVec 之间，每个 WordVec
251 00:23:52,042 --> 00:23:55,006 演讲者 SPEAKER_07：将生成一个查询、一个键和一个值。
252 00:23:55,705 --> 00:24:15,986 演讲者 SPEAKER_07：从本幻灯片所关注的 WordVec 的角度来看，它查看其查询，这是一个学习到的向量，并将其与相邻 WordVec 生成的键进行比较，如果找到良好的匹配，它将发送相邻 WordVec 产生的部分值作为我的新值。
253 00:24:16,786 --> 00:24:21,830 演讲者 SPEAKER_07：所以，它真正关注的是相似的事物，并将它们结合起来以获得新的表示。
254 00:24:23,126 --> 00:24:25,450 演讲者 SPEAKER_07：这就是变压器的工作原理。
255 00:24:27,792 --> 00:24:40,951 演讲者 SPEAKER_07：现在我将向您展示我们可以通过使用集合变压器和内置坐标变换和解析的简单生成模型来实现什么，以及它将在一些相对简单的数据上做什么。
256 00:24:43,796 --> 00:24:44,696 演讲者 SPEAKER_07：所以，你们不要笑。
257 00:24:45,678 --> 00:24:47,019 演讲者 演讲者_07：这些是 MNIST 数字。
258 00:24:47,661 --> 00:24:48,803 演讲者 演讲者_07：这些是20世纪80年代的东西。
259 00:24:48,863 --> 00:24:50,484 演讲者 演讲者_07：那是20世纪80年代，对吧？
260 00:24:50,971 --> 00:24:52,071 演讲者 演讲者_07：是的。
261 00:24:53,093 --> 00:24:55,915 讲者 SPEAKER_07：这些是 MNIST 数字的困难例子，有点边缘情况。
262 00:24:56,917 --> 00:24:59,140 讲者 SPEAKER_07：这就是我要应用的地方。
263 00:24:59,460 --> 00:25:03,625 讲者 SPEAKER_07：所以这只是确保这个想法可行。
264 00:25:04,425 --> 00:25:16,558 讲者 SPEAKER_07：所以我们将如何建模 MNIST 数字，我们将有一个部分层，这些部分将是笔画的片段，我们还将有一个孔层，这些孔将像整个数字那样，是高级胶囊。
265 00:25:16,779 --> 00:25:18,902 演讲者 SPEAKER_07: 它们并不完全对应于数字。
266 00:25:21,211 --> 00:25:26,417 演讲者 SPEAKER_07: 所以这些部分实际上是 11 乘 11 的模板，这些模板会被学习。
267 00:25:27,839 --> 00:25:31,484 演讲者 SPEAKER_07: 我不会详细讲解这些部分是如何被学习的。
268 00:25:31,965 --> 00:25:35,191 演讲者 SPEAKER_07: 它的学习方式基本上与洞的学习方式相同，所以我将重点讲解洞是如何被学习的。
269 00:25:36,833 --> 00:25:43,201 演讲者 SPEAKER_07：你实际上是通过混合模型来模拟每个像素强度的，这些预测来自各个部分。
270 00:25:43,182 --> 00:25:50,730 演讲者 SPEAKER_07：每个部分都可以进行仿射变换，也就是说，它有一个姿态矩阵，允许它以不同的方式实例化自己。
271 00:25:51,872 --> 00:26:10,573 演讲者 SPEAKER_07：所以，如果给你展示一些数字，那么如果你看那个四，我将用红色显示如果你从图像中提取四的部分，然后从这些部分中重建四的情况。
272 00:26:11,599 --> 00:26:17,726 演讲者 SPEAKER_07：我将用绿色显示如果你从图像中提取四的部分会发生什么。
273 00:26:18,467 --> 00:26:22,210 演讲者 SPEAKER_07：然后从这四个部分中激活高级胶囊。
274 00:26:23,111 --> 00:26:28,096 演讲者 SPEAKER_07：然后从这些高级胶囊激活中重建低级胶囊。
275 00:26:28,476 --> 00:26:30,317 演讲者 SPEAKER_07：您实际上现在是从高级胶囊生成它们。
276 00:26:30,817 --> 00:26:34,602 演讲者 SPEAKER_07：然后从这些低级部分重建像素。
277 00:26:35,041 --> 00:26:36,163 演讲者 SPEAKER_07：我现在用绿色向您展示这一点。
278 00:26:36,644 --> 00:26:39,987 演讲者 SPEAKER_07：如果红色和绿色完全相同，您将看到黄色。
279 00:26:39,967 --> 00:26:43,570 演讲者 SPEAKER_07：您可以看到，您可以看到红色和绿色边缘的黄色，它们略有不同。
280 00:26:44,913 --> 00:26:49,679 演讲者 SPEAKER_07：我右边展示的是 24 个高级胶囊的激活情况。
281 00:26:50,378 --> 00:27:01,152 演讲者 SPEAKER_07：这 24 个高级胶囊将学会变成像整个数字这样的东西，但它们将学会变成更大的东西，但不是精确的数字。
282 00:27:04,476 --> 00:27:09,281 演讲者 SPEAKER_07：为了展示它是如何将部分组合成整体的，如果你看看这四个，
283 00:27:09,936 --> 00:27:12,760 演讲者 SPEAKER_07：然后你看第五列的部分。
284 00:27:14,782 --> 00:27:19,288 演讲者 SPEAKER_07：第五部分是相同的部分，但使用了不同的仿射变换。
285 00:27:19,930 --> 00:27:28,741 演讲者 SPEAKER_07：您可以看到，当我改变，当我改变仿射变换时，它在图像中的实例化方式非常不同。
286 00:27:30,624 --> 00:27:32,807 演讲者 SPEAKER_07：因此，相同的部分可以以非常不同的方式使用。
287 00:27:34,189 --> 00:27:37,192 演讲者 SPEAKER_07：但它可以从这些仿射变换部分中识别出这些数字。
288 00:27:39,400 --> 00:28:06,133 演讲者 SPEAKER_07：现在我想向您展示的是，在我们学习之后，我们学习提取部分，然后我们学习解释这些部分的组合，然后我们取这些高级向量，那些在 24 个高级胶囊的激活模式中发生的事情，右侧列中的事物。
289 00:28:07,462 --> 00:28:12,790 讲者 SPEAKER_07：我们将这些激活向量绘制成 t-SNE 图。
290 00:28:13,531 --> 00:28:25,828 即，我们将向量嵌入到二维地图中，使得相似的向量彼此靠近，不相似的向量彼此远离，但重点是相似的向量要靠近。
291 00:28:25,848 --> 00:28:31,958 我们将这些向量嵌入到地图中，记住，这东西一生从未见过标签。
292 00:28:32,038 --> 00:28:33,820 它从未被告知过任何关于标签的事情。
293 00:28:33,881 --> 00:28:35,242 演讲者 SPEAKER_07: 这完全是未监督的。
294 00:28:35,981 --> 00:28:37,683 演讲者 SPEAKER_07: 我们可以看到。
295 00:28:39,125 --> 00:28:46,773 演讲者 SPEAKER_07: 所以它有 10 个类别，这 10 个类别分布得很好，但也有些错误。
296 00:28:48,075 --> 00:29:03,171 演讲者 SPEAKER_07: 但如果你现在只是说，我会给每个类别一个标签，例如，我可以从每个类别中挑选一个成员，看看它的标签是什么，几乎可以肯定，它的标签就是该类别中其他所有事物的标签。
297 00:29:04,551 --> 00:29:14,628 讲者 SPEAKER_07：然后我可以在基本上没有标签或根据你的看法有 10 个标签的情况下，在 MNIST 上做到 98.7%的正确率。
298 00:29:15,671 --> 00:29:19,336 讲者 SPEAKER_07：所以 MNIST 的自然类别就凸显出来了。
299 00:29:19,856 --> 00:29:28,446 讲者 SPEAKER_07：这是通过学习具有这种宽泛部分概念的生成模型实现的，这些部分与整体有特定的坐标关系。
300 00:29:28,727 --> 00:29:37,518 讲者 SPEAKER_07：对于 MNIST 来说，它们是可变形的，所以需要我之前提到的那些点状绿色线条来说明部分与整体的关系是依赖于特定的整体的。
301 00:29:39,859 --> 00:29:41,561 演讲者 SPEAKER_07: 所以它工作了。
302 00:29:41,582 --> 00:29:44,625 演讲者 SPEAKER_07: 我还剩下三分钟和三张幻灯片，所以这很完美。
303 00:29:48,109 --> 00:29:49,711 演讲者 SPEAKER_07: 这有两个大问题。
304 00:29:50,755 --> 00:29:55,401 演讲者 SPEAKER_07: 其中一个问题是视觉并不是真正处理整个图像。
305 00:29:55,741 --> 00:29:59,287 讲者 SPEAKER_07：视觉有一个很小的黄斑并决定将其放置在哪里。
306 00:29:59,386 --> 00:30:04,413 讲者 SPEAKER_07：所以视觉的真正循环是一个采样过程，我们几乎看不到几乎所有东西都以高分辨率呈现。
307 00:30:07,257 --> 00:30:14,366 讲者 SPEAKER_07：当我们对每个注视点进行视觉处理时，我坚信我们只看到一幅图像和一些地面。
308 00:30:14,869 --> 00:30:19,056 讲者 SPEAKER_07：当然，还有所有这些错觉，你可以看到一个花瓶，或者你可以看到两张脸。
309 00:30:19,938 --> 00:30:22,561 演讲者 SPEAKER_07：一对面孔，这是一回事。
310 00:30:22,961 --> 00:30:26,688 演讲者 SPEAKER_07：或者你可以看到一个面孔，这是另一回事。
311 00:30:26,708 --> 00:30:34,920 演讲者 SPEAKER_07：所以如果视觉在心理上由前景和背景组成，这个胶囊模型就是前景感知的模型。
312 00:30:35,525 --> 00:30:37,867 演讲者 SPEAKER_07：它不是用来感知背景的模型。
313 00:30:37,907 --> 00:30:43,694 讲者 SPEAKER_07：为了模拟地面，你需要一种更接近纹理建模的方法，而不是将事物分割成部分。
314 00:30:44,375 --> 00:30:46,317 讲者 SPEAKER_07：变分自编码器在这方面非常出色。
315 00:30:47,118 --> 00:30:57,651 讲者 SPEAKER_07：因此，Sarah 训练了一个堆叠胶囊自编码器和变分自编码器的组合，以用高度纹理的背景解释 MNIST 数字。
316 00:30:58,001 --> 00:30:59,604 讲者 SPEAKER_07：结果证明这效果要好得多。
317 00:30:59,625 --> 00:31:01,968 讲者 SPEAKER_07：变分自编码器模型背景。
318 00:31:02,409 --> 00:31:05,413 讲者 SPEAKER_07：它仍然不如没有杂乱背景的效果好。
319 00:31:05,933 --> 00:31:15,067 讲者 SPEAKER_07：但我相信让这种理论在背景杂乱的情况下工作，就像人们一样，可以说，背景杂乱，我们只将其视为背景杂乱。
320 00:31:15,087 --> 00:31:19,295 讲者 SPEAKER_07：我们不使用高级基于部分的结构模型来对其进行建模。
321 00:31:20,276 --> 00:31:21,498 演讲者 SPEAKER_07：这是留给图表的。
322 00:31:22,961 --> 00:31:23,300 演讲者 SPEAKER_07：好的。
323 00:31:25,795 --> 00:31:33,492 演讲者 SPEAKER_07：下一个点，抱歉，我已经说过了。
324 00:31:36,307 --> 00:31:40,712 演讲者 SPEAKER_07：下一个点是，这些都是二维的，我们需要处理真实的 3D 图像。
325 00:31:41,473 --> 00:31:51,066 讲者 SPEAKER_07：Sarah 之前版本中的 Capsules 在 Norb 图像上工作过，这些图像是由 Jan 设计的，用于测试是否可以处理 3D 形状，即不使用颜色直方图的真正 3D 形状。
326 00:31:53,730 --> 00:32:01,219 讲者 SPEAKER_07：为了让这些东西工作，我们需要前端 Capsules，即主要 Capsules，来表示物体的合理部分。
327 00:32:01,958 --> 00:32:12,094 讲者 SPEAKER_07：如果你把视觉看作是逆向图形，图形处理整个形状，获取部分，获取部分的部分，以及部分的部分，最终得到类似三角形的东西，然后进行渲染。
328 00:32:13,036 --> 00:32:17,762 讲者 SPEAKER_07：所以如果你想进行逆向图形处理，最底层将是逆向渲染。
329 00:32:17,782 --> 00:32:21,788 讲者 SPEAKER_07：只有最底层处理光的属性和反照率等事物。
330 00:32:22,790 --> 00:32:24,834 讲者 SPEAKER_07：更高层次将涉及几何学。
331 00:32:25,214 --> 00:32:28,539 讲者 SPEAKER_07：而我所谈论的是与几何学相关的层次。
332 00:32:28,519 --> 00:32:34,288 讲者 SPEAKER_07：我们现在正在研究反转渲染器，以便获取合理的部分。
333 00:32:34,907 --> 00:32:36,871 演讲者 SPEAKER_07: 我们有几种不同的方法来做这件事。
334 00:32:36,911 --> 00:32:47,365 演讲者 SPEAKER_07: 你可以使用表面网格，或者使用已知部分，这被称为 geons，或者使用半空间的交集，还有许多不同的方法。
335 00:32:47,924 --> 00:32:51,390 演讲者 SPEAKER_07: 我只剩下六秒钟了，所以我最好有一个结论。
336 00:32:53,432 --> 00:32:57,597 演讲者 SPEAKER_07: 关于坐标变换和解析树的先验知识很容易放入生成模型中。
337 00:32:57,950 --> 00:33:05,923 讲者 SPEAKER_07：将你的知识放入生成模型中，有趣的一点是，识别模型、编码器并不会进入你模型的复杂性。
338 00:33:05,982 --> 00:33:13,615 讲者 SPEAKER_07：你可以让编码器尽可能复杂，在最小描述长度或贝叶斯术语中，重要的是生成模型的复杂性。
339 00:33:14,175 --> 00:33:22,589 讲者 SPEAKER_07：所以创建一个简单的生成模型，它有很多复杂的指令，并将反转它这个糟糕的问题转移到巨大的集合变换器上。
340 00:33:22,569 --> 00:33:28,640 讲者 SPEAKER_07：如果你让变换器足够大，有足够的层，并在足够多的数据上训练它，成功就有保障了。
341 00:33:30,849 --> 00:33:31,010 演讲者 SPEAKER_06: 好的。
342 00:33:58,682 --> 00:34:01,086 演讲者 SPEAKER_02: 所以我很高兴介绍 Yann LeCun。
343 00:34:02,188 --> 00:34:20,994 演讲者 SPEAKER_02: 所以 Yann 是 Facebook 的首席人工智能科学家，也是纽约 Facebook 人工智能研究实验室的首任主任，后来将该实验室扩展到法国、加拿大和美国的许多其他地点。
344 00:34:20,974 --> 00:34:28,914 演讲者 SPEAKER_02: 他还是纽约大学计算机科学、数据科学、神经科学以及电子和计算机工程学教授。
345 00:34:30,257 --> 00:34:37,092 讲者 SPEAKER_02：众所周知，他一直在机器学习领域工作，还涉及计算机视觉、移动机器人和计算神经科学。
346 00:34:37,764 --> 00:34:50,884 讲者 SPEAKER_02：我个人几年前在伊恩组织的一个关于 AI 善行的 NYU 会议上认识了他。
347 00:34:51,726 --> 00:34:59,536 讲者 SPEAKER_02：从那时起，我们和其他人也一起合作，和他合作真是太棒了。
348 00:34:59,516 --> 00:35:09,164 讲者 SPEAKER_02：看到这种让 AI 真正进步并有益的激情如何结合成这个伟大倡议，真是太好了。
349 00:35:09,184 --> 00:35:18,452 讲者 SPEAKER_02：但除了他在技术和领导方面的惊人角色外，我还一直觉得伊恩是一个非常积极的人。
350 00:35:18,512 --> 00:35:21,916 讲者 SPEAKER_02：你可以看到他真的很享受他所做的研究。
351 00:35:21,976 --> 00:35:24,637 讲者 SPEAKER_02：当他谈论自己的研究时，他总是面带微笑。
352 00:35:25,199 --> 00:35:26,360 讲者 SPEAKER_02：他真的很热爱生活。
353 00:35:26,679 --> 00:35:29,322 演讲者 SPEAKER_02：他是个好人，喜欢航海。
354 00:35:29,302 --> 00:35:29,842 演讲者 SPEAKER_02：很多。
355 00:35:30,282 --> 00:35:32,806 演讲者 SPEAKER_02：他喜欢美食，尤其是法国菜。
356 00:35:35,670 --> 00:35:55,938 演讲者 SPEAKER_02：作为三位主席中的意大利人，我被分配来发表这个句子，我认为我们在这里需要说这句话，因为与 Jeff 和 Yoshua 一起，Ian 是所谓 AI 的教父之一。
357 00:35:55,958 --> 00:35:58,481 说话人 SPEAKER_02：请大家再次欢迎 Ian。
358 00:36:06,713 --> 00:36:11,219 说话人 SPEAKER_09：嗯，我和意大利教父还有一样的东西，那就是我在新泽西有一栋房子。
359 00:36:14,563 --> 00:36:17,025 说话人 SPEAKER_09：好的，我要谈谈自监督学习。
360 00:36:17,045 --> 00:36:23,074 说话人 SPEAKER_09：这将是比 Jeff 所讲的内容更高级的演讲，更偏向于启发性的，而不是技术性的。
361 00:36:24,235 --> 00:36:26,898 演讲者 SPEAKER_09：我需要两个麦克风。
362 00:36:28,414 --> 00:36:39,797 演讲者 SPEAKER_09：好的，首先我会从深度学习的定义开始，因为我经常在各种社交网络上活跃，似乎人们对这到底是什么存在一些混淆。
363 00:36:40,478 --> 00:36:44,847 演讲者 SPEAKER_09：它不是监督学习，也不是神经网络，或者不仅仅是神经网络。
364 00:36:45,228 --> 00:36:50,659 演讲者 SPEAKER_09：它基本上是构建系统的一种想法，即通过组装参数化模块。
365 00:36:50,639 --> 00:36:52,601 演讲者 SPEAKER_09：进入计算图。
366 00:36:52,621 --> 00:37:03,376 演讲者 SPEAKER_09：这些图可能是动态的，也就是说它们不一定确定，不是静态的，它们可以依赖于数据，依赖于输入数据，根据具体情况而定。
367 00:37:04,036 --> 00:37:06,500 演讲者 SPEAKER_09：然后使用基于梯度的学习方法来优化它们。
368 00:37:06,800 --> 00:37:18,856 演讲者 SPEAKER_09：这是一个非常、非常一般的定义，但它的想法是你不是直接编程一个系统，你编写一个定义架构的程序，但有一些参数留给了你，你通过学习来调整这些参数。
369 00:37:18,836 --> 00:37:20,860 讲者 SPEAKER_09：可能会有数十亿这样的参数。
370 00:37:21,661 --> 00:37:30,032 讲者 SPEAKER_09：我们之前看到了 Jeff 描述的例子，这基本上是工程架构的一个好例子。
371 00:37:30,092 --> 00:37:41,047 讲者 SPEAKER_09：所以它为你提供了一种语言，将先验知识或归纳偏差（正如机器学习人员喜欢说的）工程到系统中。
372 00:37:42,394 --> 00:38:04,431 讲者 SPEAKER_09：深度学习可以稍微超越人们对神经网络的一般观念的一点是，输出不一定只是通过一些前馈过程计算出来的，它可能是某种复杂计算的结果，例如，通过最小化某种类型的能量函数，对吧？
373 00:38:04,452 --> 00:38:06,494 演讲者 SPEAKER_09：所以你可以在深度学习系统中进行推理。
374 00:38:08,382 --> 00:38:11,847 演讲者 SPEAKER_09：然后它并没有指定学习范式。
375 00:38:12,108 --> 00:38:25,007 演讲者 SPEAKER_09：当然，你可以在监督学习的情况下使用深度学习，这非常成功，也可以在强化学习的情况下使用，至少对于游戏来说非常成功，以及在自监督或无监督学习的情况下。
376 00:38:26,286 --> 00:38:35,115 演讲者 SPEAKER_09：所以我们经常读到关于深度学习今天局限性的讨论，但其中大部分局限性实际上是监督学习的局限性，而不是深度学习的局限性。
377 00:38:35,135 --> 00:38:41,983 讲者 SPEAKER_09：好了，这个问题解决了，监督学习确实有效，但效果非常好，但需要大量的样本。
378 00:38:42,563 --> 00:38:56,277 讲者 SPEAKER_09：事实上，可能是神经网络在 90 年代中期逐渐消失的原因之一是我们能够拥有的数据量非常有限。
379 00:38:56,661 --> 00:39:00,208 讲者 SPEAKER_09：基本上就是手写识别和一点语音识别，就这些。
380 00:39:01,070 --> 00:39:09,063 讲者 SPEAKER_09：所以我们实际上无法训练大型网络，部分原因是数据不足，部分原因是我们的机器速度太慢，部分原因是我们还没有弄清楚一些概念。
381 00:39:09,543 --> 00:39:14,231 演讲者 SPEAKER_09: 但这正是过去 10 年左右发生的变化。
382 00:39:15,628 --> 00:39:24,525 演讲者 SPEAKER_09: 所以它对语音识别、图像识别、正如您所知，自然语言处理等都非常有效，翻译等。
383 00:39:26,228 --> 00:39:35,847 演讲者 SPEAKER_09: 我认为在计算机视觉领域的进步非常惊人，实际上也导致了计算机视觉应用领域的爆炸式增长。
384 00:39:35,827 --> 00:39:39,797 演讲者 SPEAKER_09: 而且很棒的是，其中很多都是开源的。
385 00：39：39,876 --> 00：39：54,951 演讲者 SPEAKER_09： 你可以从不同的地方下载各种代码，基本上在你想要解决的任何计算机视觉问题方面都是高性能的。
386 00:39:54,931 --> 00:39:56,835 演讲者 演讲者_09：所有这些都在实时运行，一切如此。
387 00:39:56,916 --> 00:40:01,588 演讲者 演讲者_09：所以这是我们预期从深度学习中得到的，但也有我们从深度学习中没有得到的东西。
388 00：40：02,951 --> 00：40：04,195 议长 SPEAKER_09：或者至少我没想到。
389 00:40:04,315 --> 00:40:10,610 演讲者 SPEAKER_09：这是过去几个月内我巴黎 Facebook AI 研究团队的一些同事的最新工作。
390 00:40:10,590 --> 00:40:17,019 演讲者 SPEAKER_09：Guillaume Lample 和 François Charton，他们展示了可以使用深度学习进行符号操作。
391 00:40:17,320 --> 00:40:28,675 演讲者 SPEAKER_09：可以进行诸如解积分等符号操作，他们使用的架构是 Transformer，我无需过多描述，因为 Jeff 刚刚部分介绍了这一点。
392 00:40:28,775 --> 00:40:37,407 演讲者 SPEAKER_09：所以他们使用了一个相当大的 Transformer，并通过生成方程在监督模式下对其进行训练。
393 00:40:37,387 --> 00:40:51,233 讲者 SPEAKER_09：以一种相当复杂的方式，然后，你知道的，展示积分，我的意思是，不是一个方程，而是一个公式，然后训练系统产生该公式的积分。
394 00:40:51,875 --> 00:40:55,481 讲者 SPEAKER_09：他们还为此进行了关于一阶和二阶微分方程的实验。
395 00:40:55,461 --> 00:41:08,661 讲者 SPEAKER_09：这个系统在他们生成的数据集上工作得非常好，他们已经证明它解决了 MATLAB、Maple 和 Mathematica 都无法解决的问题。
396 00:41:10,396 --> 00:41:26,362 讲者 SPEAKER_09：这真的很令人印象深刻，这是纯监督学习，使用生成数据，一个非常大的神经网络，它似乎在进行某种符号操作，但实际上并没有进行符号操作，因为系统中的所有东西都由向量表示。
397 00:41:26,916 --> 00:41:30,061 演讲者 SPEAKER_09: 没有符号，没有逻辑，没有规则。
398 00:41:31,643 --> 00:41:35,871 演讲者 SPEAKER_09: 这基本上是一个经过训练来完成这项任务的大型神经网络。
399 00:41:36,311 --> 00:41:48,789 演讲者 SPEAKER_09: 所以，如果你愿意的话，它有点像直观的符号积分，或者函数或微分方程的积分。
400 00:41:50,574 --> 00:41:57,286 演讲者 SPEAKER_09: 第二件事是，深度学习在短短几年内就变得无处不在。
401 00:41:57,347 --> 00:42:02,876 说话人 SPEAKER_09：我得到了一些让我感到震惊的统计数据。
402 00:42:02,916 --> 00:42:07,023 说话人 SPEAKER_09：现在，自动紧急制动系统在很多汽车中已成为标准。
403 00:42:07,284 --> 00:42:10,710 说话人 SPEAKER_09：实际上，在欧洲，包括低端车型在内，每辆汽车都配备了这一系统。
404 00:42:10,690 --> 00:42:26,893 说话人 SPEAKER_09：这些基本上是将卷积神经网络插入到观察挡风玻璃的摄像头中，如果检测到前方有障碍物且驾驶员注意力不集中，则会激活制动。
405 00:42:27,934 --> 00:42:31,298 说话人 SPEAKER_09：根据统计，这减少了 40%的碰撞。
406 00:42:31,418 --> 00:42:35,043 说话人 SPEAKER_09：因此，它挽救了生命。
407 00:42:36,086 --> 00:42:39,231 说话人 SPEAKER_09：我们经常读到关于人工智能的负面影响，但这是一个积极的影响。
408 00:42:39,833 --> 00:42:46,423 说话人 SPEAKER_09：当然，在乳腺摄影的医学影像领域使用深度学习引起了极大的兴奋。
409 00:42:46,443 --> 00:42:49,168 讲者 SPEAKER_09：这些是我同事在纽约大学工作中的照片。
410 00:42:51,130 --> 00:42:56,559 讲者 SPEAKER_09：但也有很多 AI 的应用是幕后进行的，尽管你可以读到，
411 00:42:56,539 --> 00:42:58,141 讲者 SPEAKER_09：在许多媒体和新闻中。
412 00:43:00,563 --> 00:43:16,521 讲者 SPEAKER_09：比如仇恨言论、过滤、暴力呼吁、停止武器销售等，以及在我们一些同事工作的公司中的各种社交媒体上的恐怖主义宣传，这些都非常有用。
413 00：43：16,880 --> 00：43：23,407 演讲者 SPEAKER_09：网络上发生了很多事情，很多事情必须被删除，这是通过深度学习完成的。
您从 Facebook、Instagram、Google、YouTube 等公司提取深度学习技术
415 00：43：29,427 --> 00：43：30,289 议长 SPEAKER_09：那些公司倒闭了。
416 00：43：30,309 --> 00：43：31,795 议长 SPEAKER_09：他们现在完全是围绕它构建的。
417 00:43:34,356 --> 00:43:38,867 演讲者 SPEAKER_09：像翻译这样的更明显的事情，当然，但这是很有趣的。
418 00:43:39,728 --> 00:43:53,697 演讲者 SPEAKER_09：当然，人们对强化学习非常兴奋，它在游戏和模拟中效果非常好，但它的速度非常慢，因为它需要很多很多次试验来训练一个系统达到任何程度的性能。
419 00:43:53,677 --> 00:44:12,295 演讲者 SPEAKER_09：例如，Facebook 开发的围棋选手，与 DeepMind 的 AlphaZero 有些相似，大约需要两周时间在 2,000 个 GPU 上训练，并且需要玩 2,000 万场比赛，这比任何人在一生中能玩的都要多。
420 00:44:12,275 --> 00:44:24,005 演讲者 SPEAKER_09：DeepMind 的 StarCraft 游戏系统 AlphaStar，相当于 200 年的实时游戏时间，才能在单一地图上略高于人类的表现。
421 00:44:25,166 --> 00:44:35,443 讲者 SPEAKER_09：最近 OpenAI 独立开发的魔方操作系统在模拟中相当于需要 10,000 年。
422 00:44:36,083 --> 00:44:41,391 讲者 SPEAKER_09：所以这些系统在模拟中工作得非常好，但在现实世界中呢？
423 00:44:41,472 --> 00:44:43,896 讲者 SPEAKER_09：那么，如果你想要训练一辆车自动驾驶呢？
424 00:44:44,657 --> 00:44:48,322 讲者 SPEAKER_09：而这在模拟中很难做到非常精确。
425 00:44:48,860 --> 00:44:56,411 说话人 SPEAKER_09: 因此，我们在现实世界中实际上无法做到这一点，因为这样做会毁掉很多汽车，然后让汽车运行数百万次，等等。
426 00:44:57,452 --> 00:45:02,340 说话人 SPEAKER_09: 因此，这是一个巨大的挑战，那就是我们如何让机器学习更接近人类和动物？
427 00:45:02,420 --> 00:45:08,429 说话人 SPEAKER_09: 为什么人类可以在 20 小时的训练中学会开车，大多数人不会出事故？
428 00:45:11,152 --> 00:45:12,876 说话人 SPEAKER_09: 这就是其中的一个挑战之一
429 00:45:14,324 --> 00:45:14,985 演讲者 SPEAKER_09: 关于深度学习。
430 00:45:15,005 --> 00:45:19,208 演讲者 SPEAKER_09: 我看到了三个挑战，这些问题我们都在一定程度上在努力解决。
431 00:45:20,251 --> 00:45:28,980 演讲者 SPEAKER_09: 正如我所说，深度学习在感知方面表现良好，深度强化学习在动作生成方面表现良好，只有在试验成本低廉的情况下，所以它主要在模拟中工作。
432 00:45:30,702 --> 00:45:34,246 演讲者 SPEAKER_09: 但社区正在努力解决，并且应该更加努力解决的问题有三个。
433 00:45:34,746 --> 00:45:39,572 讲者 SPEAKER_09：第一个问题是，我们如何用更少的标签、更少的样本或更少的试验来学习？
434 00:45:40,818 --> 00:46:02,161 讲者 SPEAKER_09：关于这个问题的建议，我借鉴了 Jeff 的想法，基本上，在忽略他 15 年后又改变主意，就是使用无监督学习，或者我更喜欢称之为自监督学习，因为我们使用的算法实际上类似于监督学习，这基本上是学习填补空白。
435 00:46:02,581 --> 00:46:06,927 讲者 SPEAKER_09：transformers 和类似的东西就是这种例子，我稍后会提到。
436 00:46:06,907 --> 00:46:10,376 讲者 SPEAKER_09：所以基本上是先学习表示世界，然后再学习任务。
437 00:46:10,715 --> 00:46:11,719 演讲者 SPEAKER_09：这就是婴儿所做的事情。
438 00:46:12,541 --> 00:46:14,364 演讲者 SPEAKER_09：动物也会这样做，对吧？
439 00:46:14,405 --> 00:46:19,277 所以我们在学习任何任务之前，先了解世界，了解它是如何运作的。
440 00:46:19,297 --> 00:46:24,831 一旦我们对世界的表征很好，学习一个任务只需要几次尝试和一些样本。
441 00:46:24,811 --> 00:46:26,652 演讲者 SPEAKER_09：第二个挑战是推理。
442 00:46:27,114 --> 00:46:31,920 演讲者 SPEAKER_09：所以我刚刚展示了一个例子，说明你可以如何在不实际进行简单操作的情况下进行简单操作。
443 00:46:32,942 --> 00:46:42,012 演讲者 SPEAKER_09：问题是，你知道，我们如何超越 Denny Kahneman 所说的系统一那样的前馈计算。
444 00:46:42,773 --> 00:46:45,637 演讲者 SPEAKER_09：关于这一点，我不会过多地谈论，因为我知道 Yoshua 将会谈到那个话题。
445 00:46:45,617 --> 00:46:52,250 演讲者 SPEAKER_09: 但是问题是，我们如何使推理与基于梯度的学习相兼容？
446 00:46:53,271 --> 00:46:54,815 演讲者 SPEAKER_09: 我们如何使推理可微分？
447 00:46:54,835 --> 00:46:57,018 演讲者 SPEAKER_09: 这就是关键所在。
448 00:46:57,500 --> 00:46:59,724 演讲者 SPEAKER_09: 而没有人真正有一个完整的良好答案。
449 00:47:00,085 --> 00:47:00,646 演讲者 SPEAKER_09：这是一个挑战。
450 00:47:01,166 --> 00:47:09,481 演讲者 SPEAKER_09：然后第三个问题是，我们如何学习规划复杂动作序列，将复杂任务分解为子任务？
451 00:47:09,461 --> 00:47:20,414 然后，你知道，我们可以通过卷积网络、胶囊等，学习图像、语音、文本等的层次化表示。
452 00:47:20,876 --> 00:47:23,619 演讲者 SPEAKER_09：但是，我们如何学习动作计划的层次化表示呢？
453 00:47:24,019 --> 00:47:25,181 演讲者 SPEAKER_09：我们不知道如何做这件事。
454 00:47:25,661 --> 00:47:28,284 演讲者 SPEAKER_09：所以，我将简要谈谈第一点。
455 00:47:28,786 --> 00:47:31,588 演讲者 SPEAKER_09：第二点我提到了，但不会过多地回到这一点。
456 00:47:31,949 --> 00:47:34,913 演讲者 SPEAKER_09：至于第三点，我不知道如何解决，所以根本不会谈论它。
但我对你们可能有的任何想法都持开放态度。
458 00:47:38,778 --> 00:47:41,804 演讲者 SPEAKER_09：人类是如何如此快速且高效地学习的呢？
459 00:47:43,126 --> 00:47:45,490 演讲者 SPEAKER_09：这不是监督学习，也不是强化学习，对吧？
460 00:47:45,510 --> 00:47:54,246 演讲者 SPEAKER_09：所以我从巴黎的认知科学家 Emmanuel Dupou 那里偷来了这张幻灯片，他在 Facebook 工作过一段时间。
461 00:47:55,507 --> 00:47:58,773 演讲者 SPEAKER_09：如果你把左上角的场景展示给一个婴儿看，
462 00:47:59,260 --> 00:48:04,385 说话人 SPEAKER_09：一个小车在平台上，你把小车从平台上推下去，小车没有掉下来。
463 00:48:04,425 --> 00:48:04,985 说话人 SPEAKER_09：这里有个诀窍。
464 00:48:06,106 --> 00:48:11,893 说话人 SPEAKER_09：一个六个月大的婴儿会这样看，你知道的，就像什么也没看到一样，对吧？
465 00:48:12,273 --> 00:48:14,335 说话人 SPEAKER_09：这对那个婴儿来说似乎并不很有趣。
466 00:48:15,376 --> 00:48:17,920 演讲者 SPEAKER_09：它将像看待其他一切事物一样看待它。
467 00:48:18,960 --> 00:48:25,807 演讲者 SPEAKER_09：如果你把这个展示给一个九个月或十个月大的婴儿，她看起来就像左下角的那个小女孩。
468 00:48:26,782 --> 00:48:30,771 演讲者 SPEAKER_09：因为在八个月到九个月大的时候，婴儿开始了解重力。
469 00:48:30,911 --> 00:48:33,615 演讲者 SPEAKER_09：所以他们知道没有支撑的物体应该会掉落。
470 00:48:33,737 --> 00:48:37,423 演讲者 SPEAKER_09：所以当一个物体违反了那条规则，它们会非常惊讶。
471 00:48:37,885 --> 00:48:40,590 演讲者 SPEAKER_09：他们会像疯了一样地看它，因为他们觉得他们错过了什么。
472 00:48:42,038 --> 00:48:47,784 演讲者 SPEAKER_09：这是尝试弄清楚婴儿是否学会了基本概念的一种方法。
473 00:48:47,804 --> 00:49:04,199 演讲者 SPEAKER_09：有一种观点，回到皮亚杰和更早的时候，婴儿是按顺序学习概念的，一种接一种，越来越抽象，越来越复杂。
474 00:49:04,820 --> 00:49:07,842 讲者 SPEAKER_09：婴儿很早就学会了物体恒存。
475 00:49:07,862 --> 00:49:09,625 有些人声称这实际上是天生的。
476 00:49:10,425 --> 00:49:11,606 这是一个很大的问题。
477 00:49:11,586 --> 00:49:18,280 他们在大约三个月左右的时间学会区分有生命物体和无生命物体。
478 00:49:18,300 --> 00:49:23,110 演讲者 SPEAKER_09：它们能够快速学习类别，即使没有告诉它们任何名称。
479 00:49:23,911 --> 00:49:30,344 演讲者 SPEAKER_09：它们在九个月大时，就能学习关于重力、惯性和动量守恒等 2D 物理知识。
480 00:49:30,364 --> 00:49:31,266 演讲者 SPEAKER_09：我们是如何做到这一点的？
481 00:49:32,190 --> 00:49:34,516 演讲者 SPEAKER_09：这不仅仅是婴儿，还有动物。
482 00:49:34,536 --> 00:49:35,878 说话人 SPEAKER_09：这里有一只小猩猩。
483 00:49:36,059 --> 00:49:38,925 说话人 SPEAKER_09：他正在被展示一个与物体恒存性有关的魔术。
484 00:49:38,945 --> 00:49:42,532 说话人 SPEAKER_09：你把一个物体放在杯子里，摇动杯子，拿出物体。
485 00:49:42,592 --> 00:49:44,295 说话人 SPEAKER_09：猩猩没有看到这一点。
486 00:49:44,697 --> 00:49:45,699 演讲者 SPEAKER_09：杯子现在空了。
487 00:49:46,721 --> 00:49:47,503 演讲者 SPEAKER_09：展示空杯子。
488 00:49:49,987 --> 00:49:52,393 演讲者 SPEAKER_09：小猩猩在地上打滚大笑。
489 00:49:57,250 --> 00:49:59,411 演讲者 SPEAKER_09：因为他的世界观被打破了。
490 00:49:59,512 --> 00:50:02,135 演讲者 SPEAKER_09：他知道物体恒存。
491 00:50:02,494 --> 00:50:04,077 演讲者 SPEAKER_09：顺便说一句，猩猩没有语言。
492 00:50:04,376 --> 00:50:05,539 演讲者 SPEAKER_09：它们甚至不是群居动物。
493 00:50:07,000 --> 00:50:08,081 演讲者 SPEAKER_09：它们过着孤独的生活。
494 00:50:10,123 --> 00:50:19,994 讲者 SPEAKER_09：这就告诉了你如何变得聪明，不一定是通过语言或语言交流。
495 00:50:20,614 --> 00:50:22,036 讲者 SPEAKER_09：那么，什么是自监督学习？
496 00:50:22,155 --> 00:50:27,021 讲者 SPEAKER_09：自监督学习是过去一年半多 NLP 成功的关键。
497 00:50:27,001 --> 00:50:32,652 讲者 SPEAKER_09：这是训练一个系统来填补空白的想法，对吧？
您向系统展示一段输入，比如文本、视频，甚至图像，然后隐藏其中一部分，如果您愿意，可以将其部分遮挡，并训练一个神经网络或您喜欢的模型来预测缺失的部分。
499 00:50:47,842 --> 00:50:51,865 演讲者 SPEAKER_09：所以它可以是预测视频中的未来，或者它可以是预测文本中的缺失单词。
预测文本中缺失的单词正是 transformers 和 Bert-like 系统，现在有很多追随者，所构建的功能。
您向一个巨大的神经网络展示一段文本，最大的那些有数十亿个参数，您大约遮盖了15%的单词，然后训练这个网络预测缺失的单词。
502 00:51:14,335 --> 00:51:27,864 演讲者 SPEAKER_09：训练这样的系统很容易，因为关于哪个词可能会缺失，当然存在一些不确定性，但我们可以用整个词典的概率向量来表示这种不确定性。
503 00:51:27,885 --> 00:51:31,112 演讲者 SPEAKER_09：所以，这没问题。
504 00:51:31,092 --> 00:51:46,817 演讲者 SPEAKER_09：但对于图像来说，问题就更大了。Transformer 和 BERT 在图像领域的成功并没有得到体现，因为事实证明，在图像或视频中表示预测的不确定性比在文本中要困难得多，因为它们不是离散的。
505 00:51:47,418 --> 00:51:54,670 演讲者 SPEAKER_09：我们可以生成所有词典中单词的分布，但我们不知道如何表示所有可能的视频帧的分布。
506 00:51:54,650 --> 00:52:12,152 演讲者 SPEAKER_09：因此实际上产生了问题，那就是世界并非完全可预测，一个初始视频片段有许多可能的延续，如果你训练一个系统进行单一预测，
507 00:52:13,447 --> 00:52:18,414 演讲者 SPEAKER_09：训练一个神经网络来预测视频中的下一几个帧，你得到的是模糊的预测。
508 00:52:18,434 --> 00:52:26,123 演讲者 SPEAKER_09：原因是系统实际上无法预测未来会发生什么，因此它预测所有可能未来的平均值，而这恰好是一个模糊的图像。
509 00:52:28,867 --> 00:52:29,847 演讲者 SPEAKER_09：那么我们该如何解决这个问题呢？
510 00:52:29,907 --> 00:52:38,898 讲者 SPEAKER_09：在我看来，这是我们必须要解决的主要技术问题，如果你想要将自监督学习应用于视频等多种模态的话。
511 00:52:41,072 --> 00:52:48,382 讲者 SPEAKER_09：所以有几种不同的选择，但我觉得基于潜在变量能量模型的这个想法最有希望。
512 00:52:48,442 --> 00:52:54,849 讲者 SPEAKER_09：所以基于能量的模型有点像概率模型，只不过你不进行归一化。
513 00:52:55,030 --> 00:52:56,672 讲者 SPEAKER_09：你不使用指数也不进行归一化。
514 00:52:56,692 --> 00:53:01,677 讲者 SPEAKER_09：所以，如果你是概率论或贝叶斯，就把能量看作是负对数概率。
515 00:53:01,797 --> 00:53:04,701 除了这个，它就像一个概率模型。
516 00:53:04,681 --> 00:53:18,043 所以，你有一个能量函数，在这种情况下是 C of yy bar，它衡量一个观察值 x 和一个预测值、期望预测值 y 之间的兼容性，y 也是一个观察值。
517 00:53:18,704 --> 00:53:26,318 所以，x 将是视频的初始段，y 将是该视频的未来。
518 00:53:26,297 --> 00:53:31,206 演讲者 SPEAKER_09：然后这个基于能量的系统为你提供了这两个之间的兼容性。
519 00:53:31,507 --> 00:53:50,077 演讲者 SPEAKER_09：现在，有几种可能的不同未来，所以你在这个图中有一个可以变化的潜在变量 z，当你改变这个潜在变量时，预测值 y bar 会在某种流形上变化，这就是可能的预测、可能的未来的流形。
520 00:53:53,871 --> 00:54:09,382 演讲者 SPEAKER_09：在这方面已经有很多研究，但还没有取得巨大的成功，但有时使用各种方法训练这些系统，如对抗方法或其他方法，似乎可以减少这种模糊性。
521 00:54:09,422 --> 00:54:14,090 演讲者 SPEAKER_09：我将在几分钟内回到这个问题。
522 00:54:14,898 --> 00:54:17,641 讲者 SPEAKER_09：杰夫几十年来一直在提出这个论点。
523 00:54:18,081 --> 00:54:20,923 讲者 SPEAKER_09：正如我所说，我对此怀疑了很长时间，但后来改变了我的想法。
524 00:54:21,443 --> 00:54:36,018 讲者 SPEAKER_09：这个想法是，在使用这种自监督学习或无监督学习形式时，你从机器那里获得或提供给机器的信息比训练机器进行监督学习或强化学习时更多。
525 00:54:36,777 --> 00:54:41,782 讲者 SPEAKER_09：在强化学习中，你偶尔会给机器一个由单个标量组成的反馈。
526 00:54:41,762 --> 00:54:47,210 演讲者 SPEAKER_09：所以，不可避免地，你要求机器预测的信息量非常小。
527 00:54:47,871 --> 00:54:51,217 演讲者 SPEAKER_09：所以，不可避免地，机器要学习任何东西都需要进行许多许多次试验。
528 00:54:51,958 --> 00:54:59,889 演讲者 SPEAKER_09：在监督学习中，你每次样本都给出一些信息，这些信息是成千上万的类别之一。
529 00:54:59,869 --> 00:55:02,992 演讲者 SPEAKER_09：再次强调，这些信息相当薄弱，这也是为什么你需要这么多样本的原因。
530 00:55:03,652 --> 00:55:08,518 演讲者 SPEAKER_09：在自监督学习中，你要求机器预测整个视频帧，甚至整个视频。
531 00:55:09,378 --> 00:55:11,059 演讲者 SPEAKER_09：因此，它包含的信息量更多。
532 00:55:11,099 --> 00:55:15,623 演讲者 SPEAKER_09：为了学习关于世界的同样多的知识，你可能需要的样本更少。
533 00:55:16,083 --> 00:55:20,288 演讲者 SPEAKER_09：问题是这些数据不可靠，因为你需要处理不确定性。
534 00:55:20,568 --> 00:55:21,668 演讲者 SPEAKER_09：有许多可能的结果。
535 00:55:21,708 --> 00:55:28,375 演讲者 SPEAKER_09：所以，如果你想将自监督学习扩展到实际应用，我们需要解决这个技术问题。
536 00:55:28,355 --> 00:55:44,490 演讲者 SPEAKER_09：这让我想到了一个令人讨厌的比喻，如果智能是一块蛋糕，那么自监督学习就是蛋糕的主体，即蛋糕体，监督学习就是蛋糕上的糖霜，而强化学习就是蛋糕上的樱桃。
537 00:55:46,152 --> 00:55:48,795 演讲者 SPEAKER_09：我为所有在场的强化学习专家表示歉意。
538 00:55:50,396 --> 00:55:55,981 讲者 SPEAKER_09：我最好的朋友中有些是强化学习的人。
539 00:55:57,768 --> 00:56:04,235 你知道，这并不是说，顺便提一下，这是一种法式鸭肝酱，你知道，黑森林蛋糕，樱桃在这里是必不可少的。
540 00:56:07,998 --> 00:56:13,103 好的，所以 AI 的下一场革命将不是监督学习，也不是纯粹强化学习。
541 00:56:13,144 --> 00:56:16,447 据说，你甚至可以买一件 T 恤，有人用这个口号做了 T 恤。
542 00:56:16,827 --> 00:56:19,010 演讲者 SPEAKER_09：我从阿里·沙伊赫那里偷来了这个标语，这不是我的。
543 00:56:20,311 --> 00:56:22,914 演讲者 SPEAKER_09：而他又是从吉尔·斯科特·赫尔南那里偷来的。
544 00:56:22,894 --> 00:56:38,268 演讲者 SPEAKER_09：好的，所以我谈到了基于能量的模型这一想法，我没有时间详细解释这是什么，我将快速展示一个非常复杂的幻灯片，我不会解释，它展示了各种训练这些基于能量的模型的方法。
545 00:56:38,668 --> 00:56:42,753 演讲者 SPEAKER_09：基本上有两种主要方法用于训练它们。
546 00:56:43,112 --> 00:56:52,902 讲者 SPEAKER_09：第一个我们称之为对比，这里有很多方法你可能已经了解。
547 00:56:52,882 --> 00:57:00,833 讲者 SPEAKER_09：第二个是关于架构的，这些是我比较偏好的，但我先从对比的讲起。
548 00:57:00,893 --> 00:57:10,889 讲者 SPEAKER_09：所以训练一个基于能量的模型的一种方法是将它训练成对观察到的样本给予低能量，对未观察到的样本给予高能量。
549 00:57:10,869 --> 00:57:14,875 讲者 SPEAKER_09：所以，你知道，在以前，玻尔兹曼机是受限的。
550 00:57:14,894 --> 00:57:28,190 讲者 SPEAKER_09：玻尔兹曼机通过对比散度进行训练，这是对比学习方法的一个例子，你给机器一个数据点，然后给它一个非数据点，然后降低数据点的能量，提高非数据点的能量。
551 00:57:28,530 --> 00:57:30,472 讲者 SPEAKER_09：所以这是模型计算的能量，对吧？
552 00:57:30,492 --> 00:57:38,581 讲者 SPEAKER_09：所以你的模型在输出空间中计算一个能量函数，然后你以适当的方式塑造它。
553 00:57:39,811 --> 00:57:57,456 讲者 SPEAKER_09：现在，BERT 类型的系统，变换器通过对比方法进行预训练，这是所谓的去噪自编码器的一个特例，它出自于 Yoshua 的实验室，由 Pascal Vincent 提出。
554 00:57:57,476 --> 00:58:02,021 演讲者 SPEAKER_09：这个想法是这样的，你取一个样本，然后
555 00:58:03,385 --> 00:58:17,264 演讲者 SPEAKER_09：以某种方式对其进行破坏，比如在句子中删除单词，例如在 Bert 的情况下，然后将其通过网络运行，并训练这个网络从破坏版本恢复数据到未破坏版本。
556 00:58:18,364 --> 00:58:29,780 演讲者 SPEAKER_09：稍微思考一下，你就会很快意识到这是一种基于能量的训练形式，你迫使破坏点的能量高于未破坏点的能量。
557 00:58:32,612 --> 00:58:35,923 演讲者 SPEAKER_09：对于某种能量定义，这有点像是重建误差，如果你愿意的话。
558 00:58:37,148 --> 00:58:39,034 演讲者 SPEAKER_09：这就是一个非常成功的例子。
559 00:58:39,556 --> 00:58:40,559 演讲者 SPEAKER_09：对于文本来说效果非常好。
560 00:58:41,121 --> 00:58:42,706 演讲者 SPEAKER_09：正如我说的，对于图像来说效果不是很好。
561 00:58:43,902 --> 00:58:50,112 演讲者 SPEAKER_09：这里还有一个更成功的例子，是针对图像的，这是对比训练的另一个例子，它是对比嵌入。
562 00：58：50,733 --> 00：59：10,686 演讲者 SPEAKER_09：在过去的几个月里，有很多关于这方面的论文，使用这种方法作为预训练阶段，然后针对特定的监督任务进行微调，在计算机视觉任务上取得了破纪录的性能。
这里缺少一个参考文献，是来自 Olivier Naf 及其 DeepMind 合作者的一篇论文中的较新参考文献。
564 00:59:17,952 --> 00:59:26,280 发言人 发言人_09：但是这里的三篇论文来自 Facebook，所以 DeepFace 可以算是一篇关于人脸识别的旧论文，这是一种有点专业化的应用。
565 00:59:26,659 --> 00:59:34,427 演讲者 演讲者_09：最近的两项是所谓的 PERL，即 Misra 等人提出的“基于欺骗不变性表征学习”
566 00:59:35,487 --> 00:59:39,492 演讲者 SPEAKER_09：第二个是 MOCO，由 He Kaiming 等人提出。
567 00:59:39,911 --> 00:59:40,672 演讲者 SPEAKER_09：两者都在 Facebook。
568 00:59:40,652 --> 00:59:52,148 演讲者 SPEAKER_09：那里的想法是，它是一种各种事物的混合体，但基于我多年前提出的 Siamese 网络的理念。
569 00:59:52,847 --> 01:00:08,347 演讲者 SPEAKER_09：所以你拿一张图片，对其进行轻微的破坏，然后向两个神经网络展示这两张图片，并告诉这两个神经网络，你们应该输出相似的结果，因为展示给你们看的东西在语义上是相同的。
570 01:00:08,327 --> 01:00:21,603 讲者 SPEAKER_09：然后你从训练数据中取出两个不同的样本，把它们展示给这两个，你知道的，两个平行相同的神经网络，然后你告诉系统，无论产生什么输出，对于这两个样本都应该是不同的。
571 01:00:22,443 --> 01:00:28,670 讲者 SPEAKER_09：现在，那里的技巧，以及 Perl 和 MoCo 的技巧，是如何挑选那些负样本的。
572 01:00:28,952 --> 01:00:33,677 讲者 SPEAKER_09：所以它们有特定的方法来挑选，也就是所谓的硬负样本挖掘。
573 01:00:33,657 --> 01:00:38,163 讲者 SPEAKER_09：并且选择那些样本，以便它们实际上有助于训练。
574 01:00:38,324 --> 01:00:43,371 演讲者 SPEAKER_09：但最终，这些系统工作得相当好，并在某些标准数据集上打破了记录。
575 01:00:44,873 --> 01:00:50,942 演讲者 SPEAKER_09：所以，至少在对比自监督学习应用于图像识别方面，这是一个成功。
576 01:00:53,184 --> 01:00:54,686 演讲者 SPEAKER_09：好的。
577 01:00:56,353 --> 01:01:09,447 演讲者 SPEAKER_09：所以，当你有一个基于能量的模型并且具有潜在变量时，如果你给我一个 x 和一个 y，你必须找到这个潜在变量的值，以使系统整体能量输出最小化。
578 01:01:09,849 --> 01:01:12,135 演讲者 SPEAKER_09：你们可以把它看作是一种推理形式。
579 01:01:12,114 --> 01:01:18,443 演讲者 SPEAKER_09：好的，那么这应该就是一个推理发生的神经网络或深度学习系统的例子，对吧？
580 01:01:18,744 --> 01:01:30,141 演讲者 SPEAKER_09：你在系统中计算输出和进行推理的方式是，通过最小化关于潜在变量的能量函数，并且据说当你对输出变量进行推理时也是如此。
581 01:01:30,121 --> 01:01:41,530 演讲者 SPEAKER_09：因此，这可以成为一种通用的框架，通过从前馈到优化，从系统 1 过渡到系统 2。
582 01：01：41,831 --> 01：01：46,675 演讲者 SPEAKER_09：当然，为推理进行能量最小化的想法非常非常新。
583 01:01:46,715 --> 01:02:00,128 说话者 SPEAKER_09：这几乎被用于所有概率模型和结构预测学习，这个想法有着悠久的历史，也使用了这个想法。
584 01:02:00,108 --> 01:02:07,317 演讲者 演讲者_09：所以任何使用 HMM 的人基本上都使用了能量最小化进行推理，例如。
585 01:02:08,494 --> 01:02:17,969 演讲者 演讲者_09：好的，我将用一个非常简单的例子结束，这个例子展示了如何在随机环境中进行预测，以学习世界模型。
586 01:02:18,128 --> 01:02:25,760 讲者 SPEAKER_09：所以通过观察了解世界，然后利用观察到的知识来学习一个随后的任务。
587 01:02:26,402 --> 01:02:35,514 讲者 SPEAKER_09：这里的想法是我们想要驾驶一辆车，而驾驶汽车的问题在于预测你周围的车辆将要做什么是个好主意。
588 01:02:36,507 --> 01:02:39,152 讲者 SPEAKER_09：所以我们在这里训练一个前向模型。
589 01:02:39,753 --> 01:02:43,181 讲者 SPEAKER_09：这个前向模型将预测你周围的车辆将要做什么。
590 01：02：43,201 --> 01：02：49,313 演讲者 SPEAKER_09：你在高速公路上行驶，你将拥有一个系统来预测你周围的汽车将要做什么。
591 01：02：50,456 --> 01：02：52,760 议长 SPEAKER_09：也许你要运行几秒钟。
592 01:02:52,740 --> 01:02:59,454 说话者 SPEAKER_09：这将使您能够提前规划一种防御性策略，以避免与其他车辆相撞。
现在，当然，你周围的汽车可能会发生很多事情，你无法做出单一预测，所以预测将取决于我们可以从分布中抽取的潜在变量。
594 01:03:11,572 --> 01:03:13,394 演讲者 SPEAKER_09: 我们还依赖于您的行动。
595 01:03:13,835 --> 01:03:29,677 演讲者 SPEAKER_09: 因此，这里的正向模型将接受当前世界的状态，包括你周围的车辆、你的行动、加速、刹车、转动方向盘，以及一些随机的潜在变量，然后它会输出 100 毫秒后世界的状态。
596 01:03:31,139 --> 01:03:33,581 演讲者 SPEAKER_09: 然后，您可以运行这个，您可以展开这个。
597 01:03:33,561 --> 01:03:37,630 演讲者 SPEAKER_09: 现在，我们可以计算你周围车辆特定情况下的成本。
598 01:03:37,952 --> 01:03:40,557 说话人 SPEAKER_09：如果你离其他车辆太近，代价会很高。
599 01:03:40,757 --> 01:03:46,010 说话人 SPEAKER_09：如果你不在车道中央，这将带来很高的代价。
600 01:03:46,030 --> 01:03:50,480 说话人 SPEAKER_09：所以我们将计算一个成本，以告诉我们我们的位置有多好。
601 01:03:50,519 --> 01:03:52,143 说话人 SPEAKER_09：而这个成本将是可微分的。
602 01:03:52,123 --> 01:04:05,998 讲者 SPEAKER_09：所以我这里不是在谈论强化学习，这更接近于最优控制，因为我们在强化学习中不需要估计梯度或任何东西，我们只需要在轨迹上优化某个标准。
603 01:04:07,108 --> 01:04:13,139 我们将要做的，是使用 backprop2time 针对特定场景。
604 01:04:13,179 --> 01:04:17,025 我们将从现实世界的情况开始，运行我们的模型几秒钟。
605 01:04:18,007 --> 01:04:19,469 这将是想象中的未来。
606 01:04:20,210 --> 01:04:28,222 讲者 SPEAKER_09：然后通过系统反向传播梯度，以找到最小化总成本的动作序列，
607 01:04:28,202 --> 01:04:38,567 讲者 SPEAKER_09：或者将梯度反向传播到整个策略网络中，该网络将计算以最小化事故概率的动作。
608 01:04:40,302 --> 01:04:43,527 讲者 SPEAKER_09：所以这就是整个过程。
609 01:04:44,007 --> 01:04:58,969 讲者 SPEAKER_09：正向模型的训练是通过收集俯瞰高速公路的摄像头数据来完成的，然后提取每辆车的矩形区域，跟踪每辆车，并提取每辆车的矩形区域，这是每辆车的环境。
然后使用来自那辆汽车环境的几个帧的潜在变量训练一个神经网络，其中汽车是中间的蓝色汽车，预测下一帧的下一几个帧，并借助潜在变量。
611 01:05:15,106 --> 01:05:23,757 演讲者 演讲者_09：所以我没时间详细描述它是如何发生的以及潜在变量的作用，但它是
612 01:05:23,737 --> 01:05:30,525 演讲者 演讲者_09：对于熟悉变分自编码器的人来说，这有点类似于这个，但也有一些变化。
613 01:05:30,545 --> 01:05:31,925 演讲者 演讲者_09：这就是你得到的预测。
614 01:05:31,945 --> 01:05:37,532 演讲者 SPEAKER_09：左侧的列是观察到的。
615 01:05:37,952 --> 01:05:44,878 演讲者 SPEAKER_09：第二列是如果你有一个没有潜在变量的确定性预测器，你会得到一些模糊的预测。
616 01:05:45,559 --> 01:05:53,728 演讲者 SPEAKER_09：然后其他四列是不同潜在变量的不同采样预测，你得到的是由跟踪的汽车表示的不同未来。
617 01:05:55,750 --> 01:06:11,547 演讲者 SPEAKER_09：所以为了使它工作，需要使用各种技巧，这里就不详细介绍了，但训练好系统后，你会得到一个反应性策略，实际上可以在交通中驾驶汽车而不会撞得太厉害。
618 01:06:13,873 --> 01:06:20,262 说话人 SPEAKER_09: 但你必须意识到这是一辆隐形车，因为它被放置在一个录制环境中。
619 01:06:20,402 --> 01:06:23,447 说话人 SPEAKER_09: 所有的绿色车都被录制了，而蓝色车对它们来说是隐形的。
620 01:06:24,168 --> 01:06:28,052 说话人 SPEAKER_09: 所以有时需要蓝色车来逃脱。
621 01:06:28,072 --> 01:06:35,161 说话人 SPEAKER_09: 所以这里黄色车是实际观察到的，而几乎看不见的蓝色车是我们代理驾驶的隐形车。
622 01:06:35,202 --> 01:06:40,489 说话人 SPEAKER_09：现在它被挤压，必须基本上在两辆其他车之间逃逸。
623 01:06:41,583 --> 01:06:45,628 说话人 SPEAKER_09：好的，在剩下的零秒内得出结论。
624 01:06:48,132 --> 01:06:50,195 说话人 SPEAKER_09：如果我的幻灯片要切换。
625 01:06:51,617 --> 01:06:52,117 说话人 SPEAKER_09：好的，开始了。
626 01:06:52,978 --> 01:06:55,242 演讲者 SPEAKER_09：我认为自监督学习是未来，真的。
627 01:06:55,663 --> 01:07:06,798 演讲者 SPEAKER_09：这正是将使我们的 AI 系统或深度学习系统达到下一个层次的原因，也许通过观察学习到足够的世界背景知识，从而使某种常识出现。
628 01:07:07,719 --> 01:07:10,965 演讲者 SPEAKER_09：你知道，我在这里有点挑衅。
629 01:07:10,945 --> 01:07:22,686 演讲者 SPEAKER_09：因为有大量的数据，因为它不需要标注，我们可以训练大规模的网络，Bert 及其追随者就是例证。
630 01:07:24,668 --> 01:07:29,157 演讲者 SPEAKER_09：我们可以使用这些技术来学习世界的正向模型以实现控制。
631 01:07:30,706 --> 01:07:33,250 演讲者 SPEAKER_09：当然，挑战在于处理那里的不确定性。
632 01:07:33,610 --> 01:07:39,918 演讲者 SPEAKER_09：所以通过向量表示和能量最小化进行推理，我给出了一些例子，但还有很多工作要做。
633 01:07:40,920 --> 01:07:47,429 演讲者 SPEAKER_09：正如我之前所说的，我们需要用向量替换符号，用连续函数替换逻辑。
634 01:07:49,012 --> 01:07:53,980 说话人 SPEAKER_09：所以基本上，你知道，将离散事物连续化，基本上。
635 01:07:53,960 --> 01:07:56,728 说话人 SPEAKER_09：使其与基于梯度的学习兼容。
636 01:07:57,471 --> 01:08:00,880 说话人 SPEAKER_09：然后最后一个挑战，学习动作计划的层次表示。
637 01:08:00,900 --> 01:08:02,385 说话人 SPEAKER_09：我真的不知道如何解决这个问题。
638 01:08:02,867 --> 01:08:03,969 演讲者 SPEAKER_09: 所以，非常感谢。
639 01:08:35,083 --> 01:08:37,627 演讲者 SPEAKER_00: 所以我将介绍 Yoshua Bengio。
640 01:08:38,106 --> 01:08:41,911 演讲者 SPEAKER_00: 为了节省时间，我不会有太多时间介绍他到目前为止的所有贡献。
641 01:08:42,271 --> 01:08:47,738 演讲者 SPEAKER_00: 高维词嵌入、注意力机制、生成对抗网络。
642 01:08:48,398 --> 01:08:51,481 讲者 SPEAKER_00：你们大多数人已经听说过这些事情及其带来的影响。
643 01:08:51,981 --> 01:08:56,907 讲者 SPEAKER_00：我想谈谈的是，Yoshua 并不满足于仅仅躺在功劳簿上。
644 01:08:57,427 --> 01:09:04,095 讲者 SPEAKER_00：他继续非常努力地应对科学中的一些最大挑战，例如意识的本质。
645 01:09:04,345 --> 01:09:09,773 讲者 SPEAKER_00：他非常努力地使蒙特利尔成为地球上最重要的 AI 中心之一，并取得了一些成功。
646 01:09:10,354 --> 01:09:14,779 说话人 SPEAKER_00：说到这个星球，他致力于拯救它免受环境灾难。
647 01:09:15,280 --> 01:09:23,351 说话人 SPEAKER_00：他在远程参加会议方面有一些非常有趣的想法，以确保我们减少会议的碳足迹。
648 01:09:23,832 --> 01:09:27,297 说话人 SPEAKER_00：这次会议之后，我特别感兴趣的是他的这些想法。
649 01:09:28,179 --> 01:09:29,981 说话人 SPEAKER_00：所以请和我一起欢迎 Yoshua。
650 01:09:36,340 --> 01:09:36,780 说话人 SPEAKER_08: 谢谢。
651 01:09:36,841 --> 01:09:37,421 说话人 SPEAKER_08: 非常感谢。
652 01:09:38,842 --> 01:09:56,425 说话人 SPEAKER_08: 就像 Jeff 和 Jans 一样，我的演讲将展望如何扩展过去几年深度学习取得的惊人成功。
653 01:09:56,404 --> 01:10:12,641 说话人 SPEAKER_08: 我将承接 Jan 提到的推理问题，以及更广泛地，Dan Kahneman 所说的系统 2 处理。
654 01:10:12,958 --> 01:10:21,568 讲者 SPEAKER_08：首先，我想说几句关于为什么我们需要思考归纳偏置的一般性话语。
655 01:10:23,530 --> 01:10:31,078 讲者 SPEAKER_08：90 年代的理论，无自由定理告诉我们，没有完全通用的机器学习。
656 01:10:31,099 --> 01:10:32,680 讲者 SPEAKER_08：所以没有完全通用的 AI。
657 01:10:33,582 --> 01:10:40,248 讲者 SPEAKER_08：因此我们需要考虑
658 01:10:40,229 --> 01:10:44,552 讲者 SPEAKER_08: 但是问题来了，你知道，我们应该放入多少先验知识？
659 01:10:45,293 --> 01:10:50,099 讲者 SPEAKER_08: 当然，进化已经在各种动物中放入了许多非常具体的先验知识。
660 01:10:50,479 --> 01:11:04,413 讲者 SPEAKER_08: 但是我相信，进化在人类大脑中实现的先验知识，其中一些是非常非常通用的，使我们能够处理各种各样的任务。
661 01:11:04,394 --> 01:11:13,425 讲者 SPEAKER_08: 此外，因为它们非常通用，所以不需要很多比特来指定，这意味着进化可能更容易发现它们。
662 01:11:14,332 --> 01:11:31,548 演讲者 SPEAKER_08：所以，深度学习已经包含了这些先验知识中的许多，你知道的，卷积神经网络是一个很好的例子，它利用了图像对平移和其他变形的不变性。
663 01:11:32,090 --> 01:11:43,260 演讲者 SPEAKER_08：但我特别感兴趣，并且已经持续了二三十年，的是具有组合或指数优势的先验知识。
664 01:11:43,239 --> 01:11:59,502 演讲者 SPEAKER_08：几年前，我写了几篇论文，讨论了当前深度学习中由于每一层的特征组合和层之间的组合而存在的组合优势。
665 01:12:01,104 --> 01:12:11,677 演讲者 SPEAKER_08：今天我将告诉你们另一种组合优势，我认为我们在意识处理和推理中发现了这种优势。
666 01:12:12,282 --> 01:12:19,731 讲者 SPEAKER_08：因此，我想提到这本书，《思考，快与慢》，它对我影响很大。
667 01:12:20,393 --> 01:12:26,442 讲者 SPEAKER_08：书中讲述了这两个系统，系统一和系统二，作为大脑进行的两种计算方式。
668 01:12:27,002 --> 01:12:29,626 讲者 SPEAKER_08：并不是说大脑的不同部分在执行这些功能。
669 01:12:29,666 --> 01:12:31,408 讲者 SPEAKER_08：显然，我们不知道这个答案。
670 01:12:31,788 --> 01:12:39,640 说话人 SPEAKER_08: 但在行为层面上，它们真的很不同，是两种不同的计算方式。
671 01:12:39,619 --> 01:12:40,481 说话人 SPEAKER_08: 计算。
672 01:12:41,023 --> 01:12:57,779 说话人 SPEAKER_08: 因此，系统一基本上可以被标记为直觉或无意识的，可以在没有语言的情况下完成，实际上我们无法用语言描述在那个层面的行为。
673 01:12:57,760 --> 01:13:00,769 说话人 SPEAKER_08: 而当前的深度学习在这些方面非常出色。
674 01:13:01,171 --> 01:13:03,457 演讲者 SPEAKER_08：这就是思考系统 1 的一种方式。
675 01:13:04,761 --> 01:13:11,381 演讲者 SPEAKER_08：当前的深度强化学习在这些方面非常出色，所以需要大量练习的习惯性行为。
676 01:13:12,052 --> 01:13:30,541 演讲者 SPEAKER_08：现在，系统二处理允许我们进行涉及意识的活动，通常需要更多时间计算的活动，通常是顺序性的活动，在计算的每一步中，我们只检查几个元素。
677 01:13:30,720 --> 01:13:32,863 演讲者 SPEAKER_08：这是意识的一个非常特别的属性。
678 01:13:33,725 --> 01:13:41,537 演讲者 SPEAKER_08: 这也是我们人类推理方式的一个特性，并不一定是我们编程的机器的特性。
679 01:13:41,516 --> 01:13:45,887 演讲者 SPEAKER_08: 我的演讲将讨论深度学习如何做更多这些事情。
680 01:13:47,792 --> 01:13:58,597 演讲者 SPEAKER_08: 我之所以对这个问题的答案感兴趣，是因为我们做这些系统 2 任务的方式中，有一些东西是组合性的，因为我们所做的是，我们拿已知的事物，并以动态的方式重新组合它们。
681 01:13:58,578 --> 01:14:08,252 演讲者 SPEAKER_08: 他的组合性，因为我们所做的是，我们拿已知的事物，并以动态的方式重新组合它们。
682 01:14:08,273 --> 01:14:16,145 演讲者 SPEAKER_08：所以我这里有一些图片在下面，左边是系统一，你在驾驶自己的路径，同时可以和另一个人交谈。
683 01:14:16,166 --> 01:14:20,011 演讲者 SPEAKER_08：你不需要将你的注意力集中在驾驶上，你应该，但是...
684 01:14:19,992 --> 01:14:26,121 演讲者 SPEAKER_08：右边，你在一个新的地方驾驶，可能发生了一些奇怪的事情。
685 01:14:26,462 --> 01:14:28,625 演讲者 SPEAKER_08：你不想被别人打扰，和你交谈。
686 01:14:28,685 --> 01:14:38,699 演讲者 SPEAKER_08：你需要全神贯注于任务，并且能够创新，规划新的路径，因为有一些施工或其他事情。
687 01:14:38,740 --> 01:14:44,429 演讲者 SPEAKER_08：所以这种能力是我想要关注的重点。
688 01:14:45,029 --> 01:14:48,935 演讲者 SPEAKER_08：这种能力特别有趣的地方，我将会重点关注。
689 01:14:48,916 --> 01:15:01,979 演讲者 SPEAKER_08：这种动机，除了从人类那里得到的灵感之外，还在于它允许我们，比如在驾驶的例子中，处理与我们训练经验中看到的情况截然不同的非常新颖的情况。
690 01:15:03,715 --> 01:15:12,506 讲者 SPEAKER_08：这就是我所说的分布外泛化或分布外迁移，其中存在一些适应性调整。
691 01:15:13,787 --> 01:15:15,329 讲者 SPEAKER_08：这是其中一个动机。
692 01:15:15,951 --> 01:15:32,591 讲者 SPEAKER_08：当然，另一个动机是尝试执行我们通常与语言相关联的任务，并学习能够捕捉这些高级表示的高级表示。
693 01:15:32,572 --> 01:15:38,041 讲者 SPEAKER_08：这些描述可以即时重新组合的组件、概念。
694 01:15:38,622 --> 01:15:43,029 演讲者 SPEAKER_08：许多这些概念也与如何影响世界有关。
695 01:15:43,069 --> 01:15:48,319 演讲者 SPEAKER_08：换句话说，因果性，这也是我今天要重点讨论的主题之一。
696 01:15:49,328 --> 01:15:53,554 演讲者 SPEAKER_08：然后还有对这个问题的第三种视角。
697 01:15:53,634 --> 01:15:55,917 演讲者 SPEAKER_08：所有这些只是对同一个问题的不同看法。
698 01:15:56,958 --> 01:16:18,828 演讲者 SPEAKER_08：在分布之外进行泛化的需求对于环境中的智能体来说尤为重要，因为世界在变化，这些智能体需要理解这个世界是如何运作的，以便当事情发生变化时，因为其他智能体的干预或其他原因，他们可以高效地处理这些变化。
699 01:16:18,809 --> 01:16:38,011 演讲者 SPEAKER_08：还有另一个我今天不会谈论的方面，那就是我们对世界的理解，我们正在建立的世界模型也帮助我们找到一种好的策略来探索世界，以有目的地寻求新的知识，这正是婴儿非常、非常擅长的事情。
700 01:16:39,132 --> 01:16:40,614 演讲者 SPEAKER_08：所以这三者并不是独立的。
701 01:16:40,635 --> 01:16:45,980 演讲者 SPEAKER_08：我试图说服你们，这些都是同一主题的不同方面。
702 01:16:47,564 --> 01:16:52,409 演讲者 SPEAKER_08：我想回到先验的概念。
703 01:16:52,970 --> 01:17:10,131 演讲者 SPEAKER_08：当我阅读机器学习论文时，我发现作者能够将新的算法用归纳偏差或先验来表述，这能真正解释统计优势，这让我觉得非常兴奋。
704 01:17:10,211 --> 01:17:13,555 演讲者 SPEAKER_08：为什么这个算法在某些情况下泛化得更好？
705 01:17:13,534 --> 01:17:19,385 演讲者 SPEAKER_08：这个特定的机器学习系统利用了关于世界的哪些假设？
706 01:17:21,108 --> 01:17:25,135 说话者 SPEAKER_08：我认为当我们能够表达出来时，这真是太好了。
707 01:17:25,175 --> 01:17:33,028 说话者 SPEAKER_08：那么让我谈谈我对其中一些感兴趣的内容，它们都与这种意识处理和系统 2 处理的概念相关。
708 01:17:33,007 --> 01:18:01,952 说话者 SPEAKER_08：我将更多地谈论的是我几年前称之为“意识先验”，它表明我们意识中操作的语义高级变量具有一个联合分布，这个分布可以用一个稀疏图模型、一个稀疏因子图很好地总结，其中有许多依赖关系，但每次只涉及少数变量。
709 01:18:01,931 --> 01:18:28,006 说话者 SPEAKER_08：这些高级变量的另一个特性是它们通常在某种意义上涉及因果关系，涉及在世界中能够做事情、能够产生影响、有意图去计划这些效果，以及被控制的对象，它们是后果，感受到后果。
710 01:18:27,987 --> 01:18:31,532 演讲者 演讲者_08：所以，很多语言实际上都是关于这些事情。
711 01:18:31,792 --> 01:18:40,604 演讲者 演讲者_08：从某种意义上说，我们一直在操纵这些因果相关的实体。
712 01:18:41,506 --> 01:18:56,728 演讲者 演讲者_08：关于这一点，我不会过多谈论，但在文献中已经有所讨论，那就是这个稀疏因子图，你可以把它想象成图中连接大量变量的那些因子作为规则。
713 01:18:56,707 --> 01:19:12,559 演讲者 演讲者_08：但当然，这里会有一些软规则，毕竟能量网络就是这样，但规则可以应用于许多变量元组，对吧，所以相同的规则可以在很多地方应用。
当然，我们在机器学习的许多方面已经看到了这一点，但这是我们需要记住的。
715 01:19:16,806 --> 01:19:32,671 说话者 SPEAKER_08：当我谈到注意力机制时，您会看到这种在神经网络中将对象作为可以应用相同计算实例进行操作，不同实例可以操作的概念。
716 01:19:33,327 --> 01:19:45,743 说话者 SPEAKER_08：我想谈谈另一个先验条件，这也与因果关系有关，也就是说，我提到有一种假设，即依赖关系可以用稀疏图来表示。
现在我所提到的是我们关注的是分布外泛化，换句话说，世界是如何变化的，以及学习机器如何应对这些变化？
718 01:20:00,192 --> 01:20:01,654 演讲者 SPEAKER_08: 所以这里我们需要假设。
719 01:20:02,515 --> 01:20:13,354 演讲者 SPEAKER_08: 我将要讨论的假设是，这些变化是稀疏的，并且如果使用正确的表示，可能只发生在某个地方。
720 01:20:13,574 --> 01:20:21,628 演讲者 SPEAKER_08: 所以在正确的表示下，正确的高级表示下，世界上发生变化的事物可以被定位，可以用语言来表达。
721 01:20:21,649 --> 01:20:25,255 演讲者 SPEAKER_08: 所以每次我们用语言来解释
722 01:20:25,234 --> 01:20:27,077 说话人 SPEAKER_08: 发生在世界上的一个变化。
723 01:20:27,398 --> 01:20:29,119 说话人 SPEAKER_08: 所以，你知道，一个句子非常短。
724 01:20:29,199 --> 01:20:30,600 说话人 SPEAKER_08: 你只能指代几个事物。
725 01:20:31,181 --> 01:20:36,988 说话人 SPEAKER_08: 所以这是世界变化的一个惊人的特性，我们应该在机器学习中充分利用它。
726 01:20:38,770 --> 01:20:52,828 讲者 SPEAKER_08：然后，我所在领域的人一直在关注的一个假设，我不会过多谈论，就是在这个包含世界的模型中学习到的大部分事物
727 01:20:53,162 --> 01:21:00,293 讲者 SPEAKER_08：因果关系尽管在分布变化中保持稳定。
728 01:21:00,314 --> 01:21:06,684 讲者 SPEAKER_08：所以构建一个好的模型的关键点在于它将能够对那些变化保持鲁棒性。
729 01:21:06,743 --> 01:21:10,609 讲者 SPEAKER_08：是的，事物可能需要改变，需要适应，但尽可能少地改变。
730 01:21:11,652 --> 01:21:20,064 演讲者 SPEAKER_08：这与另一个假设相联系，即变化是局部的，我们操纵的大多数关于世界的概念都是稳定的。
731 01:21:20,045 --> 01:21:21,627 演讲者 SPEAKER_08：这是我们想要追求的。
732 01:21:21,667 --> 01:21:39,132 演讲者 SPEAKER_08：然后还有另一个我不太会多谈的，但也与意识先验相关，它说我们关心的那种时间依赖性，人类能够处理的时间依赖性，
733 01:21:39,113 --> 01:21:42,978 演讲者 SPEAKER_08：涉及的事件非常少。
因此，我们可以推理的因果链非常短，这导致的结果是，基本上我们可以处理并本质上消除长期依赖和梯度消失的问题，如果假设是正确的话。
735 01：22：01,538 --> 01：22：03,822 演讲者 SPEAKER_08：好的，现在让我深入探讨一下其中的一些事情。
736 01：22：04,847 --> 01：22：07,610 议长 SPEAKER_08：我已经用了差不多一半的时间。
737 01：22：08,733 --> 01：22：14,460 议长 SPEAKER_08：好吧，那么我们为什么要关心分布的变化呢？
738 01:22:14,500 --> 01:22:27,395 讲者 SPEAKER_08：我认为这就是进化可能将这类特殊的处理系统置于人类以及可能哺乳动物甚至鸟类中的原因。
739 01:22:27,376 --> 01:22:51,679 讲者 SPEAKER_08：以便能够处理那些分布的变化，在复杂世界中，它们不是带着对世界的全部知识出生的，必须处理真实的不稳定性，因为其他代理正在做事情，或者从它们的角度来看，不稳定性，因为它们只能感知世界的一部分，然后随着他们生活的继续，他们会发现新的方面。
740 01:22:51,658 --> 01:22:56,586 讲者 SPEAKER_08：我认为这对于必须与其他代理打交道的代理尤其重要。
741 01:22:56,605 --> 01:23:06,881 讲者 SPEAKER_08：所以，如果许多人工智能研究人员对多代理场景感兴趣，进化就是这样一个例子，其中没有固定的分布，对吧？
742 01:23:06,900 --> 01:23:12,269 演讲者 SPEAKER_08：代理看到的分布不断变化，因为其他人正在做事情，他们的策略也在变化等等。
743 01:23:13,090 --> 01:23:18,358 演讲者 SPEAKER_08：所以，这是世界中学代理普遍存在的问题。
744 01:23:19,823 --> 01:23:41,949 演讲者 SPEAKER_08：现在，这个问题，即分布外泛化问题，是我们想要解决的，然后我们想要如何解决这个问题，是语言学家们长期以来一直在讨论的，被称为系统性或系统泛化，它的想法是为了应对世界中的新情况，
745 01:23:41,930 --> 01:23:51,625 演讲者 SPEAKER_08：如果我们可以构建具有这些可以随时重组的小部分来解释我们所看到的世界模型，那将非常、非常方便。
746 01:23:51,645 --> 01:24:03,363 演讲者 SPEAKER_08：就像图片中展示的那样，我们拿已知的不同概念，以某种方式解释这个特殊电机概念的含义。
747 01:24:03,344 --> 01:24:18,365 所以这种动态的概念重组是我想要更好地理解的问题，我们如何实现它，它有助于我们应对那些看似不可能的分布变化。
748 01:24:18,345 --> 01:24:35,747 但我们可以阅读这部小说，我们可以理解它，我们甚至可以阅读开头并继续下去，我们做得很好。
749 01:24:36,188 --> 01:24:43,037 我们可以阅读这部小说，我们可以理解它，我们可以甚至阅读开头并继续下去，我们做得很好。
750 01:24:43,016 --> 01:25:02,284 讲者 SPEAKER_08：关于当前机器学习在分布变化方面如何失败或至少性能下降，已经有大量论文进行了探讨，这些变化与人类在类似任务上的表现截然不同。
751 01:25:02,925 --> 01:25:11,757 讲者 SPEAKER_08：我们一直在研究这个问题，我们最近有一篇关于视觉问答中这个问题的论文。
752 01:25:13,375 --> 01:25:28,341 讲者 SPEAKER_08：好的，我刚才谈到了系统 2，我认为这是正确的，它与几十年前经典符号 AI 设定的目标紧密相关。
753 01:25:28,481 --> 01:25:36,074 讲者 SPEAKER_08：那么，这个旧程序与我们应该花更多时间研究的新程序之间有什么联系呢？
754 01:25:36,055 --> 01:25:41,229 演讲者 SPEAKER_08: 嗯，我们希望兼得鱼与熊掌，对吧？
755 01:25:41,248 --> 01:25:46,302 演讲者 SPEAKER_08: 我们希望避免一些经典人工智能基于规则的符号操作中的陷阱。
756 01:25:46,422 --> 01:25:51,938 演讲者 SPEAKER_08: 我们希望构建能够学习和大规模高效学习的系统。
757 01:25:51,917 --> 01:25:55,481 演讲者 SPEAKER_08: 我们还希望构建基于系统一的系统。
758 01:25:55,601 --> 01:25:57,703 讲者 SPEAKER_08: 记得我说过深度学习在系统一上做得很好。
759 01:25:58,704 --> 01:26:03,409 讲者 SPEAKER_08: 但实际上，那些高级概念，我们并不能仅仅抽象地操作它们。
760 01:26:03,489 --> 01:26:05,311 讲者 SPEAKER_08: 这确实有很好的理由。
761 01:26:05,533 --> 01:26:08,515 讲者 SPEAKER_08: 它们需要与现实世界相连接。
762 01:26:08,576 --> 01:26:17,064 演讲者 SPEAKER_08：但是，我还会论证，为了在所讨论的高层次概念中高效搜索，你需要系统一来猜测出好的路径、好的计划。
763 01:26:17,045 --> 01:26:27,498 演讲者 SPEAKER_08：而且，如果你注意到，你并没有意识到你的大脑是如何找到一条好路径的。
764 01:26:28,279 --> 01:26:34,368 演讲者 SPEAKER_08：这就是，如果你注意到的话，你并不知道自己大脑是如何找到一条好路径的。
765 01:26:34,467 --> 01:26:35,529 演讲者 SPEAKER_08：它只是自然而然地出现在你面前，对吧？
766 01:26:37,332 --> 01:26:39,795 说话人 SPEAKER_08：或者好路径或者危险路径，例如。
767 01:26:39,774 --> 01:26:42,797 说话人 SPEAKER_08：所以这是由系统 1 处理的事情。
768 01:26:44,500 --> 01:26:59,154 说话人 SPEAKER_08：另一件事是，我在几十年前投入了大量时间思考并证明分布式表示的重要性，这是解释神经网络和深度学习成功的关键因素之一。
769 01:26:59,755 --> 01:27:00,654 说话人 SPEAKER_08：所以我们要保留这一点。
770 01:27:00,676 --> 01:27:07,301 演讲者 SPEAKER_08：我们希望将对象表示为属性向量，这些属性是通过学习得到的。
771 01:27:07,282 --> 01:27:15,417 演讲者 SPEAKER_08：最后，我们希望能够操纵不确定性，这并不总是通过简单的操作就能做到的。
772 01:27:16,342 --> 01:27:39,667 演讲者 SPEAKER_08：但与此同时，我们希望引入一些我们在某些规则和事实以及推理工作中发现的优势，这些规则和事实使得以新的方式结合规则和事实进行系统化泛化变得自然。
773 01:27:39,648 --> 01:27:52,948 演讲者 SPEAKER_08：由此产生了一个有趣的想法，我们在深度学习中很少考虑，那就是我们希望能够将知识分解成更小的部分。
774 01:27:53,181 --> 01:28:00,813 演讲者 SPEAKER_08：这些可以互相交换，这样我们就可以用新的方式操纵变量和实例。
775 01:28:01,673 --> 01:28:05,880 演讲者 SPEAKER_08：我将就此谈谈间接引用。
776 01:28:07,082 --> 01:28:19,140 演讲者 SPEAKER_08：所以我认为将使我们能够在深度学习中做这些事情的构建块本质上是注意力及其变体。
777 01:28:19,199 --> 01:28:22,885 演讲者 SPEAKER_08：注意力是意识处理的一个关键成分。
778 01:28:22,864 --> 01:28:29,015 演讲者 SPEAKER_08：它允许人们关注几个元素，但实际上还有很多其他内容。
779 01:28:31,060 --> 01:28:32,561 演讲者 SPEAKER_08：所以 Jeff 已经谈到了 Transformer。
780 01:28:32,582 --> 01:28:38,072 演讲者 SPEAKER_08：Transformer 基于我们为机器翻译引入的这些软注意力机制。
781 01:28:38,051 --> 01:28:56,819 演讲者 SPEAKER_08：其中，我们从两个模块中匹配一个键和一个查询，一个是顶部的模块，比如说，另一个是底部的模块之一，当匹配良好时，就会从底部模块向顶部模块发送一些值向量。
782 01:28:56,800 --> 01:29:09,043 讲者 SPEAKER_08: 实际上，它所做的就是将神经网络从操作向量的机器转变为操作向量集的机器。
783 01:29:09,604 --> 01:29:15,417 讲者 SPEAKER_08: Jeff 已经告诉你们这如何在胶囊设置中发挥作用，但实际上它比这更通用。
784 01:29:17,100 --> 01:29:33,609 讲者 SPEAKER_08: 有趣的是，像这样的注意力机制作为大脑中较大实体（如模块）之间通信的方式，需要以方向表示事物的名称。
785 01:29:34,229 --> 01:29:38,738 讲者 SPEAKER_08: 因此，注意力机制允许模块之间建立动态连接。
786 01:29:38,717 --> 01:29:51,778 讲者 SPEAKER_08: 在传统的神经网络中，从神经元 A 到神经元 B 的连接始终存在，连接它们的权重也不需要标记来说明，这是从神经元 A 传来的信号，对吧？
787 01:29:52,179 --> 01:30:04,337 讲者 SPEAKER_08: 所以神经元 B 知道这里的信息来自神经元 A。但如果神经元 B 得到的信息可能来自 A、C 或 D，那么这对它来说就非常有用了。
788 01:30:04,317 --> 01:30:22,038 讲者 SPEAKER_08: 通信不仅要包括值，还要包括对应于注意力机制中的键，这本质上就像类型或名称，允许间接引用内容来源。
789 01:30:23,115 --> 01:30:27,572 讲者 SPEAKER_08: 因此，它使我们能够跟踪这些实体，这些实体不再是像胶囊那样的。
790 01:30:28,555 --> 01:30:34,998 讲者 SPEAKER_08：所以它们不是单个数字，而更像是可以传递和操作的对象。
791 01:30:36,109 --> 01:30:43,100 讲者 SPEAKER_08：好的，我想说几句关于与神经科学和认知神经科学之间联系的话。
792 01:30:44,221 --> 01:30:52,373 讲者 SPEAKER_08：以前，比如说在上个世纪，由于各种原因，研究意识在许多科学领域都是禁忌，这些原因我无法一一细说。
793 01:30:52,413 --> 01:30:53,815 讲者 SPEAKER_08：但幸运的是，这种情况已经改变了。
794 01:30:53,836 --> 01:31:05,171 讲者 SPEAKER_08：特别是在认知神经科学领域，本世纪及其前一个世纪的末期有很多研究，特别是 Bars 的全球工作空间理论，以及本世纪由 Stan Dehaene 进行的最新研究，这些理论真正确立了这些理论来解释许多客观的神经科学观察。
795 01:31:05,152 --> 01:31:16,060 讲者 SPEAKER_08：有趣的是，我认为，对于机器学习来说，现在来引入一些不同的东西，引入，你知道，这有什么意义？
796 01:31:16,962 --> 01:31:25,069 讲者 SPEAKER_08：对于机器学习来说，现在来引入一些不同的东西，引入，你知道，这有什么意义？
797 01:31:25,168 --> 01:31:35,158 讲者 SPEAKER_08：为什么大脑会有这种瓶颈，信息必须通过这个瓶颈，只有少数元素被广播到大脑的其他部分？
798 01:31:35,137 --> 01:31:39,546 讲者 SPEAKER_08：我们为什么会有只包含六七个元素的短期记忆呢？
799 01:31:39,587 --> 01:31:40,328 讲者 SPEAKER_08：这说不通。
800 01:31:40,347 --> 01:31:43,014 讲者 SPEAKER_08：我的计算器都比这做得好。
801 01:31:43,054 --> 01:31:44,636 讲者 SPEAKER_08：所以这肯定有原因。
802 01:31:45,297 --> 01:31:47,662 说话人 SPEAKER_08：我认为机器学习可以帮助我们揭示这些原因。
803 01:31:49,414 --> 01:31:55,010 说话人 SPEAKER_08：所以我会跳过那个，但底线是让意识中的魔法消失。
804 01:31:56,594 --> 01:31:58,899 说话人 SPEAKER_08：与语言有联系，但我将跳过这一点。
805 01:32:00,966 --> 01:32:05,618 说话人 SPEAKER_08：我已经提到了意识先验，但让我尝试说服你们。
806 01:32:05,597 --> 01:32:24,381 讲者 SPEAKER_08：那么，我们正在讨论关于世界的假设，而我们用语言处理的概念有一种非凡的特性，那就是在一个句子中，即使这个句子包含的变量很少，我们也可以说出具有非常高概率的真实事物。
807 01:32:24,681 --> 01:32:29,006 讲者 SPEAKER_08：如果你这么想，如果我试图根据其他四个像素来预测一个像素，
808 01:32:28,987 --> 01:32:32,112 讲者 SPEAKER_08：我通常无法做出非常强的预测。
809 01:32:32,592 --> 01:32:36,479 讲者 SPEAKER_08：而我可以说出类似的话，如果我扔下球，它就会落在地上。
810 01:32:36,618 --> 01:32:37,900 演讲者 SPEAKER_08: 这几乎是肯定的。
811 01:32:38,542 --> 01:32:52,024 演讲者 SPEAKER_08: 所以这表明在那个表示层面上，我们的知识以这种非常稀疏的图的形式表示，其中每个依赖关系，这些因素，涉及两个、三个、四个、五个实体，就这么多。
812 01:32:52,003 --> 01:33:02,199 演讲者 SPEAKER_08: 当然，它们之间以复杂的方式相互连接，但推理就是通过遍历这个图来推断我们关心的东西。
813 01:33:02,737 --> 01:33:06,583 演讲者 SPEAKER_08: 好的，这就是稀疏性假设。
814 01:33:07,645 --> 01:33:15,899 讲者 SPEAKER_08: 我提到的另一个是，不仅图是稀疏的，而且当它变化时，它以稀疏的方式变化。
815 01:33:17,182 --> 01:33:23,613 讲者 SPEAKER_08: 好的，让我跳过元学习，因为时间飞逝。
816 01:33:23,594 --> 01:33:25,457 讲者 SPEAKER_08: 那么为什么它会以稀疏的方式变化呢？
817 01:33:25,497 --> 01:33:28,923 讲者 SPEAKER_08: 直观地说，它以稀疏的方式变化是因为物理学的原理。
818 01:33:29,666 --> 01:33:35,617 演讲者 SPEAKER_08：代理在特定时间、特定地点做某事，并产生效果。
819 01:33:37,239 --> 01:33:42,430 演讲者 SPEAKER_08：最终，这种效果可能对整个宇宙产生后果，但这需要时间。
820 01:33:42,409 --> 01:34:03,421 演讲者 SPEAKER_08：因此，如果我们能构建出具有正确抽象的世界模型，将那些变化仅锁定在一个或几个变量上，那么我们将能够适应这些变化，因为我们不需要那么多的数据，那么多的观察，
821 01:34:03,402 --> 01:34:05,244 演讲者 SPEAKER_08：以便弄清楚发生了什么变化。
822 01:34:05,645 --> 01:34:18,828 演讲者 SPEAKER_08：这与我从 Bernard Shopkoff 及其合作者那里学到的美丽理论和概念有关，称为独立机制。
823 01:34:18,809 --> 01:34:26,204 演讲者 SPEAKER_08：这里以图形方式展示，我有一个关于孩子和眼镜的小例子。
824 01:34:26,244 --> 01:34:34,421 演讲者 SPEAKER_08：所以，如果我现在看到你，然后我戴上一些深色眼镜，发生的事情是只有一个比特发生了变化，对吧？
825 01:34:35,009 --> 01:34:40,359 演讲者 SPEAKER_08：在正确的抽象空间中翻转并说，我戴上了一些深色眼镜。
826 01:34:41,862 --> 01:34:54,385 讲者 SPEAKER_08：如果我要在像素级别解释这个问题，我需要改变很多东西，比如我的视觉处理方式等等，而如果我有正确的表示，我可以更容易地解释这种变化。
827 01:34:56,069 --> 01:35:06,578 讲者 SPEAKER_08：因此，结果是，当你拥有正确的模型，特别是正确的因果模型时，当分布发生变化时，你可以非常快速地适应这种变化。
828 01:35:07,059 --> 01:35:13,024 讲者 SPEAKER_08：所以这是一个主张和假设，我们一直在做大量工作来验证它。
829 01:35:14,605 --> 01:35:26,076 讲者 SPEAKER_08：特别是，我们用它来实证地展示，最近又用理论证明了正确的模型
830 01:35:26,055 --> 01:35:51,252 演讲者 SPEAKER_08：预测正确因果结构的模型，至少在这个只有两个变量 A 和 B 的非常简单的例子中，可以更快地适应由于干预而导致的分布变化，特别是对原因的干预，换句话说，需要更少的例子，因此在统计意义上更快，比错误的模型更快。
831 01:35:51,233 --> 01:35:56,341 演讲者 SPEAKER_08：所以你可以用它来确定哪个是正确的模型，对吧？
832 01:35:56,381 --> 01:36:02,149 演讲者 SPEAKER_08：所以如果你只有两个模型，你可以并行运行它们，看看哪个收敛得更快。
833 01:36:02,671 --> 01:36:07,318 演讲者 SPEAKER_08：但我们已经在另一篇论文中推广了这个方法。
834 01:36:07,297 --> 01:36:11,265 演讲者 SPEAKER_08：我们在哪里学习整个图，整个因果关系图。
835 01:36:11,286 --> 01:36:26,354 演讲者 SPEAKER_08：所以我们有一个实验，我们知道地面实况图，我们在图中的一个节点上进行干预，改变图，学习者只看到干预前后的数据，并试图学习模型。
836 01:36:26,394 --> 01:36:27,737 演讲者 SPEAKER_08：它不知道模型，对吧？
837 01:36:27,716 --> 01:36:40,920 演讲者 SPEAKER_08：但它也学会了预测干预发生的位置，在看到许多这些分布变化后，它实际上找到了正确的因果关系图，这并不明显。
838 01:36:40,979 --> 01:36:44,966 演讲者 SPEAKER_08：如果你只看到观测结果而没有分布的变化，实际上
839 01:36:45,182 --> 01:36:48,307 演讲者 SPEAKER_08：是无法正确恢复图的。
840 01:36:49,189 --> 01:36:49,430 演讲者 SPEAKER_08：好的。
841 01:36:49,990 --> 01:37:02,289 演讲者 SPEAKER_08：然后我想谈谈最近工作的最后一部分，这部分与意识先验的另一个后果有关，这更多与这些神经网络的架构有关。
842 01:37:02,310 --> 01:37:12,185 说话者 SPEAKER_08：我在开头提到，我们希望能够动态地重新组合片段，我还提到了注意力机制
843 01:37:12,166 --> 01:37:13,627 演讲者 演讲者_08：这对我们来说很重要。
所以注意力机制非常有趣，因为，嗯，一方面，它们让我们能够一次只关注少数几件事情，这些事情将进入我们的短期、有意识的短期记忆，我们正在操纵并寻求某种连贯的解释。
845 01:37:29,091 --> 01:37:35,724 说话者 SPEAKER_08：并且注意力机制也可以用来动态决定哪个模块在与哪个模块对话。
846 01:37:36,645 --> 01:37:51,792 讲者 SPEAKER_08：这就是我们用这种架构所探索的内容，我们称之为循环独立机制，或者 RIMS，这里的循环网络可以替换 LSTMs 或任何你喜欢的。
847 01:37:51,771 --> 01:38:00,930 讲者 SPEAKER_08：它具有模块化结构，所以不是只有一个同质状态，而是被分解成许多模块，每个模块都有自己的状态。
848 01:38:01,652 --> 01:38:09,627 讲者 SPEAKER_08：而且每个模块内部就像是一个普通的循环网络，随便你喜欢什么，但它们之间通信的方式是通过瓶颈。
849 01:38:09,608 --> 01:38:37,152 讲者 SPEAKER_08：是通过张力机制来决定的，首先确定哪些模块将被激活，哪些模块被允许发言，然后我们还使用张力机制以键值对的形式在模块之间交换信息，就像胶囊一样，但我们把它们视为
850 01:38:37,131 --> 01:38:41,256 演讲者 SPEAKER_08：将要匹配的对象。
851 01:38:41,737 --> 01:38:46,502 演讲者 SPEAKER_08：所以如果你想到编程中的函数，你有类型化的函数。
852 01:38:47,283 --> 01:38:50,867 演讲者 SPEAKER_08：函数是很好的模块化组件，可以相互组合。
853 01:38:51,547 --> 01:38:53,810 演讲者 SPEAKER_08：它们有这些类型化的参数。
854 01:38:54,390 --> 01:38:59,157 演讲者 SPEAKER_08：换句话说，一个函数期望第一个参数是某种类型。
855 01:38:59,176 --> 01:39:04,202 演讲者 SPEAKER_08：你可以把一个特定模块期望的一个参数的查询方式想成是一样的。
856 01:39:04,403 --> 01:39:06,564 演讲者 SPEAKER_08：所以每个模块
857 01:39:06,545 --> 01:39:30,072 演讲者 SPEAKER_08：基本上是在说，哦，对于我正在进行的第一个参数，我期望一个特定类型的对象，这个类型将由一个查询向量表示，如果这个查询向量与另一个模块实际产生的对象的键向量匹配得很好，那么这两个模块将会连接在一起，源模块产生的值将被发送到
858 01:39:30,051 --> 01:39:31,673 说话人 SPEAKER_08: 嗯，说到模块网络。
859 01:39:31,694 --> 01:39:37,082 说话人 SPEAKER_08: 当然，这一切当然不是按照我所说的那样，通过离散的选择来完成的。
860 01:39:37,122 --> 01:39:41,207 说话人 SPEAKER_08: 它都是通过软注意力以软的方式完成的，所以你可以将整个背景放进去。
861 01:39:42,831 --> 01:39:43,752 说话人 SPEAKER_08: 它确实效果很好。
862 01:39:44,353 --> 01:39:48,498 演讲者 SPEAKER_08: 嘿，嘿，嗯，嗯，所以这是，嗯，嗯，
863 01:39:49,778 --> 01:39:54,167 演讲者 SPEAKER_08: 在 Atari 上的强化学习实验，但最有趣的是，它在哪？
864 01:39:54,707 --> 01:39:57,132 演讲者 SPEAKER_08: 不，我还有其他幻灯片。
865 01:39:58,375 --> 01:40:02,823 演讲者 SPEAKER_08: 最有趣的是，与其他 LSTM 相比，它在分布外的工作效果非常好。
866 01:40:03,164 --> 01:40:10,099 演讲者 SPEAKER_08：所以如果分布发生变化，如果你将数据扩展到更长的序列等，这效果惊人地好。
867 01:40:10,078 --> 01:40:16,445 演讲者 SPEAKER_08：我们正在进行这项工作的扩展，以各种方式，但我没有时间详细说明。
868 01:40:16,466 --> 01:40:17,247 演讲者 SPEAKER_08：所以让我来总结一下。
869 01:40:17,827 --> 01:40:39,411 演讲者 SPEAKER_08：我给你们介绍了我正在与我的合作者一起探索的一些关于世界的假设，或者这些假设已经在文献中被讨论过，我认为这些假设可以融入机器学习系统中，以实现一些
870 01:40:39,390 --> 01:40:43,511 演讲者 SPEAKER_08：与系统 2 相关的计算能力。
871 01:40:44,515 --> 01:40:47,409 演讲者 SPEAKER_08：在此，我要感谢大家的关注。
872 01:41:05,328 --> 01:41:16,307 演讲者 SPEAKER_00：最后，我们进入讨论环节，我们非常幸运地有一位杰出的主持人 Leslie Pack-Kelbling，她是麻省理工学院计算机科学与工程系的教授。
873 01:41:16,828 --> 01:41:25,564 演讲者 SPEAKER_00：我不会详细介绍她的众多荣誉，但她是一位备受尊敬的机器人学家，同时也是《机器学习研究杂志》的创始编辑。
874 01:41:26,962 --> 01:41:27,662 演讲者 SPEAKER_05: 好的，谢谢。
875 01:41:27,804 --> 01:41:35,597 演讲者 SPEAKER_05: 我们从演讲者和问题流中得到了各种各样的思考，我也一直在关注这些问题。
876 01:41:36,640 --> 01:41:45,055 演讲者 SPEAKER_05: 我将尝试对这些问题进行一些聚类和过滤，因为你们不希望它们以原始形式存在。
877 01:41:45,034 --> 01:41:47,119 演讲者 SPEAKER_05: 我想这里有两个类别。
878 01:41:47,220 --> 01:41:53,395 讲者 SPEAKER_05：有一系列技术问题，还有一些关于研究理念和想法的元问题。
879 01:41:53,435 --> 01:41:58,546 讲者 SPEAKER_05：所以我认为我们将从一些技术问题开始，然后转到一些元问题。
880 01:41:59,309 --> 01:42:02,435 讲者 SPEAKER_05：所以一个技术问题是
881 01:42:03,073 --> 01:42:18,234 讲者 SPEAKER_05：您觉得神经网络作为计算机科学或机器学习概念，与神经网络作为自然或人类计算过程的模拟之间的联系。
882 01:42:18,574 --> 01:42:25,503 演讲者 SPEAKER_05: 我想问大家，对你们来说，坚持我们对自然计算的了解有多重要？
883 01:42:27,287 --> 01:42:28,287 演讲者 SPEAKER_07: 好的，我先来。
884 01:42:29,078 --> 01:42:45,019 演讲者 SPEAKER_07: 我认为神经计算和自然计算可以启发我们提出工程模型，这样我们可以了解人们如何做事，并且它们会建议我们如何尝试做事。
885 01:42:45,199 --> 01:42:57,515 演讲者 SPEAKER_07: 例如，我认为从一个拥有数百万参数的系统开始训练，并希望它能做任何有意义的事情，除非你知道大脑就是这样做的，否则你不会相信。
886 01:42:59,167 --> 01:43:02,015 演讲者 演讲者_07：但是细节... 杰夫，我们听不清楚你。
887 01:43:02,034 --> 01:43:02,837 演讲者 演讲者_07：你听不清楚我吗？
888 01:43:02,858 --> 01:43:04,362 演讲者 演讲者_07：你需要拿稳麦克风。
889 01:43:05,746 --> 01:43:06,788 演讲者 演讲者_07：你现在能听清楚了吗？
890 01:43:06,989 --> 01:43:07,652 演讲者 SPEAKER_09：非常好。
891 01:43:10,699 --> 01:43:11,944 演讲者 SPEAKER_07：好的，所以我认为...
892 01:43:13,003 --> 01:43:15,667 演讲者 SPEAKER_07：大脑启发了我们，提出了想法。
893 01:43:15,927 --> 01:43:26,465 演讲者 SPEAKER_07：特别是，它提出使用大量数据逐步调整权重可以使系统在没有编程的情况下执行复杂的计算。
894 01:43:27,126 --> 01:43:29,168 演讲者 SPEAKER_07：这个想法相当奇特。
895 01:43:29,328 --> 01:43:35,278 演讲者 SPEAKER_07：除非有例子证明那样的事情，否则你们不会相信。
896 01:43:35,297 --> 01:43:35,417 演讲者 SPEAKER_05：好。
897 01:43:35,438 --> 01:43:35,838 演讲者 SPEAKER_05：其他人呢？
898 01:43:36,899 --> 01:43:38,501 演讲者 SPEAKER_09: 嗯。
899 01:43:38,521 --> 01:43:39,844 演讲者 SPEAKER_09: 很明显，这是一个鼓舞人心的例子。
900 01:43:39,904 --> 01:43:43,810 演讲者 SPEAKER_09: 所以像卷积网络这样的东西显然是受到了神经科学经典工作的启发。
901 01:43:44,690 --> 01:43:56,569 演讲者 SPEAKER_09: 我们现在使用的很多想法在计算神经科学中都有其对应物，比如分立归一化，这是现在神经网络中的一种标准工具，还有整流等。
902 01:43:56,829 --> 01:44:01,556 演讲者 SPEAKER_09: 我们还发现了其他一些事情。
903 01:44:01,537 --> 01:44:07,764 演讲者 SPEAKER_09: 几年前，在各个地方，有人提出了一个想法，即神经网络可以通过一些联想记忆来增强。
904 01:44:08,444 --> 01:44:11,868 演讲者 SPEAKER_09: 然后你看大脑，嗯，这看起来像海马体一样的东西。
905 01:44:12,628 --> 01:44:16,894 演讲者 SPEAKER_09: 这并不十分精确，但显然存在某种并行性。
906 01:44:18,055 --> 01:44:25,923 说话人 SPEAKER_09: 这就像 AI 和航空之间的几乎陈词滥调的类比，我们
907 01:44:25,904 --> 01:44:31,573 说话人 SPEAKER_09: 我们从鸟类中获得灵感，但我们建造的东西不会拍翅膀，也没有羽毛。
908 01:44:31,632 --> 01:44:33,836 说话人 SPEAKER_09: 所以这有点相似。
909 01:44:33,855 --> 01:44:38,342 说话人 SPEAKER_09: 但最终，我认为我们很多人进入这个领域是因为我们想理解人类智能。
910 01:44:39,304 --> 01:44:40,305 演讲者 SPEAKER_09：让我补充一点。
911 01:44:40,326 --> 01:44:41,728 演讲者 SPEAKER_08：我显然同意所有这些观点。
912 01:44:41,747 --> 01:44:50,881 演讲者 SPEAKER_08：所以我的动力在于，我认为有一个非常惊人的假设。
913 01:44:50,862 --> 01:44:56,347 演讲者 SPEAKER_08：几个简单的原则可以解释大脑中发生的大多数事情。
914 01:44:56,387 --> 01:45:02,916 讲者 SPEAKER_08：当然，大脑也是一个充满技巧的袋子，但也有一些简单的原则使我们能够完成这些非常复杂的通用任务。
915 01:45:04,037 --> 01:45:15,250 讲者 SPEAKER_08：如果我们研究机器学习和人工智能，我们可以测试这些原则中的一些，这可以为大脑研究方面的朋友们提供一些想法。
916 01:45:15,229 --> 01:45:33,154 讲者 SPEAKER_08：因此，从某种意义上说，我们可以进行互利共赢的探索，揭示这些简单的原则，这些原则既有助于构建智能机器，也有助于理解大脑的工作原理以及什么是智能。
917 01:45:34,585 --> 01:45:35,907 讲者 SPEAKER_05：酷。
918 01:45:35,926 --> 01:46:01,487 讲者 SPEAKER_05：好吧，还有一件事，我想我和观众中的一些人都注意到了，我觉得你们每个人都提到了一些代表性和推理方面的内容，我想一些经典的人工智能专家会接受并称之为他们的工具包的一部分，比如组合性、表示、学习潜在表示、稀疏性、分解等等。
919 01:46:01,466 --> 01:46:08,520 讲者 SPEAKER_05：然而，有时我觉得你们中的一些人可能对符号人工智能领域有些贬低。
920 01:46:08,560 --> 01:46:11,064 讲者 SPEAKER_05：那么，我们能成为朋友吗？不能吗？
921 01:46:15,434 --> 01:46:15,634 讲者 SPEAKER_05：杰夫？
922 01:46:19,240 --> 01:46:20,944 演讲者 演讲者_07：嗯，我们有着悠久的历史。
923 01:46:22,814 --> 01:46:30,345 演讲者 演讲者_07：所以我上次向 AAAI 提交论文时，收到了我收到的最糟糕的评审。
924 01:46:31,105 --> 01:46:32,768 演讲者 演讲者_07：而且很刻薄。
925 01:46:32,787 --> 01:46:40,698 演讲者 演讲者_07：它说，Hinton 已经研究这个想法七年了，但没有人感兴趣。
926 01:46:40,739 --> 01:46:41,761 演讲者 SPEAKER_07: 是时候继续前进了。
927 01:46:44,324 --> 01:46:50,913 演讲者 SPEAKER_07: 现在，想法是这样的，你可能可以用一个向量来表示一个词的意义。
928 01:46:52,345 --> 01:46:54,287 演讲者 SPEAKER_07: 这需要一段时间来克服。
929 01:46:54,547 --> 01:47:00,494 演讲者 SPEAKER_07: 我们现在应该，我们现在处于一个位置，我们应该说，让我们忘记过去。
930 01:47:00,854 --> 01:47:08,604 演讲者 SPEAKER_07：让我们看看我们能否将梯度下降的想法应用于一个庞大的参数系统中。
931 01:47:09,265 --> 01:47:12,710 演讲者 SPEAKER_07：让我们看看能否采用那个想法，因为那实际上是我们迄今为止发现的全部。
932 01:47:12,810 --> 01:47:13,591 演讲者 SPEAKER_07：这真的有效。
933 01:47:13,690 --> 01:47:15,113 演讲者 SPEAKER_07：这个方法有效的事实令人惊讶。
934 01:47:15,873 --> 01:47:18,657 说话人 SPEAKER_07：让我们看看我们是否可以学会那样进行推理。
935 01:47:19,885 --> 01:47:21,807 说话人 SPEAKER_05：我将从那些人那里得到答案。
936 01:47:21,868 --> 01:47:31,225 说话人 SPEAKER_05：但是我想建议，仅仅因为 AAAI 曾经对你不好，或者可能好几次，这不是一个正确的方法，对吧？
937 01:47:31,505 --> 01:47:34,130 说话人 SPEAKER_05：我们不应该总是进行归纳并一直很刻薄。
938 01:47:34,149 --> 01:47:34,890 说话人 SPEAKER_07：我完全同意你的看法。
939 01:47:34,911 --> 01:47:39,057 说话人 SPEAKER_07：我只是在尝试解释为什么有些轻微的敌意。
940 01:47:42,818 --> 01:47:44,480 说话人 SPEAKER_09：所以，我的回答非常相似。
941 01:47:45,462 --> 01:47:52,213 讲者 SPEAKER_09：事实上，我在结论幻灯片里提到了，你知道的，用向量替换符号，用连续函数替换逻辑。
942 01:47:52,354 --> 01:47:57,682 讲者 SPEAKER_09：这样做的原因是我们希望使推理与学习兼容。
943 01:47:58,984 --> 01:48:05,855 讲者 SPEAKER_09：而我们已知唯一有效的学习方法是基于梯度的学习，因此我们必须使其与基于梯度的学习兼容。
944 01:48:05,836 --> 01:48:07,958 讲者 SPEAKER_09：所以我们必须使事物可微分。
945 01:48:08,059 --> 01:48:10,060 说话人 SPEAKER_09：我不知道如何精确地做到这一点。
946 01:48:10,081 --> 01:48:27,242 说话人 SPEAKER_09：我知道这个想法对于真正对逻辑感兴趣的人来说是异端或震惊，或者 whatever，因为你几乎不得不放弃大量相关的工作。
947 01:48:28,023 --> 01:48:34,289 说话人 SPEAKER_09：几年前也出现过类似的现象，就是
948 01:48:34,270 --> 01:48:43,115 说话人 SPEAKER_09：在 NLP 中的 transformers 和其他类似模型，其中大量的语言知识对于他们来说已经不再很有用了。
949 01:48:46,640 --> 01:48:47,541 说话人 SPEAKER_08: 话都说过一遍了。
950 01:48:47,560 --> 01:49:13,743 说话人 SPEAKER_08: 正如你们也从我的演讲中听到的，我认为我们应该展望未来，思考如何同时获得深度学习的优势并解决一些问题，比如推理，以及我认为的语言理解等等。
951 01:49:13,724 --> 01:49:26,502 说话人 SPEAKER_08: 这些问题在传统上与符号相关联，但我认为也可以使用更现代的方法来解决。
952 01:49:26,542 --> 01:49:32,109 说话人 SPEAKER_08: 我认为，特别是注意力机制是解决这个问题的关键，正如我试图说服大家的那样。
953 01:49:34,033 --> 01:49:38,819 演讲者 SPEAKER_05: 你真的认为没有基于梯度的学习方法是有用的替代方案吗？
954 01:49:40,521 --> 01:49:41,645 演讲者 SPEAKER_09: 好吧。
955 01:49:43,029 --> 01:49:49,948 演讲者 SPEAKER_09: 所以人们曾经提出并有效工作的所有学习方法都是基于某种优化，对吧？
956 01:49:50,510 --> 01:49:52,877 演讲者 SPEAKER_05: 随机森林？
957 01:49:54,612 --> 01:49:55,932 演讲者 演讲者_09：这是一种优化。
958 01:49:55,953 --> 01:49:58,275 演讲者 演讲者_09：我的意思是，它是贪婪的，但是的。
959 01:49:59,817 --> 01:50:03,081 演讲者 演讲者_09：并且有贝叶斯和类似的东西的边际化。
960 01:50:03,121 --> 01:50:08,966 演讲者 演讲者_09：我的意思是，你可以对这一点进行评估。
961 01:50:09,046 --> 01:50:11,128 演讲者 SPEAKER_09: 在某种程度上，是这样的。
962 01:50:11,269 --> 01:50:14,693 演讲者 SPEAKER_09: 如果有其他方法，我想知道是什么。
963 01:50:15,373 --> 01:50:18,856 演讲者 SPEAKER_09: 这实际上提出了一个问题，大脑是否最小化一个目标函数？
964 01:50:19,198 --> 01:50:19,518 演讲者 SPEAKER_09: 不清楚。
965 01:50:20,378 --> 01:50:22,341 演讲者 SPEAKER_09: 好的，第二件事。
966 01:50:23,484 --> 01:50:27,028 演讲者 SPEAKER_09: 如果你打算优化一个函数，你打算用什么来优化它？
967 01:50:27,689 --> 01:50:35,555 演讲者 SPEAKER_09: 要么是 0 阶，无梯度，要么是 1 阶有梯度，或者更高阶，我们仍然使用梯度，但使用其他东西。
968 01:50:35,576 --> 01:50:41,082 演讲者 SPEAKER_09: 0 阶比 1 阶效率低得多，所以如果你能使用梯度，请务必使用。
969 01:50:41,341 --> 01:50:53,052 讲者 SPEAKER_09：事实上，强化学习中存在一些目标不可微分的算法，这些算法使用一个评论家（critic），其目的是通过近似使其可微分来使目标函数可微分。
970 01:50:53,033 --> 01:50:55,279 讲者 SPEAKER_09：是的，梯度设计是有效的。
971 01:50:57,525 --> 01:50:57,846 讲者 SPEAKER_05：那很好。
972 01:50:57,867 --> 01:51:04,966 讲者 SPEAKER_05：这其实不是问题所在，但是的。
973 01:51:05,707 --> 01:51:14,654 演讲者 SPEAKER_05：所以也许我们应该讨论一些关于方法论等方面的问题。
974 01:51:15,775 --> 01:51:23,342 演讲者 SPEAKER_05：我想到了一件事，因为观众中有很多学生，所以有很多和学生相关的问题。
975 01:51:25,125 --> 01:51:32,912 演讲者 SPEAKER_05：我认为很多学生都有的一个担忧是，现在很多大公司都在进行大量研究，而这些公司拥有巨大的资源。
976 01:51:32,891 --> 01:51:45,359 演讲者 SPEAKER_05：问题是，当 Facebook、Google 等公司能够发起这些庞大的项目时，大学的作用是什么？这些项目似乎让学生无法与之竞争。
977 01:51:45,380 --> 01:51:46,041 演讲者 SPEAKER_07：我可以接那个吗？
978 01:51:47,623 --> 01:52:06,131 演讲者 SPEAKER_07：我还是认为真正原创的想法来自于一个优秀系所的硕士研究生，在得到良好建议的情况下，他（或她）不会重复历史，而是在思考如何做某事上花费了几年的时间。
979 01:52:07,252 --> 01:52:13,162 演讲者 SPEAKER_07：这在大公司里也可以做到，但我认为这主要是在大学里完成的。
980 01:52:13,261 --> 01:52:14,965 演讲者 SPEAKER_07：我认为这正是大学真正擅长的。
981 01:52:21,037 --> 01:52:22,520 说话人 SPEAKER_08: 我可以给这个加点东西。
982 01:52:22,621 --> 01:52:23,063 说话人 SPEAKER_08: 是的，请吧。
983 01:52:23,082 --> 01:52:36,057 说话人 SPEAKER_08: 在人工智能领域有很多真正困难的问题，这些问题可以在某种显微镜下进行研究。
984 01:52:36,037 --> 01:52:51,717 说话人 SPEAKER_08: 我的意思是，我认为我们在这个领域，尤其是在机器学习中，对玩具问题过于迅速地视而不见，专注于这些需要两周时间、使用 2,000 个 CPU 和 GPU 才能运行的真正困难的基准测试。
985 01:52:51,698 --> 01:53:01,631 演讲者 SPEAKER_08：但是确实存在一些非常有趣的问题，你可以分析一个问题，你可以用合理的资源进行实验。
986 01:53:01,690 --> 01:53:12,104 演讲者 SPEAKER_08：现在，我承认有时没有这些资源会让人感到沮丧，但使用这么多能源也存在环境问题。
987 01:53:13,706 --> 01:53:19,393 演讲者 SPEAKER_09：因此，我建议我们创建一个新的会议，即国际玩具问题深度学习会议。
988 01:53:21,550 --> 01:53:22,371 演讲者 SPEAKER_05：你能重复一下吗？
989 01:53:22,411 --> 01:53:23,511 说话人 SPEAKER_05: 我实际上没听见你。
990 01:53:23,532 --> 01:53:23,953 说话人 SPEAKER_05: 继续指。
991 01:53:24,613 --> 01:53:25,413 说话人 SPEAKER_09: 在玩具问题上。
992 01:53:25,554 --> 01:53:29,358 说话人 SPEAKER_05: 在玩具问题上，我明白了。
993 01:53:29,377 --> 01:53:29,519 演讲者 演讲者_05: 好的。
994 01:53:29,538 --> 01:53:33,323 演讲者 演讲者_05: 好的。
995 01:53:33,342 --> 01:53:36,685 演讲者 演讲者_07: 实际上，这与我几年前给 Jan 的建议有关。
996 01:53:36,706 --> 01:53:44,654 演讲者 演讲者_07: 我想开一个名为 MNIPS 的会议，其中你的算法需要在 MNIST 上进行测试。
997 01:53:44,635 --> 01:53:45,275 说话人 SPEAKER_05: 很好。
998 01:53:47,078 --> 01:53:55,453 说话人 SPEAKER_05: 所以我认为继续讨论一些学生的事情，我的意思是，我认为学生们也很感兴趣的是他们应该阅读和学习什么？
999 01:53:55,533 --> 01:54:03,907 说话人 SPEAKER_05: 我注意到你们确实提到了来自之前时代的概念，比如说概率模型。
1000 01:54:03,987 --> 01:54:05,750 说话人 SPEAKER_05: 但是你们认为学生们应该阅读什么？
1001 01:54:07,632 --> 01:54:10,136 演讲者 SPEAKER_08：当然，他们最好不是都读同一件事。
1002 01:54:12,091 --> 01:54:14,654 演讲者 SPEAKER_05：我认为这实际上是一个非常重要的观点，对吧？
1003 01:54:14,673 --> 01:54:15,935 演讲者 SPEAKER_05：我们不应该是一个单一文化。
1004 01:54:16,556 --> 01:54:21,863 演讲者 SPEAKER_07：我有一个导师，他的建议是阅读会腐蚀思想。
1005 01:54:23,326 --> 01:54:23,685 说话人 SPEAKER_05：扭曲？
1006 01:54:24,167 --> 01:54:24,768 说话人 SPEAKER_07：不，旋转。
1007 01:54:25,347 --> 01:54:26,630 说话人 SPEAKER_05：旋转？
1008 01:54:26,649 --> 01:54:26,829 说话人 SPEAKER_07：哦，好的。
1009 01:54:26,850 --> 01:54:32,117 演讲者 SPEAKER_07：他的建议是，不要阅读文献，先自己想出解决问题的方法。
1010 01:54:32,337 --> 01:54:36,802 演讲者 SPEAKER_07：当你想出解决问题的方法后，再去阅读文献。
1011 01:54:36,823 --> 01:54:37,203 演讲者 SPEAKER_05：是的，我同意。
1012 01:54:40,002 --> 01:54:41,786 演讲者 SPEAKER_05：你们有什么要补充的吗？
1013 01:54:41,867 --> 01:54:45,895 讲者 SPEAKER_09: 我认为费曼也有类似的建议。
1014 01:54:47,921 --> 01:54:48,984 讲者 SPEAKER_05: 好的，让我们看看。
1015 01:54:52,412 --> 01:54:57,505 讲者 SPEAKER_05: 是的，我们不想回答这些问题中的大多数。
1016 01:54:59,442 --> 01:55:01,944 讲者 SPEAKER_05: 好的，让我回来。
1017 01:55:01,985 --> 01:55:09,576 讲者 SPEAKER_05：所以，我心中还有一个问题，就是这次会议的开始很棒。
1018 01:55:09,636 --> 01:55:11,819 讲者 SPEAKER_05：我们开始讨论卷积，但这并不好。
1019 01:55:11,899 --> 01:55:14,382 讲者 SPEAKER_05：也许我们需要胶囊，而变压器很有用。
1020 01:55:15,083 --> 01:55:20,832 讲者 SPEAKER_05：而且有一种感觉，我们作为整个领域，正在共同提出有助于我们的机制，对吧？
1021 01:55:20,891 --> 01:55:23,055 演讲者 SPEAKER_05：各种结构偏差等等。
1022 01:55:23,555 --> 01:55:26,298 演讲者 SPEAKER_05：你认为会有六个这样的吗？
1023 01:55:26,500 --> 01:55:28,943 演讲者 SPEAKER_05：还是我们得找到 60 个？
1024 01:55:28,922 --> 01:55:35,640 演讲者 SPEAKER_05：或者有没有一种意义上，这些机制是一个封闭集，能够达到，比如说，人类水平的 AI？
1025 01:55:37,766 --> 01:55:40,755 演讲者 SPEAKER_08：数字越小越好，但我们不知道。
1026 01:55:43,502 --> 01:55:50,733 演讲者 SPEAKER_09：是的，我觉得如果它是小数字，比如，比如说 6、10 种架构类别，那就很好。
1027 01:55:51,314 --> 01:55:53,235 演讲者 SPEAKER_09：但这是否可能并不完全清楚。
1028 01:55:55,800 --> 01:56:02,087 演讲者 SPEAKER_09：我的意思是，给我们带来希望的可能是一些大脑皮层的明显一致性。
1029 01:56:03,009 --> 01:56:06,154 演讲者 SPEAKER_09：但是，我们大脑皮层中只有一小部分神经元。
1030 01:56:06,173 --> 01:56:12,362 演讲者 SPEAKER_09：所以其余部分似乎并不像那样各向同性或均匀。
1031 01:56:15,497 --> 01:56:22,007 演讲者 SPEAKER_05：您对一些大型 AI 公司正在进行的研究活动有保留意见吗？
1032 01:56:27,036 --> 01:56:27,277 演讲者 SPEAKER_08：是的。
例如，如果它能帮助化石燃料行业，
不，实际上，Facebook 和 Google 的数据中心正在变得碳中和，并且将在今年年底之前实现，至少对于 Facebook 来说如此。
我不确定 Google，但...我认为他们应该做一些关于虚假新闻的事情，但...是的，事实上我们在做。
我应该说的是这只是...
1037 01:57:07,337 --> 01:57:22,106 说话人 SPEAKER_08：我还想补充一点，你知道，如果这些拥有大量人工智能专业知识的公司不也在通过建造东西或为军事应用进行研究来赚钱，那就更好了。
1038 01:57:28,515 --> 01:57:31,220 说话人 SPEAKER_07：我认为我们三个人都同意这一点。
1039 01:57:31,560 --> 01:57:43,796 说话人 SPEAKER_07：实际上，我对谷歌取消了一个项目印象深刻，这个项目本会导致从国防部获得数十亿美元的金额，因为谷歌员工反对这个项目。
1040 01:57:44,478 --> 01:57:52,248 说话人 SPEAKER_07：这让我觉得谷歌其实并不是那么糟糕的公司。
1041 01:57:52,269 --> 01:57:54,492 说话人 SPEAKER_09: 嗯，Facebook 从不做这种事情。
1042 01:57:54,511 --> 01:57:56,194 说话人 SPEAKER_09: 所以这从来不是问题。
1043 01:57:57,641 --> 01:58:02,350 说话人 SPEAKER_05: 好的，那么让我们谈谈稍微不那么有争议的话题。
1044 01:58:03,291 --> 01:58:07,798 说话人 SPEAKER_05: 那么你的新旧想法是从哪里来的？
1045 01:58:08,239 --> 01:58:10,462 演讲者 SPEAKER_05：您是如何决定要研究哪些问题的？
1046 01:58:10,483 --> 01:58:11,826 演讲者 SPEAKER_08：这通常在我早上醒来时产生。
1047 01:58:13,828 --> 01:58:16,613 演讲者 SPEAKER_05：好的，您是如何决定所有这些问题的？
1048 01:58:16,634 --> 01:58:18,015 演讲者 SPEAKER_08：不，这是系统一。
1049 01:58:20,158 --> 01:58:22,283 讲者 SPEAKER_08: 不，说真的，我是指直觉，对吧？
1050 01:58:23,257 --> 01:58:26,067 讲者 SPEAKER_08: 然后，当然，你做实验，它失败了，一次又一次。
1051 01:58:26,389 --> 01:58:27,351 讲者 SPEAKER_08: 嗯，有时候它是有效的。
1052 01:58:28,454 --> 01:58:31,485 讲者 SPEAKER_08: 你必须听从那个直觉。
1053 01:58:31,605 --> 01:58:33,993 讲者 SPEAKER_08: 就是这样我们做科学。
1054 01:58:37,061 --> 01:58:45,390 讲者 SPEAKER_09: 嗯，我当然也非常依赖直觉和这类东西。
1055 01:58:45,409 --> 01:58:52,315 讲者 SPEAKER_09: 但我认为你必须找出真正问题、重要问题的核心。
1056 01:58:53,237 --> 01:58:57,399 讲者 SPEAKER_09: 然后想法就来了，之后它们就变得显而易见。
1057 01：58：58,721 --> 01：58：59,802 议长 SPEAKER_09：至少它们对你来说是显而易见的。
可能需要20年世界上的其他人才能意识到这是显而易见的，但已经发生了。
1059 01:59:06,896 --> 01:59:09,121 演讲者 演讲者_09：但这是那种类型的进步。
80年代初期，我就有了关于多层神经网络的感觉，这显然是一个前进的方向，然后是卷积神经网络，这也是一个明显的方向。
1061 01:59:24,327 --> 01:59:26,930 讲者 SPEAKER_09：这需要很长时间才变得流行。
1062 01:59:26,911 --> 01:59:32,878 讲者 SPEAKER_09：现在我对自监督学习，关于处理不确定性和预测的问题有一种感觉。
1063 01:59:33,198 --> 01:59:51,061 讲者 SPEAKER_09：这些问题是我们需要解决的，像重要的问题，而不是，你知道，当然，通过各种方法提高实际系统的性能总是有用的，但我更感兴趣的是那些有长期影响的事情。
1064 01:59:53,675 --> 02:00:10,231 讲者 SPEAKER_05：所以关于神经网络一度不太受欢迎，而一些勇敢的人继续研究它们的问题，是否...固执。
1065 02:00:10,212 --> 02:00:12,676 讲者 SPEAKER_05: 倔强，倔强，太倔强了是好事。
1066 02:00:13,095 --> 02:00:25,373 讲者 SPEAKER_05: 那么，问题来了，我是指，如果你现在正研究一个目前非常不受欢迎的想法，你知道，我该如何，我应该怎么进行？
1067 02:00:25,434 --> 02:00:29,520 讲者 SPEAKER_05: 当人们写恶意的评论，没有人喜欢我的研究时，我该怎么办？
1068 02:00:30,125 --> 02:00:37,380 讲者 SPEAKER_07: 我想首先你应该记住的是，大多数非常不受欢迎的想法之所以不受欢迎，是因为它们本身不好。
1069 02:00:40,345 --> 02:00:42,250 演讲者 SPEAKER_07：这就是那个棘手的区分，对吧？
1070 02:00:42,310 --> 02:00:42,730 演讲者 SPEAKER_07：是的。
1071 02:00:43,412 --> 02:00:45,577 演讲者 SPEAKER_07：我不知道。
1072 02:00:48,221 --> 02:00:48,381 演讲者 SPEAKER_05：好的。
1073 02:00:50,145 --> 02:00:51,188 演讲者 SPEAKER_05：任何，没有吗？
1074 02:00:52,466 --> 02:00:54,010 演讲者 SPEAKER_05：不是，如果它不是，它永远不会放弃。
1075 02:00:54,029 --> 02:00:55,212 演讲者 SPEAKER_05：这就是你说的吗？
1076 02:00:55,231 --> 02:00:58,237 演讲者 SPEAKER_08：不，我认为你必须看看证据，对吧？
1077 02:00:58,256 --> 02:00:59,880 讲者 SPEAKER_08: 这不能只是你的直觉。
1078 02:01:00,961 --> 02:01:09,817 讲者 SPEAKER_08: 在考虑证据和仅凭信仰之间有一条细线。
1079 02:01:11,118 --> 02:01:13,242 讲者 SPEAKER_08: 但你需要这种信仰来前进。
1080 02:01:13,301 --> 02:01:16,568 讲者 SPEAKER_08: 也许它第一次失败了，但有一个小转折会让它成功。
1081 02:01:18,573 --> 02:01:21,516 演讲者 SPEAKER_07: 如果你真的相信一个想法，你就永远不应该放弃它。
1082 02:01:22,257 --> 02:01:22,719 演讲者 SPEAKER_05: 我支持这一点。
1083 02:01:23,260 --> 02:01:27,244 演讲者 SPEAKER_07: 正因如此，我仍在思考如何让玻尔兹曼机工作。
1084 02:01:29,408 --> 02:01:31,891 演讲者 SPEAKER_07: 我有一套至少让我自己满意的逻辑。
1085 02:01:34,375 --> 02:01:35,777 说话人 SPEAKER_07：逻辑？
1086 02:01:35,817 --> 02:01:36,518 说话人 SPEAKER_07：是的，逻辑。
1087 02:01:38,320 --> 02:01:39,582 说话人 SPEAKER_07：逻辑是这样的。
1088 02:01:40,503 --> 02:01:43,448 说话人 SPEAKER_07：如果你相信一个想法，并且你有良好的直觉，你应该去工作。
1089 02:01:43,849 --> 02:01:46,993 说话人 SPEAKER_07：如果你有错误的直觉，你做什么其实都无关紧要。
1090 02:01:48,965 --> 02:01:49,726 说话人 SPEAKER_05：好的，很好。
1091 02:01:50,609 --> 02:01:53,997 说话人 SPEAKER_05：实际上，这是一个我的问题，真的。
1092 02:01:54,037 --> 02:02:02,139 说话人 SPEAKER_05：杰夫说，对于研究生来说，长时间思考一个难题是很重要的。
1093 02:02:02,801 --> 02:02:04,746 说话人 SPEAKER_05: 我想知道你们是否
1094 02:02:05,367 --> 02:02:16,208 说话人 SPEAKER_05: 我感觉当前的发表周期既快又短视，我对它对领域的影响感到担忧，我想知道你们是否也有同样的感受。
1095 02:02:16,229 --> 02:02:16,970 说话人 SPEAKER_08: 我感到沮丧。
1096 02:02:19,395 --> 02:02:25,688 说话人 SPEAKER_08: 计算机科学、机器学习和人工智能领域的当前一代研究人员
1097 02:02:25,667 --> 02:02:32,458 演讲者 SPEAKER_08：似乎非常关注短期收益，只忙于下一个会议的截止日期。
1098 02:02:32,859 --> 02:02:38,648 演讲者 SPEAKER_08：所以我有很多学生来我的办公室说，我接下来的四周能做什么？
1099 02:02:41,051 --> 02:02:41,693 演讲者 SPEAKER_08：因为有这个截止日期。
1100 02:02:41,712 --> 02:02:43,034 演讲者 SPEAKER_05：你们都没有这么做，对吧？
1101 02:02:45,715 --> 02:02:47,761 说话人 SPEAKER_08：我认为这对领域来说真的很糟糕。
1102 02:02:48,743 --> 02:02:58,914 说话人 SPEAKER_08：我们需要改变一些结构性的东西，以鼓励人们承担更多风险，并在更长远的时间范围内工作。
1103 02:02:59,940 --> 02:03:02,904 说话人 SPEAKER_09：我认为有一个完整的谱系，对吧？
1104 02:03:02,923 --> 02:03:10,912 说话人 SPEAKER_09：我的意思是，在基准和所有这些记录上确实有很多实用性。
1105 02:03:11,894 --> 02:03:13,676 说话人 SPEAKER_09：这最后非常实用。
1106 02:03:14,235 --> 02:03:15,597 说话人 SPEAKER_09：所以这没问题。
1107 02:03:16,498 --> 02:03:22,465 说话人 SPEAKER_09：问题是，随着我们领域的扩大，它变得越来越应用化，因为越来越多的人对那些应用感兴趣。
1108 02:03:22,484 --> 02:03:23,506 说话人 SPEAKER_09：这就是他们来到这个领域的原因。
1109 02:03:23,926 --> 02:03:28,310 说话人 SPEAKER_09：所以问题是，什么是
1110 02:03:28,291 --> 02:03:43,847 演讲者 SPEAKER_09：长期从事工作的人数总数，以及他们是否仍然在那些更偏向应用导向的会议和场所中发声，例如，视觉会议或自然语言处理会议。
1111 02:03:44,469 --> 02:03:52,898 演讲者 SPEAKER_09：因此，应该有空间为那些更侧重于方法的会议留出位置，在这些会议中，不强调打破记录，或许是这样的
1112 02:03:54,042 --> 02:03:57,447 演讲者 SPEAKER_09：新提出的针对玩具问题的深度学习会议。
1113 02:04:00,210 --> 02:04:17,113 演讲者 SPEAKER_09：但这可能仍然允许人们保持高频率的发表论文，这是获得工作和类似事情所需的系统要求，但在同时，仍然在解决长期复杂问题和雄心勃勃的问题。
1114 02:04:18,966 --> 02:04:23,773 讲者 SPEAKER_08：现在的发表压力比我在读研究生时强得多。
1115 02:04:24,954 --> 02:04:30,662 讲者 SPEAKER_08：而且博士生在攻读博士学位期间发表的论文数量是疯狂的，对吧？
1116 02:04:30,682 --> 02:04:32,725 讲者 SPEAKER_09：我们不会承认自己能进入自己的博士项目。
1117 02:04:33,105 --> 02:04:33,726 讲者 SPEAKER_05：绝对不行。
1118 02:04:34,067 --> 02:04:37,391 讲者 SPEAKER_05：问题是论文内容的积分是否不同。
1119 02:04:38,073 --> 02:04:38,393 讲者 SPEAKER_08：是的。
1120 02:04:40,582 --> 02:04:51,100 讲者 SPEAKER_08：实际上，一个副作用是一旦论文被发表，我的意思是，就像半成品一样进入会议论文，一旦被接受，他们通常会转向其他事情。
1121 02:04:52,242 --> 02:04:54,024 讲者 SPEAKER_08：是的，没错。
1122 02:04:54,045 --> 02:05:02,979 演讲者 SPEAKER_07: 嗯，我有一个模型，描述了人们在一个短暂的时间内对一个想法进行工作，并取得一些进展，然后发表一篇论文的过程。
1123 02:05:02,960 --> 02:05:11,613 演讲者 SPEAKER_07: 就像有人拿一本难题数独书，逐页填上一些简单的数独题。
1124 02:05:11,632 --> 02:05:13,416 演讲者 SPEAKER_07: 这真的会让其他人感到困扰。
1125 02:05:16,359 --> 02:05:16,900 演讲者 SPEAKER_06: 很好。
1126 02:05:18,783 --> 02:05:20,506 演讲者 演讲者_05: 现在是7点30分。
1127 02:05:20,525 --> 02:05:24,632 演讲者 演讲者_05: 我们需要停下来吗？
1128 02:05:24,653 --> 02:05:25,012 演讲者 演讲者_05: 好的。
1129 02:05:25,314 --> 02:05:26,454 演讲者 演讲者_05: 有几个问题来自观众。
1130 02:05:26,494 --> 02:05:27,636 演讲者 SPEAKER_05: 我不知道机制。
1131 02:05:27,756 --> 02:05:30,622 演讲者 SPEAKER_05: 哦，那里有一个麦克风，那里也有一个麦克风。
1132 02:05:31,122 --> 02:05:31,582 演讲者 SPEAKER_05: 好的。
1133 02:05:33,554 --> 02:05:45,823 演讲者 SPEAKER_07: 所以问题是，我们能否称做 AI 为做科学？
1134 02:05:46,564 --> 02:05:49,572 说话人 SPEAKER_07: 你必须给出的答案是是或否，答案是是。
1135 02:05:52,605 --> 02:05:55,292 说话人 SPEAKER_08: 我认为在人工智能领域你可以做很多不同的事情。
1136 02:05:55,332 --> 02:06:03,029 说话人 SPEAKER_08: 其中一些更偏向于工程方面，而另一些则更偏向于理解某事物。
1137 02:06:03,511 --> 02:06:05,215 说话人 SPEAKER_08: 那更偏向于科学方面。
1138 02:06:05,532 --> 02:06:07,033 演讲者 SPEAKER_09: 是的，这是工程科学，对吧？
1139 02:06:07,054 --> 02:06:12,158 演讲者 SPEAKER_09: 所以这里有创造性的部分，就是你构思一个物品。
1140 02:06:12,560 --> 02:06:16,304 演讲者 SPEAKER_09: 然后是科学部分，你分析它是如何工作的，为什么它不工作，诸如此类。
1141 02:06:16,724 --> 02:06:23,451 演讲者 SPEAKER_09: 在科学和技术的历史上，往往是在物品被创造出来之后，才有了解释它的理论。
1142 02:06:23,891 --> 02:06:26,954 演讲者 SPEAKER_09: 一个很好的例子是蒸汽机的发明。
1143 02:06:27,655 --> 02:06:35,404 演讲者 SPEAKER_09: 人们用了 100 年才弄清楚热力学，并解释了热机及其它方面的局限性。
1144 02:06:35,384 --> 02:06:38,109 演讲者 SPEAKER_09: 所以我们现在可以制造蒸汽机了。
1145 02:06:39,171 --> 02:06:42,458 演讲者 SPEAKER_09: 那么热力学在哪里呢？
1146 02:06:43,902 --> 02:06:46,448 演讲者 SPEAKER_09：智能的等价物是什么？
1147 02:06:46,507 --> 02:06:49,814 演讲者 SPEAKER_09：我的科学，科学问题。
1148 02:06:51,431 --> 02:06:53,855 演讲者 SPEAKER_05：在那里，麦克风那里。
1149 02:06:53,876 --> 02:06:54,237 演讲者 SPEAKER_04：谢谢。
1150 02:06:54,778 --> 02:06:56,360 演讲者 SPEAKER_04：非常精彩的演讲。
1151 02:06:56,862 --> 02:06:57,944 演讲者 SPEAKER_04：我有两个问题。
1152 02:06:58,064 --> 02:07:09,423 演讲者 SPEAKER_04：一个是，我不知道你们三位中有没有看过谷歌的 Cholette 发表的这篇论文，他讨论的
1153 02:07:09,809 --> 02:07:17,698 演讲者 SPEAKER_04：不一定是什么是通用智能，而是更多地关于它不是什么，以及如何潜在地衡量它。
1154 02:07:18,219 --> 02:07:32,475 讲者 SPEAKER_04：第二个问题是，人类能够普遍具有智能并创造出像数学这样的东西，因此我们可以像 F=MA 或 E=MC²这样的公式进行解析性创造。
1155 02:07:32,994 --> 02:07:37,038 讲者 SPEAKER_04：计算量几乎和 2 乘以 3 等于 6 一样简单。
1156 02:07:37,680 --> 02:07:53,336 讲者 SPEAKER_04：所以只需要几个晶体管，可能只需要几瓦或毫瓦，而深度学习的大部分内容在总体上非常强大，但需要兆瓦或千瓦或数百瓦。
1157 02:07:54,277 --> 02:08:01,904 讲者 SPEAKER_04：那么，有没有可能，使用这些神经网络架构，我们不一定
1158 02:08:02,189 --> 02:08:09,550 演讲者 SPEAKER_04：最终我们需要拥有计算复杂度极高或容量极大的东西。
1159 02:08:10,659 --> 02:08:20,917 演讲者 SPEAKER_08：但你知道，F=MA 是从一个拥有大量神经元、大量计算的人脑中产生的。
1160 02:08:21,599 --> 02:08:34,862 演讲者 SPEAKER_08：如果我们想要机器能够产生这类东西，尽管最终产品可能只是一个简单的方程，但背后有大量的计算、经验和学习。
1161 02:08:35,483 --> 02:08:36,704 演讲者 SPEAKER_04：我并不是在争论这一点。
1162 02:08:38,926 --> 02:08:42,091 演讲者 演讲者_05：我被告知我们只剩下时间问一个问题了，对此我感到很遗憾。
1163 02:08:42,652 --> 02:08:46,756 演讲者 演讲者_05：我们将立即在中间的麦克风那里接受那个问题。
1164 02:08:47,198 --> 02:08:47,878 演讲者 演讲者_01：每个麦克风一个问题。
1165 02:08:49,119 --> 02:08:53,405 演讲者 演讲者_01：看起来你们在很多事情上意见一致得非常激烈。
1166 02:08:54,327 --> 02:09:01,355 演讲者 SPEAKER_01：可能需要的前置知识性质，自监督或无监督学习的价值。
1167 02:09:01,336 --> 02:09:13,292 演讲者 SPEAKER_01：我想知道在座的各位对于这些问题的细节部分，是否可能存在分歧或对如何采取方法或哪些要素重要有不同的看法。
1168 02:09:14,333 --> 02:09:16,396 演讲者 SPEAKER_08：Leslie 已经尝试过这样对我们了，但没起作用。
1169 02:09:18,420 --> 02:09:21,283 演讲者 SPEAKER_07：我可以告诉你们我们之间有一个分歧。
1170 02:09:22,546 --> 02:09:28,474 演讲者 SPEAKER_07：Yoshua 的电子邮件地址以 Quebec 结尾，我认为在那之后应该跟一个国家代码，他没有。
1171 02:09:31,036 --> 02:09:33,561 演讲者 SPEAKER_09：我保持在这个辩论之外。
1172 02:09:34,243 --> 02:09:34,623 演讲者 SPEAKER_05：好的。
1173 02:09:35,185 --> 02:09:40,557 演讲者 SPEAKER_05：在这个话题上，我们结束了，Vince 说。
1174 02:09:40,637 --> 02:09:43,002 演讲者 SPEAKER_05: 非常感谢我们的演讲者。
1175 02:09:54,087 --> 02:09:59,698 演讲者 SPEAKER_00: 现在提醒大家，我们听到了很多关于系统 1、系统 2、诺贝尔奖得主以及丹尼尔·卡尼曼的讨论。
1176 02:10:00,420 --> 02:10:04,127 演讲者 SPEAKER_00: 有人在推特上机智地指出，他今晚实际上就在观众席上。
1177 02:10:05,449 --> 02:10:13,527 演讲者 SPEAKER_00: 我只想提醒大家，明天早上 8 点，我们将与丹尼尔·卡尼曼以及一些图灵奖得主进行炉边谈话。
1178 02：10：13,567 --> 02：10：15,470 议长 SPEAKER_00：所以请早点起床。