1 00:00:05,245 --> 00:00:10,631 说话人 说话人_00：在我们开始之前，我最近在斯坦福做过同样的演讲。
2 00:00:10,650 --> 00:00:17,839 说话人 说话人_00：我向邀请我的人建议，我可以只做一次演讲，两个听众都来，但他们更愿意将其作为两个单独的演讲。
3 00:00:18,400 --> 00:00:21,785 说话人 说话人_00：所以如果你最近参加过这次演讲，我建议你现在离开。
4 00:00:22,446 --> 00:00:23,367 说话人 说话人_00：你不会学到任何新东西。
5 00:00:24,487 --> 00:00:25,870 说话人 SPEAKER_00: 好的。
6 00:00:28,513 --> 00:00:32,097 说话人 SPEAKER_00: 我打算结合一些最近在神经网络领域的新想法。
7 00:00:32,683 --> 00:00:42,014 说话人 SPEAKER_00: 尝试解释神经网络如何在不违反神经元基本工作原理的情况下表示部分-整体层次结构。
8 00:00:43,875 --> 00:00:49,360 说话人 SPEAKER_00: 我将用一种假想系统来解释这些想法。
9 00:00:50,402 --> 00:00:55,728 说话人 SPEAKER_00：我开始编写一个系统设计文档，最后我决定单独的设计文档本身就很有趣。
10 00:00:56,429 --> 00:00:58,670 说话人 SPEAKER_00：所以这只是一个空想产品，不存在的东西。
11 00:00:58,930 --> 00:01:01,594 说话人 SPEAKER_00：现在有一些部分已经存在，但...
12 00:01:02,030 --> 00:01:05,713 说话人 SPEAKER_00：我发现用虚构系统的背景来解释这些想法很容易。
13 00:01:11,240 --> 00:01:18,308 说话人 SPEAKER_00：现在大多数研究神经网络的人都在做工程，他们并不真正关心它是否与大脑的工作方式完全一致。
14 00:01:18,849 --> 00:01:20,292 说话人 SPEAKER_00：他们并不试图理解大脑是如何工作的。
15 00:01:20,311 --> 00:01:22,034 说话人 SPEAKER_00：他们试图创造酷炫的技术。
16 00:01:22,875 --> 00:01:24,956 说话人 SPEAKER_00：所以在 ResNet 中，100 层是完全可以的。
17 00:01:25,498 --> 00:01:28,981 说话人 SPEAKER_00：在卷积神经网络中，权重共享是可行的。
18 00:01:29,131 --> 00:01:37,918 说话人 SPEAKER_00：一些研究人员，尤其是计算神经科学家，试图研究神经网络、人工神经网络，以了解大脑可能实际上是如何工作的。
19 00:01:38,859 --> 00:01:40,742 说话人 SPEAKER_00：我认为我们还有很多东西要向大脑学习。
20 00:01:41,862 --> 00:01:52,433 说话人 SPEAKER_00：我想我们应该记住，大约半个世纪以来，支撑神经网络研究不断前进的唯一信念就是，必须有可能让这些事物学习复杂事物，因为大脑可以。
21 00:01:55,897 --> 00:01:56,337 说话人 SPEAKER_00: 所以
22 00:01:57,969 --> 00:01:59,852 说话人 SPEAKER_00: 每张图像都有一个不同的解析树。
23 00:02:01,534 --> 00:02:03,617 说话人 SPEAKER_00: 这就是图像中部件的孔的结构。
24 00:02:05,439 --> 00:02:16,814 说话人 SPEAKER_00: 在一个真实的神经网络中，你不能动态分配，你不能只是抓取一些神经元然后说，好的，你现在代表这个，因为你没有随机访问内存。
25 00:02:16,854 --> 00:02:20,139 说话人 SPEAKER_00: 你不能随意设置神经元的权重。
26 00:02:20,560 --> 00:02:24,044 说话人 SPEAKER_00: 神经元的功能由其连接决定，而这些连接只会缓慢改变。
27 00:02:24,598 --> 00:02:27,310 说话人 SPEAKER_00: 最可能的情况是，它们大多数情况下是缓慢改变的。
28 00:02:29,759 --> 00:02:35,502 说话人 SPEAKER_00: 所以问题是，如果你不能快速改变神经元的功能，你该如何表示动态的解析树？
29 00:02:40,444 --> 00:02:42,067 说话人 说话人_00：在符号人工智能中，这不是问题。
30 00:02:42,086 --> 00:02:48,453 说话人 说话人_00：你只需抓取一块内存，这就是它的通常含义，然后说，这将要代表解析树中的一个节点。
31 00:02:48,813 --> 00:02:52,638 说话人 说话人_00：我将给它指向其他节点、代表其他节点的其他内存块的指针。
32 00:02:53,098 --> 00:02:53,838 说话人 说话人_00：所以没有问题。
33 00:02:54,759 --> 00:03:04,789 说话人 SPEAKER_00：大约五年来，我一直在研究一种名为胶囊的理论，即由于无法动态分配神经元，因此我们将提前分配它们。
34 00:03:05,371 --> 00:03:09,675 说话人 SPEAKER_00：所以我们将取一组神经元，并将它们分配到解析树中的不同可能节点。
35 00:03:10,567 --> 00:03:14,570 说话人 SPEAKER_00：对于大多数图像来说，这些神经元组中的大多数都将保持沉默。
36 00:03:15,192 --> 00:03:16,353 说话人 SPEAKER_00：其中一些将会活跃。
37 00:03:17,354 --> 00:03:20,897 说话人 说话人_00: 然后对于活跃的部分，我们必须动态地将它们连接到分析树中。
38 00:03:21,437 --> 00:03:25,002 说话人 说话人_00: 因此，我们需要一种方法在这些神经元组之间进行路由。
39 00:03:26,183 --> 00:03:27,485 说话人 说话人_00: 那就是胶囊理论。
40 00:03:28,366 --> 00:03:34,171 说话人 说话人_00: 我有一些非常能干的同事与我一起工作，他们实际上让这一切都运作起来。
41 00:03:34,352 --> 00:03:36,093 说话人 SPEAKER_00: 但这很艰难。
42 00:03:37,094 --> 00:03:39,897 说话人 SPEAKER_00: 我的观点是科学家们想要工作，而科学家们不想要工作。
43 00:03:40,132 --> 00:03:41,513 说话人 SPEAKER_00: 而胶囊处于中间状态。
44 00:03:42,093 --> 00:03:43,756 说话人 SPEAKER_00: 像反向传播这样的技术只想工作。
45 00:03:43,776 --> 00:03:44,717 说话人 SPEAKER_00: 你试试，它们是有效的。
46 00:03:46,057 --> 00:03:48,060 说话人 SPEAKER_00: 我还有其他一些想法，但就是不想工作。
47 00:03:49,121 --> 00:03:51,324 说话人 SPEAKER_00: 胶囊式（Capsules）介于两者之间，我们让它工作了。
48 00:03:52,104 --> 00:03:59,532 说话人 SPEAKER_00: 但我现在有一个新理论，可以看作是一种有趣的胶囊模型，其中每个胶囊都是通用的。
49 00:03:59,932 --> 00:04:07,000 说话人 SPEAKER_00：也就是说，不是每个胶囊都只对应一种特定的事物，每个胶囊可以代表任何事物。
50 00:04:09,157 --> 00:04:13,644 说话人 SPEAKER_00：但是硬件仍然以胶囊的形式存在，有时也被称为嵌入。
51 00:04:16,988 --> 00:04:20,634 说话人 SPEAKER_00：所以我将要介绍的想象系统叫做 Glom。
52 00:04:21,475 --> 00:04:25,002 说话人 SPEAKER_00：在 Glom 中，硬件被分配到列中。
53 00:04:26,244 --> 00:04:32,093 说话人 说话人_00：每一列都包含了对图像一小块区域发生情况的多个层次表示。
54 00:04:33,507 --> 00:04:39,394 说话人 说话人_00：所以在某一列中，你可能会有一个较低层次的表示，表明它是鼻孔。
55 00:04:40,475 --> 00:04:42,259 说话人 说话人_00：而更高一个层次可能会说它是鼻子。
56 00:04:42,319 --> 00:04:43,699 说话人 说话人_00：再高一个层次可能会说它是脸部。
57 00:04:43,740 --> 00:04:44,822 说话人 SPEAKER_00: 上升一个层次，一个人。
58 00:04:45,182 --> 00:04:46,644 说话人 SPEAKER_00: 顶层可能说是派对。
59 00:04:47,204 --> 00:04:48,165 说话人 SPEAKER_00: 整个场景就是这样。
60 00:04:50,449 --> 00:04:57,117 说话人 SPEAKER_00: 表示部分-整体层次结构的思想是使用这些不同层次之间的嵌入之间的共识岛屿。
61 00:04:58,346 --> 00:05:06,278 说话人 说话人_00：在场景级别，在最高级别，你希望每个图像块都拥有相同的嵌入，因为每个块都是同一场景的块。
62 00:05:07,261 --> 00:05:13,771 说话人 说话人_00：在物体级别，你希望属于该物体的所有不同块的嵌入都相同。
63 00:05:14,713 --> 00:05:17,697 说话人 说话人_00：因此，当你向上层递进时，你试图使事物越来越相同。
64 00:05:18,439 --> 00:05:21,283 说话人 说话人_00：这就是你如何压缩冗余的方式。
嵌入向量是像指针一样的东西，嵌入向量是动态的，它们是神经激活而不是神经权重，所以为每张图像有不同的嵌入向量是可以的。
66 00：05：39,209 --> 00：05：44,274 演讲者 SPEAKER_00：所以，如果你有一维的补丁行，这里有一张小图片。
67 00：05：45,475 --> 00：05：47,057 演讲者 SPEAKER_00：这些是补丁的列。
68 00:05:48,737 --> 00:05:49,278 说话者 说话者_00：嗯。
69 00:05:49,815 --> 00:05:52,480 说话人 SPEAKER_00: 你会有一个卷积神经网络作为前端。
70 00:05:53,942 --> 00:06:00,350 说话人 SPEAKER_00: 然后在前端之后，你生成最低级别的嵌入，表示每个特定区域的情况。
71 00:06:01,172 --> 00:06:03,956 说话人 SPEAKER_00: 因此，底部黑色箭头的这一层，它们都是不同的。
72 00:06:04,697 --> 00:06:09,343 说话人 SPEAKER_00: 当然，这些嵌入维度可能有数千维，在你的大脑中可能是数十万维。
73 00:06:10,425 --> 00:06:18,456 说话人 说话人_00：二维向量是不对的，但至少我可以通过使用方向来表示两个向量相同的位置。
74 00:06:19,144 --> 00:06:22,887 说话人 说话人_00：在最低级别，所有的补丁都将有不同的表示。
75 00:06:23,968 --> 00:06:30,394 说话人 说话人_00：但在更高一级别，前两个补丁可能属于一个鼻孔，例如。
76 00:06:31,255 --> 00:06:36,821 说话人 说话人_00：所以，是的，它们将具有相同的嵌入。
77 00:06:37,721 --> 00:06:41,985 说话人 SPEAKER_00: 但是再往上一层，前三个补丁可能属于同一个鼻子。
78 00:06:42,966 --> 00:06:44,367 说话人 SPEAKER_00: 因此它们都将拥有相同的嵌入。
79 00:06:45,228 --> 00:06:48,612 说话人 SPEAKER_00: 注意，尽管图像中的内容相当不同，
80 00:06:49,536 --> 00:06:54,264 说话人 SPEAKER_00: 在部件级别，这三个红色向量都应该是相同的。
81 00:06:55,286 --> 00:07:00,112 说话人 SPEAKER_00: 我们正在做的是，对于表面上非常不同的事物，我们得到相同的表示。
82 00:07:00,954 --> 00:07:05,661 说话人 SPEAKER_00: 我们通过给不同的事物相同的表示，在图像中找到空间一致性。
83 00:07:07,083 --> 00:07:11,189 说话人 SPEAKER_00: 在物体层面上，你可能有鼻子和嘴巴。
84 00:07:12,230 --> 00:07:15,055 说话人 SPEAKER_00: 它们是同一个人的脸，是同一张脸的组成部分。
85 00:07:15,187 --> 00:07:20,370 说话人 SPEAKER_00: 因此所有这些向量都是相同的，这个网络还没有稳定下来以产生未见过的内容。
86 00:07:22,324 --> 00:07:26,709 说话人 SPEAKER_00: 所以，共识岛屿捕捉了解析树。
87 00:07:27,310 --> 00:07:29,194 说话人 SPEAKER_00: 现在它们比解析树更强大。
88 00:07:29,793 --> 00:07:33,298 说话人 SPEAKER_00: 它们可以捕捉到像“闭嘴”这样的内容。
你可以在一个层面上拥有关闭和上升是不同的向量，但在更高层面上，关闭和上升可以具有完全相同的向量，即“闭嘴”的向量，它们可以是分离的。
所以你在这里可以做一些比无上下文文法更强大的事情，但基本上它是一个解析树。
如果你是一名物理学家，你可以将这些层面想象成具有实值向量的冰山模型，而不是二进制自旋。
你可以将它们想象成在不同层面之间的坐标变换，这使得它变得更加复杂。
93 00:08:08,459 --> 00:08:19,011 说话人 说话人_00: 这是一种多级糖霜模型，但各级之间存在复杂的交互，因为例如，在红色箭头和它们上面的黑色箭头之间，
94 00:08:19,463 --> 00:08:22,466 说话人 说话人_00: 你需要鼻子和脸之间的坐标变换。
95 00:08:23,427 --> 00:08:24,408 说话人 说话人_00: 但我们稍后再说。
96 00:08:26,471 --> 00:08:29,033 说话人 说话人_00: 如果你不是物理学家，就忽略所有这些，因为那不会帮到你。
97 00:08:33,458 --> 00:08:40,947 讲者：我想开始，这可能是特别适合自然语言课程，因为有些人不是视觉型的人。
98 00:08:41,570 --> 00:08:47,958 讲者：我要尝试向你们证明坐标系并非只是笛卡尔所发明的东西。
99 00:08:48,720 --> 00:08:57,072 讲者：坐标系是大脑很久以前就发明出来的，我们在理解图像时使用坐标系。
100 00:08:58,114 --> 00:09:01,778 讲者：我还想展示图像的句法树的心理学现实。
101 00:09:02,880 --> 00:09:09,129 说话人 SPEAKER_00：所以我将用我在 20 世纪 70 年代很久以前发明的一个任务来做这件事。
102 00:09:09,480 --> 00:09:10,702 说话人 SPEAKER_00：实际上，当我还是研究生的时候。
103 00:09:11,303 --> 00:09:16,030 说话人 SPEAKER_00：你必须完成这个任务才能从中获得全部的好处。
104 00:09:19,274 --> 00:09:27,106 说话人 SPEAKER_00：所以我想让你想象一下，在你面前的桌子上，有一个标准方向的线框立方体。
105 00:09:27,768 --> 00:09:28,990 说话人 SPEAKER_00: 它正放在桌面上。
106 00:09:29,711 --> 00:09:37,481 说话人 SPEAKER_00: 从你的角度看，有一个前下右角和一个后上左角。
107 00:09:37,702 --> 00:09:39,284 说话人 SPEAKER_00: 好了。
108 00:09:40,192 --> 00:09:45,357 说话人 SPEAKER_00: 前下右角正放在桌面上，与其他四个角一起。
109 00:09:46,619 --> 00:09:51,722 说话人 说话人_00：立方体的对角线穿过中心，顶部的左后角就在对角线的另一端。
110 00:09:53,125 --> 00:09:54,206 说话人 说话人_00：到目前为止，一切顺利。
111 00:09:55,105 --> 00:10:02,173 说话人 说话人_00：现在我们要旋转立方体，让这个手指保持在桌面上，而另一个手指垂直地放在它上面。
112 00:10:03,533 --> 00:10:04,575 说话人 说话人_00：这个手指不应该移动过。
113 00:10:05,696 --> 00:10:09,019 说话人 SPEAKER_00: 好的，现在我们已经将立方体调整到一个位置，那个
114 00:10:09,320 --> 00:10:11,302 说话人 SPEAKER_00: 之前是体对角线的现在变成了垂直。
115 00:10:12,201 --> 00:10:19,989 说话人 SPEAKER_00: 你只需要用下面的手指，因为那只手指还在桌面上，然后用下面的手指指向立方体的其他角。
116 00:10:21,049 --> 00:10:22,010 说话人 SPEAKER_00: 所以我想让你实际做一下。
117 00:10:22,051 --> 00:10:22,410 说话人 说话人_00：出发吧。
118 00:10:22,791 --> 00:10:30,518 说话人 说话人_00：用你的拇指，将你的食指放在刚刚变成垂直的那条对角线的另一端，然后指向其他角落。
119 00:10:33,159 --> 00:10:39,225 说话人 说话人_00：幸运的是，这是 Zoom，所以你们大多数人，其他人，都不会看到你们做了什么。
120 00:10:39,442 --> 00:10:41,785 说话人 说话人_00：我看到有些人没有指向，这很不好。
121 00:10:43,408 --> 00:10:50,860 说话人 SPEAKER_00: 大多数人指出另外四个角，最常见的回答是说它们在这里，这里，这里和这里。
122 00:10:51,341 --> 00:10:54,225 说话人 SPEAKER_00: 他们指出在轴的中点上的正方形中的四个角。
123 00:10:57,610 --> 00:10:59,433 说话人 SPEAKER_00: 这是不对的，正如你可能想象的那样。
124 00:11:00,274 --> 00:11:07,086 说话人 SPEAKER_00: 很容易看出这是错误的，因为如果你想象立方体处于正常方向并数角的话，有八个角。
125 00:11:08,179 --> 00:11:09,402 说话人 说话人_00：这两个角在哪里。
126 00:11:10,243 --> 00:11:11,663 说话人 说话人_00：那么另外两个角去哪里了？
127 00:11:13,046 --> 00:11:18,533 说话人 说话人_00：有一种理论是，当你旋转立方体时，离心力使它们飞到了你的潜意识中。
128 00:11:19,553 --> 00:11:20,575 说话人 说话人_00：这并不是一个非常好的理论。
129 00:11:21,375 --> 00:11:28,164 说话者 SPEAKER_00：这里发生的事情是，除非你是像晶体学家这样的人，否则你根本不知道其他角落在哪里。
130 00:11:29,506 --> 00:11:34,692 说话者 SPEAKER_00：你可以想象到立方体的某些部分，但你无法想象其他角落的结构，它们形成了什么样的结构。
131 00:11:36,445 --> 00:11:43,653 说话者 SPEAKER_00：人们给出的一个常见反应，即正方形中的四个角落，正在做些非常奇怪的事情。
132 00:11:43,820 --> 00:11:50,248 说话者 SPEAKER_00：它试图说，好吧，我不知道立方体的这些部分在哪里，但我对立方体有些了解。
133 00:11:50,307 --> 00:11:51,830 说话人 说话人_00：我知道角落是四个一组出现的。
134 00:11:52,650 --> 00:11:59,220 说话人 说话人_00：我知道一个立方体有这种四重旋转对称性，或者两个双边对称面，一个直角旋转。
135 00:12:00,221 --> 00:12:04,225 说话人 说话人_00：所以人们在做回应时，会保留立方体的对称性。
136 00:12:05,106 --> 00:12:06,870 说话人 说话人_00：他们给出一个正方形中的四个角落。
137 00:12:08,591 --> 00:12:13,437 说话人 说话人_00：现在，他们实际上指出的，如果那样做的话，是两个金字塔，
138 00:12:14,043 --> 00:12:15,524 说话人 说话人_00：每个都有正方形底座。
139 00:12:16,265 --> 00:12:18,870 说话人 说话人_00：一个是倒置的，它们底部对底部地粘在一起。
140 00:12:19,750 --> 00:12:21,273 说话人 说话人_00：所以你可以很容易地想象出来。
141 00:12:21,774 --> 00:12:24,677 说话人 SPEAKER_00: 这是一个底座为正方形的金字塔，下面还嵌套了一个。
142 00:12:25,359 --> 00:12:28,244 说话人 SPEAKER_00: 因此现在你得到了两个手指作为这两个金字塔的顶点。
143 00:12:29,666 --> 00:12:43,745 说话人 SPEAKER_00: 这有趣的地方在于，你保留了立方体的对称性，代价是进行了一些相当激进的改变，即把面变成了顶点，把顶点变成了面。
144 00:12:44,418 --> 00:12:47,001 说话人 SPEAKER_00: 你指出的那个，如果你那样做，将会是一个八面体。
145 00:12:48,485 --> 00:12:50,868 说话人 SPEAKER_00: 它有八个面和六个顶点。
146 00:12:51,590 --> 00:12:53,533 说话人 SPEAKER_00: 一个立方体有六个面和八个顶点。
147 00:12:54,394 --> 00:13:07,455 说话人 SPEAKER_00: 所以为了保留你对立方体所知道的对称性，如果你那样做了，你做了一件非常激进的事情，那就是将面换成顶点，将顶点换成面。
148 00:13:07,890 --> 00:13:09,614 说话人 SPEAKER_00: 我应该向你展示答案的样子。
149 00:13:10,235 --> 00:13:15,323 说话人 SPEAKER_00：我要退后一步，尽量让光线充足，也许你们能看见这个立方体。
150 00:13:18,811 --> 00:13:28,567 说话人 SPEAKER_00：这是一个立方体，你们可以看到其他边形成了一种围绕中间的波浪形环。
151 00:13:30,230 --> 00:13:31,653 说话人 SPEAKER_00：所以我拍了一张它的照片。
152 00:13:34,638 --> 00:13:48,479 说话人 SPEAKER_00：这里的彩色杆是立方体的其他边，那些不接触你们指尖的边，你们的上手指连接到那些折页的三个顶点，你们的手指底部连接到最低的三个顶点那里。
153 00:13:49,860 --> 00:13:51,102 说话者 说话者_00：这就是一个立方体的样子。
154 00:13:51,183 --> 00:13:52,785 说话者 说话者_00：这是你从未想过的事情。
155 00:13:52,806 --> 00:13:55,770 说话者 说话者_00：这只是一个完全不同的立方体模型。
156 00:13:56,051 --> 00:13:57,552 说话者 说话者_00：它太不同了，我要给它起一个不同的名字。
157 00:13:57,572 --> 00:14:00,577 说话人 说话人_00: 我把它称为六面体。
158 00:14:01,908 --> 00:14:07,155 说话人 说话人_00: 有一点需要注意，六面体和立方体在概念上是完全不同的。
159 00:14:07,596 --> 00:14:11,923 说话人 说话人_00: 如果你认为一个实际上是一个立方体，你就不会知道一个是另一个。
160 00:14:12,684 --> 00:14:20,456 说话人 说话人_00: 这就像倾斜的方形和直立钻石之间的歧义，但更强大，因为你对它不熟悉。
161 00:14:21,111 --> 00:14:24,456 说话人 SPEAKER_00：这就是我的演示，证明人们确实使用坐标系。
162 00:14:24,636 --> 00:14:38,134 说话人 SPEAKER_00：如果你使用不同的坐标系来描述事物，这里我通过使对角线垂直并要求你相对于这个垂直轴来描述它，来强迫你使用不同的坐标系，那么熟悉的事物就变得完全陌生了。
163 00:14:39,297 --> 00:14:42,841 说话人 SPEAKER_00：当你相对于这个新框架看到它们时，它们就完全是不同的事物了。
164 00:14:44,384 --> 00:14:47,288 说话人 SPEAKER_00: 注意到像卷积神经网络这样的东西是没有这个特点的。
165 00:14:47,486 --> 00:14:51,630 说话人 SPEAKER_00: 它们不能看一样的东西，却有两个完全不同的内部表示。
166 00:14:53,432 --> 00:14:55,714 说话人 说话人_00：我也在向您展示我正在做解析。
167 00:14:56,053 --> 00:14:57,034 说话人 说话人_00：所以这里我已经把它着色了。
168 00:14:57,075 --> 00:15:02,659 说话人 说话人_00：所以您将其解析成我称之为“王冠”的东西，它是由三个向上和向外倾斜的三角形叶片组成。
169 00:15:04,120 --> 00:15:05,162 说话人 说话人_00：这里是一个不同的解析。
170 00:15:06,302 --> 00:15:08,404 说话人 SPEAKER_00: 同样的绿色翻盖向上向外倾斜。
171 00:15:09,066 --> 00:15:11,607 说话人 SPEAKER_00: 现在我们有一个红色翻盖向下向外倾斜。
172 00:15:12,649 --> 00:15:16,211 说话人 SPEAKER_00: 我们有一个中央矩形，你只看到矩形的两端。
173 00:15:17,153 --> 00:15:23,600 说话人 SPEAKER_00: 如果你知道，如果你能感觉到这一点，我闭上你的眼睛问你，有没有平行边？
174 00:15:24,561 --> 00:15:27,844 说话人 SPEAKER_00: 你非常清楚那两条边，两条蓝色边是平行的。
175 00:15:28,585 --> 00:15:33,570 说话人 SPEAKER_00: 你通常不会注意到其他平行的边，尽管你知道通过对称性，必须还有其他一对。
176 00:15:34,490 --> 00:15:35,432 说话人 SPEAKER_00: 类似地，对于王冠。
177 00:15:35,471 --> 00:15:42,739 说话人 SPEAKER_00: 如果你看到了王冠，然后我让你闭上眼睛，问你平行边在哪里，你看不到任何平行边。
178 00:15:43,376 --> 00:15:48,263 说话人 SPEAKER_00: 这是因为您用于那些叶片的坐标系与边缘对齐。
179 00:15:48,923 --> 00:15:52,828 说话人 SPEAKER_00: 只有当它们与您使用的坐标系对齐时，您才会注意到平行边缘。
180 00:15:53,590 --> 00:15:58,356 说话人 SPEAKER_00: 所以对于这个矩形，平行边缘与坐标系对齐，而对于叶片则不对齐。
181 00:15:59,118 --> 00:16:06,346 说话人 SPEAKER_00: 所以您知道那两条蓝色边缘是平行的，但您不知道其中一条绿色边缘和一条红色边缘也是平行的。
182 00:16:10,445 --> 00:16:16,394 说话人 SPEAKER_00：所以这不像 NECA 魔方那种模糊性，当你翻转它时，你会认为现实中的事物是不同的。
183 00:16:16,453 --> 00:16:17,575 说话人 SPEAKER_00：事物处于不同的深度。
184 00:16:18,376 --> 00:16:21,761 说话人 SPEAKER_00：这就像下个周末，我们应该去拜访亲戚。
185 00:16:22,822 --> 00:16:25,447 说话人 SPEAKER_00：所以如果你把句子“下个周末，我们应该去拜访亲戚”取出来。
186 00:16:26,107 --> 00:16:31,054 说话人 SPEAKER_00: 这可以意味着下个周末，我们将要去做的是拜访亲戚。
187 00:16:31,676 --> 00:16:36,283 说话人 SPEAKER_00: 或者这也可能意味着下个周末，我们将要的是拜访亲戚。
188 00:16:37,158 --> 00:16:39,019 说话人 SPEAKER_00: 现在，这些词义完全不同。
189 00:16:39,620 --> 00:16:41,423 说话人 SPEAKER_00: 它们恰好具有相同的真值条件。
190 00:16:41,703 --> 00:16:44,607 说话人 SPEAKER_00: 在真值条件意义上，它们的意思是相同的。
191 00:16:45,109 --> 00:16:48,393 说话人 SPEAKER_00: 因为如果你在拜访亲戚，你就是拜访亲戚。
192 00:16:49,193 --> 00:16:50,475 说话人 SPEAKER_00: 就是这样一种歧义。
193 00:16:50,836 --> 00:16:54,480 说话人 SPEAKER_00: 对于世界上正在发生的事情没有分歧，但看待这个句子的方式完全不同。
194 00:16:59,047 --> 00:17:03,452 说话人 SPEAKER_00: 这是在 20 世纪 70 年代绘制的。
195 00:17:03,994 --> 00:17:06,237 说话人 SPEAKER_00: 这就是 20 世纪 70 年代的 AI。
196 00:17:06,637 --> 00:17:12,145 说话人 SPEAKER_00: 这是对王冠解释的一种结构描述。
197 00:17:13,608 --> 00:17:17,074 说话人 SPEAKER_00: 所以你有了所有各个部分在层次结构中的节点。
198 00:17:17,855 --> 00:17:20,038 说话人 SPEAKER_00：我也在弧线上放了一些东西。
199 00:17:20,057 --> 00:17:25,527 说话人 SPEAKER_00：这里的 Rwx 是王冠和叶片之间的关系。
200 00:17:26,508 --> 00:17:28,651 说话人 SPEAKER_00：这可以表示为一个矩阵。
201 00:17:28,671 --> 00:17:34,941 说话人 SPEAKER_00：这实际上是王冠的固有参考系与叶片的固有参考系之间的关系。
202 00:17:35,680 --> 00:17:40,226 说话人 SPEAKER_00: 注意，如果我改变我的视角，这并不会改变。
203 00:17:41,587 --> 00:17:45,412 说话人 SPEAKER_00: 所以这种关系将是一个很好的东西，可以放入神经网络的权重中。
204 00:17:45,893 --> 00:17:49,678 说话人 SPEAKER_00: 因为您希望神经网络能够独立于视角来识别形状。
205 00:17:50,519 --> 00:17:55,085 说话人 SPEAKER_00: 而 RWX 是关于形状的知识，它独立于视角。
206 00:17:57,146 --> 00:17:59,349 说话人 SPEAKER_00: 这是锯齿形解释。
207 00:18:00,592 --> 00:18:03,055 说话人 SPEAKER_00: 而这里我添加了另一件事。
208 00:18:03,794 --> 00:18:05,396 说话人 SPEAKER_00：重蓝色框中的东西。
209 00:18:06,498 --> 00:18:11,747 说话人 SPEAKER_00：它们是节点与观察者之间的关系。
210 00:18:12,468 --> 00:18:13,589 说话人 SPEAKER_00：这需要更加明确。
211 00:18:13,971 --> 00:18:23,405 说话人 SPEAKER_00：王冠固有坐标系与观察者固有坐标系（即眼球）之间的坐标变换是 RWV。
212 00:18:24,803 --> 00:18:26,443 说话人 说话人_00：这完全是另一种不同的事情。
213 00:18:26,964 --> 00:18:28,967 说话人 说话人_00：因为当你改变视角时，这也会改变。
214 00:18:29,606 --> 00:18:35,152 说话人 说话人_00：实际上，当你改变视角时，所有那些蓝色框中的东西都会以一致的方式一起改变。
215 00:18:36,453 --> 00:18:43,420 说话人 说话人_00：这里有一个简单的关联，那就是如果你取 RWV，然后乘以 RWX，你得到 RXV。
216 00:18:44,560 --> 00:18:48,825 说话人 SPEAKER_00：您可以将观点信息轻松传播到结构描述中。
217 00:18:50,026 --> 00:18:52,228 说话人 SPEAKER_00：这就是我认为的内心图像。
218 00:18:52,444 --> 00:18:54,106 说话人 SPEAKER_00: 而不是一堆像素。
219 00:18:55,148 --> 00:18:58,794 说话人 SPEAKER_00: 这是一个带有相关视角信息的结构描述。
220 00:19:02,298 --> 00:19:04,682 说话人 SPEAKER_00: 这解释了许多心理图像的特性。
221 00:19:05,163 --> 00:19:11,311 说话人 SPEAKER_00: 比如，如果你要对像 RWX 这样的东西进行推理，你会形成一个心理图像。
222 00:19:12,512 --> 00:19:14,736 说话人 SPEAKER_00：也就是说，你填充，你选择一个视角。
223 00:19:15,857 --> 00:19:20,865 说话人 SPEAKER_00：我想再做一个演示来让你信服，解决心理图像问题时，你总是选择一个视角。
224 00:19:21,352 --> 00:19:25,556 说话人 SPEAKER_00：所以我将给你另一个非常简单的心理意象问题，冒着超时风险。
225 00:19:26,175 --> 00:19:36,846 说话人 SPEAKER_00：想象一下，你处于一个特定的点，然后向东走一英里，然后向北走一英里，然后再向东走一英里。
226 00:19:36,905 --> 00:19:39,667 说话人 SPEAKER_00：你返回起点的方向是什么？
227 00:19:40,890 --> 00:19:42,310 说话人 SPEAKER_00：这不是一个很难的问题。
228 00:19:43,051 --> 00:19:45,614 说话人 SPEAKER_00: 它有点偏南，而且相当偏西，对吧？
229 00:19:46,414 --> 00:19:50,278 说话人 SPEAKER_00: 它并不完全是西南方向，但有点像西南方向。
230 00:19:50,545 --> 00:20:00,133 说话人 SPEAKER_00: 现在，当你完成那个任务时，从你的视角来看，你想象的是先向东走了一英里，然后向北走了一英里，再向东走了一英里。
231 00:20:01,497 --> 00:20:02,917 说话人 SPEAKER_00: 我来告诉你你没有想象到的事情。
232 00:20:03,318 --> 00:20:07,301 说话人 SPEAKER_00：你没有想到你向东走了一英里，然后又向北走了一英里，然后再向东走了一英里。
233 00:20:07,982 --> 00:20:12,547 说话人 SPEAKER_00：如果你把北边不设为上方，你完全可以完美地解决这个问题，但你把北边设为上方了。
234 00:20:13,087 --> 00:20:14,348 说话人 SPEAKER_00：你也没有想到这一点。
235 00:20:14,749 --> 00:20:17,231 说话人 SPEAKER_00：你向东走了一英里，然后向北走了一英里，然后再向东走了一英里。
236 00:20:17,991 --> 00:20:18,772 说话者 SPEAKER_00: 你没有想象过这一点。
237 00:20:18,792 --> 00:20:21,355 说话者 SPEAKER_00: 你向东走一英里，然后向北走一英里，以此类推。
238 00:20:21,375 --> 00:20:28,382 说话者 SPEAKER_00: 你在特定的比例、特定的方向和特定的位置上想象过它。
239 00:20:28,480 --> 00:20:32,164 说话者 SPEAKER_00: 你可以回答关于它大概有多大等问题。
240 00:20:32,184 --> 00:20:40,474 说话人 SPEAKER_00：这就是解决这些涉及使用事物之间关系的任务时的证据，你会在脑海中形成一个图像。
241 00:20:41,457 --> 00:20:46,182 说话人 SPEAKER_00：好的，关于心理图像的内容就到这里。
242 00:20:46,202 --> 00:20:49,287 说话人 SPEAKER_00：所以我现在将为您简要介绍对比学习。
243 00:20:50,208 --> 00:20:58,077 说话人 SPEAKER_00：所以在这里演讲中存在一个完全的脱节，但我很快就会回来。
244 00:20:58,278 --> 00:20:58,317 未知说话者：嗯
245 00:20:59,497 --> 00:21:08,147 说话者 SPEAKER_00：与自监督学习不同，我们试图使两张图像的不同裁剪具有相同的表示。
246 00:21:12,011 --> 00:21:24,728 说话者 SPEAKER_00：很久以前，Becker 和 Hinton 有一篇论文，我们就是用这种方法来发现图像中的低级连贯性，比如表面的连续性或表面的深度。
247 00:21:25,788 --> 00:21:29,614 说话者 SPEAKER_00：自从那时以来，它已经得到了很大的改进，并且已经被用于进行分类等任务。
也就是说，你取一个包含一个突出对象的图像，然后你说，如果我裁剪包含该对象任何部分的图像，它应该与包含该对象部分的另一个裁剪图像具有相同的表示。
249 00:21:49,422 --> 00:21:50,022 说话者 说话者_00：并且
250 00：21：50,492 --> 00：21：53,636 演讲者 SPEAKER_00：这在过去几年里已经发展了很多。
251 00:21:54,237 --> 00:22:00,344 说话者 SPEAKER_00：我将要谈论的是我所在的多伦多小组几年前开发的一个模型，名为 SimClear，但还有很多其他模型。
252 00:22:00,845 --> 00:22:02,287 说话人 SPEAKER_00: 从那时起，事情已经有所改善。
253 00:22:05,630 --> 00:22:16,702 说话人 SPEAKER_00: 在 SimClear 中，你取一个 ImageX，取两个不同的裁剪，并对每个裁剪进行不同的颜色失真。
254 00:22:16,970 --> 00:22:20,214 说话人 SPEAKER_00: 这样做是为了防止它使用颜色直方图来判断它们是相同的。
255 00:22:21,737 --> 00:22:25,122 说话人 SPEAKER_00: 所以你玩弄颜色，让它不能简单地使用颜色。
256 00:22:27,325 --> 00:22:31,951 说话者 SPEAKER_00: 这就得到了 x̄i 和 x̄j。
257 00:22:32,692 --> 00:22:44,170 说话者 SPEAKER_00: 然后将这些输入到相同的神经网络 F 中，然后得到表示 H。然后，将表示 H 输入到另一个神经网络中，该神经网络对其进行了一点压缩。
258 00:22:44,931 --> 00:22:46,452 说话者 SPEAKER_00: 它进入低维空间。
259 00:22:46,923 --> 00:22:50,567 说话者 SPEAKER_00: 这是一个额外的复杂性，我不会解释，但它使它工作得更好。
260 00:22:51,768 --> 00:22:52,750 说话人 SPEAKER_00: 你可以不做那样做。
261 00:22:53,631 --> 00:22:55,952 说话人 SPEAKER_00: 你会得到两个嵌入 zi 和 zj。
262 00:22:57,234 --> 00:23:00,557 说话人 SPEAKER_00: 你的目标是最大化这些向量之间的一致性。
263 00:23:02,299 --> 00:23:08,567 说话人 SPEAKER_00: 因此，你从随机神经网络、随机神经网络权重开始。
264 00:23:09,288 --> 00:23:12,811 说话者 SPEAKER_00: 让我们取两个补丁，并将它们通过这些变换。
265 00:23:13,061 --> 00:23:15,285 说话者 SPEAKER_00: 让我们尝试使 zi 与 zj 相同。
266 00:23:15,765 --> 00:23:25,277 说话者 SPEAKER_00: 因此，我们将 i 的组件和 j 的组件之间的平方差进行反向传播。嘿， presto，你发现的是一切都在崩溃。
267 00:23:27,378 --> 00:23:31,805 说话者 SPEAKER_00: 对于每张图像，它总是会生成相同的 zi 和 zj。
268 00:23:32,464 --> 00:23:34,627 说话者 SPEAKER_00: 然后你就会意识到，嗯，这并不是我所说的“一致”。
269 00:23:35,068 --> 00:23:42,057 说话者 SPEAKER_00: 我的意思是，当你从同一张图片中获取两个不同的区域时，它们应该是相同的；当你从不同的图片中获取两个不同的区域时，它们应该是不同的。
270 00:23:42,609 --> 00:23:44,352 说话者 SPEAKER_00: 否则，这就不算真正的“一致”，对吧？
271 00:23:48,798 --> 00:23:50,580 说话者 SPEAKER_00: 所以你需要有负例。
272 00:23:50,942 --> 00:23:54,646 说话人 SPEAKER_00: 你必须展示来自不同图像的裁剪，并说明这些应该不同。
273 00:23:55,748 --> 00:23:59,333 说话人 SPEAKER_00: 如果它们已经不同，你就不要试图让它们变得更多不同。
274 00:24:00,114 --> 00:24:03,298 说话人 SPEAKER_00: 让事物变得非常不同很容易，但这不是你想要的。
275 00:24:03,358 --> 00:24:04,901 说话人 SPEAKER_00: 你只是要确保它们足够不同。
276 00:24:04,980 --> 00:24:09,106 说话人 SPEAKER_00：所以来自不同图像的作物不会被看作来自同一图像。
277 00:24:09,407 --> 00:24:14,252 说话人 SPEAKER_00：如果它们碰巧非常相似，你会把它们分开，这样就可以阻止你的表示坍缩。
278 00:24:14,272 --> 00:24:17,174 说话人 SPEAKER_00：这被称为对比学习，它非常有效。
279 00:24:18,836 --> 00:24:30,027 说话人 SPEAKER_00：所以你可以通过尝试最大化来自同一图像的两个图像块之间的表示的一致性来进行无监督学习。
280 00:24:31,469 --> 00:24:38,115 说话者 SPEAKER_00: 在你完成之后，你只需将图像块表示输入到线性分类器中。
281 00:24:38,617 --> 00:24:44,965 说话者 SPEAKER_00: 一系列权重，这样你就可以将表示乘以权重矩阵，通过 softmax 得到类别标签。
282 00:24:45,807 --> 00:24:48,130 说话者 SPEAKER_00: 然后通过梯度下降进行训练。
283 00:24:49,030 --> 00:24:55,538 说话者 SPEAKER_00: 你会发现这几乎和在有标签数据上训练一样好。
284 00:24:56,159 --> 00:24:59,663 说话人 SPEAKER_00：现在你只训练了基于标记数据的最后一个线性分类器。
285 00:25:00,484 --> 00:25:02,686 说话人 SPEAKER_00：之前的层是在未标记数据上训练的。
286 00:25:03,729 --> 00:25:08,253 说话人 SPEAKER_00：而你成功地在不需要标签的情况下训练了你的表示。
287 00:25:12,048 --> 00:25:13,509 说话人 SPEAKER_00：现在，这里有个问题。
288 00:25:14,671 --> 00:25:20,459 说话人 SPEAKER_00: 它工作得非常好，但它实际上是在混淆物体和整个场景。
289 00:25:21,721 --> 00:25:31,614 说话人 SPEAKER_00: 因此，说来自同一场景的两个不同补丁应该在场景级别获得相同的向量标签是有意义的，因为它们来自同一场景。
290 00:25:33,175 --> 00:25:37,842 说话人 SPEAKER_00: 但如果其中一个补丁包含物体 A 和 B 的片段，而另一个补丁包含物体 A 和 C 的片段怎么办？
291 00:25:38,261 --> 00:25:41,987 说话人 SPEAKER_00: 你真的不希望这两个补丁在物体级别上有相同的表示。
292 00:25:42,557 --> 00:25:45,520 说话人 SPEAKER_00：我们必须区分这些不同级别的表示。
293 00:25:46,882 --> 00:25:56,491 说话人 SPEAKER_00：对于对比学习，如果你不使用任何形式的门控或注意力，那么实际上你是在 seam 级别进行学习。
294 00:25:59,335 --> 00:26:12,548 说话人 SPEAKER_00：我们希望的是，在对象级别得到的表示，如果两个补丁都来自对象 A，则应该是相同的，但如果一个补丁来自对象 A，另一个补丁来自对象 B，则应该是不同的。
295 00:26:12,982 --> 00:26:16,587 说话人 SPEAKER_00：为了做到这一点，我们需要某种形式的注意力来判断它们是否真正来自同一事物。
296 00:26:17,909 --> 00:26:19,490 说话人 SPEAKER_00: 因此，Glom 被设计来做这件事。
297 00:26:19,550 --> 00:26:28,942 说话人 SPEAKER_00: 它被设计用来采用对比学习，并引入类似 Transformers 中的注意力机制，以便不试图说事物不同时它们实际上是相同的。
298 00:26:31,385 --> 00:26:35,211 说话人 SPEAKER_00: 我应该在这里提到，你们大多数人都会熟悉 BERT。
299 00:26:36,051 --> 00:26:42,180 说话人 SPEAKER_00: 你们可以将输入到 BERT 中的词片段想象成我在这里使用的图像块。
300 00:26:42,380 --> 00:26:46,544 说话人 说话人_00：在 BERT 中，你有一整列相同词片段的表示。
301 00:26:47,865 --> 00:26:55,392 说话人 说话人_00：在 BERT 中，当你向上移动时，可能发生的情况是，你得到了语义上更丰富的表示。
302 00:26:56,673 --> 00:27:02,198 说话人 说话人_00：但在 BERT 中，并没有尝试获取更大事物的表示，比如整个短语。
303 00:27:05,121 --> 00:27:08,044 说话人 说话人_00：接下来我要谈论的，将是一种修改 BERT 的方法。
304 00:27:08,104 --> 00:27:11,626 说话人 说话人_00：随着你向上移动，你会得到越来越大的一致性岛屿。
305 00:27:12,063 --> 00:27:26,823 说话人 说话人_00：例如，经过几层之后，像 New 和 York 这样的词将会有不同的 York 片段，假设他有两个不同的片段，如果按照 Glomlite 方式处理，它们将会有完全相同的表示。
306 00:27:27,644 --> 00:27:37,257 说话人 说话人_00：然后，再向上提升一个层次，New 的片段，嗯，New 可能是一个独立的事物，但 York 的所有片段将会有完全相同的表示。
307 00:27:38,898 --> 00:27:40,280 说话人 说话人_00：它们将会有这个一致性岛屿。
308 00:27:40,732 --> 00:27:44,356 说话人 SPEAKER_00: 这将是一个复合事物的表示。
309 00:27:44,696 --> 00:27:48,401 说话人 SPEAKER_00: 随着你往上走，你会得到这些代表越来越大事物的共识岛屿。
310 00:27:49,121 --> 00:27:51,243 说话人 SPEAKER_00: 这将是一种更有用的 BERT。
311 00:27:51,743 --> 00:28:10,722 说话人 SPEAKER_00: 因为不是通过取代表词片段的向量，然后通过取每个分量的最大值等方式将它们混合在一起，例如，取每个分量的最大值，这只是一个疯狂的做法，你会在学习过程中明确地形成部分-整体层次结构中更大部分的表示。
312 00:28:12,204 --> 00:28:15,969 说话人 SPEAKER_00: 好的。
313 00:28:15,989 --> 00:28:29,103 说话人 SPEAKER_00: 在 Glom 中，我们追求的是一种比由于表面在图像的邻近区域倾向于具有相同的深度和方向而产生的空间连贯性更复杂的空间连贯性。
314 00:28:30,243 --> 00:28:41,115 说话人 SPEAKER_00: 我们追求的是这样的空间连贯性：如果你在图像中找到一个嘴巴，然后在图像中找到一个鼻子，并且它们之间有正确的关系来构成一个脸，
315 00:28:41,450 --> 00:28:43,633 说话人 SPEAKER_00: 那就是一种特定的连贯性。
316 00:28:44,334 --> 00:28:50,561 说话人 SPEAKER_00: 我们想要无监督地进行，并发现图像中的这种一致性。
317 00:28:53,946 --> 00:28:57,832 说话人 SPEAKER_00: 在我详细介绍 GLOM 之前，我想先声明一下。
318 00:29:00,976 --> 00:29:05,701 说话人 SPEAKER_00: 多年来，计算机视觉将视觉视为静态图像，具有统一的分辨率，
319 00:29:06,069 --> 00:29:07,090 说话人 SPEAKER_00: 你想要描述其中的内容。
320 00:29:08,332 --> 00:29:10,054 说话人 SPEAKER_00：现实世界的视觉工作方式并非如此。
321 00:29:10,473 --> 00:29:14,817 说话人 SPEAKER_00：在现实世界中，这实际上是一个循环，你决定看向哪里。
322 00:29:14,837 --> 00:29:19,563 说话人 SPEAKER_00：如果你是人或者机器人，你最好要智能地去做这件事。
323 00:29:20,683 --> 00:29:24,827 说话人 SPEAKER_00：这为你提供了一个光阵列的样本。
324 00:29:24,867 --> 00:29:30,112 说话人 SPEAKER_00：它将光阵列、入射光转换成视网膜图像。
325 00:29:30,833 --> 00:29:34,997 说话人 SPEAKER_00：在你的视网膜上，中间部分具有高分辨率，边缘部分具有低分辨率。
326 00:29:35,787 --> 00:29:44,383 说话人 SPEAKER_00：因此，你专注于特定的细节，永远不会以均匀的分辨率处理整个图像。
327 00:29:44,804 --> 00:29:52,377 说话人 SPEAKER_00：你总是专注于某个事物，并处理你注视的地方以高分辨率，其他地方则以低得多分辨率，尤其是在边缘。
328 00:29:53,557 --> 00:30:07,615 说话者 说话者_00：我将忽略所有关于如何决定看哪里以及如何整合来自不同注视点的信息的复杂性，让我们只谈谈第一个注视点或一个新图像。
329 00:30:08,176 --> 00:30:11,320 说话者 说话者_00：所以你看了某个地方，那么在第一个注视点上会发生什么？
330 00:30:12,103 --> 00:30:18,230 说话者 说话者_00：我们知道大脑中的相同硬件将在下一个注视点被重复使用，但让我们先考虑第一个注视点。
331 00:30:20,759 --> 00:30:23,162 说话者 说话者_00：所以，最后这是架构的图片。
332 00:30:24,884 --> 00:30:34,817 说话人 SPEAKER_00: 这就是单个位置的架构，就像 BERT 中的单个词片段。
333 00:30:34,836 --> 00:30:38,321 说话人 SPEAKER_00: 这显示了多个帧发生的情况。
334 00:30:38,862 --> 00:30:42,988 说话人 SPEAKER_00: 所以 Glom 实际上是为视频设计的，但我只谈论将其应用于静态图像。
335 00:30:43,848 --> 00:30:49,415 说话人 SPEAKER_00: 你应该把静态图像想成一个非常无聊的视频，其中所有帧都彼此相同。
336 00:30:50,981 --> 00:30:54,705 说话人 SPEAKER_00：我现在向您展示三个相邻的层级。
337 00:30:56,708 --> 00:30:59,029 说话人 SPEAKER_00：并且向您展示随着时间的推移发生了什么。
338 00:30:59,049 --> 00:31:04,655 说话人 SPEAKER_00：所以如果您看中间层级，可能那是一个主要部分层级。
339 00:31:06,218 --> 00:31:11,522 说话人 SPEAKER_00：并且看看那个写着层级 L 的框。它在第四帧。
340 00:31:13,144 --> 00:31:14,645 说话人 SPEAKER_00：那么右手水平 L 框。
341 00:31:15,847 --> 00:31:20,112 说话人 SPEAKER_00：那么让我们看看那个框的状态，那个嵌入的状态是如何确定的。
342 00:31:20,547 --> 00:31:22,368 说话人 SPEAKER_00：所以在这个框内部，我们将得到一个嵌入。
343 00:31:23,590 --> 00:31:32,681 说话人 SPEAKER_00：而这个嵌入将代表那个小图像块在主要部分级别的状态。
344 00:31:35,565 --> 00:31:44,275 说话人 SPEAKER_00: 在这个图中，所有这些嵌入都会始终用于视网膜图像的同一块区域。
345 00:31:45,916 --> 00:31:47,919 说话人 SPEAKER_00: 好的。
346 00:31:47,939 --> 00:31:50,402 说话人 SPEAKER_00: 层级 L 的嵌入
347 00:31:50,567 --> 00:31:51,628 说话人 SPEAKER_00: 在右侧。
348 00:31:51,689 --> 00:31:55,473 说话人 SPEAKER_00: 你可以看到这里有三件事情决定了它。
349 00:31:55,493 --> 00:31:56,455 说话人 SPEAKER_00: 这是绿色的箭头。
350 00:31:56,476 --> 00:31:59,960 说话人 SPEAKER_00: 对于静态图像，绿色的箭头相当无聊。
351 00:32:00,000 --> 00:32:05,267 说话人 SPEAKER_00: 它只是说，你应该与水平 L 的前一个状态相似。所以它只是在做时间积分。
352 00:32:07,088 --> 00:32:13,397 说话人 SPEAKER_00：实际上，蓝色箭头是一个包含几个隐藏层的神经网络。
353 00:32:14,598 --> 00:32:17,502 说话人 SPEAKER_00：我只是在向你展示嵌入层，而不是整个神经网络的全部层。
354 00:32:18,277 --> 00:32:21,299 说话人 SPEAKER_00：我们需要几个隐藏层来完成所需的坐标变换。
355 00:32:22,461 --> 00:32:29,189 说话人 SPEAKER_00：蓝色箭头基本上是在前一个时间步的下一级获取信息。
356 00:32:30,210 --> 00:32:35,275 说话人 SPEAKER_00：所以层级 L 减一在第三帧可能代表我认为我可能是一个鼻孔。
357 00:32:36,316 --> 00:32:41,141 说话人 SPEAKER_00：如果你认为你可能是鼻孔，那么在下一个层级你预测的是鼻子。
358 00:32:42,162 --> 00:32:47,607 说话人 SPEAKER_00：更重要的是，如果你有一个鼻孔的坐标帧，你可以预测鼻子的坐标帧。
359 00:32:47,790 --> 00:32:53,176 说话人 SPEAKER_00：可能不是完全准确，但你对于节点的方向、位置、比例有一个相当好的了解。
360 00:32:53,196 --> 00:32:54,959 说话人 SPEAKER_00: 所以那个自下而上的神经网络。
361 00:32:56,420 --> 00:32:56,579 说话人 SPEAKER_00: 是。
362 00:32:58,162 --> 00:33:06,391 说话人 SPEAKER_00: 这是一个可以接受任何心智部分或层次的神经网络，所以当你取一个鼻孔时，它也可以接受方向盘并从方向盘预测汽车。
363 00:33:07,090 --> 00:33:11,836 说话人 SPEAKER_00: 并预测你在下一个层次上拥有的东西。
364 00:33:14,538 --> 00:33:17,021 说话人 SPEAKER_00: 红箭头代表从上至下的神经网络。
365 00:33:17,895 --> 00:33:25,045 说话人 SPEAKER_00: 所以红箭头是从整个面部预测鼻子的。
366 00:33:25,846 --> 00:33:28,409 说话人 SPEAKER_00: 再次强调，它有几个隐藏层来协调变换。
367 00:33:29,250 --> 00:33:42,766 说话人 SPEAKER_00: 因为如果你知道面部的坐标系，并且知道面部与鼻子之间的关系，这些关系将体现在那个自上而下的神经网络权重中，那么你就可以预测出这是一个鼻子，以及鼻子的姿态。
368 00:33:43,567 --> 00:33:46,671 说话人 SPEAKER_00: 所有这些都将包含在那个嵌入向量中的活动中。
369 00:33:48,153 --> 00:33:53,640 说话人 SPEAKER_00: 好的，现在这一切都在硬件的一列中发生。
370 00:33:54,079 --> 00:33:56,323 说话人 SPEAKER_00: 这都是关于图像的特定区域。
371 00:33:57,203 --> 00:34:01,769 说话人 SPEAKER_00: 所以这非常像 BERT 中的一个单词片段正在发生的事情。
372 00:34:02,170 --> 00:34:03,791 说话人 SPEAKER_00: 你们都有这些层次的表现。
373 00:34:04,893 --> 00:34:11,681 说话人 SPEAKER_00: 究竟它与 BERT 的关系是什么，有点令人困惑。
374 00:34:11,840 --> 00:34:16,606 说话人 SPEAKER_00: 我会在最后提供一篇长篇论文的参考文献，其中有一节专门讲述这与 BERT 的关系。
375 00:34:17,110 --> 00:34:19,652 说话人 SPEAKER_00: 但因为这里有时间步长，所以有点令人困惑。
376 00:34:20,494 --> 00:34:23,898 说话人 SPEAKER_00: 这使得一切更加复杂。
377 00:34:23,938 --> 00:34:25,641 说话人 SPEAKER_00: 好的。
378 00:34:26,862 --> 00:34:29,646 说话人 SPEAKER_00: 所以有三个方面决定了级别和嵌入。
379 00:34:30,307 --> 00:34:34,253 说话人 SPEAKER_00: 但是还有一个第四个因素，就在底部黑色部分。
380 00:34:35,936 --> 00:34:38,639 说话人 SPEAKER_00：这就是不同地点之间相互作用的唯一方式。
381 00:34:39,661 --> 00:34:42,864 说话人 SPEAKER_00：这就是一个非常简化的变压器形式。
382 00:34:43,519 --> 00:34:52,090 说话人 SPEAKER_00：如果你以 BERT 中的变压器为例，并说，让我们让嵌入、键、查询和值都彼此相同。
383 00:34:53,052 --> 00:34:54,153 说话人 SPEAKER_00：我们只有一个向量。
384 00:34:55,675 --> 00:35:05,228 说话人 SPEAKER_00：现在你试图让一列中的 L 层嵌入与附近列的 L 层嵌入相同。
385 00:35:07,110 --> 00:35:08,231 说话人 SPEAKER_00：但这将是受控的。
386 00:35:08,371 --> 00:35:13,358 说话人 SPEAKER_00：只有当它已经非常相似时，你才会尝试让它相同。
387 00:35:15,615 --> 00:35:17,057 说话人 SPEAKER_00：这就是注意力的工作方式。
388 00:35:18,418 --> 00:35:21,983 说话人 SPEAKER_00: 你在位置 X 取 L 层嵌入，即 LX。
389 00:35:23,023 --> 00:35:26,288 说话人 SPEAKER_00: 然后在附近的 Y 位置取 L 层嵌入，即 LY。
390 00:35:27,369 --> 00:35:32,675 说话人 SPEAKER_00: 你计算标量积，然后取指数并归一化。
391 00:35:33,056 --> 00:35:34,177 说话人 SPEAKER_00: 换句话说，你执行 softmax 操作。
392 00:35:35,438 --> 00:35:43,648 说话人 SPEAKER_00: 这就给出了你在希望使 LX 与 LY 相同的愿望中使用的权重。
393 00:35:45,585 --> 00:35:56,436 说话人 SPEAKER_00: 因此，这个程序从邻居那里产生的输入是附近列嵌入级别的注意力加权平均值。
394 00:35:57,677 --> 00:35:59,539 说话人 SPEAKER_00: 这是你额外获得的一个输入。
395 00:35:59,639 --> 00:36:02,201 说话人 SPEAKER_00: 它试图让你与附近的事物达成一致。
396 00:36:02,722 --> 00:36:05,224 说话人 说话人_00：这就是导致你们得到这些共识孤岛的原因。
397 00:36:10,708 --> 00:36:14,833 说话人 说话人_00：所以回到这张图，我认为
398 00:36:17,344 --> 00:36:18,887 说话人 说话人_00：是的。
399 00:36:18,907 --> 00:36:22,152 说话人 说话人_00：这是我们希望看到的，以及原因。
400 00:36:23,815 --> 00:36:40,003 说话人 SPEAKER_00: 我们在对象层面上达成那么大的共识，是因为我们试图在那里达成共识，我们试图学习从红色箭头到上一级以及从绿色箭头到上一级的坐标变换，以便我们达成共识。
401 00:36:41,766 --> 00:36:41,867 说话人 SPEAKER_00: 好的。
402 00:36:45,509 --> 00:36:57,846 说话人 SPEAKER_00: 现在，我们需要关注的一件事是，在感知方面困难的事情，在语言中可能并不那么糟糕，但在视觉感知中可能更糟，那就是有很多歧义。
403 00:36:58,746 --> 00:37:01,269 说话人 SPEAKER_00: 例如，如果我正在看一条线图，我会看到一个圆。
404 00:37:02,351 --> 00:37:08,460 说话人 SPEAKER_00: 好吧，一个圆可以是脸的右眼，也可以是脸的左眼，还可以是汽车的前轮或后轮。
405 00:37:08,840 --> 00:37:10,722 说话人 SPEAKER_00: 圆可以代表各种各样的事物。
406 00:37:10,762 --> 00:37:13,726 说话人 SPEAKER_00: 我们希望消除对圆的歧义。
407 00:37:14,838 --> 00:37:19,304 说话人 SPEAKER_00: 并且有一系列使用诸如马尔可夫随机场等方法的研究。
408 00:37:19,985 --> 00:37:33,342 说话人 SPEAKER_00：这里我们需要一个变分马尔可夫随机场，我称之为变换随机场，因为例如眼睛和嘴巴之间的交互需要通过角变换进行门控。
409 00:37:34,282 --> 00:37:37,206 你知道，让我们以鼻子和嘴巴为例，因为那是我标准的东西。
410 00:37:38,027 --> 00:37:43,494 如果你拿一个可能是鼻子的东西，你想问，有没有人支持鼻子的想法？
411 00:37:44,976 --> 00:37:58,177 好吧，你希望向附近的所有东西发送一条消息，说，你有没有正确的姿态和正确的身份来支持我是鼻子的想法？
412 00:37:59,398 --> 00:38:03,744 说话人 SPEAKER_00: 例如，您想从鼻子发送一条消息
413 00:38:04,248 --> 00:38:17,543 说话人 SPEAKER_00: 您会向所有附近的地点发送消息，询问是否有人有一个与我预测的鼻子姿态相对应的嘴巴姿态，通过将鼻子和嘴巴之间的坐标变换相乘，现在我可以预测嘴巴的姿态。
414 00:38:18,143 --> 00:38:21,067 说话人 SPEAKER_00: 是否有任何人拥有那种姿态，并认为那可能是一个嘴巴？
415 00:38:22,208 --> 00:38:24,831 说话人 SPEAKER_00: 我想您可以看到，您将不得不发送很多不同的消息。
416 00:38:26,632 --> 00:38:29,916 说话人 SPEAKER_00：对于可能支持你的每一种其他事物，你都需要发送不同的信息。
417 00:38:29,936 --> 00:38:32,500 说话人 SPEAKER_00：所以你需要一个多头
418 00:38:33,255 --> 00:38:41,666 说话人 SPEAKER_00：变换器，它将执行这些坐标变换，并且在返回时必须对逆变换进行角变换。
419 00:38:42,186 --> 00:38:49,134 说话人 SPEAKER_00：因为如果鼠标支持你，它需要支持的是鼻子，而不是嘴巴的姿态，而是适当的姿态。
420 00:38:50,094 --> 00:38:53,820 说话人 SPEAKER_00: 这将变得非常复杂，你将会有平方级别的坐标变换交互。
421 00:38:54,701 --> 00:38:57,963 说话人 SPEAKER_00: 有一种更简单的方法，这被称为霍夫变换。
422 00:38:59,065 --> 00:39:02,789 说话人 SPEAKER_00: 至少如果你有表示歧义的方法，它会更简单。
423 00:39:06,043 --> 00:39:16,135 说话人 SPEAKER_00: 所以，你不会像鼻子和嘴巴这样的部分之间进行直接交互，而是让每个部分预测整体。
424 00:39:17,737 --> 00:39:23,704 说话人 SPEAKER_00：鼻子可以预测面部，也可以预测面部的姿态，嘴巴也可以预测面部。
425 00:39:24,625 --> 00:39:29,331 说话人 SPEAKER_00：现在，这些将在 Glom 的不同列中，但在 Glom 的一个列中，你将有一个鼻子预测面部。
426 00:39:30,152 --> 00:39:32,534 说话人 SPEAKER_00：在相邻的列中，你将有一个嘴巴预测面部。
427 00:39:33,375 --> 00:39:35,577 说话人 SPEAKER_00：这两个面部应该是相同的，
428 00:39:35,844 --> 00:39:37,007 说话者 SPEAKER_00：如果这真是一张脸。
所以当你对附近事物进行注意力加权平均时，你所做的是确认你所拥有的假设，即应该在一列假设中的假设，这个姿势的脸，得到了来自附近列的支持，这些列从非常不同的数据中推导出相同的嵌入。
430 00:40:00,940 --> 00:40:03,304 一个人是从鼻子推导出来的，另一个人是从嘴巴推导出来的。
431 00:40:05,326 --> 00:40:07,347 说话者 说话者_00：这不需要任何动态路由。
432 00：40：08,789 --> 00：40：15,938 发言者 SPEAKER_00：因为嵌入总是指的是图像的同一小块中发生的事情，在一列内，没有路由。
433 00:40:16,639 --> 00:40:22,445 说话人 SPEAKER_00: 在列之间，有点像路由，但只是标准的变换器注意力。
434 00:40:22,947 --> 00:40:26,831 说话人 SPEAKER_00: 你只是在尝试同意相似的事情。
435 00:40:26,851 --> 00:40:31,096 说话人 SPEAKER_00: 好的，这就是 GLOM 应该工作的方式。
436 00:40:32,577 --> 00:40:34,320 说话人 SPEAKER_00: 最大的问题在于，
437 00:40:35,244 --> 00:40:41,793 说话人 SPEAKER_00：如果我看到一个圆圈，它可能是一只左眼，可能是一只右眼，可能是一辆车的方向盘，可能是一辆车的后轮。
438 00:40:42,494 --> 00:40:53,130 说话人 SPEAKER_00：因为我在特定级别对特定补丁的嵌入必须能够代表任何事物，当我遇到模糊的事物时，我必须处理它可能是哪个孔的所有可能性。
439 00:40:54,351 --> 00:41:05,067 说话人 SPEAKER_00：所以，与其在部分级别尝试解决模糊性，我可以选择跳到更高一级别，通过查看事物是否相同来解决这个问题，这是一种更容易解决模糊性的方法。
440 00:41:05,789 --> 00:41:11,516 说话人 SPEAKER_00：但这样做付出的代价是，我必须能够在更高一级别代表我得到的所有模糊性。
441 00:41:13,318 --> 00:41:14,679 说话人 SPEAKER_00：现在，结果证明你可以做到这一点。
442 00:41:14,699 --> 00:41:22,971 说话人 SPEAKER_00：我们做了一个小玩具示例，实际上可以保留这种歧义，但很难。
443 00:41:23,472 --> 00:41:25,554 说话人 SPEAKER_00：这是神经网络擅长的事情。
444 00:41:26,896 --> 00:41:35,626 说话人 SPEAKER_00：所以如果你想到下一层的嵌入，你将有一大堆活动的神经元。
445 00:41:36,298 --> 00:41:44,668 说话人 SPEAKER_00: 你想要表示一个高度多模态的分布，比如可能是一辆以这种姿态的汽车，或者以那种姿态的汽车，或者以这种姿态的脸，或者以那种姿态的脸。
446 00:41:45,530 --> 00:41:47,972 说话人 SPEAKER_00: 所有这些都是寻找圆的可能预测。
447 00:41:49,514 --> 00:41:51,577 说话人 SPEAKER_00: 因此你必须表示所有这些。
448 00:41:52,719 --> 00:41:54,320 说话人 SPEAKER_00: 那么问题是，神经网络能做这个吗？
449 00:41:55,141 --> 00:42:00,027 说话人 SPEAKER_00：我认为他们必须这样做的方式是，嵌入层中的每个神经元，
450 00:42:01,324 --> 00:42:11,516 说话人 SPEAKER_00：代表在这个可能身份和可能姿态的巨大空间上的未归一化对数概率分布，身份和姿态的交叉积。
451 00:42:12,478 --> 00:42:18,865 说话人 SPEAKER_00：因此，神经元是这个空间上的一个相当模糊的对数概率分布。
452 00:42:20,228 --> 00:42:26,655 说话人 SPEAKER_00：当你激活神经元时，它的意思是，将那个对数概率分布添加到你已经拥有的分布中。
453 00:42:27,817 --> 00:42:30,639 说话人 SPEAKER_00: 现在如果您有一大堆对数概率分布，
454 00:42:31,311 --> 00:42:32,414 说话人 SPEAKER_00: 然后将它们全部加在一起。
455 00:42:32,454 --> 00:42:37,601 说话人 SPEAKER_00: 您可以得到一个更加尖锐的对数概率分布。
456 00:42:38,782 --> 00:42:55,949 说话人 SPEAKER_00: 当您将其指数化以获得概率分布时，它会变得非常尖锐，因此在这个姿态和身份的联合空间中的基函数变得非常模糊，该空间中对数概率中的基函数可以组合起来产生尖锐的结论。
457 00:42:58,592 --> 00:42:59,074 说话人 SPEAKER_00: 嗯。
458 00:43:00,235 --> 00:43:02,356 说话人 SPEAKER_00: 我认为这就是神经元表示事物的方式。
459 00:43:02,416 --> 00:43:07,242 说话人 SPEAKER_00: 大多数人认为神经元就是他们所代表的事物。
460 00:43:08,563 --> 00:43:12,407 说话人 SPEAKER_00: 但在感知过程中，显然必须处理不确定性。
461 00:43:13,048 --> 00:43:18,094 说话者 SPEAKER_00: 因此神经元必须擅长表示多模态分布。
462 00:43:18,876 --> 00:43:21,538 说话者 SPEAKER_00: 这是我能想到的唯一一种擅长做这件事的方法。
463 00:43:23,400 --> 00:43:24,621 说话者 SPEAKER_00: 这是一个相当薄弱的论据。
464 00:43:25,322 --> 00:43:30,208 说话者 SPEAKER_00: 这正是乔姆斯基相信语言不是通过学习获得的论据，因为他想不出它是如何被学习的。
465 00:43:30,728 --> 00:43:40,465 说话人 SPEAKER_00：我的观点是神经元必须使用这种表示，因为我实在想不出其他的方法来做这件事。
466 00:43:40,485 --> 00:43:44,172 说话人 SPEAKER_00：好吧，我之所以说那么多，是因为我太激动了，没有控制好自己的情绪。
467 00:43:44,211 --> 00:43:55,032 说话人 SPEAKER_00：现在你可以这样做的原因，你在未归一化的对数概率空间中拥有这些非常模糊分布的原因。
468 00:43:55,365 --> 00:44:04,661 说话人 SPEAKER_00：是因为这些神经元都专注于图像的一小块区域，它们都在尝试表示该区域中发生的事情。
469 00:44:05,643 --> 00:44:07,505 说话人 说话人_00：你只是在尝试表示一件事物。
470 00:44:07,726 --> 00:44:10,690 说话人 说话人_00：你不是在尝试表示一组可能的对象。
471 00:44:11,432 --> 00:44:14,757 说话人 说话人_00：如果你在尝试表示一组可能的对象，你会遇到一个糟糕的绑定问题。
472 00:44:15,059 --> 00:44:26,293 说话人 说话人_00：你不能使用这些非常模糊的分布，但只要你知道所有这些神经元，所有活跃的神经元都指向同一事物，那么你可以进行交集操作。
473 00:44:26,853 --> 00:44:31,398 说话人 SPEAKER_00: 你可以将日志概率分布相加，并交集它们所代表的事物的集合。
474 00:44:34,501 --> 00:44:36,204 说话人 SPEAKER_00: 好的，我快要讲完了。
475 00:44:36,784 --> 00:44:38,347 说话人 SPEAKER_00: 你会如何训练这样一个系统？
476 00:44:39,188 --> 00:44:45,014 说话人 SPEAKER_00: 嗯，显然你可以按照你训练的方式训练它，但你也可以进行深度端到端训练。
477 00:44:45,382 --> 00:45:15,356 说话人 SPEAKER_00：对于 Glom，它将包含的内容以及我们训练的玩具示例的方式是这样的，你拿一张图片，去掉图片的一些区域，然后让 Glom 稳定下来大约 10 次迭代，它试图填充图片中最低层级的表示，即最低层的嵌入。
478 00:45:15,690 --> 00:45:22,219 说话人 SPEAKER_00：它填充得不对，所以你现在开始反向传播这个错误，你正在通过这个网络在时间上反向传播。
479 00:45:22,820 --> 00:45:25,003 说话人 SPEAKER_00：所以它也会在层级之间上下反向传播。
480 00:45:27,146 --> 00:45:34,275 说话人 SPEAKER_00：所以你基本上只是在做由于填充错误而产生的错误的时间反向传播。
481 00:45:34,295 --> 00:45:38,862 说话人 SPEAKER_00: 这基本上就是 BERT 的训练方式，你也可以用同样的方式训练 GLOM。
482 00:45:39,682 --> 00:45:44,449 说话人 SPEAKER_00: 但我也想在训练中增加一些内容，以鼓励岛屿的形成。
483 00:45:46,083 --> 00:45:53,590 说话人 SPEAKER_00: 我们希望鼓励在更高层次上形成大片的相同向量岛屿。
484 00:45:54,672 --> 00:45:56,673 说话人 SPEAKER_00: 你可以通过使用对比学习来实现这一点。
485 00:45:58,414 --> 00:46:12,188 说话人 SPEAKER_00：那么，如果你思考在下一个时间步，一个嵌入是如何确定的，它是通过结合许多不同的因素来确定的。
486 00:46:12,969 --> 00:46:14,891 说话人 SPEAKER_00：上一个时间步发生了什么
487 00:46:15,394 --> 00:46:32,132 说话人 SPEAKER_00：在这个表示级别和这个位置，上一个时间步在这个位置发生了什么，但在下一个级别向下、向上，以及在同一级别附近的位置上一个时间步发生了什么。
488 00:46:33,594 --> 00:46:39,119 说话人 SPEAKER_00：所有这些的加权平均我将称之为共识嵌入，这就是你用于下一个嵌入的内容。
489 00:46:40,661 --> 00:46:44,945 说话人 SPEAKER_00：我想你可以看到，如果我们尝试构建自下而上的神经网络，
490 00:46:45,077 --> 00:47:00,016 讲者 SPEAKER_00：在自上而下的神经网络中，如果我们试图让它们的预测与共识一致，共识已经包含了由于注意力等待而从附近位置折叠的信息。
491 00:47:01,338 --> 00:47:09,748 讲者 SPEAKER_00：因此，通过尝试使自上而下和自下而上的神经网络与共识一致，你是在尝试使它们与附近相似位置发生的事情一致。
492 00:47:10,510 --> 00:47:12,773 讲者 SPEAKER_00：因此，你将训练它形成岛屿。
493 00:47:16,516 --> 00:47:22,623 讲者 SPEAKER_00：这对神经科学家来说更有趣，而对从事自然语言处理的人来说则不然，所以我将忽略这一点。
494 00:47:25,405 --> 00:47:37,079 说话者 SPEAKER_00：你可能认为在物体级别复制所有这些嵌入是浪费的，所以想法是物体级别将是一个由具有完全相同向量表示的大量补丁组成的集合。
495 00:47:38,280 --> 00:47:39,402 说话者 SPEAKER_00：这似乎是浪费的。
496 00:47:39,871 --> 00:47:41,596 说话者 SPEAKER_00：但实际上生物学中充满了这样的事情。
497 00:47:42,016 --> 00:47:49,519 说话者 SPEAKER_00：你的所有细胞都有完全相同的 DNA，器官的所有部分都有相当相同的蛋白质表达向量。
498 00:47:50,041 --> 00:47:54,554 说话者 SPEAKER_00：所以有很多复制操作来保持局部性。
499 00:47:55,362 --> 00:48:06,536 说话者 SPEAKER_00：这里也是一样，实际上在确定解释时，这种复制非常有用，因为在确定下来之前，你不知道哪些东西应该和哪些其他东西相同。
500 00:48:06,936 --> 00:48:15,907 说话者 SPEAKER_00：所以，在各个位置使用独立的向量来表示物体级别的状态，为你提供了在合理的方式中逐渐分割事物的灵活性。
501 00:48:17,309 --> 00:48:19,411 说话者 SPEAKER_00：这让你可以下多个赌注。
502 00:48:19,695 --> 00:48:21,978 说话者 SPEAKER_00：你所做的不太像聚类。
503 00:48:22,380 --> 00:48:27,927 说话者 SPEAKER_00：你是在创建由相同向量组成的簇，而不是在固定数据中寻找簇。
504 00:48:28,327 --> 00:48:31,791 说话者 SPEAKER_00：所以聚类，你得到的是固定的数据，然后找到簇。
505 00:48:31,931 --> 00:48:37,840 说话者 SPEAKER_00：在这里，每一层的嵌入随时间变化。
506 00:48:38,221 --> 00:48:42,146 说话者 SPEAKER_00：它们由自上而下和自下而上的输入以及来自附近位置的输入所决定。
507 00:48:42,666 --> 00:48:46,871 说话者 SPEAKER_00：所以你做的是形成簇，而不是在固定数据中发现它们。
508 00:48:47,572 --> 00:48:49,094 说话者 SPEAKER_00：这有点不同的味道。
509 00:48:49,581 --> 00:48:51,306 说话者 SPEAKER_00：并且可以更快地稳定下来。
510 00:48:55,878 --> 00:48:58,967 说话人 SPEAKER_00: 这复制的另一个优点是。
511 00:49:00,195 --> 00:49:05,342 说话人 SPEAKER_00: 你不希望随着层级提高，你的 Transformer 中有更多的工作。
512 00:49:06,222 --> 00:49:08,726 说话人 SPEAKER_00: 但是在更高层级，你需要更长的范围交互。
513 00:49:09,246 --> 00:49:12,891 说话人 SPEAKER_00: 对于最低层级，你希望在 Transformer 中拥有较短的交互范围。
514 00:49:13,512 --> 00:49:14,393 说话者 说话者_00：它们可能是密集的。
515 00:49:14,893 --> 00:49:17,416 说话者 说话者_00：当你达到更高的层次时，你希望有更长的范围交互。
516 00:49:18,016 --> 00:49:19,498 说话者 说话者_00：所以你可以使它们变得稀疏。
517 00:49:20,440 --> 00:49:25,326 说话者 说话者_00：人们已经为类似 BERT 的系统做了这样的事情。
518 00:49:25,880 --> 00:49:37,315 说话人 SPEAKER_00：这里很容易使它们变得稀疏，因为你可以预见到大岛屿，所以你只需要看到一个大岛屿的一块区域，就能知道那个岛屿的向量表示。
519 00:49:38,056 --> 00:49:48,648 说话人 SPEAKER_00：因此，如果你在向上移动时有这些大岛屿的共识，稀疏表示将工作得更好，所以想法是你有更长的范围和更稀疏的连接，随着向上移动，计算量在每个级别都是相同的。
520 00:49:50,692 --> 00:49:53,034 说话人 SPEAKER_00：现在简要总结一下。
521 00:49:54,753 --> 00:49:57,998 说话人 SPEAKER_00：我展示了如何在 Glom 中结合神经网络的三项重要进展。
522 00:49:58,438 --> 00:50:00,681 说话人 SPEAKER_00：我实际上并没有谈论神经网络场。
523 00:50:01,322 --> 00:50:03,947 说话人 SPEAKER_00：这对于自上而下的网络来说很重要。
524 00:50:04,307 --> 00:50:07,994 说话人 SPEAKER_00：也许因为我还有两分钟的时间，我会简要地提一下神经网络场。
525 00:50:13,882 --> 00:50:17,849 说话人 SPEAKER_00：是的，当我训练那个自上而下的神经网络时，我遇到了一个问题。
526 00:50:18,791 --> 00:50:20,152 说话人 SPEAKER_00: 问题在于，
527 00:50:22,090 --> 00:50:27,155 说话人 SPEAKER_00: 如果你观察那些红色箭头和绿色箭头，它们相当不同。
528 00:50:28,177 --> 00:50:32,262 说话人 SPEAKER_00: 但如果你观察物体层级之上的层级，所有这些向量都是相同的。
529 00:50:32,322 --> 00:50:39,429 说话人 SPEAKER_00: 当然，在一个工程系统中，我想要在每个位置复制神经网络。
530 00:50:39,670 --> 00:50:42,713 说话者 SPEAKER_00：所以我到处都使用完全相同的自上而下和自下而上的神经网络。
531 00:50:43,956 --> 00:50:48,621 说话者 SPEAKER_00：那么问题来了，同一个神经网络如何被赋予一个黑色箭头，
532 00:50:49,427 --> 00:50:53,735 说话者 SPEAKER_00：有时产生一个红色箭头，有时产生一个绿色箭头，方向差异很大。
533 00:50:54,697 --> 00:51:01,489 说话者 SPEAKER_00：它如何在有鼻子和嘴巴的地方产生鼻子和嘴巴，尽管脸部的向量在所有地方都是相同的？
534 00:51:02,429 --> 00:51:15,132 说话者 SPEAKER_00: 答案是，自上而下的神经网络不仅获取人脸向量，还获取它生成路径向量的补丁位置。
535 00:51:16,275 --> 00:51:23,023 说话者 SPEAKER_00: 所以，应该获取红色向量的三个补丁与应该获取绿色向量的三个补丁位于不同的位置。
536 00:51:23,784 --> 00:51:28,329 说话者 SPEAKER_00: 所以，如果我用一个同时获取位置作为输入的神经网络，它就能做到以下这些。
537 00:51:29,070 --> 00:51:32,873 说话者 SPEAKER_00: 它可以获取编码在黑色向量中的姿态，即人脸的姿态。
538 00:51:34,235 --> 00:51:40,882 说话者 SPEAKER_00: 它可以预测下一级向量的图像位置。
539 00:51:41,891 --> 00:51:43,775 说话者 SPEAKER_00: 并且姿态也是相对于图像的。
540 00:51:44,315 --> 00:51:52,471 说话者 SPEAKER_00: 因此，知道图像中的位置和整个脸部的姿态，它可以确定在哪个位置需要预测脸部的一部分。
541 00:51:53,092 --> 00:51:57,539 说话者 SPEAKER_00: 因此，在一个位置，它可以预测，嗯，这里应该有鼻子，并给出红色向量。
542 00:51:58,019 --> 00:52:04,592 说话人 SPEAKER_00：在另一个位置，它可以预测图像块来自哪里，那里应该有嘴巴，所以它可以给你绿色箭头。
543 00:52:04,572 --> 00:52:11,938 说话人 SPEAKER_00：因此，你可以在上一级获得相同的向量，通过给出它预测的位置，来预测下一级不同位置的向量。
544 00:52:12,400 --> 00:52:14,126 说话人 SPEAKER_00：这就是神经网络场中发生的事情。
545 00:52:19,000 --> 00:52:19,460 说话人 SPEAKER_00：好的。
546 00:52:21,282 --> 00:52:23,045 说话人 SPEAKER_00：这次演讲相当复杂。
547 00:52:23,525 --> 00:52:26,889 说话人 SPEAKER_00：关于这个话题，在档案中有一篇很长的论文，详细介绍了更多内容。
548 00:52:27,811 --> 00:52:32,036 说话人 SPEAKER_00：你们可以把这次演讲看作是阅读那篇论文的鼓励。
549 00:52:32,697 --> 00:52:33,097 说话人 SPEAKER_00：这就结束了。
550 00:52:33,878 --> 00:52:34,539 说话人 SPEAKER_00: 准时到达。
551 00:52:39,244 --> 00:52:39,985 说话人 SPEAKER_00: 好的，谢谢。
552 00:52:40,005 --> 00:52:40,967 说话人 SPEAKER_00: 非常感谢。
553 00:52:41,568 --> 00:52:41,768 说话人 SPEAKER_00: 嗯。