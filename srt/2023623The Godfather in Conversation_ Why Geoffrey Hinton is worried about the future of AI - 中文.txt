1 00:00:02,410 --> 00:00:06,495 说话人 SPEAKER_00: 为本视频的主题人物 Geoffrey Hinton 写一个简短的介绍。
2 00:00:09,157 --> 00:00:14,505 说话人 SPEAKER_00: Geoffrey Hinton 是多伦多大学名誉教授，被誉为人工智能之父。
3 00:00:16,126 --> 00:00:21,373 说话人 SPEAKER_00: 他最近离开谷歌，以便更自由地讨论不受控制的 AI 发展带来的危险。
4 00:00:23,335 --> 00:00:30,544 说话人 SPEAKER_00: 我们在他在伦敦的家中采访了他，谈论了他帮助创造的技术、其众多好处以及他为何突然担心人类面临风险。
5 00:00:35,317 --> 00:00:37,140 说话人 SPEAKER_01：我收到了华尔街日报的请求。
6 00:00:37,439 --> 00:00:39,383 说话人 SPEAKER_01：他们希望我更正我的讣告。
7 00:00:39,622 --> 00:00:40,784 说话人 SPEAKER_01：你是什么意思？
8 00:00:40,804 --> 00:00:42,307 说话人 SPEAKER_01：他们希望我更正我的讣告。
9 00:00:42,326 --> 00:00:43,387 说话人 SPEAKER_02: 他们好像预先写好了。
10 00:00:43,408 --> 00:00:46,533 说话人 SPEAKER_01: 他们好像预先写好了我的讣告。
11 00:00:46,552 --> 00:00:48,115 说话人 SPEAKER_01: 我想知道马克·吐温会对此说些什么。
12 00:00:48,134 --> 00:01:01,594 说话人 SPEAKER_02: 所以我想我们这里其实不需要介绍，我就直接，嗯，跳进去吧。
13 00:01:03,228 --> 00:01:14,662 说话人 SPEAKER_02：你最近在接受采访时表示，用于聊天机器人和其他生成式 AI 的数字智能可能比我们拥有的生物智能更好。
14 00:01:15,603 --> 00:01:18,347 说话人 SPEAKER_02：你能简要解释一下是什么让你得出这个结论吗？
15 00:01:19,608 --> 00:01:26,317 说话人 SPEAKER_01：所以，在数字计算机中，它是设计成你可以明确告诉它做什么，然后它会按照你说的去做。
16 00:01:27,280 --> 00:01:29,201 说话人 SPEAKER_01：即使它在学习东西，
17 00:01:29,435 --> 00:01:34,725 说话人 SPEAKER_01：两台不同的数字计算机可以用相同的学到的知识做完全一样的事情。
18 00:01:35,968 --> 00:01:49,957 说话人 SPEAKER_01：这意味着你可以制作 10,000 份相同的知识的副本，让它们都在不同的计算机上运行，每当一个副本学到一些东西，它都可以非常高效地将其传达给所有其他副本。
19 00:01:50,849 --> 00:02:01,313 说话人 SPEAKER_01：所以你可以有 10,000 个数字代理在外部，一种蜂群思维，它们可以通过共享神经网络中的连接强度来极其高效地共享知识。
20 00:02:01,796 --> 00:02:02,878 说话人 SPEAKER_01：而我们做不到这一点。
21 00:02:03,760 --> 00:02:08,992 说话人 SPEAKER_01：如果你学到一些东西，并且想告诉我，你必须用句子来说。
22 00:02:08,973 --> 00:02:15,219 说话人 SPEAKER_01：或者图片，那样你只能分享非常有限的信息。
23 00:02:15,760 --> 00:02:23,991 说话人 SPEAKER_01：所以，你向我传达你所学到的东西的速度，远远比不上这些数字智能传达信息的速度，这使得它们更优秀。
24 00:02:24,752 --> 00:02:26,614 说话人 SPEAKER_01：它们之间可以学到很多东西。
25 00:02:27,414 --> 00:02:33,241 说话人 SPEAKER_02：你说数字智能是永生的，而生物智能是有限的。
26 00:02:34,582 --> 00:02:35,925 说话人 SPEAKER_02：你这是什么意思？
27 00:02:36,343 --> 00:02:50,304 说话人 SPEAKER_01：所以，如果我学习到一个在数字计算机上模拟的神经网络中的连接强度，那么如果一台特定的计算机损坏了，这些相同的连接强度可以在另一台计算机上使用。
28 00:02:51,506 --> 00:03:00,359 说话人 SPEAKER_01：即使所有的数字计算机都损坏了，如果你把连接强度存储在某个地方，你就可以制作另一台数字计算机，并在那台其他数字计算机上运行相同的权重。
29 00:03:01,441 --> 00:03:02,401 说话人 SPEAKER_01：但是，在我们这里，
30 00:03:03,293 --> 00:03:08,441 我们学习到的知识，连接强度，都是我们特定大脑的。
31 00:03:08,581 --> 00:03:09,824 每个大脑都有所不同。
32 00:03:10,283 --> 00:03:12,167 你大脑中的神经元都略有不同。
33 00:03:12,929 --> 00:03:18,217 说话人 SPEAKER_01：你学习是为了利用你大脑的独特之处。
34 00:03:18,257 --> 00:03:25,048 说话人 SPEAKER_01：所以一旦你在大脑中学会了连接强度，如果你告诉我那些连接强度，它们对我没有任何好处，因为我的大脑是不同的。
35 00:03:26,412 --> 00:03:32,177 说话人 SPEAKER_01：所以数字计算机是永恒的，因为你可以将同样的知识运行在不同的硬件上。
36 00:03:32,897 --> 00:03:37,663 说话人 SPEAKER_01：我们是永恒的，因为硬件和知识是紧密相连的。
37 00:03:38,144 --> 00:03:42,388 说话人 SPEAKER_01：你不能将连接强度与它们运行的特定大脑分开。
38 00:03:43,508 --> 00:03:45,191 说话人 SPEAKER_01：所以如果大脑死亡，知识也会死亡。
39 00:03:47,772 --> 00:03:52,538 说话人 SPEAKER_00：我们为什么应该担心数字智能取代生物智能？
40 00:03:53,462 --> 00:04:06,856 说话人 SPEAKER_01：因为我认为它更适合共享大量不同数字智能体所学习的内容，这些智能体共享相同的权重，并且只共享权重的更新，现在它们可以同时学习 10,000 种不同的东西。
41 00:04:08,078 --> 00:04:12,282 说话人 SPEAKER_01：但是我认为数字智能可能拥有比人脑更好的学习算法。
42 00:04:13,223 --> 00:04:19,689 试图在脑中找到一个与反向传播算法一样有效的学习算法的所有尝试。
43 00:04:19,670 --> 00:04:21,932 在这些数字智能中。
44 00:04:22,572 --> 00:04:24,014 到目前为止，这些尝试都失败了。
45 00:04:24,656 --> 00:04:30,122 说话人 SPEAKER_01：我们还没有找到像反向传播算法那样能够很好地扩展到非常大的系统的东西。
46 00:04:30,702 --> 00:04:32,305 说话人 SPEAKER_01：所以我认为它们有两个优势。
47 00:04:32,345 --> 00:04:39,233 说话人 SPEAKER_01：它们可能有一个更好的学习算法，并且它们可以比生物智能更有效地共享知识。
48 00:04:39,252 --> 00:04:44,197 说话人 SPEAKER_02：在你进入这个领域的时候，机器智能有两个学派。
49 00:04:45,158 --> 00:04:47,382 说话人 SPEAKER_02：主流和神经网络。
50 00:04:48,610 --> 00:04:51,033 说话人 SPEAKER_02：你能描述一下这两种方法之间的区别吗？
51 00:04:51,555 --> 00:04:52,956 说话人 SPEAKER_01：我可以稍微夸张一下。
52 00:04:53,197 --> 00:04:57,303 说话人 SPEAKER_01：所以关于智能，有两种不同的模型。
53 00:04:57,944 --> 00:05:00,007 说话人 SPEAKER_01：其中一个模型就是它全部关乎推理。
54 00:05:01,250 --> 00:05:03,353 说话人 SPEAKER_01：而我们推理的方式是通过逻辑。
55 00:05:03,874 --> 00:05:05,456 说话人 SPEAKER_01：这就是人的特别之处。
56 00:05:06,798 --> 00:05:12,607 说话人 SPEAKER_01：我们应该做的是理解我们实际使用的逻辑类型。
57 00:05:13,728 --> 00:05:16,153 说话人 SPEAKER_01：这也与以下想法相符，
58 00:05:16,824 --> 00:05:29,629 说话人 SPEAKER_01：你存储的知识是符号表达式，所以我可以对你说一句话，你将 somehow 存储它，然后以后你将能够用它来推断其他句子。
59 00:05:30,028 --> 00:05:33,636 说话人 SPEAKER_01：但你的头脑里装的是类似句子但经过整理的东西。
60 00:05:34,779 --> 00:05:42,367 说话人 SPEAKER_01：还有一种完全不同的智能模型，那就是它全部关于学习大脑细胞网络中的连接强度。
61 00:05:43,309 --> 00:05:47,773 说话人 SPEAKER_01：它擅长的是像感知和运动控制这样的东西，而不是推理。
62 00:05:47,973 --> 00:05:50,795 说话人 SPEAKER_01：推理出现得晚得多，而且我们在这方面并不擅长。
63 00:05:51,836 --> 00:05:53,338 说话人 SPEAKER_01：你直到相当老了才会学习如何做这件事。
64 00:05:54,660 --> 00:05:58,163 说话人 SPEAKER_01：因此，推理实际上是一个非常糟糕的生物智能模型。
65 00:05:58,204 --> 00:06:03,588 说话人 SPEAKER_01：生物智能是关于控制你的身体和看到事物的。
66 00:06:04,497 --> 00:06:08,822 说话人 SPEAKER_01：那是一个完全不同的范式，对头脑中的事物有不同的看法。
67 00:06:09,303 --> 00:06:14,151 说话人 SPEAKER_01：那就是它不是存储符号串，只是连接串。
68 00:06:15,132 --> 00:06:23,024 说话人 SPEAKER_01：符号 AI 观点的关键问题是，这些符号表达式的形式是什么，以及如何对它们进行推理？
69 00:06:24,365 --> 00:06:27,932 说话人 SPEAKER_01：对于神经网络的观点，核心问题相当不同。
70 00:06:27,951 --> 00:06:32,158 说话人 SPEAKER_01：它是，你是如何学习这些连接字符串，以便你可以做所有这些美妙的事情？
71 00:06:32,560 --> 00:06:35,142 说话人 SPEAKER_01：因此，学习一直是神经网络观点的核心。
72 00:06:35,684 --> 00:06:38,067 说话人 SPEAKER_01：对于符号观点，他们说，我们稍后再考虑学习问题。
73 00:06:38,127 --> 00:06:41,571 说话人 SPEAKER_01：首先，你必须弄清楚知识是如何表示的，以及我们如何对它进行推理。
74 00:06:42,331 --> 00:06:44,035 说话人 SPEAKER_01：所以这些观点完全不同。
75 00:06:44,154 --> 00:06:46,778 说话人 SPEAKER_01：一个从逻辑中汲取灵感，另一个从生物学中汲取灵感。
76 00:06:47,478 --> 00:06:53,927 说话人 SPEAKER_01：长期以来，逻辑阵营的人认为从生物学中汲取灵感是愚蠢的。
77 00:06:54,194 --> 00:07:04,646 说话人 SPEAKER_01：这有点奇怪，因为冯·诺伊曼和图灵都认为神经网络是攻击智能的方法，但不幸的是他们都英年早逝。
78 00:07:07,470 --> 00:07:11,093 说话人 SPEAKER_00：你能从高层次上描述一下神经网络是如何工作的吗？
79 00:07:12,776 --> 00:07:13,357 说话人 SPEAKER_01：我可以试试。
80 00:07:14,437 --> 00:07:19,964 说话人 SPEAKER_01：那么让我们先描述一下它是如何识别物体和图像的。
81 00:07:20,113 --> 00:07:24,620 说话人 SPEAKER_01：假设我们只想判断图像中是否有鸟。
82 00:07:25,079 --> 00:07:28,444 说话人 SPEAKER_01：假设鸟大致位于图像中间的主要关注对象中。
83 00:07:29,026 --> 00:07:31,389 说话人 SPEAKER_01：你必须说，这是鸟还是不是鸟？
84 00:07:33,271 --> 00:07:34,552 说话人 SPEAKER_01：所以你可以想象一个图像。
85 00:07:34,612 --> 00:07:36,735 说话人 SPEAKER_01：假设它是 100 像素乘以 100 像素。
86 00:07:37,255 --> 00:07:38,478 说话人 SPEAKER_01：那是 10,000 像素。
87 00:07:39,119 --> 00:07:41,000 说话人 SPEAKER_01：每个像素是三种颜色，RGB。
88 00:07:41,521 --> 00:07:43,084 说话人 SPEAKER_01：所以这是 30,000 个数字。
在计算术语中，识别图像中的鸟包含提取30000个数字并输出一个表示是或否是鸟的数字。
您可以使用标准计算机程序来尝试实现这一点，人们尝试了很长时间，但始终无法使其工作得很好。
91 00：08：01,930 --> 00：08：03,411 议长 SPEAKER_01：就像 50 年来他们一直在努力做到这一点。
92 00：08：04,995 --> 00：08：07,759 演讲者 SPEAKER_01：或者你可以做一个多层神经网络。
93 00:08:08,319 --> 00:08:11,805 说话者 SPEAKER_01：我先来告诉你如何手动连接神经网络。
94 00:08:12,730 --> 00:08:20,324 所以你会有像素，这是最底层，然后你会有一层特征检测器。
95 00:08:21,165 --> 00:08:36,712 典型的特征检测器可能从一排像素中传来大的正连接强度，从相邻的一排像素中传来大的负连接强度，其他地方则没有连接强度。
96 00:08:37,402 --> 00:08:45,253 所以如果两排像素都亮，它将从这里获得大的正输入，同时也从那里获得大的负输入，因此它不会做任何事情。
97 00:08:46,053 --> 00:08:53,263 说话人 SPEAKER_01：但如果这些是明亮的，给它一个大的正输入，而那些不是明亮的，所以它不会被这些抑制，它会变得非常兴奋。
98 00:08:53,703 --> 00:08:58,110 说话人 SPEAKER_01：它会说，嘿，我找到了我喜欢的东西，这里明亮像素，这里暗像素。
99 00:08:58,933 --> 00:09:00,296 说话人 SPEAKER_01：那是一个边缘检测器。
100 00:09:00,796 --> 00:09:06,102 说话人 SPEAKER_01：我刚刚告诉了你如何通过手工使用正负权重来连接，以检测一点垂直边缘。
101 00:09:07,164 --> 00:09:14,734 说话者 SPEAKER_01：现在想象一下，有成千上万这样的家伙在不同的位置、不同的方向和不同的尺度上检测图像中的不同边缘。
102 00:09:15,796 --> 00:09:17,557 说话者 SPEAKER_01：那将是你的第一个特征检测层。
103 00:09:18,519 --> 00:09:21,582 说话者 SPEAKER_01：现在如果我要手动连接它，我的第二个特征检测层
104 00:09:22,423 --> 00:09:28,815 说话者 SPEAKER_01：我可能有一个检测器，它可以检测两个在细小角度相交的边缘，就像这样。
105 00:09:29,336 --> 00:09:31,019 说话人 SPEAKER_01：所以它在寻找这个边缘和那个边缘。
106 00:09:31,419 --> 00:09:36,087 说话人 SPEAKER_01：如果它们同时活跃，它会说，嘿，可能这里有个喙。
107 00:09:36,769 --> 00:09:39,472 说话人 SPEAKER_01：它可能是各种其他东西，但可能只是个喙。
108 00:09:39,913 --> 00:09:42,118 说话人 SPEAKER_01：所以你有一个有点像喙的特征。
109 00:09:43,581 --> 00:09:47,908 说话人 SPEAKER_01：在那个层中，你可能还有一个检测整个一圈的边缘的特征。
110 00:09:49,423 --> 00:09:56,054 说话人 SPEAKER_01：因此，你将会有圆形检测器和可能的喙检测器，以及该层中的许多其他检测器。
111 00:09:56,075 --> 00:09:58,057 说话人 SPEAKER_01：但它们检测的是稍微复杂一些的东西。
112 00:09:59,179 --> 00:10:11,799 说话人 SPEAKER_01：然后在那个层之上，你可能会有一些检测到与可能的圆形、可能的眼睛在正确空间关系中的潜在喙，这样它可能是鸟的头。
113 00:10:13,361 --> 00:10:15,144 说话人 SPEAKER_01：那么这就像是你的第三层。
114 00:10:16,306 --> 00:10:25,437 说话人 SPEAKER_01：也许在你的第三层中，你还能检测到鸟的脚和翅膀，那么在下一层可能就能有鸟的检测器。
115 00:10:25,878 --> 00:10:32,667 说话人 SPEAKER_01：如果这些事物中有几个被激活了，比如，这里有头，这里有翅膀，这里有脚，那么它可能就是一只鸟。
116 00:10:33,908 --> 00:10:39,414 说话人 SPEAKER_01：好的，所以我告诉你如何手动连接所有这些，但你永远不可能做得很好。
117 00:10:40,216 --> 00:10:44,000 说话人 SPEAKER_01：所以，我们不是手动全部连接，
118 00:10:44,317 --> 00:10:45,940 说话人 SPEAKER_01：我们可以想象尝试去学习它。
119 00:10:46,880 --> 00:10:50,785 说话人 SPEAKER_01：我已经告诉你们我们想要学习的东西，但现在我要告诉你们我们是如何学习的。
120 00:10:51,407 --> 00:10:53,308 说话人 SPEAKER_01：而我们学习的方式一开始听起来很奇怪。
121 00:10:54,551 --> 00:11:02,921 说话者 SPEAKER_01：与其将所有连接强度都连接起来以获得所需的检测器，你开始时使用随机的连接强度，所有连接上的随机数字。
122 00:11:03,902 --> 00:11:10,409 说话者 SPEAKER_01：然后你输入一张鸟的图片，然后通过这些特征检测器的层向前推进，它表现得完全随机。
123 00:11:11,335 --> 00:11:15,682 说话者 SPEAKER_01：输出端的鸟类检测器会说 0.5，它是一只鸟。
124 00:11:16,624 --> 00:11:20,951 说话者 SPEAKER_01：当它确定是鸟时，它会说 1，当它确定不是鸟时，它会说 0，对我来说，它可能会说大约 0.5。
125 00:11:21,952 --> 00:11:23,455 说话人 SPEAKER_01：现在你可以问以下问题。
126 00:11:25,057 --> 00:11:27,942 说话人 SPEAKER_01：我该如何改变网络中的所有连接强度？
127 00:11:29,273 --> 00:11:34,945 说话人 SPEAKER_01：所以，与其说“0.5 是鸟”，假设它是鸟，它说“0.51 是鸟”。
128 00:11:35,706 --> 00:11:42,000 说话人 SPEAKER_01：所以你想问的问题是，我该如何改变特定的连接强度，使其更有可能是鸟？
129 00:11:43,245 --> 00:11:49,075 说话人 SPEAKER_01：你可以通过计算你得到的结果和你想要的结果之间的差异来找出这一点。
130 00:11:49,434 --> 00:11:52,359 说话人 SPEAKER_01：你想要一个，实际上得到了 0.5。
131 00:11:52,600 --> 00:11:56,505 说话人 SPEAKER_01：你计算这个差异，并将这个差异反向传递到网络中。
132 00:11:57,125 --> 00:11:59,129 说话人 SPEAKER_01：然后你使用一些微积分，这个我不会解释。
133 00:12:00,451 --> 00:12:05,658 说话人 SPEAKER_01：你能够计算网络中每个连接
134 00:12:05,639 --> 00:12:11,788 说话人 SPEAKER_01：你希望将其放大或缩小，以便更有可能说出“鸟”
135 00:12:12,350 --> 00:12:17,097 说话人 SPEAKER_01：然后你非常轻微地调整所有连接强度，使其更有可能说出“鸟”
136 00:12:18,000 --> 00:12:23,269 说话人 SPEAKER_01：然后你展示一些不是鸟的东西，现在你需要调整连接强度，使其不太可能认为那是一只鸟
137 00:12:24,770 --> 00:12:31,663 说话人 SPEAKER_01：你就这样一直进行下去，用很多鸟类和非鸟类，最终你会发现它是
138 00:12:31,863 --> 00:12:33,505 说话人 SPEAKER_01：发现了所有这些特征检测器。
139 00:12:33,525 --> 00:12:38,153 说话人 SPEAKER_01：它会发现类似喙的东西、类似眼睛的东西，以及检测脚和翅膀等所有这些。
140 00:12:38,994 --> 00:12:50,452 说话人 SPEAKER_01：如果你在成千上万的不同物体上训练它，比如一千种不同类别的物体，它会发现很好的中间特征检测器，这些检测器非常适合识别各种事物。
141 00:12:51,595 --> 00:12:56,081 说话人 SPEAKER_01：所以这个魔法在于有一个相对简单的算法叫做反向传播，
142 00:12:56,315 --> 00:13:09,673 说话人 SPEAKER_01：它将输出中的误差反向传递到网络中，并通过所有连接计算出应该如何改变它们以改善行为，然后你将它们都改变一点点，然后继续用另一个例子进行。
143 00:13:11,115 --> 00:13:13,779 说话人 SPEAKER_01：令人惊讶的是，这实际上有效。
144 00:13:14,541 --> 00:13:18,225 说话人 SPEAKER_01：多年来，人们认为这会陷入僵局，会在某个地方卡住。
145 00:13:18,567 --> 00:13:19,227 说话人 SPEAKER_01：但是，不是这样的。
146 00:13:19,248 --> 00:13:20,450 说话人 SPEAKER_01：实际上工作得非常好。
147 00:13:22,552 --> 00:13:25,697 说话人 SPEAKER_00：我很好奇，神经网络是如何处理语言的？
148 00:13:27,870 --> 00:13:32,678 说话人 SPEAKER_01：好的，现在你已经了解了我们是如何训练它来识别鸟的。
149 00:13:33,399 --> 00:13:45,681 说话人 SPEAKER_01：现在假设我们以一串词作为输入，你首先要做的事情是将一个词转换成一个嵌入向量。
150 00:13:46,302 --> 00:13:52,292 说话人 SPEAKER_01：也就是说，它是一小堆数字，用来捕捉词的意义，或者说是试图捕捉词的意义。
151 00:13:53,572 --> 00:13:58,057 说话人 SPEAKER_01：因此，在词之后的第一层将是每个词的嵌入向量。
152 00:13:59,758 --> 00:14:13,052 说话人 SPEAKER_01：现在我们将有很多嵌入向量的层，随着我们通过网络向上移动，我们将使词的嵌入向量越来越好，因为它们将考虑越来越多的上下文信息。
153 00:14:14,113 --> 00:14:18,238 说话人 SPEAKER_01：那么假设在这个句子中，我们假设没有任何大写字母，好吗？
154 00:14:18,638 --> 00:14:21,620 说话人 SPEAKER_01：那么假设在这个句子中，你有一个单词“May”。
155 00:14:23,136 --> 00:14:27,942 说话人 SPEAKER_01：嗯，最可能的意义是“May”是一个情态动词，比如“他可能会做那件事”。
156 00:14:29,764 --> 00:14:32,466 说话人 SPEAKER_01：但显然“May”还有完全不同的意义，即月份。
157 00:14:34,009 --> 00:14:39,554 说话者 SPEAKER_01：最初，它不知道，只看单词“五月”，不知道该使用哪个嵌入向量。
158 00:14:40,956 --> 00:14:50,966 说话者 SPEAKER_01：它将使用一种折衷向量，介于代表模态的“五月”嵌入向量和代表月份的“五月”嵌入向量之间的某种东西。
159 00:14:52,650 --> 00:14:56,256 说话者 SPEAKER_01：然后在下一层，它将细化这个向量。
160 00:14:57,138 --> 00:15:02,365 说话者 SPEAKER_01：它将根据得到的上下文，根据附近的嵌入向量，制作一个稍微更好的向量。
161 00:15:03,028 --> 00:15:13,124 说话人 SPEAKER_01：例如，如果附近有六月嵌入向量，那么它将使五月的嵌入向量更接近月份，而不是模态。
162 00:15:14,405 --> 00:15:19,013 说话人 SPEAKER_01：但如果附近有木材的嵌入向量，它将使它更接近模态，而不是月份。
163 00:15:21,337 --> 00:15:26,964 说话人 SPEAKER_01：当你通过网络时，它可以对这些嵌入向量进行细化，使它们变得越来越好。
164 00:15:28,065 --> 00:15:34,671 说话人 SPEAKER_01：我们将通过给它一个单词序列作为输入来训练它。
165 00:15:36,552 --> 00:15:39,735 说话人 SPEAKER_01：我们将这样做，这里将是一种方法。
166 00:15:39,755 --> 00:15:41,999 说话人 SPEAKER_01：这并不是确切的做法，但很容易理解。
167 00:15:42,899 --> 00:15:46,802 说话人 SPEAKER_01：对于最后一个词，你只需放入一个中性的词。
168 00:15:46,823 --> 00:15:48,325 说话人 SPEAKER_01：你说未知。
169 00:15:48,389 --> 00:15:52,875 说话人 SPEAKER_01：它有一个非常模糊的嵌入向量，几乎是所有单词向量的平均值。
170 00:15:52,975 --> 00:15:54,217 说话人 SPEAKER_01：它不知道，对吧？
171 00:15:55,339 --> 00:16:02,129 说话人 SPEAKER_01：现在当你通过网络前进时，最后一个单词将能够受到前面单词的影响。
172 00:16:03,631 --> 00:16:08,940 说话人 SPEAKER_01：它一开始非常模糊，但随着通过这些层，它可以变得越来越精确。
173 00:16:10,022 --> 00:16:14,227 说话人 SPEAKER_01：当你到达网络末端时，嵌入向量可能看起来像某个特定单词的嵌入向量，或者是一些单词组合的嵌入向量。
174 00:16:14,932 --> 00:16:23,461 说话人 SPEAKER_01：或者，嵌入向量可能看起来像某些单词组合的嵌入向量，或者是几个单词的平均嵌入向量。
175 00:16:25,024 --> 00:16:39,759 说话人 SPEAKER_01：通过这些层进行训练，你希望最后一个单词的嵌入向量看起来像文本中实际存在的单词的嵌入向量。
176 00:16:40,735 --> 00:16:42,221 说话人 SPEAKER_01：这就是它预测下一个单词的方式。
177 00:16:43,024 --> 00:16:52,298 说话者 SPEAKER_01：它试图将这种中性的嵌入向量转换为与文本中出现的正确单词的嵌入向量相近的向量。
178 00:16:53,880 --> 00:17:02,951 说话者 SPEAKER_01：然后你计算误差，即文本中的嵌入向量与生成的嵌入向量之间的差异，并将这个误差反向传播通过网络。
179 00:17:03,552 --> 00:17:12,541 说话者 SPEAKER_01：它正向反向通过层传播，但它是从这个词传播到前面的词，这样它们就能对这个词产生正确的影响。
180 00:17:13,702 --> 00:17:17,528 说话者 SPEAKER_01：这就是反向传播算法学习预测下一个单词。
181 00:17:18,808 --> 00:17:22,452 说话人 SPEAKER_02：尽管在这个领域有一些理论上的突破，
182 00:17:22,770 --> 00:17:25,815 说话人 SPEAKER_02：这些神经网络长时间以来效果并不好。
183 00:17:26,695 --> 00:17:27,256 说话人 SPEAKER_02：那是什么原因呢？
184 00:17:28,597 --> 00:17:30,059 说话人 SPEAKER_01：这是多种原因的综合。
185 00:17:31,000 --> 00:17:33,403 说话人 SPEAKER_01：所以我们在这方面不是很擅长。
186 00:17:33,964 --> 00:17:36,647 说话人 SPEAKER_01：也就是说，我说你放入随机权重，然后学习所有内容。
187 00:17:37,308 --> 00:17:44,037 说话人 SPEAKER_01：但是如果你没有仔细决定随机权重的类型，那么这个系统就无法起飞。
188 00:17:44,017 --> 00:17:48,681 说话人 SPEAKER_01：所以这是它们在具有许多特征检测器层的深度网络中工作不很好的技术原因之一。
189 00:17:49,122 --> 00:17:53,645 说话人 SPEAKER_01：但主要原因是我们的计算能力不足，数据也不够。
190 00:17:54,186 --> 00:17:59,672 说话人 SPEAKER_01：所以人们试图在没有太多计算能力的情况下，在相对较小的训练集上训练这些网络。
191 00:18:00,633 --> 00:18:03,335 说话人 SPEAKER_01：在那个环境下，其他方法效果更好。
192 00:18:03,976 --> 00:18:07,479 说话人 SPEAKER_01：神经网络真正发挥作用的条件是有大量数据和强大的计算能力。
193 00:18:08,039 --> 00:18:11,182 说话人 SPEAKER_01：然后你可以使用一个大型的神经网络，然后它比其他任何东西都工作得更好。
194 00:18:12,063 --> 00:18:13,904 说话人 SPEAKER_01：当时我们没有意识到这一点。
195 00:18:14,257 --> 00:18:19,424 说话人 SPEAKER_01：所以我们会偶尔幻想，嗯，假设你有很多更多的数据和更大的计算机，它会工作得更好。
196 00:18:19,464 --> 00:18:21,568 说话人 SPEAKER_01：但我们没有意识到它会好得多。
197 00:18:22,410 --> 00:18:30,923 说话者 SPEAKER_01：所以在 20 世纪 90 年代，神经网络处于相对沉寂的时期，因为其他方法在小问题上表现更好。
198 00:18:32,326 --> 00:18:36,432 说话者 SPEAKER_01：当时很多计算机科学领域的人放弃了神经网络。
199 00:18:37,814 --> 00:18:44,463 说话者 SPEAKER_01：但在心理学领域，他们并没有放弃，因为在心理学领域，他们想要的是类似大脑的东西，而神经网络显然比符号人工智能更接近大脑。
200 00:18:44,923 --> 00:18:48,710 说话者 SPEAKER_01：但在计算机科学领域，神经网络在 90 年代有点声名狼藉。
201 00:18:49,750 --> 00:18:52,935 说话人 SPEAKER_02：那么让我们快进到另一个十年，即 2000 年代。
202 00:18:54,979 --> 00:19:02,089 说话人 SPEAKER_02：您有没有一个时刻，让您意识到您一直在追求的方法将会取得胜利？
203 00:19:02,150 --> 00:19:07,196 说话人 SPEAKER_01：好的，在 2006 年，
204 00:19:07,632 --> 00:19:13,886 说话人 SPEAKER_01：我们通过无监督学习找到了更好的初始化权重方法，然后反向传播工作得更好了。
205 00:19:14,367 --> 00:19:18,417 说话者 SPEAKER_01：那时已经很清楚，反向传播真的会非常有效。
206 00:19:19,359 --> 00:19:35,746 说话者 SPEAKER_01：但在 2009 年，我的两位研究生乔治·达尔和阿卜杜拉·穆罕默德制作了一个更好的语音识别器，实际上是一个稍微更好的语音识别器，但它的性能略好于当时的技术水平，使用了深度神经网络。
207 00:19:36,487 --> 00:19:39,992 说话者 SPEAKER_01：然后很明显，这些东西有发展的方向。
208 00:19:40,353 --> 00:19:44,759 说话者 SPEAKER_01：接下来几年，所有大型语音集团都转向使用神经网络。
209 00:19:46,057 --> 00:19:52,147 说话人 SPEAKER_01：然后在 2012 年，语音功能在 Android 上推出，Android 突然赶上了 Siri。
210 00:19:52,568 --> 00:19:55,153 说话人 SPEAKER_01：它的语音识别和 Siri 一样好，因为它使用了神经网络。
211 00:19:56,134 --> 00:20:07,515 说话人 SPEAKER_01：同年，我的两位研究生，伊利亚·苏特科娃和安德烈·克里切夫斯基，开发了一个在识别物体和图像方面非常出色的神经网络。
212 00:20:07,935 --> 00:20:10,359 说话人 SPEAKER_01：它大幅超越了当时的最高水平。
213 00:20:10,778 --> 00:20:16,636 说话人 SPEAKER_01：我认为正是这种组合使得语音识别已经取得成效并投入生产。
214 00:20:17,461 --> 00:20:21,003 说话人 SPEAKER_01：大公司是这样做的，我认为公众对此并不十分了解。
215 00:20:21,444 --> 00:20:24,606 说话人 SPEAKER_01：但突然之间，它在计算机视觉方面的表现更好。
216 00:20:25,428 --> 00:20:27,049 说话人 SPEAKER_01：那是一个转折点。
2012 年，当我们以巨大的优势赢得 ImageNet 竞赛时，我们的错误率几乎是其他方法的一半。
这是一个公开的数据集，但有一个隐藏的测试集，所以你不能作弊。
所以让我们稍微关注一下2012年，因为你说那是一个非常重要的年份。
你能再次从高层次上描述一下 AlexNet 是如何工作的吗？
221 00:20:54,268 --> 00:20:57,133 说话人 SPEAKER_02：我认为这可能是以你的研究生命名的。
222 00:20:57,153 --> 00:21:03,962 说话人 SPEAKER_01：那是以亚历克斯·克雷齐斯维斯基的名字命名的，因为他是一位巫师级的程序员，他让这个程序运行起来。
223 00:21:04,964 --> 00:21:08,049 说话人 SPEAKER_01：伊利亚帮助了很多，但主要是亚历克斯的工作。
224 00:21:08,971 --> 00:21:13,438 说话人 SPEAKER_01：所以，我向你解释了，在解释反向传播时，你会有这些特征检测器的层级。
225 00:21:14,464 --> 00:21:24,494 说话人 SPEAKER_01：AlexNet 基本上就是这样的一种网络，但包含了 1000 个不同的物体类别，并且有大约 7 层特征检测器。
226 00:21:25,756 --> 00:21:32,803 说话人 SPEAKER_01：它还使用了 Yann LeCun 开发的其他技术，即卷积网络。
227 00:21:33,482 --> 00:21:35,924 说话人 SPEAKER_01：我现在会尝试解释这些，因为它们非常重要。
228 00:21:38,728 --> 00:21:43,813 说话人 SPEAKER_01：记得我之前说过，你可以通过
229 00:21:44,079 --> 00:21:50,449 说话人 SPEAKER_01：检查两行，通过有两行这样的，如果你看到那些两个特征检测器，那么就做一个喙检测器。
230 00:21:50,929 --> 00:21:53,272 说话人 SPEAKER_01：但这只是针对特定位置，对吧？
231 00:21:54,354 --> 00:22:02,605 说话人 SPEAKER_01：在卷积神经网络中，当你为某个位置制作一个特征检测器时，你会为图像中的所有位置制作相同的特征检测器。
232 00:22:04,327 --> 00:22:08,973 说话人 SPEAKER_01：所以现在，如果它在这里训练了喙，当它学习时，
233 00:22:09,325 --> 00:22:11,467 说话人 SPEAKER_01：这真是有趣，我需要为这个设计一个喙检测器。
234 00:22:11,926 --> 00:22:13,808 说话人 SPEAKER_01：所以它学习了一个检测这个喙的特征。
235 00:22:14,430 --> 00:22:18,353 说话人 SPEAKER_01：它会自动为图像中的其他所有位置制作副本。
236 00:22:19,034 --> 00:22:24,138 说话人 SPEAKER_01：所以如果现在鸟出现在不同的位置，它将会有特征检测器来识别它。
237 00:22:25,480 --> 00:22:30,884 说话人 SPEAKER_01：所以这个想法，将特征检测器复制到每个位置，本质上就是一个卷积网络。
238 00:22:32,567 --> 00:22:36,971 说话人 SPEAKER_01：这使得整个系统在位置上的泛化能力大大提高。
239 00:22:37,010 --> 00:22:39,113 说话人 SPEAKER_01：现在它可以应对位置变化的情况。
240 00:22:39,633 --> 00:22:42,316 说话人 SPEAKER_01：因为每个位置都有这些特征检测器的副本。
241 00:22:43,797 --> 00:23:00,573 说话人 SPEAKER_01：通过卷积网络和多层特征，亚历克斯在一种名为图形处理单元的设备上非常高效地编程了所有这些，这种设备最初是为计算机图形开发的，但它就像一台微型超级计算机。
242 00:23:01,413 --> 00:23:06,618 说话人 SPEAKER_01：它可以在众多独立进程中同时进行大量的计算。
243 00:23:07,273 --> 00:23:10,598 说话人 SPEAKER_01：这使得我们的计算能力比普通计算机提高了约 30 倍。
244 00:23:11,421 --> 00:23:14,786 说话人 SPEAKER_01：30 倍的增长相当于计算机领域 10 年的进步。
245 00:23:15,446 --> 00:23:18,832 说话人 SPEAKER_01：所以我们突然可以在计算能力上跃进 10 年。
246 00:23:20,654 --> 00:23:25,142 说话人 SPEAKER_01：编程这些 GPU 板子非常困难。
247 00:23:26,104 --> 00:23:29,569 说话人 SPEAKER_01：亚历克斯设法编程了两块，使它们能够协作，这更加困难。
248 00:23:31,472 --> 00:23:34,917 说话人 SPEAKER_01：最后一个要素是 ImageNet 数据集。
249 00:23:35,454 --> 00:23:47,590 说话人 SPEAKER_01：所以有人叫李飞飞，她和她的合作者整理了一大套图片，然后举办了一场公开竞赛，大约有一百万张图片，包含一千种不同的物体。
250 00:23:47,631 --> 00:23:49,933 说话人 SPEAKER_01：所以每种物体大约有一千个例子。
251 00:23:50,674 --> 00:23:52,617 说话人 SPEAKER_01：然后你需要学会识别这些物体。
252 00:23:53,138 --> 00:23:57,364 说话人 SPEAKER_01：然后测试集会有不同的图片，这些图片也包含这些物体。
253 00:23:57,644 --> 00:23:59,606 说话人 SPEAKER_01：因此，你需要对不同图像进行泛化。
254 00:24:00,489 --> 00:24:03,031 说话人 SPEAKER_01：结果证明，当时发明的最好的计算机视觉技术
255 00:24:03,349 --> 00:24:10,277 说话人 SPEAKER_01：的错误率高达 25%，而 Alex 的误差率只有 15%。
256 00:24:11,577 --> 00:24:13,859 说话人 SPEAKER_01：从那时起，错误率已经下降到大约 3%。
257 00:24:14,119 --> 00:24:15,080 说话人 SPEAKER_01：从那时起进展得要好得多。
258 00:24:15,461 --> 00:24:30,336 说话人 SPEAKER_01：但这是一个巨大的飞跃，计算机视觉领域的人们都非常惊讶，他们大多数人都表现得非常令人钦佩，就是说，我们从未想过这会奏效，但嘿，它奏效了，所以我们决定改变我们之前所做的事情。
259 00:24:30,653 --> 00:24:32,194 说话人 SPEAKER_01：这就是科学家们通常不会做的事情。
260 00:24:32,394 --> 00:24:35,479 说话人 SPEAKER_01：科学家们通常只是随着年龄的增长抱怨新东西都是胡说八道。
261 00:24:35,919 --> 00:24:41,164 说话人 SPEAKER_02：那么您如何描述自那时以来人工智能创新的步伐呢？
262 00:24:41,905 --> 00:24:43,327 说话人 SPEAKER_01：它只是越来越快。
263 00:24:43,607 --> 00:24:53,960 说话人 SPEAKER_01：所以如果那时问我，这些神经网络何时能进行比当前技术水平更好的机器翻译，我会说可能需要 10 年。
264 00:24:54,579 --> 00:24:58,585 说话人 SPEAKER_01：因为机器翻译是这样的东西
265 00:24:58,565 --> 00:25:08,682 说话人 SPEAKER_01：如果你有一个全部关于处理符号串的理论，机器翻译就是为你量身定做的，因为你在一种语言中有符号串，你必须产生另一种语言的符号串。
266 00:25:09,482 --> 00:25:13,569 说话人 SPEAKER_01：符号派的人认为，你只是在操作字符串来完成这个任务。
267 00:25:14,912 --> 00:25:23,626 说话人 SPEAKER_01：神经网络派的人认为，你必须将这个符号串转换成这些大的神经网络活动模式，然后你还得将它转换回符号输出。
268 00:25:25,008 --> 00:25:35,642 说话人 SPEAKER_01：我非常惊讶，机器翻译只用了几年时间就变得很好，然后在一年或两年后，谷歌开始使用它，这极大地提高了机器翻译的质量。
269 00:25:36,343 --> 00:25:48,078 说话人 SPEAKER_01：就像在中文这样的语言中，这是来自记忆的，但计算机翻译和人工翻译之间的差距，一夜之间就缩小了一半。
270 00:25:49,273 --> 00:25:50,335 说话人 SPEAKER_01：我认为是中文做到了这一点。
271 00:25:50,996 --> 00:25:52,898 说话人 SPEAKER_01：但在很多语言中，它只是让翻译变得更好。
272 00:25:53,278 --> 00:25:56,282 说话人 SPEAKER_01：从那时起，显然，它已经变得相当好了。
273 00:25:56,884 --> 00:25:59,247 说话人 SPEAKER_01: 但到 2015 年，它已经运作得相当好了。
274 00:26:00,188 --> 00:26:01,170 说话人 SPEAKER_01: 这真的让我感到惊讶。
275 00:26:01,269 --> 00:26:02,151 说话人 SPEAKER_01: 只用了三年时间。
276 00:26:04,693 --> 00:26:07,117 说话人 SPEAKER_00: 你说你对创新的步伐感到惊讶。
277 00:26:07,597 --> 00:26:11,703 说话人 SPEAKER_00: 你第一次使用像 ChatGPT 这样的大型语言模型时，你怎么想的？
278 00:26:12,124 --> 00:26:13,065 说话人 SPEAKER_00: 我们让你惊讶了吗？
279 00:26:13,085 --> 00:26:18,893 说话人 SPEAKER_01: 我只是对它的好感到震惊。
280 00:26:19,987 --> 00:26:25,700 说话人 SPEAKER_01: 它可以给出非常连贯的答案，并且可以进行一些推理。
281 00:26:26,301 --> 00:26:29,429 说话人 SPEAKER_01: 尽管目前还不是很复杂的推理，但它的能力会大大提高。
282 00:26:30,230 --> 00:26:38,670 说话人 SPEAKER_01：例如，我问它，这是 GPT-4，我向它提出了一个符号 AI 人士给我的谜题。
283 00:26:39,426 --> 00:26:40,768 说话人 SPEAKER_01：他认为它做不到。
284 00:26:41,648 --> 00:26:44,092 我实际上把这个谜题做得更难，它仍然能做。
285 00:26:44,751 --> 00:26:45,913 所以这个谜题是这样的。
286 00:26:46,673 --> 00:26:51,097 说话人 SPEAKER_01：我家里的房间要么是白色，要么是蓝色，要么是黄色。
287 00:26:53,740 --> 00:26:56,344 说话人 SPEAKER_01：黄色的油漆一年后就会褪成白色。
288 00:26:57,565 --> 00:27:00,428 说话人 SPEAKER_01：两年后，我想所有的房间都是白色的。
289 00:27:00,748 --> 00:27:01,409 说话人 SPEAKER_01：我应该怎么做？
290 00:27:04,451 --> 00:27:07,914 说话人 SPEAKER_01：一个人类可能会说，你应该把蓝色的房间刷成白色。
291 00:27:08,991 --> 00:27:15,339 说话人 SPEAKER_01：GPT-4 说的是你应该把蓝色的房间刷成黄色，但这也可以，因为黄色会逐渐变成白色。
292 00:27:16,340 --> 00:27:21,086 说话人 SPEAKER_01：我不明白它是如何做到这一点的，除非它理解了这个问题。
293 00:27:21,807 --> 00:27:25,633 说话人 SPEAKER_01：它只是预测下一个单词并使用统计学的想法。
294 00:27:26,733 --> 00:27:32,181 说话者 SPEAKER_01：在某种程度上这是真的，但不是大多数人理解的统计学意义上的。
295 00:27:33,358 --> 00:27:42,229 说话者 SPEAKER_01：它从数据中分析出如何提取句子的含义，并使用句子的含义来预测下一个单词。
296 00:27:42,730 --> 00:27:45,512 说话者 SPEAKER_01：它真的理解了，这相当令人震惊。
297 00:27:46,614 --> 00:27:51,799 说话者 SPEAKER_02：那么，你对更广泛的反应，公众对 Chat GPT 的反应感到惊讶吗？
298 00:27:53,261 --> 00:27:56,865 说话人 SPEAKER_01：嗯，鉴于它工作得很好，公众的反应并不令人惊讶。
299 00:27:57,106 --> 00:27:58,387 说话人 SPEAKER_01：但有趣的是，
300 00:27:59,599 --> 00:28:02,544 说话人 SPEAKER_01：大多数人不会说，它不理解。
301 00:28:03,305 --> 00:28:05,988 说话人 SPEAKER_01：他们说，哇，它理解了我说的内容，并给了我一个连贯的回答。
302 00:28:06,348 --> 00:28:07,250 说话人 SPEAKER_01：我能用它来做什么？
303 00:28:08,471 --> 00:28:10,894 说话人 SPEAKER_01：我认为大多数人对此的看法是正确的。
304 00:28:11,996 --> 00:28:15,259 说话人 SPEAKER_01：当然，它可以用于大量的事物。
305 00:28:16,000 --> 00:28:20,006 说话人 SPEAKER_01：所以我知道有人为医疗服务回答投诉信。
306 00:28:21,969 --> 00:28:26,413 说话人 SPEAKER_01：他以前要花 25 分钟来撰写一封解决问题的信。
307 00:28:27,015 --> 00:28:29,218 说话人 SPEAKER_01：现在他只需将问题输入到
308 00:28:30,565 --> 00:28:33,569 说话人 SPEAKER_01：GPT-4，然后它就会写这封信。
309 00:28:34,089 --> 00:28:38,698 说话人 SPEAKER_01：然后他只需看一下这封信，决定是否可以发送，现在只需要 5 分钟。
310 00:28:39,258 --> 00:28:41,141 说话人 SPEAKER_01：所以他现在效率提高了五倍。
311 00:28:42,143 --> 00:28:46,209 说话人 SPEAKER_01：这种情况将会无处不在，就像法律助理也会这样。
312 00:28:46,990 --> 00:28:48,712 说话人 SPEAKER_01：程序员已经变得这样了。
313 00:28:49,173 --> 00:28:55,864 说话人 SPEAKER_01：如果程序员得到像 GPT-4 这样的帮助，他们可以更有效率，因为它知道如何编程。
314 00:28:56,890 --> 00:29:01,496 说话人 SPEAKER_01：你可能认为它只是因为看过很多程序而知道如何编程。
315 00:29:03,699 --> 00:29:06,824 说话人 SPEAKER_01：所以我有一个非常聪明且编程能力很强的前研究生。
316 00:29:08,144 --> 00:29:12,070 说话人 SPEAKER_01：他做了一项小实验，他的名字叫 Radford Neal。
317 00:29:12,530 --> 00:29:22,424 说话人 SPEAKER_01：他使用了 GPT-4，并定义了一种具有非常不寻常语法的新的编程语言。
318 00:29:23,806 --> 00:29:30,893 说话者 SPEAKER_01：定义了这种编程语言后，仅用文本输入给 GPT-4，然后给它一个程序，问它会做什么？
319 00:29:32,095 --> 00:29:33,096 说话者 SPEAKER_01：它回答正确。
320 00:29:34,136 --> 00:29:39,461 说话者 SPEAKER_01：所以基本上，它能够理解一种新编程语言的定义，并找出该语言中的程序会做什么。
321 00:29:40,823 --> 00:29:46,429 说话者 SPEAKER_01：再次强调，在这种情境下，它只是预测下一个词的想法是没有意义的。
322 00:29:46,469 --> 00:29:48,230 说话人 SPEAKER_01：它必须理解正在发生的事情。
323 00:29:49,152 --> 00:29:52,075 说话人 SPEAKER_02：那么您认为这种人工智能在造福社会方面有哪些最有希望的机会？
324 00:29:53,032 --> 00:29:56,340 说话人 SPEAKER_02：对于这种类型的人工智能来说，有哪些造福社会的机会？
325 00:29:58,306 --> 00:30:00,170 说话人 SPEAKER_01：很难挑选一个，因为有很多。
326 00:30:00,951 --> 00:30:07,768 说话人 SPEAKER_01：就像，任何涉及输出文本的工作都会大幅提高生产力。
327 00:30:08,997 --> 00:30:12,020 说话人 SPEAKER_01：关于提高生产力有许多问题。
328 00:30:12,040 --> 00:30:17,228 说话人 SPEAKER_01：在我们的社会中，提高生产力并不一定是好事，因为它可能会让富人更富，穷人更穷。
329 00:30:17,868 --> 00:30:21,433 说话人 SPEAKER_01：但在一个公正的社会里，仅仅提高生产力就应该是好事。
330 00:30:22,134 --> 00:30:23,376 说话人 SPEAKER_01: 所以会有那样的事情。
331 00:30:24,999 --> 00:30:26,721 说话人 SPEAKER_01: 对于预测来说非常棒。
332 00:30:26,760 --> 00:30:29,605 说话人 SPEAKER_01: 它在预测天气方面会更好。
333 00:30:30,361 --> 00:30:31,722 说话人 SPEAKER_01: 人们还不知道会好多少。
334 00:30:32,103 --> 00:30:35,267 说话人 SPEAKER_01：但它已经擅长预测洪水了。
335 00:30:36,028 --> 00:30:37,328 说话人 SPEAKER_01：它能预测地震。
336 00:30:38,069 --> 00:30:40,653 说话人 SPEAKER_01：它能设计新的纳米材料。
337 00:30:41,354 --> 00:30:44,458 说话人 SPEAKER_01：所以对于太阳能电池板这样的东西，你希望能够设计新的纳米材料。
338 00:30:44,798 --> 00:30:46,200 说话人 SPEAKER_01：或者用于超导。
339 00:30:46,240 --> 00:30:49,023 说话人 SPEAKER_01：我不知道它是否已经用于超导，但它很可能已经如此。
340 00:30:49,744 --> 00:30:52,587 说话人 SPEAKER_01：你希望它在高温下。
341 00:30:52,567 --> 00:30:55,030 说话人 SPEAKER_01：它在设计药物方面真的很擅长。
342 00：30：56,432 --> 00：31：01,138 演讲者 SPEAKER_01：也就是说，找到会与其他特定分子结合的分子。
DeepMind 用它创建了 AlphaFold。
344 00：31：06,766 --> 00：31：09,609 演讲者 SPEAKER_01：现在这不是聊天机器人，那只是深度学习。
345 00：31：10,971 --> 00：31：15,116 演讲者 SPEAKER_01：但是深度学习的基本技术已经
346 00:31:16,767 --> 00:31:24,758 说话人 SPEAKER_01：基本上解决了如何从蛋白质的碱基序列中推断其形状的问题。
347 00:31:25,239 --> 00:31:27,162 说话人 SPEAKER_01：如果你知道它采取的形状，你就知道它的功能。
348 00:31:27,702 --> 00:31:30,145 说话人 SPEAKER_01：我认为聊天机器人将会被广泛应用于各个领域。
349 00:31:31,868 --> 00:31:33,651 说话人 SPEAKER_02：我们还讨论了很多关于医疗保健的话题。
350 00:31:33,671 --> 00:31:38,557 说话人 SPEAKER_02：我的意思是，你提到了药物发现，但医疗保健也是另一个可以真正受益的领域。
351 00:31:38,577 --> 00:31:38,818 说话人 SPEAKER_01：是的。
352 00:31:39,539 --> 00:31:46,690 说话人 SPEAKER_01：在解读医学扫描方面，比如如果你做一个 CT 扫描，CT 扫描中有很多信息，
353 00:31:47,159 --> 00:32:01,672 说话人 SPEAKER_01：而这些信息并没有被利用，大多数医生也不知道这些信息是什么，这将能够从 CT 扫描中获得更多信息，以及能够与医生竞争，说出你有什么癌症或它长得有多大。
354 00:32:01,692 --> 00:32:10,701 说话人 SPEAKER_01：目前，例如，当医生告诉你癌症的大小，你会得到一个像三厘米这样的数字，而一个月前它是两厘米。
355 00:32:11,862 --> 00:32:15,224 说话人 SPEAKER_01：现在，如果这东西看起来像章鱼，那这个数字就不是很有用，对吧？
356 00:32:17,077 --> 00:32:21,884 说话人 SPEAKER_01：神经网络将能够更好地理解癌症的体积以及它的变化。
357 00:32:23,285 --> 00:32:25,607 说话人 SPEAKER_01：所以在那方面将会非常巨大。
358 00:32:26,169 --> 00:32:30,914 说话人 SPEAKER_01：它已经在很多种扫描的水平上达到人类水平，而且会变得更好。
359 00:32:32,316 --> 00:32:34,838 说话人 SPEAKER_01：它对诊断疾病将非常有帮助。
360 00:32:35,160 --> 00:32:43,068 说话人 SPEAKER_01：目前，在北美有大量的人因为医生误诊而死亡。
361 00:32:44,450 --> 00:32:55,644 说话人 SPEAKER_01：谷歌正在生产一个名为 MedPalm2 的系统，它已经学会了进行诊断，我认为它的表现已经超过了普通医生。
362 00:32:56,286 --> 00:32:59,109 说话人 SPEAKER_01：我对这个不太确定，因为我已经不在谷歌了，而且这件事很近。
363 00:33:00,132 --> 00:33:04,237 说话人 SPEAKER_01：但它的确可以与医生相提并论，而且它会快速变得更好。
364 00:33:04,257 --> 00:33:09,384 说话人 SPEAKER_01：所以您是否希望有一个全科医生，一个家庭医生？
365 00:33:10,105 --> 00:33:12,127 说话人 SPEAKER_01：您去看一些罕见的疾病，
366 00:33:12,361 --> 00:33:16,930 说话人 SPEAKER_01：你希望你的家庭医生已经看过数百例这种罕见疾病的病例。
367 00:33:16,950 --> 00:33:18,854 说话人 SPEAKER_01：而 MedPalm2 将会是这样。
368 00:33:19,496 --> 00:33:23,364 说话人 SPEAKER_01：所以它最终将更擅长诊断。
369 00:33:25,627 --> 00:33:28,453 说话人 SPEAKER_00：听起来人工智能将带来许多重要的好处。
370 00:33:29,516 --> 00:33:32,563 说话人 SPEAKER_00: 但你已经表达了对当前创新速度的担忧。
371 00:33:33,324 --> 00:33:33,744 说话人 SPEAKER_01: 为什么？
372 00:33:34,265 --> 00:33:44,604 说话人 SPEAKER_01: 好吧，就像 50 年一样，我在 49 年里认为，为了使数字模型更好，我们需要让它们更像大脑工作。
373 00:33:45,285 --> 00:33:55,462 说话人 SPEAKER_01: 所以我一直观察大脑所做的，而数字模型没有做的事情，比如以临时方式快速改变连接强度，这可以使数字模型变得更好。
374 00:33:57,771 --> 00:34:07,191 说话人 SPEAKER_01：最近我意识到，因为这些数字模型具有这种蜂群意识，当一个代理学习到一些东西时，所有其他代理都知道。
375 00:34:07,828 --> 00:34:10,893 说话人 SPEAKER_01：它们实际上可能已经比生物智能更好了。
376 00:34:11,795 --> 00:34:18,385 说话人 SPEAKER_01：所以我完全改变了我的观点，从之前认为它们要很长时间才能做到大脑能做的一切。
377 00:34:19,067 --> 00:34:23,894 说话人 SPEAKER_01：它们将在 30 到 50 年内超过我们，这是我直到最近才认为的。
378 00:34:24,896 --> 00:34:29,123 说话人 SPEAKER_01：几个月前，我突然意识到他们可能已经比我们更优秀了。
379 00:34:29,563 --> 00:34:31,186 说话人 SPEAKER_01：他们只是规模更小。
380 00:34:31,369 --> 00:34:34,836 说话人 SPEAKER_01：而当它们变得更大时，它们就会比我们更聪明。
381 00:34:35,599 --> 00:34:36,621 说话人 SPEAKER_01：这相当可怕。
382 00:34:36,641 --> 00:34:43,375 说话人 SPEAKER_01：观点突然改变，不再是 30 到 50 年，而是 5 年到 20 年左右。
383 00:34:44,117 --> 00:34:51,893 说话人 SPEAKER_01：因此，我们现在必须认真对待这个问题，这些事物可能会比我们更聪明。
384 00:34:52,210 --> 00:34:55,313 说话人 SPEAKER_01：这是一个充满不确定性的时期，没有人真正知道会发生什么。
385 00:34:56,014 --> 00:34:59,137 说话人 SPEAKER_01：也许事情会停滞不前，也许它们不会比我们更聪明。
386 00:34:59,856 --> 00:35:01,059 说话人 SPEAKER_01：但我真的不相信。
387 00:35:01,418 --> 00:35:02,840 说话人 SPEAKER_01：我认为它们会比我们更聪明。
388 00:35:03,201 --> 00:35:12,869 说话人 SPEAKER_01：但也许当它们比我们更聪明时，我们能够使它们保持善良，我们能够使它们比关心自己更多关心人，不像人类。
389 00:35:13,309 --> 00:35:13,990 说话人 SPEAKER_01：但也许不会。
390 00:35:14,811 --> 00:35:18,355 说话人 SPEAKER_01：所以我们必须要非常认真地思考这些问题。
391 00:35:18,474 --> 00:35:20,277 说话人 SPEAKER_01：我对这些问题并不在行。
392 00:35:21,539 --> 00:35:23,820 说话人 SPEAKER_01：我只对这些学习算法有所研究。
393 00:35:25,023 --> 00:35:29,467 说话人 SPEAKER_01：我突然意识到这些超级智能可能很快就会到来。
394 00:35:30,507 --> 00:35:38,817 说话人 SPEAKER_01：我只是拉响警报，让人们听听那些长期以来一直在思考如何阻止他们夺取控制权的人。
395 00:35:40,217 --> 00:35:45,764 说话人 SPEAKER_01：我希望政治家们能听听那些人的意见，而不是说，嗯，嗯，他们是科幻小说作家。
396 00:35:46,244 --> 00:35:47,125 说话人 SPEAKER_01：这永远不可能发生。
397 00:35:48,016 --> 00:35:54,402 说话人 SPEAKER_02：有没有什么特别的时刻，你提到说这是最近的事情，你对此的看法有所改变？
398 00:35:54,844 --> 00:36:04,474 说话人 SPEAKER_01：我正在开发适用于生物系统的学习算法，这些算法可以在生物系统中运行，它们不使用反向传播。
399 00:36:05,655 --> 00:36:10,581 说话人 SPEAKER_01：但我无法让它们像我们在这些数字系统中运行的反向传播算法那样工作得更好。
400 00:36:11,623 --> 00:36:18,572 说话人 SPEAKER_01：而且它们在小网络中可以工作，但当规模扩大时，数字系统总是比生物系统工作得更好。
401 00:36:19,614 --> 00:36:21,775 说话人 SPEAKER_01：突然间我想这可能是我的错。
402 00:36:22,217 --> 00:36:27,003 说话人 SPEAKER_01：可能不是我的学习算法本身就是一个差劲的学习算法。
403 00:36:27,023 --> 00:36:29,525 说话人 SPEAKER_01：可能是因为这些数字系统本身就更好。
404 00:36:31,407 --> 00:36:36,454 说话人 SPEAKER_01：就在那时，我突然改变了关于我们何时会得到超级智能的看法。
405 00:36:37,375 --> 00:36:41,260 说话人 SPEAKER_01：然后我跟我的一些前学生和前同事谈了谈。
406 00:36:41,746 --> 00:36:44,170 说话人 SPEAKER_01：他们中的一些人鼓励我把这件事公之于众。
407 00:36:45,032 --> 00:36:47,596 说话人 SPEAKER_01：不是因为我想推荐任何解决方案。
408 00:36:49,018 --> 00:36:52,164 说话人 SPEAKER_01：并不是说减少碳排放一切就会好起来。
409 00:36:54,188 --> 00:36:56,532 说话人 SPEAKER_01：而是因为他们认为
410 00:36:56,797 --> 00:36:58,079 说话人 SPEAKER_01：我在这个领域很有名。
411 00:36:58,199 --> 00:37:12,956 说话人 SPEAKER_01：如果我在公众面前说超级智能可能很快就会到来，政客们可能会开始相信这是可能的，并开始认真倾听那些长时间思考如何防止这些事物获得控制的研究人员。
412 00:37:13,978 --> 00:37:23,329 说话人 SPEAKER_02：那么从您的角度来看，政府在帮助确保这些 AI 以负责任的方式发展方面可以扮演什么角色？
413 00:37:23,849 --> 00:37:29,016 说话人 SPEAKER_01：所以有很多其他人谈论过的各种风险，我特别不想谈论，比如...
414 00:37:29,603 --> 00:37:33,907 说话人 SPEAKER_01：它们会夺走工作，并加剧贫富差距。
415 00:37:34,728 --> 00:37:37,773 说话人 SPEAKER_01：它们将使人们无法判断新闻是真是假。
416 00:37:38,795 --> 00:37:45,623 说话人 SPEAKER_01：它们将鼓励社会分裂成两个相互不听取对方意见、持有完全对立观点的战争阵营。
417 00:37:46,864 --> 00:37:49,467 说话人 SPEAKER_01：他们将制造设计用来杀人的人形战斗机器人。
418 00:37:50,048 --> 00:37:52,391 说话人 SPEAKER_01：我所说的这些风险都是众所周知的，我并不想讨论。
419 00:37:52,431 --> 00:37:54,213 说话人 SPEAKER_01：并不是我不认为它们很重要。
420 00:37:54,233 --> 00:37:55,675 说话人 SPEAKER_01：我认为它们可能更加紧迫。
421 00:37:56,896 --> 00:37:59,019 说话人 SPEAKER_01：但是很多人都在谈论这些风险。
422 00:37:59,489 --> 00:38:03,275 说话人 SPEAKER_01：我所说的风险是这些事物最终会变得比我们聪明并最终接管一切的风险。
423 00:38:04,277 --> 00:38:10,527 说话人 SPEAKER_01：对于这种风险，政府可能可以采取一些措施，因为没有人希望这样。
424 00:38:12,150 --> 00:38:15,976 说话人 SPEAKER_01：好吧，如果你排除了这些超级智能，没有人希望这样。
425 00:38:16,958 --> 00:38:21,565 说话人 SPEAKER_01: 因此，所有不同的政府都应该能够达成一致
426 00:38:22,726 --> 00:38:27,755 说话人 SPEAKER_01: 他们应该能够共同努力防止这种情况，因为这符合他们的利益。
427 00:38:28,195 --> 00:38:29,036 说话人 SPEAKER_01: 这以前已经发生过。
428 00:38:29,157 --> 00:38:37,831 说话人 SPEAKER_01: 即使在冷战期间，美国和俄罗斯也能共同努力防止发生全球核战争，因为这对所有人来说都是一场灾难。
429 00:38:38,858 --> 00:38:46,208 说话人 SPEAKER_01：对于这种存在性威胁，如果可能预防，应该让每个人都能够共同努力来限制它。
430 00:38:46,748 --> 00:38:54,920 说话人 SPEAKER_01：我不知道是否可能预防它，但至少我们应该能够在那个特定的威胁上实现国际合作，即人工智能接管的存在性威胁。
431 00:38:55,922 --> 00:39:02,992 说话人 SPEAKER_01：我认为应该做的一件事是，无论这些东西在哪里被开发，尤其是这些大型聊天机器人，
432 00:39:04,659 --> 00:39:15,155 说话人 SPEAKER_01：政府应该鼓励公司投入大量资源，因为这些东西变得越来越智能，进行实验以找出如何控制它们。
433 00:39:16,317 --> 00:39:26,753 说话者 SPEAKER_01：所以他们应该研究这些事物可能如何逃脱，并对此进行实证研究，投入大量资源，因为这是我们唯一的机会。
434 00:39:27,728 --> 00:39:32,454 说话者 SPEAKER_01：在他们变得超级智能之前，我们也许可以进行实验，看看会出什么问题。
435 00:39:33,376 --> 00:39:37,322 说话者 SPEAKER_01：我坚信我们需要这方面的实证数据。
436 00:39:37,342 --> 00:39:41,967 说话者 SPEAKER_01：你不能让哲学家、政治家和立法者随意制定规则。
437 00:39:42,668 --> 00:39:47,496 说话人 SPEAKER_01：你需要对这些事情进行实证研究，看看它们是如何出错，以及你如何控制它们。
438 00:39:48,577 --> 00:39:50,460 说话人 SPEAKER_01：这只能由开发它们的人来完成。
439 00:39:51,862 --> 00:39:56,688 说话人 SPEAKER_01：既然你无法阻止它们的发展，你能做的最好的就是
440 00:39:57,039 --> 00:40:08,117 说话人 SPEAKER_01： somehow have governments put a lot of pressure on these companies to put a lot of resources into investigating empirically how to keep them under control when they're not quite as smart as us.
441 00:40:09,320 --> 00:40:15,489 说话人 SPEAKER_02：那么您认为这些大型科技公司在这些发展发生的地方扮演着怎样的角色？
442 00:40:15,931 --> 00:40:18,474 说话人 SPEAKER_02：他们会在没有那种政府监管的情况下这样做吗？
443 00:40:19,027 --> 00:40:27,619 说话人 SPEAKER_01：所以，很多大公司里的人，我所知道的那些在大公司里担任高级职务的人，都非常担心这个问题，并且为此投入了工作。
444 00:40:28,641 --> 00:40:29,742 说话人 SPEAKER_01：他们对此非常关心。
445 00:40:30,523 --> 00:40:32,586 说话人 SPEAKER_01：但他们有义务对股东负责。
446 00:40:33,469 --> 00:40:35,512 说话人 SPEAKER_01：我认为是为了获得高额利润。
447 00:40:36,492 --> 00:40:40,057 说话人 SPEAKER_01：而获得高额利润，尤其是在短期内，
448 00:40:40,342 --> 00:40:44,748 说话人 SPEAKER_01：并不利于投入大量精力确保其安全性。
449 00:40:45,769 --> 00:40:47,092 说话人 SPEAKER_01：你看，这在所有行业中都存在。
450 00:40:47,813 --> 00:40:58,568 说话人 SPEAKER_01：在美国铁路行业，拥有告知你车轮是否锁定的安全装置需要花钱，而大型铁路公司宁愿发生事故也不愿这么做。
451 00:41:01,213 --> 00:41:04,257 说话人 SPEAKER_01：谷歌，我知道一些关于这个大公司的事情，
452 00:41:04,237 --> 00:41:10,884 说话人 SPEAKER_01：并不完全如此，因为它明白如果发生不好的事情，它将遭受巨大的声誉损失。
453 00:41:11,384 --> 00:41:13,445 说话人 SPEAKER_01：这就是为什么谷歌没有发布这些聊天机器人。
454 00:41:13,525 --> 00:41:14,407 说话人 SPEAKER_01：它把它们保留为私密。
455 00:41:14,708 --> 00:41:16,650 说话人 SPEAKER_01：它不希望它们在世界各地供人们玩耍。
456 00:41:17,210 --> 00:41:26,340 说话人 SPEAKER_01：它想利用它们为你提供更好的搜索结果或帮你完成 Gmail，而不是让人们来玩耍。
457 00:41:27,521 --> 00:41:33,686 说话人 SPEAKER_01：它只能那样负责，直到 OpenAI 和微软将其推出，然后谷歌不得不竞争。
458 00:41:33,987 --> 00:41:39,416 说话人 SPEAKER_01：但大公司的大人物们真的很在乎他们的声誉，以及避免产生不良影响。
459 00:41:40,418 --> 00:41:49,653 说话人 SPEAKER_01：但也许可以通过政府采取行动，坚持要求他们投入大量工作来解决安全问题，使他们更加关注这个问题。
460 00:41:50,516 --> 00:41:55,945 说话人 SPEAKER_01：还有其他事情可能会发生，比如在公司内部，这非常困难。
461 00:41:56,431 --> 00:42:07,047 说话人 SPEAKER_01：让人们研究长期存在的生存威胁，因为他们是由公司支付的，存在利益冲突，这也是我离开谷歌的原因之一。
462 00:42:07,489 --> 00:42:10,954 说话人 SPEAKER_01：不是因为谷歌做了什么错事，只是我不想有任何利益冲突。
463 00:42:13,338 --> 00:42:19,688 说话人 SPEAKER_01：大型公司肯定可以做的一件事是投入更多资金支持研究这些问题的基金会。
464 00:42:20,173 --> 00:42:27,463 说话人 SPEAKER_01：例如，谷歌投入了 3 亿美元到一个名为 Anthropic 的基金会，该基金会正在研究这些问题。
465 00:42:29,545 --> 00:42:30,847 说话人 SPEAKER_01：他们可以投入更多的资金。
466 00:42:32,429 --> 00:42:46,789 说话人 SPEAKER_02：我想知道您会给那些刚刚进入这个领域的研究人员什么建议或指导，他们想要确保自己在推进这个领域的同时，也要以负责任的方式进行。
467 00:42:48,742 --> 00:42:57,704 说话人 SPEAKER_01：嗯，我会给出的一个建议是看看有多少人在努力让这些事物变得更好，有多少人在努力防止它们失控。
468 00:42:57,764 --> 00:43:03,318 说话人 SPEAKER_01：你会发现有 99 个人在努力让它们变得更好，而只有一个人在努力防止它们失控。
469 00:43:03,358 --> 00:43:06,246 说话人 SPEAKER_01：那么你可以在哪里产生最大的影响？
470 00:43:06,226 --> 00:43:09,088 说话人 SPEAKER_01：可能是在防止它们失控方面工作。
471 00:43:09,108 --> 00:43:10,530 说话人 SPEAKER_01：这是第一条建议。
472 00:43:11,371 --> 00:43:23,623 说话人 SPEAKER_01：另一条建议是对年轻研究者的普遍建议，那就是寻找你认为大家都在做错的地方，并相信你的直觉。
473 00:43:24,664 --> 00:43:33,431 说话者 SPEAKER_01：在你弄清楚你的直觉为什么错误之前，相信它，并在你认为其他人做错的时候，尝试其他的方法。
474 00:43:34,677 --> 00:43:37,019 说话者 SPEAKER_01：事实上，要么你有好的直觉，要么你没有。
475 00:43:37,641 --> 00:43:43,889 说话者 SPEAKER_01：如果你有好的直觉，你应该听从它们，跟随你的直觉，并在此基础上工作，直到你发现为什么它是错误的。
476 00:43:45,311 --> 00:43:49,255 说话者 SPEAKER_01：如果你有不好的直觉，你做什么其实都无关紧要，所以你不妨跟随你的直觉。
你所描述的风险令人担忧，但难道不能只是拉一下开关就关闭它吗？
478 00：43：56,806 --> 00：43：59,608 演讲者 SPEAKER_00：人类最终不是仍然在控制之中吗？
479 00：44：00,449 --> 00：44：03,974 议长 SPEAKER_01：我们很容易想到我们可以把它关掉。
480 00：44：05,777 --> 00：44：07,960 演讲者 SPEAKER_01：想象一下，这些东西比我们聪明得多。
481 00:44:08,840 --> 00:44:12,023 说话人 SPEAKER_01：记住，他们已经阅读了马基雅维利所写的所有东西。
482 00:44:12,724 --> 00:44:16,668 说话人 SPEAKER_01：他们会阅读人类欺骗文献中的每一个例子。
483 00:44:17,708 --> 00:44:21,092 说话人 SPEAKER_01：他们将真正成为人类欺骗的专家，因为他们已经从我们这里学到了这一点。
484 00:44:22,293 --> 00:44:23,474 说话人 SPEAKER_01：他们将会比我们做得更好。
485 00:44:24,295 --> 00:44:26,577 说话人 SPEAKER_01：他们将会像你操纵一个幼儿一样。
486 00:44:27,478 --> 00:44:29,840 你知道，你会对你的幼儿说，你是想吃豌豆还是花椰菜？
487 00:44:30,320 --> 00:44:34,164 幼儿并没有意识到，实际上他不必两者都要。
488 00:44:34,329 --> 00:44:39,416 他只是想哪个更不喜欢，然后说他会选择另一个。
489 00：44：39,797 --> 00：44：46,644 演讲者 SPEAKER_01：所以如果他们能纵人，他们就能纵人按下按钮和拉杆。
490 00:44:47,925 --> 00:44:50,108 说话者 SPEAKER_01：所以我们有一个很好的唐纳德·特朗普的例子。
特朗普可以操纵人们，所以他可以在从未亲自去过那里的情况下入侵华盛顿的一座建筑。
492 00:44:57,197 --> 00:45:00,961 说话者 SPEAKER_01：你不必阻止唐纳德·特朗普做任何身体上的事情。
493 00:45:01,853 --> 00:45:04,096 说话人 SPEAKER_01：你必须阻止他说话，以防止这种情况发生。
494 00:45:05,036 --> 00:45:05,998 说话人 SPEAKER_01：这些都是聊天机器人。
495 00:45:06,697 --> 00:45:12,525 说话人 SPEAKER_01：所以，仅仅通过谈话，它们无法造成任何真正的伤害，因为这需要人们去造成伤害。
496 00:45:12,965 --> 00:45:17,451 说话人 SPEAKER_01：一旦你能操纵人们，那么你就能完成任何你想要的事情。
497 00:45:20,092 --> 00:45:25,980 说话人 SPEAKER_00：你一生致力于理解人脑的工作原理，并在人工智能发展中发挥了关键作用。
498 00:45:26,681 --> 00:45:28,603 说话人 SPEAKER_00：接下来你有什么计划，杰弗里·辛顿？
499 00:45:30,170 --> 00:45:38,036 说话人 SPEAKER_01：好的，我今年 75 岁，已经到了写程序不太擅长的地步，因为我总是忘记我使用的变量名等。
500 00:45:38,657 --> 00:45:42,322 说话人 SPEAKER_01：还有，我忘记……我复制粘贴，然后忘记修改粘贴的内容。
501 00:45:43,181 --> 00:45:47,726 说话人 SPEAKER_01: 因此，我在编程上慢了很多，这非常令人烦恼。
502 00:45:48,166 --> 00:45:50,769 说话人 SPEAKER_01: 没有以前那么好，这非常令人烦恼。
503 00:45:52,030 --> 00:45:58,556 说话人 SPEAKER_01: 很久以前我就决定，当我达到那个地步时，我会成为一个哲学家。
504 00:45:59,650 --> 00:46:01,172 说话人 SPEAKER_01: 因此，我将成为一个哲学家。