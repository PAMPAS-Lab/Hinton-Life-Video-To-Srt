1 00:00:12,686 --> 00:00:22,184 说话人 SPEAKER_00：大家好，非常感谢大家的参与，我们有幸并且非常高兴地邀请到 Jeff Hinton 教授与我们同在。
2 00:00:23,187 --> 00:00:27,355 说话人 SPEAKER_00：Hinton 教授代表摩洛哥人工智能社区向大家
3 00:00:27,672 --> 00:00:30,335 说话人 SPEAKER_00：摩洛哥人工智能科学家和研究人员。
4 00:00:30,657 --> 00:00:32,219 说话人 SPEAKER_00：能够邀请到您我们感到非常荣幸。
5 00:00:32,478 --> 00:00:39,609 说话人 SPEAKER_00：我相信 Hinton 教授无需介绍，但我很荣幸能阅读他的简介并介绍他。
6 00:00:39,729 --> 00:00:49,545 说话人 SPEAKER_00：Geoffrey Hinton 教授是引入反向传播算法的研究者之一，也是第一个将反向传播用于学习词嵌入的人。
7 00:00:50,335 --> 00:00:55,604 说话人 SPEAKER_00：Hinton 教授在其数十年的职业生涯中发明了几个基础性的深度学习技术。
8 00:00:56,185 --> 00:01:07,066 说话人 SPEAKER_00：他对神经网络研究的其他贡献包括玻尔兹曼机、分布式表示、时间延迟神经网络、专家混合、变分学习和深度学习。
9 00:01:07,406 --> 00:01:08,427 说话人 说话人_00: 他的研究
10 00:01:08,864 --> 00:01:16,153 说话人 说话人_00: 加拿大多伦多的研究小组在深度学习领域取得了重大突破，他们的革命性语音识别和物体分类技术。
11 00:01:16,855 --> 00:01:22,563 说话人 说话人_00: 鹤汀教授于1978年在爱丁堡大学获得人工智能博士学位。
12 00:01:23,024 --> 00:01:29,572 说话人 说话人_00: 在卡内基梅隆大学担任五年教职后，他成为了加拿大研究院的院士。
13 00:01:29,552 --> 00:01:36,740 讲者 SPEAKER_00：为了高级研究，他转到了多伦多大学的计算机科学系，现在是一名荣誉教授。
14 00:01:37,120 --> 00:01:42,947 讲者 SPEAKER_00：他还是谷歌的工程副总裁兼 Vector 研究所的首席科学顾问。
15 00:01:43,688 --> 00:01:48,072 讲者 SPEAKER_00：Hinton 教授获得了许多奖项，我无法一一列举。
16 00:01:48,093 --> 00:01:50,295 讲者 SPEAKER_00：他是院士，我只想提及一些。
17 00:01:50,314 --> 00:01:59,424 说话人 SPEAKER_00：他是英国皇家学会会员，美国国家工程院和美国艺术与科学学院的前成员。
18 00:01:59,658 --> 00:02:14,717 说话人 SPEAKER_00：他的其他奖项包括大卫·鲁梅尔哈特奖、基拉姆工程奖、IEEE 弗兰克·罗森布拉特奖、IEEE 詹姆斯·柯克·麦克斯韦尔金牌和本田奖，当然还有都灵奖。
19 00:02:14,979 --> 00:02:17,861 说话人 SPEAKER_00：我们有幸邀请您，Hinton 教授。
20 00:02:18,002 --> 00:02:19,264 说话人 SPEAKER_00：请，您开始吧。
21 00:02:20,806 --> 00:02:22,087 说话人 SPEAKER_01: 感谢您的介绍。
22 00:02:33,306 --> 00:02:38,995 说话人 SPEAKER_02: 好的，我今天要讲的演讲和我在 NeurIPS 上最近讲的演讲非常相似。
23 00:02:39,795 --> 00:02:41,618 说话人 SPEAKER_02: 这篇论文是关于前向-前向算法的。
24 00:02:43,562 --> 00:02:52,875 说话人 SPEAKER_02: 其动机是为了尝试理解大脑如何获取梯度。
25 00:02:52,895 --> 00:02:56,780 说话人 SPEAKER_02：我们都知道反向传播工作得非常好。
26 00:02:57,622 --> 00:03:01,407 说话人 SPEAKER_02：它创造了像 Chat GPT 这样的东西，非常令人印象深刻。
27 00:03:01,639 --> 00:03:07,370 说话人 SPEAKER_02：这引发了一个问题，大脑是使用反向传播还是使用其他方式来获取梯度？
28 00:03:08,752 --> 00:03:18,889 说话人 SPEAKER_02：而与其专注于制作更大、更好的模型，在过去几年里，我一直专注于大脑是如何获取梯度的。
29 00:03:19,240 --> 00:03:22,705 说话者 SPEAKER_02：首先，我觉得大脑必须使用反向传播，因为它效果非常好。
30 00:03:23,626 --> 00:03:32,098 说话者 SPEAKER_02：现在我得出结论，它可能并没有使用反向传播，而且可能没有像使用反向传播的大系统那样有效。
31 00:03:34,080 --> 00:03:39,627 说话者 SPEAKER_02：没有令人信服的证据表明在大脑皮层中存在反向传播，即导数的反向传播。
32 00:03:40,687 --> 00:03:48,104 说话者 SPEAKER_02：如果你必须处理像视频这样的实时连续输入，那么时间反向传播显然是不可能的。
33 00:03:49,006 --> 00:03:52,334 说话者 SPEAKER_02：根本没时间让大脑停下来，将事情反向回传到过去。
34 00:03:53,697 --> 00:03:55,741 说话者 SPEAKER_02：如果你观察大脑的解剖结构，全都是错的。
35 00:03:56,643 --> 00:03:59,710 说话者 SPEAKER_02：所以，在两个向前连接的皮层区域之间，
36 00:04:00,584 --> 00:04:02,788 说话者 SPEAKER_02：以及向后连接的区域之间。
37 00:04:02,807 --> 00:04:11,723 讲者 SPEAKER_02：如果按照皮层区域与感知输入的接近程度进行排序，存在前向连接和反向连接，但反向连接并不与前向连接相对应。
38 00:04:12,584 --> 00:04:14,507 讲者 SPEAKER_02：实际上，你发现的是一些小环路。
39 00:04:15,408 --> 00:04:18,052 讲者 SPEAKER_02：所以在皮层下区域，
40 00:04:18,336 --> 00:04:21,899 讲者 SPEAKER_02：如果皮层下区域的一个层有活动的话。
41 00:04:22,440 --> 00:04:30,247 说话人 SPEAKER_02：它将在下皮质区和上皮质区经过大约六个不同的突触，活动才会回到起点。
42 00:04:31,108 --> 00:04:35,833 说话人 SPEAKER_02：所以它看起来是为执行诸如自动编码循环等活动而设置的，但并未为反向传播做好准备。
43 00:04:38,074 --> 00:04:45,541 说话人 SPEAKER_02：最后一个论点是反向传播需要精确的模型来描述你在正向传播中执行的计算，以便计算导数。
44 00:04:46,720 --> 00:05:00,797 说话人 SPEAKER_02：如果你有低功耗模拟硬件或像大脑这样的噪声硬件，其中单个神经元的输入输出特性会随时间漂移，那么获取梯度将会非常困难。
45 00:05:01,978 --> 00:05:13,591 说话人 SPEAKER_02：我们需要一个对硬件行为多变且无法正确建模的算法。
46 00:05:14,372 --> 00:05:16,035 说话人 SPEAKER_01：这就是前向-前向算法。
47 00:05:19,019 --> 00:05:25,271 说话人 SPEAKER_01：关于大脑，我们还知道它具有高度循环性。
48 00:05:26,413 --> 00:05:34,769 说话人 SPEAKER_02：例如，如果你研究小鼠的视觉皮层，虽然小鼠不是特别擅长视觉，但它们确实有视觉皮层。
49 00:05:35,228 --> 00:05:38,175 说话者 SPEAKER_02：如果你观察所谓的视觉皮层，
50 00:05:39,725 --> 00:05:42,949 说话者 SPEAKER_02：当鼠标行为不正常时，神经元由视觉驱动。
51 00:05:43,329 --> 00:05:51,500 说话者 SPEAKER_02：但是一旦鼠标开始表现行为，那么神经元就更多地由鼠标的肢体行为驱动，而不是由视觉驱动。
52 00:05:53,562 --> 00:05:55,966 说话者 SPEAKER_02：但大脑的每个地方，事物都是高度重复的。
53 00:05:57,007 --> 00:06:02,475 说话人 SPEAKER_02：这与纯前馈网络完全不匹配。
54 00:06:03,281 --> 00:06:14,055 说话人 SPEAKER_02：反向传播的问题在于我们工作的方式是，现在我们得到的大语言模型知道的比我们多得多，而且它们使用的权重要少得多。
55 00:06:16,218 --> 00:06:21,163 说话人 SPEAKER_02：所以反向传播实际上是为了将大量知识压缩到很少的权重中，比如只有一兆。
56 00:06:22,987 --> 00:06:24,749 说话人 SPEAKER_02：在大脑皮层中，你面临的是相反的问题。
57 00:06:25,750 --> 00:06:28,192 说话人 SPEAKER_02：您大约有 100 万亿个连接，
58 00:06:28,915 --> 00:06:31,017 说话人 SPEAKER_02：但您只能活大约 10 的 9 次方秒。
59 00:06:31,197 --> 00:06:33,420 说话人 SPEAKER_02：幸运的是，对我来说，这大约是 2 乘以 10 的 9 次方。
60 00:06:34,242 --> 00:06:39,769 说话人 SPEAKER_02：因此，与您拥有的参数数量相比，您的经验实际上并不多。
61 00:06:40,529 --> 00:06:45,956 说话人 SPEAKER_02：而真正大的语言模型已经看到了数以万亿计的训练示例。
62 00:06:46,838 --> 00:06:51,264 说话人 SPEAKER_02：所以这是光谱的两端。
63 00:06:51,363 --> 00:06:55,428 说话人 SPEAKER_02：反向传播，你有小网络和大量数据。
64 00:06:55,797 --> 00:06:58,942 说话人 SPEAKER_02：而大脑皮层，你有大网络但数据不多。
65 00:07:00,504 --> 00:07:02,867 说话人 SPEAKER_01：所以对学习算法的要求有些不同。
66 00:07:07,516 --> 00:07:10,079 说话人 SPEAKER_01：所以前向算法是这样的。
67 00:07:12,423 --> 00:07:14,826 说话人 SPEAKER_02：我们将训练前馈网络的每一层。
68 00:07:15,588 --> 00:07:19,694 说话人 SPEAKER_02：所以首先，我们将有一个前馈网络，但稍后会将其推广到循环网络。
69 00:07:20,232 --> 00:07:43,973 说话人 SPEAKER_02：你将训练每一层，当它遇到正数据向量，即来自训练集的一个向量时，具有高良度，而当它遇到负向量，即不是来自训练集的向量时，具有低良度，而且有许多方法可以获得这些负向量，但最明显的方法是让模型自己生成它们，就像在玻尔兹曼机中，它自己生成自己的负数据。
70 00:07:46,516 --> 00:07:49,699 说话人 SPEAKER_02：我们将逐层贪婪地训练层。
71 00:07:49,814 --> 00:07:50,415 说话人 SPEAKER_01：首先。
72 00:07:52,557 --> 00:07:56,822 说话人 SPEAKER_01：我将描述一些生成负数据向量的方法。
73 00:08:01,026 --> 00:08:05,271 说话人 SPEAKER_02：所以每一层隐藏层都将由 ReLUs 组成。
74 00:08:05,492 --> 00:08:10,137 说话人 SPEAKER_02：不一定要是 ReLUs，你可以使用各种东西，但现阶段我使用 ReLUs，即修正线性单元。
75 00:08:11,759 --> 00:08:17,627 说话人 SPEAKER_02：并且将有一个“良好度”函数，最初它将等于活动平方和。
76 00:08:18,298 --> 00:08:20,182 说话人 SPEAKER_02：你可以使用许多可能的“良好度”函数。
77 00:08:21,062 --> 00:08:22,105 说话人 SPEAKER_02：这是最明显的一个。
78 00:08:24,007 --> 00:08:37,149 说话人 SPEAKER_02：每一隐藏层将要尝试计算输入数据为正数据的概率，即真实数据，而不是假数据，即模型自身生成或其他方式生成的数据。
79 00:08:39,133 --> 00:08:43,158 说话人 SPEAKER_02：所以它将说这是正数据的概率，
80 00:08:43,392 --> 00:08:48,399 说话人 SPEAKER_02：是整个层的良好度对数减去某个阈值。
81 00:08:49,441 --> 00:08:59,054 说话人 SPEAKER_02：所以我们希望层的“好”是高的，即层中活动量的平方和对于正数据，我们希望它对于负数据是低的。
82 00:09:04,363 --> 00:09:07,947 说话人 SPEAKER_01：现在，你可以看到如何学习这样一个层。
83 00:09:08,738 --> 00:09:14,326 说话人 SPEAKER_02：但显然，在你学习了一个层之后，该层中的活动量对于正数据将是高的，对于负数据将是低的。
84 00:09:14,667 --> 00:09:16,529 说话人 SPEAKER_02：所以下一层的工作将非常简单。
85 00:09:16,909 --> 00:09:20,095 说话人 SPEAKER_02：只需查看在层之前活动是否频繁。
86 00:09:20,635 --> 00:09:21,918 说话人 SPEAKER_02：如果是，它表示为正面。
87 00:09:23,840 --> 00:09:33,615 说话人 SPEAKER_02：为了防止这种情况，我们将在将其呈现给第二个隐藏层之前，使用简单形式的层归一化来规范化第一隐藏层中活动向量的长度。
88 00:09:35,501 --> 00:09:43,791 说话人 SPEAKER_02：因此，第一隐藏层试图根据活动向量的长度、长度的平方、平方和来决定是正面还是负面的数据。
当我们通过将其标准化为固定长度来归一化时，我们就移除了用于将输入分类为正面或负面的第一隐藏层中使用的所有活动。
90 00:09:59,488 --> 00:10:05,475 说话人 SPEAKER_02：所以现在第二隐藏层必须使用其他类型的信息，即相对活动中的信息
91 00：10：06,046 --> 00：10：11,535 演讲者 SPEAKER_02：所以你可以把它看作是第一个隐藏层中的活动向量有一个长度和一个方向。
我们使用长度来判断是正数据还是负数据，然后通过归一化去除长度，并将方向发送到第二隐藏层。
93 00:10:22,417 --> 00:10:26,485 说话人 SPEAKER_02：第二隐藏层需要做什么，就是将那个方向
94 00:10:26,971 --> 00:10:36,682 说话人 SPEAKER_02：并且使用其输入权重矩阵，它必须将方向中的一些信息转换为长度，以便用于判断是正数据还是负数据。
95 00:10:41,187 --> 00:10:45,373 说话人 SPEAKER_01：首先，我将向您展示 FF 进行监督学习。
96 00:10:47,294 --> 00:10:56,927 说话人 SPEAKER_02：由于这是一个前馈网络，我们没有进行反向传播，因此如何给它一个标签并不明显，因为我们通常在输出处放置标签。
97 00:10:57,750 --> 00:11:01,715 说话人 SPEAKER_02：但是我们要做的是，我们要把标签放入输入中。
98 00:11:04,538 --> 00:11:08,182 说话人 SPEAKER_02：所以正图像是指包含正确标签的图像。
99 00:11:08,883 --> 00:11:12,027 说话人 SPEAKER_02：实际上，我会把图像作为标签的一部分放入图像中。
100 00:11:12,888 --> 00:11:20,235 说话人 SPEAKER_02：你可以在 MNIST 中这样做，因为 Yann LeCun 在每个数字周围留下了一个大黑边，这样卷积网络的工作就更容易了。
101 00:11:20,777 --> 00:11:24,500 说话人 SPEAKER_02：但这意味着你可以添加标签，而不会干扰图像。
102 00:11:25,898 --> 00:11:31,846 说话人 SPEAKER_02：所以正面的图像将使用一个 N 中选一的代码，在前 10 个像素处包含正确的标签。
103 00:11:33,570 --> 00:11:35,373 说话人 SPEAKER_02：实际上，不是一，而是五。
104 00:11:35,472 --> 00:11:37,275 说话人 SPEAKER_02：我让它更活跃，以便它有更大的效果。
105 00:11:38,898 --> 00:11:42,264 说话人 SPEAKER_02：所以前 10 个像素将包含九个零和一个五。
106 00:11:43,385 --> 00:11:46,910 说话人 SPEAKER_02：负图像包括一个错误的标签。
107 00:11:48,293 --> 00:11:51,298 说话人 SPEAKER_02：正负图像之间的唯一区别是标签。
108 00:11:53,422 --> 00:12:01,230 说话人 SPEAKER_02：与该标签不相关的图像特征将被算法忽略，因为这些特征无法帮助它区分正负案例。
109 00:12:02,672 --> 00:12:11,741 说话人 SPEAKER_02：如果我在页边空白处添加一些随机噪声，它就会忽略那些随机噪声，因为随机噪声与正负图像之间的差异不相关。
110 00:12:12,942 --> 00:12:16,047 说话人 SPEAKER_01：这就是监督学习的优点，它忽略了无关紧要的东西。
111 00:12:19,870 --> 00:12:22,533 说话人 SPEAKER_01：所以有两种方法可以在网络学习后对其进行测试。
112 00:12:23,341 --> 00:12:25,364 说话人 SPEAKER_02：你可以给它一个中性标签。
113 00:12:26,586 --> 00:12:30,049 说话人 SPEAKER_02：首先取前 10 个像素，使它们都处于同等活跃状态。
114 00:12:33,394 --> 00:12:36,679 说话人 SPEAKER_02：然后正向通过网络以获取隐藏层的活动。
115 00:12:38,261 --> 00:12:42,849 说话人 SPEAKER_02：然后将所有这些隐藏活动作为 softmax 的输入。
116 00:12:43,509 --> 00:12:45,331 说话人 SPEAKER_02：这就叫做线性分类器。
117 00:12:46,054 --> 00:12:47,375 说话人 SPEAKER_02：尽管它是非线性的。
118 00:12:48,236 --> 00:12:56,466 说话人 SPEAKER_02：这样就可以使用学习到的隐藏活动来学习一个简单的模型，该模型可以分类数字。
119 00:12:57,366 --> 00:12:58,368 说话人 SPEAKER_02：这很快。
120 00:12:58,389 --> 00:13:00,230 说话人 SPEAKER_02：你只需要将事物通过网络运行一次。
121 00:13:02,113 --> 00:13:09,801 说话者 SPEAKER_02：一种更好的方法，但速度较慢，就是给网络提供同一张图片多次，每次都使用每个可能的标签。
122 00:13:10,101 --> 00:13:13,226 说话者 SPEAKER_02：然后你看到哪个标签在隐藏层中给出了最高的总优良度。
123 00:13:14,048 --> 00:13:15,410 说话者 SPEAKER_02：这就是你真正训练的内容。
124 00:13:16,172 --> 00:13:17,734 说话者 SPEAKER_02：这就是测试它的正确方法。
125 00:13:18,355 --> 00:13:26,087 说话人 SPEAKER_02：但是需要运行很多次，次数与标签数量相同，如果有 10 个标签，这没问题，但如果有一千个标签，成本就会很高。
126 00:13:26,989 --> 00:13:31,996 说话人 SPEAKER_02：然后你会首先使用快速方法得到一个可能的标签短列表。
127 00:13:32,498 --> 00:13:36,244 说话人 SPEAKER_02：然后你可以依次检查短列表中每个标签的好坏。
128 00:13:36,510 --> 00:13:39,695 说话人 SPEAKER_02：所以你可能得到最好的五个标签并检查它们。
129 00:13:40,375 --> 00:13:43,380 说话人 SPEAKER_01：所以它相对高效，即使是对于大型标签集。
130 00:13:48,268 --> 00:14:04,289 说话人 SPEAKER_02：在 MNIST 上，如果你使用全连接网络且非卷积，通常 MNIST 的测试错误率约为 1.4%，如果你使用反向传播，大约在 1.3%到 1.4%之间。
131 00:14:05,299 --> 00:14:19,874 说话人 SPEAKER_02：使用前向-前向算法，它不进行反向传播，如果你只是将负标签，你在负例中使用的标签，设置为随机，训练速度会慢得多。
132 00:14:20,894 --> 00:14:26,299 说话人 SPEAKER_02：因为在训练的后期，它获取的大多数负例显然是负例。
133 00:14:27,380 --> 00:14:29,943 说话人 SPEAKER_02：鉴于它已经知道的情况，这些标签并不合理。
134 00:14:30,244 --> 00:14:31,424 说话人 SPEAKER_02：所以它没有学到任何东西。
135 00:14:33,042 --> 00:14:39,250 说话人 SPEAKER_02：你可以通过给它一些难以区分的负面案例来让它学得更快。
136 00:14:40,270 --> 00:14:52,907 说话人 SPEAKER_02：而你要这样做的方式是，在你训练前馈算法的同时，也训练使用隐藏活动来对图像进行分类的线性 softmax 分类器。
137 00:14:54,472 --> 00:15:09,350 说话人 SPEAKER_02：然后你查看 SOPAC 分类器的输出，并从错误类别的分布中挑选一个更活跃的类别，不是正确的类别，而是你挑选的。
138 00:15:09,431 --> 00:15:12,916 说话人 SPEAKER_02：所以你更频繁地挑选困难负样本，而不是简单负样本。
139 00:15:13,817 --> 00:15:15,259 说话人 SPEAKER_02：这使得它学习得更快。
140 00:15:15,578 --> 00:15:20,565 说话人 SPEAKER_02：然后它比反向传播慢两倍左右学习。
141 00:15:23,126 --> 00:15:24,908 说话人 SPEAKER_01：它的性能与反向传播相当。
142 00:15:26,471 --> 00:15:49,539 说话人 SPEAKER_02：如果你在所有四个方向上将图像抖动最多两个像素，那么现在有 25 个不同的图像位置，如果你长时间训练，可以得到大约 0.64%的错误率，这与你通过抖动图像使用反向传播得到的结果相当。
143 00:15:50,600 --> 00:15:55,205 说话人 SPEAKER_02：如果你使用卷积网络，这也会使反向传播的速度更快。
144 00:15:55,926 --> 00:16:01,211 说话人 SPEAKER_02：因此，对于 MNIST，抖动图像可以使你获得与卷积网络相似的性能。
145 00:16:02,613 --> 00:16:04,775 说话人 SPEAKER_02：如果你这样做，你也会得到很好的感受域。
146 00:16:06,197 --> 00:16:09,201 说话人 SPEAKER_02：所以我将向你展示一些感受域。
147 00:16:12,544 --> 00:16:20,033 说话人 SPEAKER_02：所以你在这里看到的是在第一隐藏层，它正在学习的感受域。
148 00:16:20,130 --> 00:16:27,985 说话人 SPEAKER_02：你将看到前 10 个像素是特征检测器对标签单元的权重。
149 00:16:29,107 --> 00:16:31,591 说话人 SPEAKER_02：右边的两个红色方框我已经放大了。
150 00:16:32,934 --> 00:16:42,712 说话人 SPEAKER_02：如果你看右边的顶部特征，如果你看到两条大致水平的线，中间是黑色的，
151 00:16:43,672 --> 00:16:53,285 说话人 SPEAKER_02：这很可能是三或七，中间有横杠，并且它学会了这一点。
152 00:16:53,667 --> 00:16:54,988 说话人 SPEAKER_02：所以它学会了有意义的特征。
153 00:16:55,008 --> 00:17:06,404 说话者 SPEAKER_02：我们可以解释它学到的内容，这是一个非常合理的功能，它说，如果你看到这个，那可能就是三或七，因此它学到了来自三和七的大权重。
154 00:17:08,865 --> 00:17:13,230 说话者 SPEAKER_02：这意味着当你将其中之一作为标签输入时，就会激活这个功能。
155 00:17:13,590 --> 00:17:18,075 说话者 SPEAKER_02：但是如果你输入一个错误的标签，这个功能就不会那么活跃。
156 00:17:18,355 --> 00:17:19,396 说话者 SPEAKER_02：所以它不会那么高兴。
157 00:17:19,436 --> 00:17:20,617 说话人 SPEAKER_02：所以它会知道这是一个负面案例。
158 00:17:24,602 --> 00:17:37,454 说话人 SPEAKER_02：所以，这个前向算法版本的一个主要问题是由于它没有反向传播，你在后续层学到的知识不会影响你在早期层学到的知识。
159 00:17:38,144 --> 00:17:43,832 说话人 SPEAKER_02：这似乎很不好，因为这是反向传播的一个主要优点。
160 00:17:44,452 --> 00:17:48,377 说话人 SPEAKER_02：而且看起来如果我们使用这个算法，我们就失去了这一点。
161 00:17:50,280 --> 00:17:54,247 说话者 SPEAKER_02：如果你想要模拟感知中的自上而下的效应，而这正是我所做的，那情况尤其糟糕。
162 00:17:56,288 --> 00:18:00,996 说话者 SPEAKER_02：所以这里有三个感知中自上而下效应的例子。
163 00:18:01,684 --> 00:18:08,873 说话者 SPEAKER_02：如果你看那两个词中间的 H，它们完全一样，但如果你看动词，它就是 H，如果你看猫，它就是 A。
164 00:18:09,473 --> 00:18:17,281 说话者 SPEAKER_02：如果你不去注意字母，而是注意整个单词，你会根据上下文不同地解释那个 H。
165 00:18:18,624 --> 00:18:22,989 说话者 SPEAKER_02：同样，如果你首先看到右边的图片，你会看到一个脸。
166 00:18:24,089 --> 00:18:26,932 说话者 SPEAKER_02：所以中间的那一对，你把它解释为鼻子。
167 00:18:28,499 --> 00:18:33,325 说话者 SPEAKER_02：从下往上的数据并没有真正告诉你那是一个鼻子，它告诉你那是一对，如果有的话。
168 00:18:34,125 --> 00:18:38,852 说话者 SPEAKER_02：但是从整个图像向上看的数据告诉你那里应该有一个鼻子，这就是你看到的样子。
169 00:18:39,833 --> 00:18:42,076 说话者 SPEAKER_02：这就是自上而下的信息产生的强烈影响。
170 00:18:43,617 --> 00:18:49,765 说话者 SPEAKER_02：然后如果你看底部的句子，如果我把这个句子给你，
171 00:18:52,039 --> 00:18:56,905 说话者 SPEAKER_02：单独一句话，你就能很好地理解“scrummed”这个词可能是什么意思。
172 00:18:57,605 --> 00:19:02,571 说话者 SPEAKER_02：可能意味着她用这个东西打他的头，或者以某种方式攻击他。
173 00:19:05,575 --> 00:19:10,840 说话者 SPEAKER_02：这可能意味着她用烹饪得很好给他留下了印象，但这种情况不太可能。
174 00:19:11,883 --> 00:19:16,748 说话者 SPEAKER_02：所以你可以从单个上下文中理解一个词的含义。
175 00:19:17,452 --> 00:19:26,544 说话者 SPEAKER_02：这是上下文告诉您如何创建表示“scrummed”一词含义的向量的另一个例子。
176 00:19:31,750 --> 00:19:42,481 说话者 SPEAKER_02：因此，我们将通过将静态图像视为视频来使前向算法处理上下文的影响。
177 00:19:43,323 --> 00:19:46,047 说话人 SPEAKER_02：这个视频非常无聊，因为每一帧都是一样的。
178 00:19:46,907 --> 00:19:49,991 说话人 SPEAKER_02：但是我们将使用一个专门设计用于处理视频的循环网络。
179 00:19:50,571 --> 00:19:53,476 说话人 SPEAKER_02：我们将会给它一个非常无聊的视频，它是一张静态图片。
180 00:19:56,339 --> 00:19:58,742 说话人 SPEAKER_02：然后学习在时间上是贪婪的。
181 00:19:58,803 --> 00:20:00,244 说话人 SPEAKER_02：它没有随时间进行背景处理。
182 00:20:00,885 --> 00:20:02,969 说话人 SPEAKER_02：但是它在层上并不贪婪，您很快就会看到。
183 00:20:06,973 --> 00:20:09,857 说话人 SPEAKER_02：所以我将使用这种类型的网络。
184 00:20:09,877 --> 00:20:13,261 说话人 SPEAKER_02：这是我从去年发表的一篇论文中摘录的。
185 00:20:13,343 --> 00:20:28,121 说话人 SPEAKER_02：在一个我称之为 Glom 的系统上，该系统旨在解释神经网络如何在不根据部分-整体层次结构重新布线的情况下对部分-整体层次结构进行建模。
186 00:20:28,142 --> 00:20:35,510 说话人 SPEAKER_02：所以在神经网络中，神经元的操作取决于它们的连接强度，它们不能随意地即时执行不同的任务。
187 00:20:37,732 --> 00:20:39,756 说话人 SPEAKER_02：这使得在神经网络中实现灵活的图结构，如部分-整体层次结构变得困难。
188 00:20:40,309 --> 00:20:46,259 说话人 SPEAKER_02：这对于每个图像中不同的部分-整体层次结构来说都是如此。
189 00:20:47,000 --> 00:20:55,253 说话人 SPEAKER_02：关于如何通过具有代表部分或空洞的相似向量岛屿来实现这些层次结构的 Glom 论文。
190 00:20:56,474 --> 00:21:03,527 说话人 SPEAKER_02：这需要一种这样的架构，你可以从中学习。
191 00:21:04,708 --> 00:21:05,710 说话人 SPEAKER_02：当我
192 00:21:06,532 --> 00:21:08,535 说话人 SPEAKER_02：在 Glom 论文中，这有点尴尬。
193 00:21:08,555 --> 00:21:12,721 说话人 SPEAKER_02：我没有为这种架构找到一种生物上可行的学习算法。
194 00:21:13,761 --> 00:21:18,788 说话人 SPEAKER_02：现在正向算法适用于这种架构，并且更加符合生物原理。
195 00:21:20,210 --> 00:21:31,983 说话人 SPEAKER_02：所以如果你看中间层，即 L 层，以及右侧的框，该框在任何时间点的活动
196 00:21:32,048 --> 00:21:40,978 说话人 SPEAKER_02：这一层是由来自下方、前一时间步的底层输入决定的。
197 00:21:41,858 --> 00:21:50,528 说话人 SPEAKER_02：来自上一时间步的顶层输入以及来自同一层级的绿色横向输入。
198 00:21:51,670 --> 00:21:58,798 说话人 SPEAKER_02：那么，如果你现在考虑如何在该层中获取正数据的较高活动水平，那么获取较高活动水平的方式，主要方式，就是顶层输入（红色箭头）和底层输入（蓝色箭头）达成一致，指向同一方向。
199 00:21:59,436 --> 00:22:17,380 说话人 SPEAKER_02：那么你将会有较高的活动水平。
200 00:22:17,900 --> 00:22:19,301 说话人 SPEAKER_02：然后你将会有高活动。
201 00:22:20,429 --> 00:22:28,968 说话人 SPEAKER_02：您可以看到，前向-前向算法正在尝试在自上而下的预测和自下而上的特征提取之间达成一致。
202 00:22:29,869 --> 00:22:37,846 说话人 SPEAKER_02：而那个自上而下的预测，指向中间层最右边框的红色箭头，如果您看它从哪里来，
203 00:22:38,349 --> 00:22:50,227 说话人 SPEAKER_02：它实际上来自两个时间步之前的输入数据，确切地说，是三个时间步之前，因为它必须从左侧的 L 层向上传递，然后再向上到 L+1 层，然后再次下降到 L 层。
204 00:22:52,569 --> 00:23:00,662 说话人 SPEAKER_02：因此，上下文信息来自较早的时间步，并且已经通过了更多层的处理。
205 00:23:01,756 --> 00:23:25,131 说话人 SPEAKER_02：这里发生的事情是，当它试图在 L 级别获得高活动度时，前向算法真正试图做的是让基于更大上下文但较旧数据的自上而下活动与基于更小上下文但更新数据的自下而上活动达成一致。
206 00:23:26,534 --> 00:23:29,518 说话人 SPEAKER_02：所以它必须学会成为一个预测模型。
207 00:23:29,599 --> 00:23:37,491 说话人 SPEAKER_02：所以如果视频实际上在移动，我用移动视频也做过，效果也很好，只要运动简单。
208 00:23:38,292 --> 00:23:47,006 说话人 SPEAKER_02：它将学会一个预测模型，并将寻找预测模型预测的内容与您实际看到的内容之间的共识。
209 00:23:47,046 --> 00:23:54,477 说话人 SPEAKER_02：因此我们现在正在获得感知中的自上而下的效应。
210 00:23:56,836 --> 00:24:01,321 说话人 SPEAKER_01：现在，这些自上而下的效应不像反向传播那样快速传播。
211 00:24:03,865 --> 00:24:09,633 说话人 SPEAKER_01：所以让我向您展示一下进行数字时的样子。
212 00:24:10,755 --> 00:24:14,579 说话人 SPEAKER_02：视频的帧只是数字，每次都是同一个数字。
213 00:24:16,102 --> 00:24:26,556 说话人 SPEAKER_02：在顶层，我们放入一个标签，每次都是同一个标签，使用 1/n。实际上，是 5，不是 1，但就是这样。
214 00:24:28,695 --> 00:24:30,739 说话人 SPEAKER_02：这就是循环神经网络的重训练。
215 00:24:31,941 --> 00:24:35,666 说话人 SPEAKER_01：如果你用前向-前向算法训练这个循环神经网络，它工作得相当好。
216 00:24:38,471 --> 00:24:45,922 说话人 SPEAKER_02：所以底层视频像素，顶层被固定为正数据的正确标签和负数据的错误标签。
217 00:24:47,104 --> 00:24:50,890 说话人 SPEAKER_01：我们运行了八次迭代并
218 00:24:53,536 --> 00:24:58,323 说话人 SPEAKER_01：首先，我尝试让效果尽可能好。
219 00:24:58,344 --> 00:25:02,549 说话人 SPEAKER_02：我尝试将高活动度作为良善函数。
220 00:25:03,191 --> 00:25:07,837 说话人 SPEAKER_02：所以你试图得到正数的活动度平方和较大，负数的活动度平方较小。
221 00:25:09,981 --> 00:25:14,208 说话人 SPEAKER_02：结果发现，实际上将低活动度作为良善函数效果更好。
222 00:25:14,888 --> 00:25:19,797 说话人 SPEAKER_02：你试图得到正数数据低活动度，负数数据高活动度。
223 00:25:19,944 --> 00:25:26,076 说话人 SPEAKER_02：在这种情况下，你想要的顶层输入与底层输入正好相反。
224 00:25:26,096 --> 00:25:31,326 说话人 SPEAKER_02：这更像是预测编码，你试图让顶层输入消除底层输入。
225 00:25:34,292 --> 00:25:36,436 说话人 SPEAKER_02：这实际上效果更好，更像是大脑的工作方式。
226 00:25:37,199 --> 00:25:39,702 说话人 SPEAKER_02：对于熟悉的数据，你的活动通常较少。
当是令人惊讶的数据时，你会有更多的活动。
所以如果你使用两层 ReLU（修正线性单元）隐藏层并且运行八步。
229 00：25：57,333 --> 00：26：01,638 演讲者 SPEAKER_02：首先，我开始收集四个时间步长后的梯度，因为我认为它应该稳定下来一点。
230 00：26：02,079 --> 00：26：05,545 演讲者 SPEAKER_02：实际上，如果你从头开始收集渐变，效果会更好。
231 00:26:06,772 --> 00:26:11,621 说话人 SPEAKER_02：然后您将学习率从初始学习率衰减到零，这个过程在 60 个 epoch 之后完成。
232 00:26:12,402 --> 00:26:15,847 说话人 SPEAKER_02：所以它的运行时间大约是反向传播的三到五倍。
233 00:26:15,867 --> 00:26:18,352 说话人 SPEAKER_02：并且它还在进行多次迭代。
234 00:26:18,511 --> 00:26:19,913 说话人 SPEAKER_02：所以它的速度比反向传播慢得多。
235 00:26:20,776 --> 00:26:24,141 说话人 SPEAKER_02：在测试时，
236 00:26:24,626 --> 00:26:27,872 说话人 SPEAKER_02：然后你采用昂贵的分类方法。
237 00:26:27,932 --> 00:26:32,599 说话人 SPEAKER_02：你用不同的标签运行网络 10 次，并选择具有最高好处的那个。
238 00:26:33,300 --> 00:26:39,351 说话人 SPEAKER_02：现在它的错误率为 1.31%，这在有后向传播训练的合理模型得到的范围内。
239 00:26:40,794 --> 00:26:50,549 说话人 SPEAKER_02：这似乎比我之前提到的非循环网络稍微好一点，但这可能并不显著，但至少它并不明显更差。
240 00:26:55,558 --> 00:27:12,982 说话人 SPEAKER_02：如果你尝试更难的任务，比如 CIFAR-10，其中背景中有很多无关信息，并且你使用两个或三个隐藏层的循环网络，并使用局部连接性。
241 00:27:13,683 --> 00:27:15,326 说话人 SPEAKER_02：所以我并没有使用卷积。
242 00:27:15,626 --> 00:27:21,875 说话人 SPEAKER_02：我没有共享权重，因为这从生物学上讲是不可能的，但我使用了局部感受野。
243 00:27:21,895 --> 00:27:25,059 说话人 SPEAKER_02：我这样做的方式是每个隐藏层
244 00:27:25,765 --> 00:27:28,368 说话人 SPEAKER_02：有一种 32x32 的布局。
245 00:27:30,892 --> 00:27:36,720 说话人 SPEAKER_02：所以一个单元大致位于输入图像的某个部分。
246 00:27:38,281 --> 00:27:47,915 说话人 SPEAKER_02：在每个隐藏层中，你将其连接到图像中该点为中心的 11x11 感受野内的单元。
247 00:27:50,138 --> 00:27:52,442 说话人 SPEAKER_02：您也这样做对于自下而上的连接。
248 00:27:52,461 --> 00:27:54,625 说话人 SPEAKER_02：您也这样做对于自上而下的连接。
249 00:27:55,329 --> 00:28:01,657 说话人 SPEAKER_02：因此它具有局部连接性，这限制了连接的数量，使其泛化能力更好一些。
250 00:28:04,442 --> 00:28:12,011 说话人 SPEAKER_02：我使用 softmax 线性分类器运行了 8 次迭代来选择硬负标签。
251 00:28:13,353 --> 00:28:20,021 说话人 SPEAKER_02：如果你用相同的架构，至少是它的前馈部分，并用反向传播进行训练，
252 00:28:21,115 --> 00:28:26,741 说话人 SPEAKER_02：使用两个隐藏层时，错误率约为 37%，使用三个隐藏层时，错误率约为 39%。
253 00:28:27,722 --> 00:28:30,586 说话人 SPEAKER_02：你必须用很强的权重衰减对其进行很强的正则化。
254 00:28:32,749 --> 00:28:38,876 说话人 SPEAKER_02：如果你用前向前算法做同样的事情，效果略差。
255 00:28:39,938 --> 00:28:42,540 说话人 SPEAKER_02：它不如反向传播好，但很接近。
256 00:28:43,622 --> 00:28:47,547 说话人 SPEAKER_02：而且，随着你进入更多的隐藏层，它并没有显著变差。
257 00:28:48,288 --> 00:28:50,750 说话人 SPEAKER_02：实际上，它可能变得更好，但这可能并不重要。
258 00:28:51,962 --> 00:28:54,726 说话人 SPEAKER_02：所以它是有效的，但效果不如反向传播好。
259 00:28:56,428 --> 00:29:09,441 说话人 SPEAKER_02：但我的看法是大脑可能没有反向传播那样工作得很好，这有点令人害怕，因为这暗示我们现在拥有的数字技术最终可能会非常、非常好，甚至可能超过我们。
260 00:29:14,086 --> 00:29:19,471 说话人 SPEAKER_01：如果你认为这个网络正在稳定下来时发生的事情，
261 00:29:19,891 --> 00:29:24,517 说话人 SPEAKER_02：它没有进行反向传播，但它正在进行我称之为反向松弛的其他操作。
262 00:29:25,198 --> 00:29:31,446 说话人 SPEAKER_02：所以如果我们回到网络的画面，这个将会做到。
该信息通过红色箭头向下传递，如果提供自上而下的输入，那有助于训练自下而上的输入
264 00:29:46,874 --> 00:29:59,432 说话者 SPEAKER_02：这意味着更高层次的表现形式信息正在影响自下而上的输入，所以如果你看中间层，中间层的右手边框。
265 00：30：00,239 --> 00：30：08,969 演讲者 SPEAKER_02：自下而上的蓝色箭头，那里的学习受到基于旧视频帧的从上面下来的内容的影响。
266 00：30：08,989 --> 00：30：18,019 演讲者 SPEAKER_02：所以你得到了我们想要的东西，那就是高级表征可以影响低级表征的学习。
267 00:30:19,060 --> 00:30:25,268 说话人 SPEAKER_02：但是如果你问信息返回的速度有多快，嗯，在那个中间层，
268 00:30:25,872 --> 00:30:30,417 说话人 SPEAKER_02：自上而下的信息与自下而上的信息混合在一起。
269 00:30:32,141 --> 00:30:43,576 说话人 SPEAKER_02：然后是竞争性表示，然后这种平均表示被发送到下一层，所以上面的信息正被来自底部的信息所稀释。
270 00:30:44,417 --> 00:30:54,654 说话人 SPEAKER_02：结果是，从高层传播到低层的信息速度更像是扩散或松弛，而不是传播。
271 00：30：55,455 --> 00：31：06,914 发言者 SPEAKER_02：在反向传播中，信息一直返回，而各种完整的信息则返回，在途中被所有权重矩阵修改，但未被前向传递的活动稀释。
272 00:31:07,215 --> 00:31:10,519 说话者 SPEAKER_02：这里是一个扩散过程。
273 00：31：10,558 --> 00：31：12,661 演讲者 SPEAKER_02：所以它会通过几个层次来工作，好的。
274 00：31：12,681 --> 00：31：14,541 议长 SPEAKER_02：但是它根本无法通过一百层。
275 00:31:15,423 --> 00:31:17,444 说话人 SPEAKER_02：现在，幸运的是，大脑并没有有一百层。
276 00:31:18,306 --> 00:31:26,653 说话人 SPEAKER_02：在这里发生的情况是，第一次看到图像时，信息不会完全返回到早期层。
277 00:31:27,894 --> 00:31:34,079 说话人 SPEAKER_02：但是当你看到图像时所做的学习，你将通过几层获取信息。
278 00:31:34,680 --> 00:31:36,902 说话人 SPEAKER_02：所以现在自下而上的输入，
279 00:31:37,000 --> 00:31:43,069 说话人 SPEAKER_02：中间层将学会不同，因为来自上层的信 息。
280 00:31:44,172 --> 00:31:49,441 说话人 SPEAKER_02：因此，如果我现在再次向您展示同一张图片，上下部分是不同的。
281 00:31:49,882 --> 00:31:59,498 说话人 SPEAKER_02：所以，现在，由高级表示引起的这种差异将在下一级引起差异。
282 00:31:59,967 --> 00:32:08,821 说话人 SPEAKER_02：因此，如果您多次展示一张图片，信息将通过许多层返回，但在一次展示中不会高效地通过许多层返回。
283 00:32:10,023 --> 00:32:16,035 说话人 SPEAKER_02：所以这就是反向松弛和反向传播之间的区别，我怀疑我们只能坚持使用反向松弛。
284 00:32:24,730 --> 00:32:25,029 说话人 SPEAKER_01：好的。
285 00:32:28,974 --> 00:32:31,637 说话人 SPEAKER_01：我想以这句话结束，谈谈这与生成对抗网络（GANs）的关系。
286 00:32:32,999 --> 00:32:42,528 说话人 SPEAKER_02：所以，生成对抗网络，就像玻尔兹曼机或噪声对比估计，是通过尝试区分真实数据和生成数据来工作的。
287 00:32:43,410 --> 00:32:56,163 说话人 SPEAKER_02：在正向-正向算法中，GAN 的判别模型被替换为一种贪婪的前馈模型，该模型试图在每一层进行判别，而不是只在最后一层有一个逻辑单元。
288 00:32:57,140 --> 00:33:06,854 说话人 SPEAKER_02：因为它试图在每一层进行判别，并且是贪婪的，通过贪婪训练，它可以不使用反向传播进行训练，因为我们正在每一层进行这些贪婪的判别。
289 00:33:07,734 --> 00:33:12,000 说话人 SPEAKER_02：这就是我们如何在不使用反向传播的情况下学习判别模型的方法。
290 00:33:13,544 --> 00:33:22,876 说话人 SPEAKER_02：现在，再次强调，生成模型，它通常通过将判别误差反向传播到生成模型进行训练，
291 00:33:24,865 --> 00:33:27,587 说话人 SPEAKER_02：我们不会有一个单独的生成模型。
292 00:33:28,588 --> 00:33:33,953 说话人 SPEAKER_02：我们将用判别模型的隐藏层替换生成模型的隐藏层。
293 00:33:33,973 --> 00:33:35,835 说话人 SPEAKER_02：我们将共享相同的表示。
294 00:33:37,616 --> 00:33:43,162 说话人 SPEAKER_02：然后我们将使用判别模型中的这些隐藏层来尝试预测序列中的下一个术语。
295 00:33:44,303 --> 00:33:51,269 说话人 SPEAKER_02：因此我们可以训练生成模型而不需要反向传播，因为它不需要学习其隐藏表示。
296 00:33:51,369 --> 00:33:53,471 说话人 SPEAKER_02：这只是从判别模型中窃取它们。
297 00:33:54,650 --> 00:33:57,554 说话人 SPEAKER_02：这给我们带来了几个优点和一个很大的缺点。
298 00:33:59,656 --> 00:34:06,925 说话人 SPEAKER_02：所以如果你考虑 GANs 存在的问题，它们在生成模型和判别模型之间存在对抗竞争。
299 00:34:07,226 --> 00:34:08,447 说话人 SPEAKER_02：这使得训练变得棘手。
300 00:34:08,768 --> 00:34:10,431 说话人 SPEAKER_02：你必须正确获取相对学习率。
301 00:34:12,393 --> 00:34:17,018 说话人 SPEAKER_02：如果生成模型和判别模型共享它们的隐藏表示，这个问题就会消失。
302 00:34:18,820 --> 00:34:21,585 说话人 SPEAKER_02：GANs 的另一个问题是它们存在模式坍塌。
303 00:34:21,733 --> 00:34:28,967 生成模型可能会忽略数据空间的大部分，但生成对抗网络（GAN）似乎仍然非常高兴。
304 00:34:29,007 --> 00:34:45,818 如果您与判别模型共享隐藏表示，这种情况就不会发生，因为现在隐藏表示是在整个数据空间上训练的，包括所有训练数据覆盖的内容。
305 00:34:46,489 --> 00:34:48,972 因此，您消除了模式坍塌。
306 00:34:48,992 --> 00:34:53,317 但您得到的重大缺点是您无法学习到如此好的生成模型。
目前一个很大的开放问题是，使用前向-前向算法，尤其是在循环神经网络中，是否可以学习到一个足够好的生成模型，使得模型能够产生足够好的负数据，以用于训练前向-前向算法。
308 00：35：11,795 --> 00：35：12,958 议长 SPEAKER_02：这就是我现在正在做的事情。
309 00:35:14,599 --> 00:35:15,179 说话者 SPEAKER_02：这就是结束。
非常感谢，教授，您这次精彩的、富有洞察力的演讲。
311 00:35:21,121 --> 00:35:26,027 说话人 SPEAKER_00：所以我有很多问题，我将尝试挑选一些问题来问你。
312 00:35:26,608 --> 00:35:31,956 说话人 SPEAKER_00：所以这种前向到前向算法，开辟了新的研究领域。
313 00:35:32,476 --> 00:35:40,527 说话人 SPEAKER_00：您如何看待这对其他架构、其他模型和架构的创建产生影响？
314 00:35:41,231 --> 00:35:47,262 说话人 SPEAKER_02：好吧，我认为在实用方面，反向传播在当前数字计算机上效果更好。
315 00:35:49,166 --> 00:35:54,134 说话人 SPEAKER_02：但是前向算法可能允许我们使用纯模拟计算。
316 00:35:54,715 --> 00:36:02,407 说话人 SPEAKER_02：模拟计算的问题在于它会产生噪声，杂散的电磁场会影响计算结果。
317 00:36:03,630 --> 00:36:04,692 说话人 SPEAKER_02：并且
318 00:36:04,891 --> 00:36:13,442 说话人 SPEAKER_02：因此，除非你继续数字化，否则你无法使两个不同的模拟计算机表现得完全一样。
319 00:36:13,461 --> 00:36:19,530 说话人 SPEAKER_02：当然，一旦开始数字化，就会失去所有模拟的优势。
320 00:36:20,130 --> 00:36:33,648 说话人 SPEAKER_02：你必须使用高功率，一个比特的数字可能还可以，就像大脑那样，是放电还是不放电，但得到一个 8 比特或 16 比特的数字，与纯模拟计算相比，需要消耗大量的能量。
321 00:36:34,742 --> 00:36:42,030 说话人 SPEAKER_02：前向-前向算法的优势在于你可以在不知道硬件工作原理的情况下在硬件上运行它。
322 00:36:43,010 --> 00:37:00,547 说话人 SPEAKER_02：例如，如果我在网络中间加入一个随机矩阵层，后面跟着 ReLU 单元，或者任何我喜欢的其他单元，而我甚至不知道它，然后运行前向-前向算法，它仍然可以正常运行。
323 00:37:01,152 --> 00:37:02,054 说话人 SPEAKER_02：它没有问题。
324 00:37:02,554 --> 00:37:15,596 说话人 SPEAKER_02：而如果你在反向传播网络中间有一个层，一个前馈网络，你不知道变换是什么，而且变换可能甚至不是平稳的，反向传播算法就不起作用了。
325 00:37:15,817 --> 00:37:21,967 说话人 SPEAKER_02：你最好能自己构建一个可微分的模型来模拟你网络中间的黑盒。
326 00:37:23,009 --> 00:37:25,632 说话人 SPEAKER_02：但是前向算法，它根本不会减慢这个过程。
327 00:37:25,753 --> 00:37:26,755 说话人 SPEAKER_02：没有问题。
328 00:37:27,561 --> 00:37:35,331 说话人 SPEAKER_02：如果你需要与不知道具体行为的硬件合作，这似乎非常有前景。
329 00:37:35,371 --> 00:37:36,552 说话人 SPEAKER_02：你知道它大致会如何表现。
330 00:37:36,974 --> 00:37:43,001 说话人 SPEAKER_02：你需要了解足够的信息，以便知道如何调整你的输入权重，使其更加活跃或更加不活跃。
331 00:37:43,422 --> 00:37:45,224 说话人 SPEAKER_02：但是在这个算法中你只需要知道这些。
332 00:37:46,085 --> 00:37:48,608 说话人 SPEAKER_02：所以你需要在网络中拥有一些单元。
333 00:37:48,588 --> 00:37:51,090 说话人 SPEAKER_02：它们可以改变输入权重以变得更加活跃或减少活跃度。
334 00:37:52,992 --> 00:37:56,697 说话人 SPEAKER_02：但你还有许多其他事情在进行中，它会适应这些变化。
335 00:37:57,157 --> 00:38:01,422 说话人 SPEAKER_02：这是因为两次不同的正向传递抵消了所有这些因素。
336 00:38:02,523 --> 00:38:10,634 说话人 SPEAKER_02：这里有一个非常重要的问题，那就是对比正负数据可以消除所有这些因素。
337 00:38:11,355 --> 00:38:18,443 说话人 SPEAKER_02：一旦你尝试对比两个内部表示，就像目前在典型的对比学习中做的那样，
338 00:38:18,507 --> 00:38:21,632 说话人 SPEAKER_02：你将面临所有这些随机效应的大问题。
339 00:38:22,755 --> 00:38:29,847 说话人 SPEAKER_02：但是，如果你使用正数据与负数据，会发生一个很棒的特性，那就是所有这些内部噪音和不确定性都会相互抵消。
340 00:38:30,148 --> 00:38:34,577 说话人 SPEAKER_02：因为它们在正向和反向传递中都是相同的，所以它们都会相互抵消。
341 00:38:35,478 --> 00:38:37,262 说话人 SPEAKER_00：这对硬件来说听起来非常有前景。
342 00:38:37,461 --> 00:38:42,050 说话人 SPEAKER_00：那么，您认为这会被应用于 GPU 和 TPU 等设备吗？
343 00:38:42,891 --> 00:38:49,117 说话人 SPEAKER_02：不，不，我认为这是一种完全不同的硬件，我称之为凡人计算。
344 00:38:49,599 --> 00:39:06,695 说话人 SPEAKER_02：所以如果你看看计算机的历史，当他们最初制造通用数字计算机时，每个人都认为要让它完成特定任务，就是通过编写一个程序来告诉它具体要做什么。
345 00:39:10,119 --> 00:39:10,619 说话人 SPEAKER_02：现在，
346 00:39:11,443 --> 00:39:19,931 说话人 SPEAKER_02：现在我们有了良好的学习算法，你可以通过学习让通用网络完成特定任务。
347 00:39:19,972 --> 00:39:21,134 说话人 SPEAKER_02：你不必编写程序。
348 00:39:21,614 --> 00:39:26,418 说话人 SPEAKER_02：显然，学习算法必须包含在内，但你不必为每个任务编写程序。
349 00:39:28,601 --> 00:39:37,349 说话人 SPEAKER_02：我认为这表明我们可以摒弃计算机科学的一个基本基础，那就是软件和硬件之间的区别。
350 00:39:38,891 --> 00:39:41,434 说话人 SPEAKER_02：所以如果你能将软件与硬件分离，
351 00:39:41,768 --> 00:39:46,672 说话人 SPEAKER_02：你可以有一个计算机科学系，在那里你可以讨论程序的性质，而不需要了解任何电气工程。
352 00:39:47,793 --> 00:39:52,237 说话人 SPEAKER_02：如果你不能将它们分开，你必须了解电气工程和编程。
353 00:39:53,119 --> 00:40:02,148 说话人 SPEAKER_02：此外，如果你能将硬件和软件分开，你就可以将相同的软件安装在数百万部不同的手机上。
354 00:40:02,789 --> 00:40:03,750 说话人 SPEAKER_02：所以这非常方便。
355 00:40:05,150 --> 00:40:08,014 说话人 SPEAKER_02：此外，你也可以证明关于程序所做事情的事情。
356 00:40:09,235 --> 00:40:11,336 说话人 SPEAKER_02：我建议放弃所有这些。
357 00:40:12,092 --> 00:40:15,722 说话人 SPEAKER_02：如果你看看生物学，它没有相同的限制。
358 00:40:16,846 --> 00:40:23,342 说话人 SPEAKER_02：如果你朝相反的方向看，你会说每一块硬件都将与每一块硬件不同。
359 00:40:24,485 --> 00:40:28,617 说话人 SPEAKER_02：在细节上会有所不同，就像你的大脑和我的大脑一样。
360 00:40:29,389 --> 00:40:34,914 说话人 SPEAKER_02：而你学习的权重只会在那块特定的硬件上起作用。
361 00:40:35,496 --> 00:40:41,822 说话人 SPEAKER_02：并且它们将适应那块特定硬件中特定神经元的特性。
362 00:40:41,842 --> 00:40:48,907 说话人 SPEAKER_02：或者如果是模拟硬件，那些特定模拟电路的特定特性，这些特性在不同的硬件中并不相同。
363 00:40:50,068 --> 00:40:55,393 说话人 SPEAKER_02：现在你有一个大问题，你必须分别训练每一块硬件。
364 00:40:56,175 --> 00:40:57,456 说话人 SPEAKER_02：它们需要被教育。
365 00:40:58,144 --> 00:40:59,567 说话人 SPEAKER_02：就像人一样。
366 00:41:00,708 --> 00:41:09,277 说话人 SPEAKER_02：你可以通过使用蒸馏等技巧从一块硬件获取信息到另一块硬件，这是一种教育形式。
367 00:41:10,619 --> 00:41:12,041 说话人 SPEAKER_02：但你不能只是复制权重。
368 00:41:12,702 --> 00:41:18,168 说话人 SPEAKER_02：我现在的信念是，能够直接复制权重会带来巨大的收益。
369 00:41:19,208 --> 00:41:22,432 说话人 SPEAKER_02：这就是我们当前数字硬件中反向传播的原因。
370 00:41:22,672 --> 00:41:24,175 说话人 SPEAKER_02：这就是它将比我们更好的原因。
371 00:41:25,996 --> 00:41:27,679 说话人 SPEAKER_02：但如果您想要低功耗，
372 00:41:28,688 --> 00:41:34,818 说话人 SPEAKER_02：那么探索模拟硬件是值得的，在那里您放弃软件和硬件的分离。
373 00:41:35,380 --> 00:41:38,846 说话人 SPEAKER_02：每个单独的部分都需要训练，但之后它就可以运行。
374 00:41:38,865 --> 00:41:43,152 说话人 SPEAKER_02：然后您可以用仅 30 瓦的功率运行拥有 100 万亿个连接的东西。
375 00:41:43,487 --> 00:41:48,074 说话人 SPEAKER_00: 你看到 AI 正在走向将软件和硬件分离的方向吗？
376 00:41:48,094 --> 00:41:53,461 说话人 SPEAKER_00: 我的意思是，我们现在已经知道，通常我们会先对软件进行优化，然后尝试对硬件进行优化。
377 00:41:53,842 --> 00:41:54,764 说话人 SPEAKER_00: 你对此有何看法？
378 00:41:55,244 --> 00:41:56,847 说话人 SPEAKER_02: 我认为这里会有一个分支。
这个前沿领域，你使用当前的数字硬件和巧妙的编程，分担计算量，从而实现模型并行化
抱歉，您可以在不同的计算机上使用相同的数据训练不同的模型，然后平均权重，诸如此类的事情。
381 00：42：18,956 --> 00：42：25,666 演讲者 SPEAKER_02：这将是设备变得最智能的地方。
382 00:42:26,967 --> 00:42:32,496 说话者 SPEAKER_02：但将会有一种完全不同的设备，那就是这些模拟低功耗设备。
383 00:42:34,096 --> 00:42:40,166 说话人 SPEAKER_02：其主要优势在于硬件制造成本低，因为它不需要可靠制造。
384 00:42:40,586 --> 00:42:44,434 说话人 SPEAKER_02：您不需要一个价值 100 亿美元的晶圆厂来制造硬件。
385 00:42:44,454 --> 00:42:46,297 说话人 SPEAKER_02：您实际上会用纳米技术来生长它。
386 00:42:47,378 --> 00:42:49,963 说话人 SPEAKER_02：它将以非常低的功耗运行。
387 00:42:51,666 --> 00:42:58,297 说话人 SPEAKER_02：所以你将能够在你的烤面包机里拥有一个语言界面，只需 1 美元，功耗仅为几瓦。
388 00:43:00,050 --> 00:43:08,259 说话人 SPEAKER_02：但它不会像这些真正的大、非常昂贵、非常耗电的系统一样智能，这些系统是用反向传播训练的。
389 00:43:08,440 --> 00:43:09,603 说话人 SPEAKER_02：这是我现在的信念。
390 00:43:09,871 --> 00:43:12,315 说话人 SPEAKER_00：前景非常广阔，听到这个消息真是太好了。
391 00:43:12,675 --> 00:43:15,561 说话人 SPEAKER_00：关于这次演示，您可能还有一个问题。
392 00:43:16,581 --> 00:43:21,230 说话人 SPEAKER_00：您认为这是一个新的研究领域吗？
393 00:43:21,250 --> 00:43:24,976 说话人 SPEAKER_00：因为它与我们过去使用的反向传播方式非常不同。
394 00:43:25,036 --> 00:43:28,322 说话人 SPEAKER_00：所以您觉得这正在孕育出新的不同方式吗？
395 00:43:28,342 --> 00:43:29,744 说话人 SPEAKER_02：嗯，这可不是在生孩子。
396 00:43:29,764 --> 00:43:32,248 说话人 SPEAKER_02：已经有很多人拥有所有这些信仰。
397 00:43:32,509 --> 00:43:36,114 说话人 SPEAKER_02：有个叫杰克·肯德尔的人，在一家叫雷恩的公司工作。
398 00:43:36,094 --> 00:43:41,568 说话人 SPEAKER_02：还有一群人在斯坦福相信所有这些，并试图做模拟硬件。
399 00:43:42,431 --> 00:43:46,762 说话人 SPEAKER_02：这个算法对他们来说非常相关。
400 00:43:49,730 --> 00:43:51,132 说话人 SPEAKER_00：好的，这里我有一个问题。
401 00:43:51,851 --> 00:44:01,324 说话人 SPEAKER_00：您对我们总是越来越接近了解大脑的工作持非常乐观的态度。
402 00:44:01,884 --> 00:44:11,556 说话人 SPEAKER_00：那么，您最近关于大脑的最新发现有哪些，这些发现改变了您对大脑的看法？
403 00:44:11,635 --> 00:44:15,940 说话人 SPEAKER_00: 我想你上次说过，也许我们会在五年左右找到答案。
404 00:44:15,981 --> 00:44:17,862 说话人 SPEAKER_00: 你现在还觉得我们在成长吗？
405 00:44:17,842 --> 00:44:21,509 说话人 SPEAKER_02: 我一直认为我们会在五年左右找到答案，最终我会证明我是对的。
406 00:44:25,675 --> 00:44:31,344 说话人 SPEAKER_02: 只是我们说我们在一百年内找不到答案，这不是一个好的研究策略。
407 00:44:31,385 --> 00:44:37,775 说话人 SPEAKER_02：可能更现实一些，但如果我们要 100 年后才能弄清楚，那还不如放弃。
408 00:44:39,324 --> 00:44:41,469 说话人 SPEAKER_02：显然，我们不可能在下周内弄清楚。
409 00:44:43,371 --> 00:44:53,690 说话人 SPEAKER_02：但是相信我们很可能弄清楚……我认为我们可能弄清楚的原因是，一旦足够接近，就会出现一个大的吸引子。
410 00:44:53,769 --> 00:44:57,197 说话人 SPEAKER_02：一旦足够接近，突然间所有的事情都会变得有意义。
411 00:44:57,898 --> 00:45:02,025 说话人 SPEAKER_02：关于大脑的各种奇怪事实将开始变得有意义。
412 00:45:02,561 --> 00:45:11,304 说话人 SPEAKER_02：所以这有点像奇点，突然之间你会觉得你足够接近，现在你可以看到这一切是如何联系在一起的。
413 00:45:12,748 --> 00:45:17,280 说话人 SPEAKER_02：这正是我所希望的，我希望我能亲眼看到这一幕。
414 00:45:18,289 --> 00:45:24,918 说话人 SPEAKER_00：最后一个问题，也就是关于大脑和反向传播还有很多其他问题。
415 00:45:24,938 --> 00:45:27,099 说话人 SPEAKER_00: 这个话题实际上是关于摩洛哥和人工智能的。
416 00:45:27,440 --> 00:45:40,315 说话人 SPEAKER_00: 我有一个问题，摩洛哥在人工智能领域有着很好的发展势头，摩洛哥人工智能我们努力在所有这些顶级机器学习会议和创新活动中保持强大的存在，然而对于所有这些发展中国家
417 00:45:40,295 --> 00:45:43,038 说话人 SPEAKER_00: 面临着许多挑战，比如资源，对吧？
418 00:45:43,059 --> 00:45:48,826 说话人 SPEAKER_00: 资源问题，或者可能是合格的学者提供的良好指导。
419 00:45:48,846 --> 00:46:01,041 说话人 SPEAKER_00: 那么，霍 inton 教授，您对摩洛哥的所有 AI 研究人员有什么建议，是引领非洲还是仅仅帮助非洲在 AI 领域取得进步和突破？
420 00:46:02,503 --> 00:46:06,487 说话人 SPEAKER_02: 我不确定我有没有什么非常具体的建议。
421 00:46:07,610 --> 00:46:09,492 说话人 SPEAKER_02: 谷歌的 Jeff Dean，
422 00:46:10,146 --> 00:46:11,630 说话人 SPEAKER_02: 非常热衷于帮助非洲。
423 00:46:11,650 --> 00:46:13,934 说话人 SPEAKER_02：我的意思是，他在加纳建立了一个谷歌实验室。
424 00:46:14,996 --> 00:46:26,681 说话人 SPEAKER_02：总的来说，我认为许多学术界和工业界的领先研究人员都愿意帮助非洲。
425 00:46:26,721 --> 00:46:31,210 说话人 SPEAKER_02：他们认识到那里有大量的人才。
426 00:46:31,476 --> 00:46:45,213 说话人 SPEAKER_02：我的朋友 Terry Sinofsky，他比我更懂生物，向我解释说，如果你看遗传多样性，非洲的遗传多样性比全世界其他地方加起来还要多，因为人们在那里存在的时间更长。
427 00:46:47,074 --> 00:47:00,471 说话人 SPEAKER_02：有很多原因想要帮助非洲，包括过去帝国主义国家，比如我来自的那个国家，所做的一切坏事。
428 00:47:02,105 --> 00:47:10,019 说话人 SPEAKER_02：我想你会发现，有很多学者愿意通过例如在你们的会议上发表演讲等方式来提供帮助。
429 00:47:11,802 --> 00:47:20,518 说话人 SPEAKER_00：另一个例子是，如果你们有什么具体的研究领域建议，比如根据他们所在的位置，他们可以深入研究。
430 00:47:23,324 --> 00:47:24,686 说话人 SPEAKER_01：显然。
431 00:47:25,949 --> 00:47:38,777 说话人 SPEAKER_02：有一件事是明确的，现在每个人都很清楚，使用反向传播训练的神经网络效果非常好，它们将被用于一切。
432 00:47:39,230 --> 00:47:44,958 说话人 SPEAKER_02：在非洲，可能有很多针对非洲的有趣应用。
433 00:47:45,798 --> 00:47:50,164 说话人 SPEAKER_02：这些地方将是非洲研究人员具有优势的地方。
434 00:47:50,286 --> 00:47:53,369 说话人 SPEAKER_02：他们可以理解这些应用，并与需要这些应用的人合作。
435 00:47:53,971 --> 00:47:55,552 说话人 SPEAKER_02：这似乎是显而易见的事情要做。
436 00:47:56,494 --> 00:48:06,148 说话人 SPEAKER_02：我还没有真正考虑其他的事情，但最明显的事情是考虑
437 00:48:07,141 --> 00:48:11,746 说话人 SPEAKER_02：针对非洲的具体应用，并针对这些应用进行工作。
438 00:48:13,329 --> 00:48:17,614 说话人 SPEAKER_02：这显然是一种良性的循环。
439 00:48:19,177 --> 00:48:22,362 说话人 SPEAKER_00：也许正如你之前提到的，如果这个计算发生变化，对吧？
440 00:48:22,382 --> 00:48:34,498 说话人 SPEAKER_00：所以现在我们看到这些大公司都在使用这样的计算，也许如果有一些领域实际上只需要更少的计算就能解决问题，并且还能创新，那可能非常有希望。
441 00:48:34,478 --> 00:48:36,179 说话人 SPEAKER_02：这正是我所做的。
442 00:48:36,320 --> 00:48:43,666 说话人 SPEAKER_02：我不使用，我的意思是，我在谷歌，所以我可以使用这些庞大的计算资源，但我年纪大了，所以我不喜欢学习新语言。
443 00:48:43,746 --> 00:48:45,288 说话人 SPEAKER_02：我学新语言非常慢。
444 00:48:45,907 --> 00:48:51,413 说话人 SPEAKER_02：所以实际上，我决定做一些基础研究，看看大脑可能如何获得梯度。
445 00:48:51,452 --> 00:48:56,257 说话人 SPEAKER_02：进行基础研究不需要大量的计算。
446 00:48:56,277 --> 00:49:01,943 说话人 SPEAKER_02：如果你在推动前沿，比如这些大型语言模型，那就需要大量的计算。
447 00:49:02,282 --> 00:49:04,485 说话人 SPEAKER_02：这就是我选择从事这项工作的原因之一。
448 00:49:04,465 --> 00:49:11,826 说话人 SPEAKER_02：试图理解大脑如何获取梯度，我认为这不需要大量资源。
449 00:49:12,608 --> 00:49:13,952 说话人 SPEAKER_02：只需要好的想法。
450 00:49:17,003 --> 00:49:17,563 说话人 SPEAKER_00：太棒了。
451 00:49:17,744 --> 00:49:20,949 说话人 说话人_00：非常感谢您这次的演讲，Hinton 教授。
452 00:49:21,048 --> 00:49:25,896 说话人 说话人_00：能够代表整个社区，代表摩洛哥人工智能，邀请您来，这是一件非常荣幸的事情。
453 00:49:26,195 --> 00:49:32,364 说话人 说话人_00：我们非常高兴和激动能够与大家分享您最近的研究成果。
454 00:49:32,625 --> 00:49:37,932 说话人 说话人_00：我希望您很快就能听到来自摩洛哥的一些伟大的 AI 研究成果。
455 00：49：38,454 --> 00：49：41,458 议长 SPEAKER_00：四年后，我希望你能打败法国人。