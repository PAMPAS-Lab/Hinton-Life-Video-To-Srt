1 00:00:03,710 --> 00:00:04,351 说话者 SPEAKER_02：晚上好。
2 00:00:04,391 --> 00:00:07,155 说话人 SPEAKER_02：这成功了。
3 00:00:08,416 --> 00:00:24,097 说话人 SPEAKER_02：众所周知，而且现在我们所有的院长、教务长、高科技经理都知道，我们的会议是您找到计算机科学研究前沿的地方。
4 00:00:24,397 --> 00:00:37,335 说话人 SPEAKER_02：正如我们所知，在这个时候，我们所有的院长、教务长、高科技经理都知道，我们的会议是您找到计算机科学研究前沿的地方。
5 00:00:38,256 --> 00:00:48,972 说话人 SPEAKER_02：FCRC 成立于 1993 年，其理念是每三到四年举办一次联邦活动，届时主要会议可以联合举办。
今年，我们在30个主要会议和许多相关研讨会和教程中，有创纪录的2,700名参与者。
7 00：01：01,429 --> 00：01：04,233 演讲者 SPEAKER_02：这比我们计划的多了大约 20%。
实际上，在这个话题上，如果今晚你的手机响了，那意味着有2,700人会记住你，包括所有在直播中的人。
9 00：01：17,537 --> 00：01：23,063 演讲者 SPEAKER_02：让我花点时间读出所有会议的名称，以提醒您谁都在场。
10 00:01:23,605 --> 00:01:39,421 说话人 SPEAKER_02：所以我们有 COLT、eEnergy、EC、HPDC、ICS、ISCA、ISMM、IWQOS、LCTES、PLDI、SIGMETRICS、SPAR 和 STOC。
11 00:01:40,522 --> 00:01:47,510 说话人 SPEAKER_02：正如您所知，这些会议涵盖了计算机科学研究的广泛基础领域，
12 00:01:47,844 --> 00:02:11,608 说话人 SPEAKER_02：包括计算机架构、经济学与计算、嵌入式系统、高性能与超级计算、机器学习理论、测量与建模、编译器和编程语言、内存管理、并行算法、服务质量、智能能源系统、计算理论以及许多相关主题。
13 00:02:12,212 --> 00:02:17,986 说话人 SPEAKER_02：从出席率的角度来看，我特别高兴地看到我们也创下了记录数量的
14 00:02:18,102 --> 00:02:21,067 主持人 SPEAKER_02：今年有超过 1,100 名学生参加。
15 00:02:21,927 --> 00:02:38,014 主持人 SPEAKER_02：我想鼓励大家，尤其是利用 FCRC 提供的独特机会的学生们，也要参加你研究领域之外的会议和研讨会，这样你可以接触到计算机科学其他领域的最新思想。
16 00:02:38,675 --> 00:02:43,924 主持人 SPEAKER_02：只需查看 Hoover 应用或在线日程，了解同期活动的安排。
17 00:02:45,118 --> 00:03:00,360 主持人 SPEAKER_02：现在，FCRC 的一个主要亮点是你们有机会聆听来自计算机科学不同领域的杰出领导者的全体会议演讲，当然，今晚的图灵讲座将由杰夫·辛顿和杨立昆主持。
18 00:03:00,948 --> 00:03:04,895 讲者 SPEAKER_02：所有全体会议将在这个美丽的交响乐厅空间举行。
19 00:03:05,798 --> 00:03:13,634 讲者 SPEAKER_02：下周的会议安排在每天上午 11:20，没有冲突活动，所以请务必参加。
20 00:03:13,995 --> 00:03:15,478 讲者 SPEAKER_02：您没有理由错过它们。
21 00:03:16,379 --> 00:03:21,471 讲者 SPEAKER_02：提醒一下，下周的全体会议演讲者有 Jim Smith、Cynthia Dwork、
22 00:03:21,771 --> 00:03:31,426 演讲者 SPEAKER_02：Sriram Krishnamurthy、Jeanette Wing 和 Eric Lindau，他们将由大会主席 Mary Hall 介绍。
23 00:03:32,014 --> 00:03:50,051 演讲者 SPEAKER_02：虽然我将在周五会议结束时有机会向所有人表达更全面的感谢，但我一定要向所有会议的赞助商，尤其是这里列出的 FCRC 全体赞助商表示最深切的感谢。
24 00:03:50,072 --> 00:03:59,540 演讲者 SPEAKER_02：这是一个独一无二的四年一度的事件，没有这里列出的公司站出来支持 FCRC，这是不可能实现的。
25 00:03:59,875 --> 00:04:01,295 演讲者 SPEAKER_02：所以感谢他们所有人。
26 00:04:02,197 --> 00:04:07,581 说话人 SPEAKER_02：此外，整个 ACM 团队一直在努力确保这周圆满成功。
27 00:04:08,242 --> 00:04:14,688 说话人 SPEAKER_02：我想特别感谢 Donna Capo，她在会议行政团队中的不懈领导。
28 00:04:15,430 --> 00:04:25,579 说话人 SPEAKER_02：Donna 自 1993 年 FCRC 首次举办以来就参与组织工作，对 FCRC 的成功至关重要。
29 00:04:25,899 --> 00:04:26,721 说话人 SPEAKER_02：所以，感谢你，Donna。
30 00:04:27,841 --> 00:04:28,262 说话人 SPEAKER_02: 嗯。
31 00:04:33,406 --> 00:04:38,535 说话人 SPEAKER_02: 最后，感谢大家来到凤凰城参加 FCRC，并使这个房间座无虚席。
32 00:04:39,456 --> 00:04:46,009 说话人 SPEAKER_02: 希望你们有一个愉快的会议，并享受与所有计算机科学研究同事的众多互动。
33 00:04:46,790 --> 00:04:53,642 说话人 SPEAKER_02: 就这样，我想邀请 ACM 主席 Sherry Pancake 上台介绍图灵讲座。
34 00:04:57,069 --> 00:04:57,269 说话人 SPEAKER_02: 谢谢。
35 00:05:02,853 --> 00:05:03,473 说话人 SPEAKER_00: 谢谢。
36 00:05:03,533 --> 00:05:06,276 说话人 SPEAKER_00: 我很高兴来到 FCRC。
37 00:05:06,857 --> 00:05:14,964 说话人 SPEAKER_00: 正如 Vivek 提到的，我有幸担任 ACM 的主席，这是世界上最大的计算机专业人士协会。
38 00:05:15,545 --> 00:05:19,810 说话人 SPEAKER_00：你知道吗？ACM 在全球拥有近 10 万名会员。
39 00:05:20,610 --> 00:05:27,898 说话人 SPEAKER_00：我们通过像这样的会议，在 190 个国家为计算社区提供服务。
40 00:05:28,283 --> 00:05:32,134 说话人 SPEAKER_00：我们的出版物、网络研讨会和学习资源。
41 00:05:32,755 --> 00:05:39,475 说话人 SPEAKER_00：ACM 在全球计算教育和课程指南方面也非常活跃。
42 00:05:40,432 --> 00:05:48,685 说话人 SPEAKER_00：能来 FCRC 真是太好了，正如 Vivek 所说，这是一个多么独特的机遇啊。
43 00:05:49,327 --> 00:06:03,050 说话人 SPEAKER_00：我们都知道计算已经变得更具跨学科性，但很少有机会能和来自其他领域的研究者见面和交流。
44 00:06:03,571 --> 00:06:07,437 说话人 SPEAKER_00：我真心希望大家能充分利用这个星期的时间。
45 00:06:08,951 --> 00:06:18,360 说话人 SPEAKER_00：正如我们所知，人工智能是所有科学领域增长最快的领域，也是社会上的热门话题。
46 00:06:19,742 --> 00:06:33,555 说话人 SPEAKER_00：我们所看到的 AI 的惊人进步，如果没有像今晚我们致敬的人所建立的某些基础，是根本不可能实现的。
47 00:06:34,297 --> 00:06:38,841 说话人 SPEAKER_00：例如，当我们想到影响时，
48 00:06:39,175 --> 00:06:45,884 说话人 SPEAKER_00：想想最初在游戏行业中开发 GPU 所投入的研究。
49 00:06:46,204 --> 00:07:04,812 说话人 SPEAKER_00：当时谁能想到后来它们会被组装成大型阵列，并用作庞大神经网络的平台，进而推动了机器人学和计算机视觉等领域的大幅进步？
50 00:07:06,377 --> 00:07:12,726 今晚我们所认可的进步主要是在深度学习领域。
51 00:07:14,288 --> 00:07:20,377 全世界有成亿的人从机器学习的优势中受益。
52 00:07:20,858 --> 00:07:32,654 任何拥有智能手机的人都能接触到诸如计算机视觉和语音识别等方面的惊人进步，这些进步我们几年前甚至不敢想象。
53 00:07:33,985 --> 00:07:46,958 更重要的是，也许，机器学习为科学家们提供了新的工具，使他们能够在医学、天文学和材料科学等领域取得进步。
54 00:07:49,620 --> 00:07:57,608 说话人 说话人_00: FCRC 每四年举办一次，所以当我们讨论这个会议时，我们想在欢迎会议中做一些特别的事情。
55 00:07:58,310 --> 00:08:03,654 说话人 说话人_00: 我认为你们会同意我的看法，听取今年图灵奖得主的情况确实能让这次会议变得非常特别。
56 00:08:03,853 --> 00:08:07,158 说话人 说话人_00: 2018 年 ACM AM 图灵奖上周在旧金山颁发给了三位深度学习先驱，约书亚·本吉奥、杰弗里·辛顿和杨立昆。
57 00:08:07,858 --> 00:08:23,437 说话人 说话人_00: 2018 年 ACM AM 图灵奖上周在旧金山颁发给了三位深度学习先驱，约书亚·本吉奥、杰弗里·辛顿和杨立昆。
58 00:08:24,379 --> 00:08:25,439 说话人 SPEAKER_00: 他们三个
59 00:08:25,875 --> 00:08:43,523 说话人 SPEAKER_00: 在过去 30 年的时间里，他们集体和独立地工作，首先为深度神经网络的概念基础做出了贡献，然后进行了实验，最终识别出许多非常有趣的现象。
60 00:08:43,984 --> 00:08:45,225 说话人 SPEAKER_00: 但他们并没有止步于此。
61 00:08:45,265 --> 00:08:53,317 说话人 SPEAKER_00: 他们继续开发了工程上的进步，这些进步最终有力地证明了深度
62 00:08:54,174 --> 00:09:00,366 说话人 SPEAKER_00: 神经网络实际上可以以经济的方式应用于实践。
63 00:09:00,386 --> 00:09:07,559 说话人 SPEAKER_00: 这反过来又允许其他人开发这些惊人的
64 00:09:08,384 --> 00:09:15,692 说话人 SPEAKER_00: 概念，我们现在正在从这些概念中受益，以及我们现在在许多不同领域受益的进步。
65 00:09:16,092 --> 00:09:23,682 说话人 SPEAKER_00: 计算机视觉、语音识别、自然语言处理、机器人技术，以及许多其他不同领域。
66 00:09:24,322 --> 00:09:29,469 主持人：今晚我非常高兴能够介绍今晚的演讲者。
67 00:09:29,869 --> 00:09:32,011 主持人：第一位是杰夫·辛顿。
68 00:09:32,245 --> 00:09:38,336 主持人：他将就“数字学习革命”这一主题发表图灵奖演讲。
69 00:09:38,976 --> 00:09:47,592 主持人：接下来是杨立昆，他恰如其分地将自己的演讲命名为“深度学习革命：续篇”。
70 00:09:48,073 --> 00:09:50,658 说话人 SPEAKER_00：所以，杰弗里，我想欢迎你。
71 00:10:05,235 --> 00:10:11,244 说话人 SPEAKER_07：首先，我想感谢所有在 ACM 投入时间使这一切顺利进行的人们。
72 00:10:14,908 --> 00:10:17,952 说话人 SPEAKER_07：所以，人工智能领域有两种范式。
73 00:10:20,075 --> 00:10:31,210 说话人 SPEAKER_07：自 20 世纪 50 年代以来，一直存在一种受逻辑启发的途径，其中智能的本质被视为由符号规则操作的符号表达式。
74 00:10:31,628 --> 00:10:34,711 说话人 SPEAKER_07：主要问题一直是推理。
75 00:10:34,811 --> 00:10:40,155 说话人 SPEAKER_07：我们如何让计算机像人类一样进行推理？
76 00:10:40,176 --> 00:10:44,440 说话人 SPEAKER_07：然后是受生物学启发的途径，这非常不同。
77 00:10:45,721 --> 00:10:49,865 说话人 SPEAKER_07：它将智能的本质视为学习神经网络连接强度的过程。
78 00:10:50,765 --> 00:10:55,990 说话人 SPEAKER_07：至少一开始要关注的主要是学习和感知。
79 00:10:56,010 --> 00:10:58,833 说话人 SPEAKER_07：所以它们是两种非常不同的范式，具有非常不同的初始目标。
80 00:11:01,666 --> 00:11:04,812 说话人 SPEAKER_07：它们对应该使用的内部表示有非常不同的看法。
81 00:11:05,914 --> 00:11:20,147 说话人 SPEAKER_07：所以符号范式认为你应该使用符号表达式，如果你发明了一种好的语言来表达它们，你当然可以将这些表达式交给计算机，通过应用规则，你当然可以在计算机内部得到新的表达式。
82 00:11:20,919 --> 00:11:26,147 说话人 SPEAKER_07：生物范式认为内部表征与语言完全不同。
83 00:11:26,866 --> 00:11:28,649 说话人 SPEAKER_07：它们只是大量神经活动的向量。
84 00:11:29,029 --> 00:11:31,572 说话人 SPEAKER_07：这些大量向量会对其他大量向量产生因果效应。
85 00:11:33,515 --> 00:11:35,798 说话人 SPEAKER_07：这些向量将从数据中学习。
86 00:11:35,818 --> 00:11:38,741 说话人 SPEAKER_07：所以这些向量中的所有结构都将从数据中学习得到。
87 00:11:39,363 --> 00:11:43,548 说话人 SPEAKER_07：我显然是在以一种夸张的方式描述这两个立场，以强调它们之间的差异。
88 00:11:46,572 --> 00:11:50,336 说话人 SPEAKER_07：这导致了两种完全不同的方式来尝试让计算机做你想做的事情。
89 00:11:50,602 --> 00:11:58,110 说话人 SPEAKER_07：所以一种方法，我稍微有点调皮地称之为智能设计，就是所谓的编程。
90 00:11:58,831 --> 00:12:03,677 说话人 SPEAKER_07：是你找出解决问题的方法，然后告诉计算机具体要做什么。
91 00:12:05,340 --> 00:12:13,207 说话人 SPEAKER_07：另一种方法是向计算机展示大量输入和它应该产生的输出示例，然后让计算机自己解决。
92 00:12:13,668 --> 00:12:19,075 说话人 SPEAKER_07：当然，你也需要编程计算机，但只需要用一些通用学习算法编程一次。
93 00:12:20,336 --> 00:12:21,597 说话人 SPEAKER_07：这又是一种简化。
94 00:12:23,980 --> 00:12:31,389 说话人 SPEAKER_07：所以一个人们用符号人工智能尝试了 50 年的例子，就是拿一张图片并描述图片中的内容。
95 00:12:32,711 --> 00:12:42,480 说话人 SPEAKER_07：想想看，将左边的图片中的数百万像素转换成一系列单词。
96 00:12:42,922 --> 00:12:44,663 说话人 SPEAKER_07：显然不知道如何编写这样的程序。
97 00:12:45,283 --> 00:12:47,626 说话人 SPEAKER_07：人们尝试了很长时间，但无法编写出这样的程序。
98 00:12:48,873 --> 00:12:57,780 说话人 SPEAKER_07：从事神经网络研究的人们也尝试了很长时间，最终他们成功地开发出了一种工作相当好的系统，该系统基于纯学习的方法。
99 00:13:00,624 --> 00:13:12,134 说话人 SPEAKER_07：所以神经网络的核心问题一直是，我们知道具有许多层和非线性处理元素的大的神经网络可以计算复杂的事物，至少我们相信它们可以。
100 00:13:13,796 --> 00:13:15,538 说话人 SPEAKER_07：但问题是，它们能否学会这样做？
101 00:13:16,732 --> 00:13:32,068 说话人 SPEAKER_07：那么，能否通过从一个大的网络开始，从随机权重开始，并通过某种方式训练它，使其改变权重，从而改变其计算的内容，来学习像物体识别或机器翻译这样的任务呢？
102 00:13:32,089 --> 00:13:39,716 说话人 SPEAKER_07：对于这类系统，有一个明显的学习算法，它是由图灵、塞尔弗里奇以及许多人提出的，这个算法的变体。
103 00:13:40,498 --> 00:13:42,639 说话人 SPEAKER_07：想法是，你从随机权重开始。
104 00:13:42,990 --> 00:13:45,575 说话人 SPEAKER_07：这就是图灵认为的人类智能是如何工作的。
105 00:13:45,995 --> 00:13:53,044 说话人 SPEAKER_07：你从随机权重开始，奖励和惩罚会使你改变连接强度，这样你最终就能学到东西。
106 00:13:54,888 --> 00:13:56,350 说话人 SPEAKER_07：这非常低效。
107 00:13:56,370 --> 00:13:58,251 说话人 SPEAKER_07：它将起作用，但非常低效。
108 00:14:00,956 --> 00:14:10,990 说话人 SPEAKER_07：在 20 世纪 60 年代，罗森布拉特提出了一种相当简单且高效的学习过程，比随机尝试和错误的方法高效得多，可以找出
109 00:14:11,289 --> 00:14:21,945 说话人 SPEAKER_07：如何学习从图像中提取的特征上的权重，然后你使用权重组合特征以做出决策。
110 00:14:23,908 --> 00:14:28,193 说话者 SPEAKER_07：他设法向你展示了你可以做一些类似的事情，一些相当令人印象深刻的事情。
111 00:14:28,995 --> 00:14:31,558 说话者 SPEAKER_07：但在感知器中，你不会学习特征。
112 00:14:32,580 --> 00:14:33,782 说话者 SPEAKER_07：这又是一个简化。
113 00:14:33,841 --> 00:14:38,107 说话者 SPEAKER_07：罗森布拉特有很多关于如何学习特征的想法，但他并没有发明反向传播。
114 00:14:39,082 --> 00:14:46,956 说话人 SPEAKER_07：在 1969 年，明斯基和帕帕特表明，罗森布拉特使其工作的感知器类型在功能上非常有限。
115 00:14:47,317 --> 00:14:49,542 说话人 SPEAKER_07：有一些相对简单的事情他们做不到。
116 00:14:50,663 --> 00:14:56,855 说话人 SPEAKER_07：明斯基和帕帕特强烈暗示，使它们更深或更好的学习算法并不能解决问题。
117 00:14:57,235 --> 00:14:59,299 说话人 SPEAKER_07：这种方式存在一个基本的局限性。
118 00:15:00,201 --> 00:15:02,205 说话人 SPEAKER_07：这导致了第一个神经网络冬天。
119 00:15:05,797 --> 00:15:12,123 说话人 SPEAKER_07：在 20 世纪 70 年代和 80 年代，许多不同的团队发明了反向传播算法及其变体。
120 00:15:13,124 --> 00:15:20,471 说话人 SPEAKER_07：反向传播允许神经网络学习特征检测器，并拥有多层学习特征检测器。
121 00:15:21,773 --> 00:15:23,333 说话人 SPEAKER_07：这引起了极大的兴奋。
122 00:15:25,817 --> 00:15:31,062 说话人 SPEAKER_07：这使得神经网络能够将单词转换为
123 00:15:31,817 --> 00:15:37,144 说话人 SPEAKER_07：代表单词意义的向量，它们只需尝试预测下一个单词就能做到这一点。
124 00:15:38,326 --> 00:15:44,816 说话人 SPEAKER_07：看起来它可能能够解决像语音识别和形状识别这样的难题。
125 00:15:45,277 --> 00:15:54,769 说话人 SPEAKER_07：事实上，它确实解决了，在语音识别方面表现中等，对于某些形状识别形式，它做得非常好，比如 Yann LeCun 的读取手写的网络。
126 00:15:58,274 --> 00:16:01,740 说话人 SPEAKER_07：现在我打算解释
127 00:16:02,850 --> 00:16:04,613 说话人 SPEAKER_07：非常简要地说明神经网络是如何工作的。
128 00:16:04,773 --> 00:16:08,057 说话人 SPEAKER_07：我知道你们大多数人都会知道这个，但我只是想过一遍，以防万一。
129 00:16:09,578 --> 00:16:11,640 说话人 SPEAKER_07：所以我们对神经元做了一个粗略的理想化。
130 00:16:12,822 --> 00:16:22,614 说话人 SPEAKER_07：这种理想化的目的是为了得到可以学习的东西，以便我们可以研究您如何将这些所有东西组合起来，在大型的这些事物网络中学习复杂的东西。
131 00:16:23,615 --> 00:16:27,658 说话人 SPEAKER_07：所以它有一些可以变化的输入权重，或者学习算法会变化。
132 00:16:28,200 --> 00:16:30,883 说话人 SPEAKER_07：它给出的输出等于其输入
133 00:16:31,201 --> 00:16:32,923 说话人 SPEAKER_07：只要输入超过一定量。
134 00:16:33,403 --> 00:16:39,830 说话人 SPEAKER_07：这就是一个修正线性神经元，我们实际上直到后来才开始使用，但这些神经元工作得非常好。
135 00:16:42,113 --> 00:16:49,520 说话人 SPEAKER_07：然后你将它们连接到网络中，并为每个这些神经元设置输入权重。
136 00:16:49,860 --> 00:16:54,086 说话人 SPEAKER_07：当你改变这些输入权重时，你实际上在改变这个神经元会响应的特征。
137 00:16:54,566 --> 00:16:56,989 说话人 SPEAKER_07：所以通过学习这些权重，你实际上在学习特征。
138 00:16:57,221 --> 00:17:03,368 说话人 SPEAKER_07：你添加了几层隐藏层，然后你想训练它，使得输出神经元做你想让它做的事情。
139 00:17:03,388 --> 00:17:05,590 说话人 SPEAKER_07：例如，我们可能会展示狗和猫的图片。
140 00:17:06,270 --> 00:17:09,134 说话人 SPEAKER_07：我们可能希望左边的神经元在看到狗时激活，而右边的神经元在看到猫时激活。
141 00:17:10,335 --> 00:17:11,737 说话人 SPEAKER_07：问题是，我们该如何训练它？
142 00:17:14,398 --> 00:17:17,563 说话人 SPEAKER_07：所以有两种学习算法，主要是。
143 00:17:18,242 --> 00:17:20,625 说话人 SPEAKER_07：哦，实际上有三个，但第三个效果不太好。
144 00:17:20,726 --> 00:17:22,807 说话人 SPEAKER_07：这被称为强化学习。
145 00:17:25,807 --> 00:17:29,536 说话人 SPEAKER_07：强化学习有一个非常巧妙的归谬法，叫做 DeepMind。
146 00:17:31,239 --> 00:17:33,964 说话人 SPEAKER_07：这是个笑话。
147 00:17:33,984 --> 00:17:43,884 说话人 SPEAKER_07：有监督训练，你向网络展示期望的输出，然后调整权重，直到它产生你想要的输出。
148 00:17:43,949 --> 00:17:45,692 说话人 SPEAKER_07：为此，你需要知道期望的输出是什么。
149 00:17:46,153 --> 00:17:57,570 说话人 SPEAKER_07：还有无监督学习，你取一些数据，并尝试以某种方式在隐藏层中表示这些数据，以便你可以重建数据或重建数据的一部分。
150 00:17:57,932 --> 00:18:01,357 说话人 SPEAKER_07：如果我将数据的小部分空白，现在能否从隐藏层中重建它们？
151 00:18:02,138 --> 00:18:05,805 说话人 SPEAKER_07：这就是无监督学习在神经网络中通常工作的方式。
152 00:18:08,317 --> 00:18:14,942 说话人 SPEAKER_07：所以这里有一个非常低效的监督学习方法，通过使用变异或强化方法。
153 00:18:14,962 --> 00:18:19,448 说话人 SPEAKER_07：你会做的是，你拿你的神经网络，给它一个典型的示例集。
154 00:18:20,048 --> 00:18:21,028 说话人 SPEAKER_07：你会看到它做得有多好。
155 00:18:21,509 --> 00:18:27,295 说话人 SPEAKER_07：然后你会改变一个权重，稍微调整一下，看看神经网络的表现是变好还是变差。
156 00:18:28,115 --> 00:18:29,757 说话人 SPEAKER_07：如果表现变好了，你就保留这个变化。
157 00:18:30,498 --> 00:18:32,779 说话人 SPEAKER_07：如果表现变差了，你就把它丢弃。
158 00:18:33,601 --> 00:18:37,884 说话人 SPEAKER_07：也许你会改变方向，这已经是两倍的性能提升了。
159 00:18:38,978 --> 00:18:40,941 说话人 SPEAKER_07：但这是一种极其缓慢的学习算法。
160 00:18:40,961 --> 00:18:41,662 说话人 SPEAKER_07：它将会工作。
161 00:18:42,564 --> 00:18:46,951 说话人 SPEAKER_07：但它所达到的效果可以通过反向传播许多许多倍地更快地实现。
162 00:18:47,612 --> 00:18:50,876 讲者 SPEAKER_07：所以你可以把反向传播看作是这个算法的高效版本。
163 00:18:52,799 --> 00:19:00,952 讲者 SPEAKER_07：在反向传播中，我们不是改变一个权重并测量它对网络性能的影响，
164 00:19:01,372 --> 00:19:05,397 讲者 SPEAKER_07：而是利用网络中所有的权重都在计算机内的这一事实。
165 00:19:06,180 --> 00:19:10,346 讲者 SPEAKER_07：利用这一事实来计算权重变化对性能的影响。
166 00:19:10,926 --> 00:19:13,009 说话人 SPEAKER_07：您将对所有权重并行进行操作。
167 00:19:13,671 --> 00:19:20,642 说话人 SPEAKER_07：如果您有一百万个权重，您可以并行计算这些权重中任何一个微小变化对性能的影响。
168 00:19:21,202 --> 00:19:22,885 说话人 SPEAKER_07：然后您可以并行更新它们。
169 00:19:23,866 --> 00:19:28,914 说话人 SPEAKER_07：这有其自身的问题，但它的速度会比之前的算法快一百万倍。
170 00:19:29,873 --> 00:19:32,998 众多媒体人士将其描述为指数级加速。
171 00:19:33,578 --> 00:19:35,540 实际上，这是一个线性加速。
172 00:19:35,622 --> 00:19:37,924 “指数”这个词被过度地平方使用了。
173 00:19:42,592 --> 00:19:49,001 因此我们回到了反向传播，你需要在网络中进行正向传播。
174 00:19:49,321 --> 00:19:51,325 说话人 SPEAKER_07：你看一下输出结果是什么。
175 00:19:51,457 --> 00:19:58,243 说话人 SPEAKER_07：然后使用你得到的结果和期望结果之间的差异，进行反向传播，这与正向传播有类似的风格。
176 00:19:58,704 --> 00:20:03,028 说话人 SPEAKER_07：这就像是高中或者可能是大学一年级的微积分。
177 00:20:03,829 --> 00:20:09,576 说话人 SPEAKER_07：现在你可以并行计算出每个权重应该改变的方向。
178 00:20:10,317 --> 00:20:13,240 说话人 SPEAKER_07：然后非常令人惊讶的是，你不需要对整个训练集都这样做。
179 00:20:13,259 --> 00:20:15,422 说话人 SPEAKER_07：你只需要取一小批示例。
180 00:20:15,924 --> 00:20:19,249 说话人 SPEAKER_07：然后在这个示例批次中，你计算如何改变连接强度。
181 00:20:19,970 --> 00:20:22,772 说话人 SPEAKER_07：你可能会因为那个示例批次的问题而出错。
182 00:20:23,173 --> 00:20:24,173 说话人 SPEAKER_07：但你还是改变了它们。
183 00:20:24,193 --> 00:20:25,635 说话人 SPEAKER_07：然后你取另一批例子。
184 00:20:26,115 --> 00:20:28,818 说话人 SPEAKER_07：这被称为随机梯度下降。
185 00:20:28,838 --> 00:20:39,211 说话人 SPEAKER_07：我想神经网路社区的最重要的发现之一就是随机梯度下降，尽管它实际上没有工作的权利，但实际上工作得非常好。
186 00:20:40,913 --> 00:20:42,654 说话人 SPEAKER_07：但在规模上它确实工作得很好。
187 00:20:42,694 --> 00:20:45,357 说话人 SPEAKER_07：如果你给它大量的数据和大的网络，
188 00:20:46,012 --> 00:20:46,854 说话人 SPEAKER_07：它就显示出颜色了。
189 00:20:50,140 --> 00:20:57,571 说话人 SPEAKER_07：然而，在 20 世纪 80 年代，我们对反向传播非常、非常满意。
190 00:20:57,612 --> 00:21:01,939 说话人 SPEAKER_07：它似乎解决了问题，我们相信它将解决一切。
191 00:21:03,020 --> 00:21:10,031 说话人 SPEAKER_07：实际上它在语音识别和一些物体识别方面做得相当不错，但基本上是个失望。
192 00:21:10,092 --> 00:21:11,835 说话人 SPEAKER_07：它的工作效果远没有我们想象的那么好。
193 00:21:12,727 --> 00:21:14,229 说话人 SPEAKER_07：真正的问题在于为什么。
194 00:21:14,368 --> 00:21:19,215 说话人 SPEAKER_07：当时，人们都有各种分析为什么它不起作用，其中大部分都是错误的。
195 00:21:20,057 --> 00:21:21,880 说话人 SPEAKER_07：他们说，它陷入了局部最优。
196 00:21:22,319 --> 00:21:23,662 说话人 SPEAKER_07：我们现在知道那不是问题。
197 00:21:26,806 --> 00:21:37,401 说话人 SPEAKER_07：当其他学习算法在修改后的数据集上比反向传播表现更好时，机器学习社区的大多数人接受了这样的观点，
198 00:21:37,869 --> 00:21:46,046 说话人 SPEAKER_07：你们这些人在尝试的事情是从随机权重中学习这些深层多层网络，仅使用随机梯度下降。
199 00:21:46,487 --> 00:21:47,449 说话人 SPEAKER_07：这太疯狂了。
200 00:21:48,250 --> 00:21:49,553 说话人 SPEAKER_07：这永远不会成功。
201 00:21:49,593 --> 00:21:51,016 说话人 SPEAKER_07：你要求得太多了。
202 00:21:52,439 --> 00:21:56,547 说话者 SPEAKER_07：除非你投入大量手工设计，否则根本无法让这样的系统工作。
203 00:21:57,628 --> 00:21:59,692 说话者 SPEAKER_07：你以某种方式融入了一些先验知识。
204 00:22:00,432 --> 00:22:08,285 说话者 SPEAKER_07：例如，语言学家们被灌输了一种观念，认为许多语言是与生俱来的，没有先验知识你是不可能学会语言的。
205 00:22:08,305 --> 00:22:13,773 说话者 SPEAKER_07：事实上，他们有数学定理证明，没有先验知识你是不可能学会语言的。
206 00:22:14,836 --> 00:22:18,863 说话人 SPEAKER_07：我对这个的回答是警惕带着定理的数学家。
207 00:22:23,820 --> 00:22:26,526 说话人 SPEAKER_07：所以我只想给你一些非常愚蠢的理论。
208 00:22:26,786 --> 00:22:28,709 说话人 SPEAKER_07：我是蒙提·派森的粉丝。
209 00:22:28,789 --> 00:22:30,172 说话人 SPEAKER_07：所以这里有几个非常愚蠢的理论。
210 00:22:31,654 --> 00:22:33,917 说话人 SPEAKER_07：大陆曾经是相连的，然后逐渐分离。
211 00:22:34,479 --> 00:22:37,505 说话人 SPEAKER_07：你可以想象地质学家当时认为这个理论多么荒谬。
212 00:22:38,926 --> 00:22:43,134 说话人 SPEAKER_07：从随机权重和没有先验知识开始的巨大神经网络可以学会进行机器翻译。
213 00:22:43,836 --> 00:22:46,420 说话人 SPEAKER_07：这个理论在许多人看来非常荒谬。
214 00:22:47,075 --> 00:22:53,641 说话人 SPEAKER_07：再补充一点，如果你使用一种天然疗法并且不断稀释它，你稀释得越多，它就越有效。
215 00:22:55,442 --> 00:22:56,984 说话人 SPEAKER_07：有些人也这么认为。
216 00:23:02,230 --> 00:23:06,574 说话人 SPEAKER_07：所以上面的引言实际上是从大陆漂移文献中摘录的。
217 00:23:07,775 --> 00:23:14,000 说话人 SPEAKER_07：魏格纳在 1912 年提出了这个观点，尽管他实际上有很好的论据，但还是被嘲笑了一顿。
218 00:23:14,761 --> 00:23:16,103 说话人 SPEAKER_07：他没有一个好的机制。
219 00:23:16,640 --> 00:23:22,346 说话人 SPEAKER_07：地质界说，你知道，我们必须把这些东西从教科书中和杂志中排除出去。
220 00:23:22,405 --> 00:23:23,567 说话人 SPEAKER_07：这只会让人困惑。
221 00:23:25,308 --> 00:23:28,613 说话人 SPEAKER_07：我们在第二次神经网络冬天有过这样的小经验。
222 00:23:30,775 --> 00:23:36,480 讲者 SPEAKER_07：所以 NIPS，在所有会议中，拒绝了我的论文。
223 00:23:38,723 --> 00:23:46,291 讲者 SPEAKER_07：那些事情你不会忘记。
224 00:23:46,828 --> 00:23:58,528 讲者 SPEAKER_07：像许多其他失望的作者一样，我和程序委员会的一个朋友谈了谈，我的朋友在程序委员会告诉我，你看，他们不能接受这篇论文，因为他们已经有了两篇关于深度学习的论文，他们必须决定接受哪一篇。
225 00:23:59,148 --> 00:24:04,718 讲者 SPEAKER_07：他们实际上已经接受了另一篇，所以他们不可能在同一个会议上接受两篇关于同一主题的论文。
226 00:24:06,480 --> 00:24:09,546 说话人 SPEAKER_07：我建议你现在去 NIPS 看看...
227 00:24:11,365 --> 00:24:15,270 说话人 SPEAKER_07：Yoshua Bengio 大约在 2009 年向 ICML 提交了一篇论文。
228 00:24:15,290 --> 00:24:17,394 说话人 SPEAKER_07：我不确定具体年份，但应该是在那个时候。
229 00:24:18,076 --> 00:24:25,106 说话人 SPEAKER_07：其中一位审稿人说神经网络论文在机器学习会议上没有位置。
230 00:24:25,126 --> 00:24:26,469 说话人 SPEAKER_07：所以我建议你去参加 ICML。
231 00:24:28,553 --> 00:24:31,837 说话人 SPEAKER_07：CVPR，这是领先的计算机视觉会议，
232 00:24:31,935 --> 00:24:34,119 说话人 SPEAKER_07：我认为这是最令人震惊的。
233 00:24:34,401 --> 00:24:40,993 说话人 SPEAKER_07：Jan 和他的同事提交了一篇关于语义分割的论文，击败了现有水平。
234 00:24:41,694 --> 00:24:44,721 说话人 SPEAKER_07：它打败了主流计算机视觉人员能做到的。
235 00:24:46,042 --> 00:24:46,865 说话人 SPEAKER_07：它被拒绝了。
236 00:24:47,385 --> 00:24:54,720 说话人 SPEAKER_07：其中一位审稿人说，这篇论文对我们了解计算机视觉毫无帮助，因为一切都是通过学习得到的。
237 00:24:55,932 --> 00:25:05,584 说话人 SPEAKER_07：所以观众，就像当时的计算机视觉领域一样，陷入了这样的思维定式：做计算机视觉的方式是思考视觉任务的性质。
238 00:25:06,464 --> 00:25:08,428 说话人 SPEAKER_07：你最好写下一些方程式。
239 00:25:09,008 --> 00:25:12,192 说话人 SPEAKER_07：你思考如何进行所需的视觉计算。
240 00:25:12,752 --> 00:25:15,195 说话人 SPEAKER_07：然后你得到它的实现，然后看看它是否有效。
241 00:25:17,338 --> 00:25:23,846 说话人 SPEAKER_07：认为你什么都要学习这种想法已经超出了值得考虑的范围。
242 00:25:24,755 --> 00:25:30,602 讲者 SPEAKER_07：评论家基本上没有抓住要点，要点是所有东西都是通过学习得到的。
243 00:25:31,782 --> 00:25:35,428 讲者 SPEAKER_07：他完全没能看到这一点如何彻底改变了计算机视觉。
244 00:25:35,448 --> 00:25:40,032 讲者 SPEAKER_07：现在，我不应该太严厉地批评他们，因为稍后他们表现得非常合理。
245 00:25:40,053 --> 00:25:41,755 讲者 SPEAKER_07：有了更多证据，他们突然转变了立场。
2005年至2009年之间，研究人员，其中一些在加拿大，我们授予杨荣誉加拿大人称号，因为他来自法国。
247 00:25:55,753 --> 00:26:01,520 演讲者 SPEAKER_07：使反向传播在前馈网络中工作得更好，取得了多项技术进步。
他们涉及使用无监督预训练来初始化权重，在你开启反向传播之前，比如随机丢弃单元以使整个系统更加鲁棒，以及引入了易于训练的 ReLU 单元。
249 00：26：19,260 --> 00：26：22,003 演讲者 SPEAKER_07：对我们来说，这些进步的细节就是我们的生计。
250 00:26:22,064 --> 00:26:23,585 说话人 SPEAKER_07：我们对此非常感兴趣。
251 00:26:23,945 --> 00:26:30,451 说话人 SPEAKER_07：但主要信息是，随着一些技术进步，反向传播工作得非常出色。
252 00:26:30,833 --> 00:26:36,057 说话人 SPEAKER_07：主要原因是因为我们现在拥有大量的标签数据和强大的计算能力。
253 00:26:37,380 --> 00:26:39,141 说话人 SPEAKER_07：不便的计算能力几乎没什么用。
254 00:26:41,063 --> 00:26:46,669 说话人 SPEAKER_07：但是像 GPU 这样的东西，还有最近出现的 TPU，可以让您进行大量的计算
255 00:26:47,392 --> 00:26:49,173 说话人 SPEAKER_07：并且它们带来了巨大的变化。
256 00:26:49,193 --> 00:26:53,597 说话人 SPEAKER_07：所以，我认为决定性因素是计算能力的提升。
257 00:26:54,278 --> 00:27:09,212 说话人 SPEAKER_07：因此，我认为深度学习的大部分功劳应该归功于收集大型数据库的人，比如李飞飞，以及让计算机运行更快的人，比如大卫·帕特森等人，还有很多人。
258 00:27:11,776 --> 00:27:15,019 说话人 SPEAKER_07：在我看来，杀手级应用出现在 2009 年。
259 00:27:15,403 --> 00:27:28,208 说话人 SPEAKER_07：在我实验室里我们获得了一大批 GPU，两名研究生让它们学习进行声学建模。
260 00:27:28,568 --> 00:27:38,086 说话人 SPEAKER_07：声学建模意味着你拿一个像频谱图这样的东西，并试图确定频谱图的中间帧是哪个音素的哪一部分，说话人试图表达。
261 00:27:38,911 --> 00:27:46,140 说话人 SPEAKER_07：在这个我们使用的小型数据库中，相对较小，有 183 个标签，表示可能是哪个音素的哪一部分。
262 00:27:47,221 --> 00:27:51,987 说话人 SPEAKER_07：因此，你使用具有 2000 个隐藏单元的多层网络进行预训练。
263 00:27:53,468 --> 00:27:55,711 说话人 SPEAKER_07：你不能预训练最后一层，因为你还没有知道标签。
264 00:27:56,332 --> 00:27:59,255 说话人 SPEAKER_07：你只是训练它以能够复制下一层的输出。
265 00:27:59,295 --> 00:28:03,299 说话人 SPEAKER_07：然后你打开所有层的训练学习。
266 00:28:03,840 --> 00:28:07,585 说话人 SPEAKER_07：它略好于目前的技术水平，而目前的技术水平已经发展了 30 年。
267 00:28:09,369 --> 00:28:14,435 说话人 SPEAKER_07：当语音领域的人们看到这一点时，聪明人意识到，随着更多的发展，这些技术将会非常出色。
268 00:28:16,738 --> 00:28:22,525 说话人 SPEAKER_07：我的研究生们去了像 MSR、IBM 和 Google 这样的各种小组。
269 00:28:23,085 --> 00:28:38,162 说话人 SPEAKER_07：特别是 Navdeep Jaitley 去了 Google，并将多伦多开发的声学建模系统直接移植过来。
270 00:28:38,512 --> 00:28:39,875 说话人 SPEAKER_07：它在 2012 年出现在 Android 上。
271 00:28:39,894 --> 00:28:44,281 说话人 SPEAKER_07：为了使其实时运行，进行了大量的优秀工程。
272 00:28:45,222 --> 00:28:47,086 说话人 SPEAKER_07：并且大大降低了错误率。
273 00:28:47,646 --> 00:28:51,531 说话人 SPEAKER_07：在大约同一时间，其他所有团队开始改变他们进行语音识别的方式。
274 00:28:52,133 --> 00:28:55,577 说话人 SPEAKER_07：现在所有好的语音识别器都使用神经网络。
275 00:28:55,999 --> 00:28:58,583 说话人 SPEAKER_07：它们和我们最初引入的神经网络不一样。
276 00:28:58,863 --> 00:29:02,648 说话人 SPEAKER_07：神经网络逐渐侵蚀了系统越来越多的部分。
277 00:29:03,210 --> 00:29:06,433 说话人 SPEAKER_07：所以把神经网络放入你的系统中有点像感染了坏疽。
278 00:29:06,694 --> 00:29:08,217 说话人 SPEAKER_07：它将逐渐吞噬整个系统。
279 00:29:11,790 --> 00:29:27,451 说话人 SPEAKER_07：然后在 2012 年，我的另外两名研究生将 Yann LeCun 多年来开发的神经网络应用于 Fei-Fei Liu 整理的包含 1,000 个不同类别对象的数据库中的物体识别。
280 00:29:27,971 --> 00:29:33,739 说话人 SPEAKER_07：最终，这是一个足够大的真实图像数据库，可以展示神经网络的能力，它们能做很多事情。
281 00:29:34,740 --> 00:29:40,346 说话人 SPEAKER_07：所以如果你看结果，所有的计算机视觉系统，标准的那些，
282 00:29:41,035 --> 00:29:42,778 说话人 SPEAKER_07：错误率约为 25%达到极限。
283 00:29:44,141 --> 00:29:49,130 说话人 SPEAKER_07：我们两个研究生开发的系统错误率为 16%。
284 00:29:49,891 --> 00:29:54,700 说话人 SPEAKER_07：然后对类似神经网络进一步的研究，到 2015 年，错误率已经下降到 5%。
285 00:29:54,759 --> 00:29:56,643 说话人 SPEAKER_07：现在错误率已经大大低于这个水平。
286 00:29:58,286 --> 00:30:03,194 说话人 SPEAKER_07：然后发生的事情正是科学应该发生的事情。
287 00:30:03,444 --> 00:30:09,070 说话人 SPEAKER_07：计算机视觉社区的领导者看到这个结果后说，哦，它们确实有效。
288 00:30:09,111 --> 00:30:09,632 说话人 SPEAKER_07：我们错了。
289 00:30:09,912 --> 00:30:10,772 说话人 SPEAKER_07：好的，我们要改变方向了。
290 00:30:11,292 --> 00:30:12,474 说话人 SPEAKER_07：一年之内，他们都转换了。
291 00:30:13,435 --> 00:30:15,117 说话人 SPEAKER_07：所以科学最终像它应该的那样起作用了。
292 00:30:18,401 --> 00:30:28,592 说话人 SPEAKER_07：我想最后谈谈一种全新的机器翻译方法，这种方法于 2014 年由谷歌的人提出，在蒙特利尔由 Yoshua Bengio 实验室的人提出。
293 00:30:30,242 --> 00:30:42,836 说话人 SPEAKER_07：2014 年的想法是，对于每种语言，我们将有一个神经网络，它将是一个循环神经网络，它将把接收到的该语言的单词串编码成一个大的向量。
294 00:30:43,698 --> 00:30:45,420 说话人 SPEAKER_07：我把那个大向量称为思维向量。
295 00:30:45,721 --> 00:30:49,704 说话人 SPEAKER_07：这个大向量是用来捕捉那串词语的意义的。
296 00:30:50,566 --> 00:30:57,733 说话人 SPEAKER_07：然后你将那个大向量输入到一个解码网络中，解码网络将大向量转换成另一种语言的词语串。
297 00:30:58,836 --> 00:30:59,997 说话人 SPEAKER_07：它似乎有点效果。
298 00:31:00,532 --> 00:31:02,295 说话人 SPEAKER_07：经过一点开发，效果非常好。
299 00:31:06,480 --> 00:31:18,654 说话人 SPEAKER_07：自 2014 年以来，其中一个主要的发展点是，当你解码句子的含义时，你会回顾你编码的句子，这被称为软注意力。
300 00:31:18,755 --> 00:31:24,722 说话人 SPEAKER_07：所以每次你产生一个新词时，你都在决定在翻译的句子中看向哪里。
301 00:31:25,663 --> 00:31:26,625 说话人 SPEAKER_07：这非常有帮助。
302 00:31:27,854 --> 00:31:31,499 说话人 SPEAKER_07：你现在也预先训练词嵌入，这非常有帮助。
303 00:31:32,400 --> 00:31:43,295 说话人 SPEAKER_07：预训练的方式是，你取一堆词，然后在深度网络中尝试重现这些词，但你已经省略了一些词。
304 00:31:43,615 --> 00:31:48,021 说话人 SPEAKER_07：所以从这些词中，你必须重现相同的词，但本质上是要填补空白。
305 00:31:49,864 --> 00:31:52,748 说话人 SPEAKER_07：他们使用一种叫做“变压器”的东西。
306 00:31:52,980 --> 00:32:01,753 说话人 SPEAKER_07：在这个深度网络中，每个词通过网络时，都会观察附近的词来消除歧义，确定其可能的意义。
307 00:32:02,414 --> 00:32:09,005 说话人 SPEAKER_07：所以如果你有一个像“可能”这样的词，当它进入时，你会得到一个初始向量，它在情态动词和月份之间有些模糊。
308 00:32:09,926 --> 00:32:14,753 说话人 SPEAKER_07：但如果它看到旁边的“13 号”，它就能很确定地知道它是月份。
309 00:32:15,375 --> 00:32:20,742 说话人 SPEAKER_07：所以在下一个区域，它可以消除歧义，那个意思可能是月份。
310 00:32:20,992 --> 00:32:24,415 说话人 SPEAKER_07：现在这些 Transformer 网络在获取词嵌入方面表现得非常好。
311 00:32:25,537 --> 00:32:27,880 说话人 SPEAKER_07：出乎意料的是，它们还学习到了大量的语法。
312 00:32:28,380 --> 00:32:33,365 说话人 SPEAKER_07：所以那些语言学家认为必须天生放入的东西，现在神经网络也在其中了。
313 00:32:33,384 --> 00:32:35,186 说话人 SPEAKER_07：他们获得了大量的句法理解。
314 00:32:35,887 --> 00:32:38,089 说话人 SPEAKER_07：但这都是通过数据学习的。
315 00:32:38,109 --> 00:32:42,173 说话人 SPEAKER_07：如果你查看变压器网络的早期层，它们知道词性是什么。
316 00:32:43,174 --> 00:32:47,659 说话人 SPEAKER_07：如果你查看网络的后期部分，它们知道如何消除代词指代的不确定性。
317 00:32:47,909 --> 00:32:55,859 说话人 SPEAKER_07：基本上，它们学习语法的方式就像小孩子通过观察句子来学习语法一样。
318 00:32:58,844 --> 00:33:04,531 说话人 SPEAKER_07：所以我认为机器翻译是符号 AI 的最后一根钉子，钉在了棺材上。
319 00:33:06,414 --> 00:33:09,578 说话人 SPEAKER_07：因为机器翻译是符号 AI 的理想任务。
320 00:33:10,180 --> 00:33:12,583 说话人 SPEAKER_07：它符号输入，也符号输出。
321 00:33:13,508 --> 00:33:17,855 说话人 SPEAKER_07：但如果你想要做得好，里面你需要的是大向量。
322 00:33:22,803 --> 00:33:23,123 说话人 SPEAKER_07：好的。
323 00:33:23,523 --> 00:33:32,196 说话人 SPEAKER_07：我已经说完了我想说的关于神经网络直到 2014 年左右的历史。
324 00:33:33,199 --> 00:33:40,410 说话人 SPEAKER_07：我强调了这样的观点，即存在两个阵营，而好人取得了胜利。
325 00:33:42,719 --> 00:33:48,138 说话人 SPEAKER_07：但这还没有结束，因为当然，我们现在需要的神经网络
326 00:33:48,237 --> 00:33:51,040 说话人 SPEAKER_07：开始解释推理。
327 00:33:51,681 --> 00:33:52,582 说话人 SPEAKER_07：我们目前还做不到。
328 00:33:52,843 --> 00:33:53,483 说话人 SPEAKER_07：我们正在努力。
329 00:33:54,084 --> 00:33:57,028 说话人 SPEAKER_07：推理是人们最后做的事情，而不是第一件事。
330 00:33:57,989 --> 00:34:00,593 说话人 SPEAKER_07：而推理是建立在所有这些其他东西之上的。
331 00:34:00,673 --> 00:34:05,097 说话人 SPEAKER_07：我的观点一直是，除非你理解所有这些其他东西，否则你永远不会理解推理。
332 00:34:05,398 --> 00:34:10,065 说话人 SPEAKER_07：现在我们开始理解所有这些其他东西了，我们差不多准备好开始理解推理了。
333 00:34:10,846 --> 00:34:15,931 说话者 SPEAKER_07：仅仅用一些裸符号进行推理，通过使用表达这些其他符号的规则，
334 00:34:16,402 --> 00:34:18,385 说话者 SPEAKER_07：在我看来这是毫无希望的。
335 00:34:18,545 --> 00:34:19,688 说话者 SPEAKER_07：你丢失了所有内容。
336 00:34:20,110 --> 00:34:21,050 说话者 SPEAKER_07：那里没有意义。
337 00:34:23,577 --> 00:34:24,958 说话人 SPEAKER_07: 好吧。
338 00:34:24,978 --> 00:34:27,445 说话人 SPEAKER_07: 我想稍微谈谈计算机视觉的未来。
339 00:34:28,547 --> 00:34:30,831 说话人 SPEAKER_07: 所以，卷积神经网络非常有效。
340 00:34:31,672 --> 00:34:34,579 说话人 SPEAKER_07: 卷积神经网络所做的是，它们将
341 00:34:34,762 --> 00:34:39,206 讲者 SPEAKER_07：如果一个特征在一个地方有用，那么它也会在另一个地方有用。
342 00:34:40,007 --> 00:34:44,992 讲者 SPEAKER_07：这使我们能够从不同位置结合证据来学习共享特征检测器。
343 00:34:46,273 --> 00:34:49,817 讲者 SPEAKER_07：也就是说，学习复制的特征检测器，它们在这些地方都是相同的。
344 00:34:50,878 --> 00:34:51,838 讲者 SPEAKER_07：这是一个巨大的胜利。
345 00:34:52,259 --> 00:34:53,559 说话人 SPEAKER_07：这使得数据效率更高。
346 00:34:54,201 --> 00:34:56,222 说话人 SPEAKER_07：这些是杨在 20 世纪 90 年代实现的东西。
347 00:34:56,463 --> 00:35:02,389 说话人 SPEAKER_07：它们是 20 世纪 90 年代为数不多的真正有效的东西之一，现在效果更好。
348 00:35:03,753 --> 00:35:05,655 说话人 SPEAKER_07：但我认为它们并不是人们处理视觉的方式。
349 00:35:06,356 --> 00:35:11,083 说话人 SPEAKER_07：我的意思是，我认为其中有一个方面，那就是复制的装置，这在大脑中是显然成立的。
350 00:35:13,525 --> 00:35:15,547 说话人 SPEAKER_07：但他们并不像我们一样识别物体。
351 00:35:17,391 --> 00:35:19,532 说话人 SPEAKER_07：这导致了对抗性示例。
352 00:35:19,554 --> 00:35:22,637 说话人 SPEAKER_07：所以如果给你一个大型数据库，卷积神经网络会做得很好。
353 00:35:22,677 --> 00:35:23,759 说话人 SPEAKER_07：它可能比人做得更好。
354 00:35:24,340 --> 00:35:27,003 说话人 SPEAKER_07：但它并不像人一样识别事物。
355 00:35:27,643 --> 00:35:33,050 说话人 SPEAKER_07：因此我可以改变一些东西，这会导致卷积神经网络改变主意。
356 00:35:33,503 --> 00:35:35,565 说话人 SPEAKER_07：而人甚至看不到我所做的改变。
357 00:35:36,646 --> 00:35:38,791 说话人 SPEAKER_07：他们使用的是纹理和颜色。
358 00:35:39,431 --> 00:35:44,177 说话人 SPEAKER_07：他们并没有使用物体与其部分之间的几何关系。
359 00:35:45,679 --> 00:35:56,936 说话人 SPEAKER_07：我坚信，人们识别物体主要依靠纹理和颜色，但他们非常清楚物体与其部分之间的几何关系。
360 00:35:57,737 --> 00:36:00,961 说话人 SPEAKER_07：这种几何关系完全独立于视角。
361 00:36:03,034 --> 00:36:07,501 说话人 SPEAKER_07：这给了你一个非常稳健的东西，你应该能够用更少的数据进行训练。
362 00:36:08,643 --> 00:36:18,717 说话人 SPEAKER_07：实际上，我忍不住想做一个小小的演示来让你相信，当你理解物体时，不仅仅是在做科学家的时候你会使用坐标系。
363 00:36:19,298 --> 00:36:25,327 说话人 SPEAKER_07：甚至在你天真地思考物体时，你也会对它们施加坐标系。
364 00:36:25,949 --> 00:36:27,371 说话人 SPEAKER_07：所以我要做一个小小的演示。
365 00:36:29,253 --> 00:36:31,978 说话人 SPEAKER_07：你必须参加这个演示，否则就没有乐趣了。
366 00:36:33,240 --> 00:36:37,324 说话人 SPEAKER_07：好的，所以我想让你想象坐在你面前的桌面上，有一个立方体。
367 00:36:37,786 --> 00:36:39,708 说话人 SPEAKER_07：所以这是顶部，这是底部，这是立方体。
368 00:36:40,289 --> 00:36:42,570 说话人 SPEAKER_07：它是一个像这样的线框立方体，好吗？
369 00:36:42,590 --> 00:36:43,592 说话人 SPEAKER_07：黑色电线。
370 00:36:45,114 --> 00:36:53,583 说话人 SPEAKER_07：至于这个立方体，从你的角度看，这里有前面、底部、右手角，还有顶部、后面、左手角。
371 00:36:54,483 --> 00:36:54,804 说话人 SPEAKER_07：好的。
372 00:36:55,726 --> 00:37:00,530 说话人 SPEAKER_07：接下来我要旋转这个立方体，使得顶部、后面、左手角
373 00:37:00,780 --> 00:37:04,083 说话人 SPEAKER_07：垂直于前下右上角。
374 00:37:04,103 --> 00:37:04,684 说话人 SPEAKER_07：所以我们在这里。
375 00:37:05,405 --> 00:37:12,911 说话人 SPEAKER_07：现在我想让你把指尖放在空中，可能是你的左指尖，放在立方体的顶点上，好吗？
376 00:37:13,672 --> 00:37:15,795 说话人 SPEAKER_07：现在，没有人这么做。
377 00:37:15,855 --> 00:37:16,135 说话人 SPEAKER_07: 来吧。
378 00:37:17,396 --> 00:37:23,922 说话人 SPEAKER_07: 现在，用你的另一根指尖，我想要你指向立方体的其他角，那些没有放在桌子上的角。
379 00:37:23,963 --> 00:37:26,005 说话人 SPEAKER_07: 所以有一个在桌子上，一个垂直地在这里。
380 00:37:26,666 --> 00:37:27,706 说话人 SPEAKER_07: 其他角在哪里？
381 00:37:28,726 --> 00:37:29,347 说话人 SPEAKER_07：你必须这么做。
382 00:37:29,367 --> 00:37:30,349 说话人 SPEAKER_07：你必须指出它们。
383 00:37:32,050 --> 00:37:32,431 说话人 SPEAKER_07：好吗？
384 00:37:32,871 --> 00:37:41,144 说话人 SPEAKER_07：现在，我看不见你在做什么，但我知道你们中的很多人会指出另外四个角，因为我以前做过这个。
385 00:37:42,206 --> 00:37:46,213 说话人 SPEAKER_07：现在我想让你想象一个正常方向的立方体，问它有多少个角？
386 00:37:48,557 --> 00:37:48,858 说话人 SPEAKER_07：好吗？
387 00:37:49,159 --> 00:37:50,501 说话人 SPEAKER_07：它有八个角，对吧？
388 00:37:50,561 --> 00:37:51,802 说话人 SPEAKER_07：所以这里有六个这样的东西。
389 00:37:52,423 --> 00:37:54,887 说话人 SPEAKER_07：大多数人会说，这里，这里，这里，还有这里。
390 00:37:54,947 --> 00:37:56,050 说话人 SPEAKER_07：问题是什么？
391 00:37:56,704 --> 00:37:58,065 说话人 SPEAKER_07：问题是那不是一个立方体。
392 00:37:58,746 --> 00:38:06,255 说话人 SPEAKER_07：你所做的是保留了立方体所具有的四面旋转对称性，并指出了一个完全不同的形状。
393 00:38:06,994 --> 00:38:12,681 说话人 SPEAKER_07：这是一个完全不同的形状，它具有与立方体相同数量的面，就像立方体有角一样，以及与立方体有面一样多的角。
394 00:38:12,960 --> 00:38:21,429 说话者 SPEAKER_07：如果你用角代替面，那么它就是立方体的宝石，因为你非常喜欢对称性，以至于你愿意真正地扭曲事物以保持对称性。
395 00:38:22,286 --> 00:38:31,219 说话者 SPEAKER_07：实际上，一个立方体有三个边向下延伸，有三个边向上延伸，我的六个指尖就是角的位置，明白吗？
396 00:38:31,239 --> 00:38:35,186 说话者 SPEAKER_07：人们看不到这一点，除非他们是晶体学家或者非常聪明。
397 00:38:37,429 --> 00:38:44,179 说话者 SPEAKER_07：所以，这个演示的主要目的是通过这个旋转，我迫使你们使用一个轴来观察立方体。
398 00:38:44,619 --> 00:38:51,989 说话者 SPEAKER_07：定义立方体方向的轴线并不是你通常用于立方体的坐标系轴线之一。
399 00:38:52,476 --> 00:38:57,942 说话者 SPEAKER_07：通过迫使你使用一个不熟悉的坐标系，我破坏了你关于立方体各部分位置的所有知识。
400 00:38:59,003 --> 00:39:01,284 说话者 SPEAKER_07：你理解事物是相对于坐标系而言的。
401 00:39:02,206 --> 00:39:07,030 说话者 SPEAKER_07：如果让我让你施加一个不同的坐标系，那么对你来说，它就是一个不同的对象。
402 00:39:07,831 --> 00:39:09,413 说话人 SPEAKER_07：现在，卷积网络做不到这一点。
403 00:39:10,614 --> 00:39:15,798 说话人 SPEAKER_07：正因为它们做不到这一点，我认为它们并不是人们感知形状的方式。
404 00:39:16,760 --> 00:39:20,643 说话人 SPEAKER_07：我们最近通过一些方法使神经网络做到了这一点
405 00:39:21,028 --> 00:39:31,663 说话人 SPEAKER_07：进行了自监督训练，那里有一个存档引用，如果你够快的话可以获取，或者我稍后会发推文关于它。
406 00:39:35,827 --> 00:39:41,257 说话人 SPEAKER_07：我想说的最后一件事不是关于形状识别，而是关于神经网络的未来。
407 00:39:41,878 --> 00:39:48,969 说话人 SPEAKER_07：在过去 50 年里，我们做了一件非常有趣且非常不符合生物特性的事情，那就是我们只使用了两个时间尺度。
408 00:39:49,670 --> 00:39:52,454 说话人 SPEAKER_07：也就是说，你有神经活动，它们变化很快。
409 00:39:53,416 --> 00:39:55,239 说话人 SPEAKER_07：而你又有权重，它们变化很慢。
410 00:39:55,920 --> 00:39:56,422 说话人 SPEAKER_07：就这样了。
411 00:39:57,623 --> 00:40:01,971 说话人 SPEAKER_07：但我们知道在生物学中，突触会在各种时间尺度上发生变化。
412 00:40:02,996 --> 00:40:06,882 说话人 SPEAKER_07：问题是，如果你现在引入更多的时间尺度会发生什么？
413 00:40:08,103 --> 00:40:26,827 说话人 SPEAKER_07：特别是，我们再引入一个时间尺度，假设除了这些权重缓慢变化之外——这就是长期学习中所发生的情况——权重还有一个可以更快变化并且衰减得很快的额外成分。
414 00:40:28,090 --> 00:40:33,677 说话者 SPEAKER_07：那么，如果你问，你记得一分钟前我把手指放在这个角这里吗？
415 00:40:34,699 --> 00:40:40,666 说话者 SPEAKER_07：这是在许多处于活跃状态的神经元中吗，这样你才能记住？
416 00:40:40,967 --> 00:40:41,847 说话者 SPEAKER_07：这似乎不太可能。
417 00:40:41,887 --> 00:40:51,940 说话者 SPEAKER_07：更可能的是，你对这个的记忆是在神经网络权重的快速修改中，这允许你快速重建，并且会随时间衰减。
418 00:40:53,202 --> 00:40:56,746 说话人 SPEAKER_07：所以你的记忆在权重中，是一种短期记忆。
419 00:40:56,996 --> 00:41:00,181 说话人 SPEAKER_07：一旦你这样做，就会发生各种好事。
420 00:41:01,202 --> 00:41:10,592 说话人 SPEAKER_07：你可以利用这一点来获得更好的优化方法，也可以用它来做可能与推理相关的事情。
421 00:41:11,153 --> 00:41:16,099 说话人 SPEAKER_07：你可以用它来允许神经网络进行真正的递归，不是非常深，但确实是递归。
422 00:41:16,119 --> 00:41:20,844 说话人 SPEAKER_07：我所说的真正递归是指，当你进行递归调用时，
423 00:41:21,871 --> 00:41:32,706 说话人 SPEAKER_07：就像句子中的关系从句一样，神经网络可以使用与处理整个句子相同的所有神经元和相同的权重来处理关系从句。
424 00:41:33,547 --> 00:41:40,056 说话人 SPEAKER_07：当然，为了做到这一点，它必须以某种方式记住在决定处理关系从句时发生了什么。
425 00:41:40,135 --> 00:41:41,398 说话人 SPEAKER_07：它必须将这一点存储在某个地方。
426 00:41:42,222 --> 00:41:43,663 说话人 SPEAKER_07：我觉得它不会存储在其他神经元中。
427 00:41:43,682 --> 00:41:46,925 说话人 SPEAKER_07：我认为它是通过改变突触强度来临时存储的。
428 00:41:47,405 --> 00:41:53,672 说话人 SPEAKER_07：当它处理完相对从句后，它会将其打包起来，基本上是问自己，我在开始这个处理之前在做什么？
429 00:41:54,492 --> 00:41:58,635 说话人 SPEAKER_07：它可以从这个相关记忆中的快速权重中获取信息。
430 00:41:59,677 --> 00:42:06,422 说话人 SPEAKER_07：我想以此结束，因为我在 1973 年给出的第一次演讲正是关于这个话题。
431 00:42:06,523 --> 00:42:11,266 说话人 SPEAKER_07：我有一个在拥有 64K 内存的计算机上运行的系统。
432 00:42:11,786 --> 00:42:17,733 说话人 SPEAKER_07：我还没有来得及发表它，但我觉得它又开始流行了，所以我猜想是这样。
433 00:42:17,753 --> 00:42:20,916 说话人 SPEAKER_07：这就是我的演讲结束了，我的时间也用完了。
434 00:42:32,530 --> 00:42:37,356 说话人 SPEAKER_07：现在我想介绍 Janneke，她不仅是一位同事，还是一位非常好的朋友。
435 00:42:46,938 --> 00:42:49,724 说话人 SPEAKER_01：好的，我将谈论续集。
436 00:42:51,342 --> 00:42:57,788 说话人 SPEAKER_01：但我也会先简要回顾一下历史，并介绍 Jeff 刚才提到的一些事情。
437 00:42:58,449 --> 00:43:01,711 说话人 SPEAKER_01：所以 Jeff 谈到了监督学习。
438 00:43:01,731 --> 00:43:05,396 说话人 SPEAKER_01: 如果你有大量数据，监督学习效果惊人。
439 00:43:06,356 --> 00:43:06,876 说话人 SPEAKER_01: 我们都知道这一点。
440 00:43:06,916 --> 00:43:08,719 说话人 SPEAKER_01: 因此我们可以进行语音识别。
441 00:43:08,739 --> 00:43:11,121 说话人 SPEAKER_01: 我们可以进行图像识别。
442 00:43:11,181 --> 00:43:12,842 说话人 SPEAKER_01：我们可以进行人脸识别。
443 00:43:12,922 --> 00:43:15,125 说话人 SPEAKER_01：我们可以为图像生成字幕。
444 00:43:15,164 --> 00:43:16,246 说话人 SPEAKER_01：我们可以进行翻译。
445 00:43:16,726 --> 00:43:17,788 说话人 SPEAKER_01：这效果非常好。
446 00:43:18,427 --> 00:43:29,663 说话人 SPEAKER_01：如果你给你的神经网络一个特定的结构，就像 Jeff 提到的，在 80 年代末 90 年代初，我们可以训练系统来识别手写文字。
447 00:43:29,702 --> 00:43:30,704 说话人 SPEAKER_01：这相当成功。
448 00:43:31,545 --> 00:43:38,715 说话人 SPEAKER_01：到 90 年代末，我在贝尔实验室建立的一个这样的系统可以阅读美国大约 10%到 20%的支票。
449 00:43:38,735 --> 00:43:41,920 说话人 SPEAKER_01：所以这是一个巨大的成功，甚至是一个商业上的成功。
450 00:43:41,900 --> 00:44:04,126 说话者 SPEAKER_01：但到那时，整个社区基本上已经放弃了神经网络，部分原因是缺乏它们可以工作的数据集，部分原因是当时你必须编写的软件类型相当复杂，这是一项巨大的投资，部分也是因为计算机不够快，无法用于各种其他应用。
451 00:44:04,106 --> 00:44:08,474 说话者 SPEAKER_01：但卷积神经网络确实受到了生物学的启发。
452 00:44:08,534 --> 00:44:18,614 说话者 SPEAKER_01：它们在生物学中并不是被复制的，但有很多来自生物学，来自视觉皮层的架构，以及你在研究信号处理时自然而然产生的想法。
453 00:44:18,653 --> 00:44:23,802 说话者 SPEAKER_01：过滤是一种很好的处理方式的想法。
454 00:44:23,782 --> 00:44:33,195 说话人 SPEAKER_01：信号，无论是音频信号还是图像信号，卷积是一种非常自然的滤波方法，而且你能在大脑中找到这一点并不令人惊讶。
455 00:44:34,097 --> 00:44:47,496 说话人 SPEAKER_01：当然，这些想法是由 Hubel 和 Wiesel 在 20 世纪 60 年代的经典神经科学工作中提出的，而且也被日本研究者 Fukushima 所采纳，他试图
456 00:44:47,476 --> 00:44:52,186 说话人 SPEAKER_01：如果你愿意，可以构建 Hubel 和 Wiesel 模型的计算机模型。
457 00:44:53,027 --> 00:44:59,760 说话人 SPEAKER_01：我觉得这很有启发性，并试图使用可以反向传播训练的神经网络来重现这一点。
458 00:44:59,800 --> 00:45:03,307 说话人 SPEAKER_01：这就是卷积神经网络的基本概念。
459 00:45:03,288 --> 00:45:20,992 所以卷积神经网络的想法是，世界，感知世界是组合性的，视觉世界中的物体是由部分组成的，部分是由模式组成的，而模式是由纹理或边缘的基本组合形成的，边缘是由像素排列组成的。
460 00:45:22,728 --> 00:45:30,340 因此，如果你有一个可以分层检测像素组合成边缘、边缘组成模式、模式组成物体部分的异常有用组合的系统，那么你将拥有一个识别系统。
461 00:45:30,400 --> 00:45:43,599 因此，如果你有一个可以分层检测像素组合成边缘、边缘组成模式、模式组成物体部分的异常有用组合的系统，那么你将拥有一个识别系统。
462 00:45:43,659 --> 00:45:45,882 说话人 SPEAKER_01：这种层次结构的思想实际上已经很久远了。
463 00:45:45,862 --> 00:45:49,909 说话人 SPEAKER_01：所以这实际上就是卷积神经网络的原则。
464 00:45:49,929 --> 00:46:02,813 说话人 SPEAKER_01：结果证明，层次化表示不仅对视觉有用，而且对语音、文本以及所有其他可理解的、因为它们是组合性的自然信号都很有用。
465 00:46:03,735 --> 00:46:09,947 说话人 SPEAKER_01：我认为有这样一个说法，据说是爱因斯坦说的，我认为最重要的是
466 00:46:11,581 --> 00:46:21,679 说话人 SPEAKER_01：对世界的神秘之处在于它是可理解的，这可能是由于自然信号的组合性质。
467 00:46:22,199 --> 00:46:27,510 说话人 SPEAKER_01：所以在 20 世纪 90 年代初，我们能够做到像这样的构建识别系统。
468 00:46:27,530 --> 00:46:29,353 说话人 SPEAKER_01：这是年轻时的我。
469 00:46:29,333 --> 00:46:30,755 说话人 SPEAKER_01：我在贝尔实验室。
470 00:46:30,795 --> 00:46:35,202 顺便说一下，这是我贝尔实验室在 Hondal 的电话号码，现在已经不再运营了。
471 00:46:35,804 --> 00:46:40,371 我在这里按了一个键，系统就用视频摄像头捕捉了一张图像。
472 00:46:40,391 --> 00:46:49,268 这是在装有特殊 DSP 卡的 PC 上运行的，当时可以以每秒几百个字符的速度运行那些传统网络，这非常令人惊讶。
473 00:46:49,307 --> 00:46:50,771 我们可以运行20兆浮点运算。
474 00:46:50,891 --> 00:46:52,233 说话人 SPEAKER_01：你知道，那真是太令人难以置信了。
475 00:46:52,454 --> 00:46:53,856 说话人 SPEAKER_01：所以这做得非常好。
476 00:46:55,050 --> 00:47:03,664 说话人 SPEAKER_01：不久之后，我们意识到我们也可以用它来处理自然图像，比如检测人脸，最终检测行人。
477 00:47:03,704 --> 00:47:05,266 说话人 SPEAKER_01：这花了几年时间。
478 00:47:06,349 --> 00:47:18,206 说话人 SPEAKER_01：正如 Jeff 提到的，从 90 年代中期到 2000 年代末，几乎没有人从事神经网络研究，只有我们这些疯狂的人还在做。
479 00:47:18,186 --> 00:47:43,923 说话人 SPEAKER_01：但这并没有阻止我们，所以我们一直在研究人脸检测、行人检测，甚至利用机器学习和卷积神经网络进行机器人研究，我们会用卷积神经网络来标记整个图像，使得图像中的每个像素都能被标记为机器人可通行或不可通行。
480 00:47:43,903 --> 00:47:57,365 说话人 SPEAKER_01：这个方法的好处是你可以自动收集数据，不需要手动标记，因为使用立体视觉，你可以通过 3D 重建来判断像素是否突出于地面。
481 00:47:57,867 --> 00:48:05,018 说话人 SPEAKER_01：但遗憾的是，这只能在短距离内工作，所以如果你想有一个能够规划长距离轨迹的系统，那么你可以训练一个卷积神经网络来
482 00：48：05,318 --> 00：48：11,047 演讲者 SPEAKER_01：使用这些标签预测可遍历性，然后让机器人自己开车。
所以它结合了使用卷积网提取的不同特征的这个特定机器人，以及一个快速立体视觉系统，这使得它能够避开诸如讨厌的研究生等障碍物。
484 00:48:32,706 --> 00:48:41,231 说话者 SPEAKER_01：顺便说一句，Pia Somania 和 Raya Hetzel 很确定机器人不会撞到他们，因为他们实际上编写了代码。
485 00:48:44,501 --> 00:48:49,967 说话者 SPEAKER_01：好的，然后几年后，我们使用了一个非常相似的系统来进行语义分割。
486 00:48:50,009 --> 00:48:55,235 说话人 SPEAKER_01：这实际上就是 Jeff 之前提到的那个被 2011 年 CVPR 会议拒稿的工作。
487 00:48:56,036 --> 00:49:09,851 说话人 SPEAKER_01：这是一个系统，它可以使用 FPGA 实现实时处理，基本上每秒 30 帧的速度对图像中的每个像素进行分割，分辨率相当不错。
488 00:49:09,831 --> 00:49:17,945 说话人 SPEAKER_01：它远非完美，但可以以相当合理的准确性进行标记，检测行人、道路和树木等。
489 00:49:20,650 --> 00:49:26,119 说话人 SPEAKER_01：但结果基本上并没有立即被计算机视觉社区所相信。
490 00:49:26,099 --> 00:49:41,541 说话人 SPEAKER_01：现在来衡量自那时以来所取得的进展，在过去的 10 年左右，这是一个由 Facebook 团队最近构建的一个非常系统的结果示例，他们称之为全景特征金字塔网络。
491 00:49:41,561 --> 00:49:46,588 说话人 SPEAKER_01：所以它基本上是一个大型卷积网络，具有一种提取特征的路径。
492 00:49:46,568 --> 00:49:51,155 说话人 SPEAKER_01：多层路径提取特征，然后还有另一条路径生成输出图像。
493 00:49:51,556 --> 00:49:59,909 说话人 SPEAKER_01：输出图像基本上识别并生成图像中每个实例的每个对象的掩码，并告诉你它们的类别。
494 00:50:00,230 --> 00:50:04,657 说话人 SPEAKER_01：这里显示的是类别名称，但它可以识别几百个这样的类别。
495 00:50:05,038 --> 00:50:07,362 说话人 SPEAKER_01：人，各种车辆，
496 00:50:07,730 --> 00:50:19,166 说话人 SPEAKER_01：不仅仅是物体类别，还包括背景纹理或区域，比如草地、沙滩、树木等。
497 00:50:19,666 --> 00:50:26,976 说话人 SPEAKER_01：所以，这样的系统对于自动驾驶汽车等需要完整图像像素分割识别的场景非常有用。
498 00:50:27,617 --> 00:50:30,001 说话人 SPEAKER_01：这将使构建自动驾驶汽车变得更加容易。
499 00:50:30,460 --> 00:50:34,065 说话人 SPEAKER_01：不仅限于自动驾驶汽车，还包括医学图像分析系统。
500 00:50:34,085 --> 00:50:36,690 说话人 SPEAKER_01：所以这是一个相对类似的架构。
501 00:50:36,670 --> 00:50:42,157 说话人 SPEAKER_01：人们有时称这个卷积网络为 U-net，因为它具有明显的 U 形结构。
502 00:50:42,677 --> 00:50:54,213 说话人 SPEAKER_01：再次，它有一个编码器部分，用于提取特征，然后有一个构建输出图像的部分，其中医学图像的部分被分割。
503 00:50:54,273 --> 00:50:55,775 说话人 SPEAKER_01：这是它产生的一种结果。
504 00:50:56,777 --> 00:50:59,400 说话人 SPEAKER_01：这是我在纽约大学的一些同事的一些工作。
505 00:50:59,420 --> 00:51:01,083 说话人 SPEAKER_01：我没有参与这项工作。
506 00:51:01,143 --> 00:51:05,849 说话人 SPEAKER_01：有一些同事的不同小组有一些共同作者，他们也在做这项工作。
507 00:51:05,829 --> 00:51:11,418 说话人 SPEAKER_01：从成像、X 光、乳腺摄影中检测乳腺癌。
508 00:51:12,338 --> 00:51:22,634 说话人 SPEAKER_01：实际上，目前放射学中最具挑战性的话题之一就是使用深度学习进行医学图像分析。
509 00:51:22,813 --> 00:51:28,643 说话人 SPEAKER_01：这可能会在未来几年内影响，甚至可能彻底改变放射学。
510 00:51:28,782 --> 00:51:30,284 说话人 SPEAKER_01：它在某种程度上已经做到了。
511 00:51:31,463 --> 00:51:33,686 说话人 SPEAKER_01：在这方面的更多工作。
512 00:51:33,967 --> 00:51:41,019 说话人 SPEAKER_01：这实际上是纽约大学医学院和 Facebook 研究合作，加速 MRI 数据收集。
513 00:51:41,101 --> 00:51:47,952 说话人 SPEAKER_01：所以当你进行 MRI 检查时，你必须坐在机器里大约一个小时或 20 分钟，具体取决于你要进行的检查类型。
514 00:51:47,932 --> 00:52:04,878 说话人 SPEAKER_01：这里使用这种重建卷积网络的技术，基本上可以减少数据收集时间，并获得本质上相同质量的图像。
515 00:52:06,563 --> 00:52:13,617 说话人 SPEAKER_01：这不会让放射科医生失业，但可能会让这份工作更有趣。
516 00:52:14,920 --> 00:52:18,668 说话人 SPEAKER_01：Jeff 正在提到使用神经网络进行翻译的工作。
517 00:52:18,769 --> 00:52:25,905 说话人 SPEAKER_01：我认为，这是一个非常令人惊讶且有趣的进展，即可以使用神经网络进行翻译。
518 00:52:26,559 --> 00:52:31,025 说话人 SPEAKER_01：在这方面使用的架构有很多创新。
519 00:52:31,045 --> 00:52:35,032 说话人 SPEAKER_01：所以 Jeff 谈到了注意力机制、Transformer 架构。
520 00:52:35,351 --> 00:52:39,438 说话人 SPEAKER_01：这是一个新概念，称为动态卷积，它借鉴了一些这些想法。
521 00:52:40,079 --> 00:52:41,920 说话人 SPEAKER_01：那里的效果非常好。
522 00:52:42,262 --> 00:52:43,342 说话人 SPEAKER_01：这些网络非常大。
523 00:52:43,382 --> 00:52:45,987 说话人 SPEAKER_01：它们包含几亿个参数。
524 00:52:46,827 --> 00:52:54,920 说话人 SPEAKER_01：因此，其中的挑战之一实际上是在 GPU 上运行它们，需要有足够的内存来运行它们。
525 00:52:54,940 --> 00:52:58,146 说话人 SPEAKER_01：我们基本上在那里受限于 GPU 内存。
所以，那些图像分割的想法已经被从事自动驾驶汽车研究的人们所采用，尤其是现在属于英特尔的公司 Mobile Life 的人们，这可以追溯到好几年前。
527 00：53：11,110 --> 00：53：18,637 演讲者 SPEAKER_01：我认为，第一个用于自动驾驶汽车或驾驶辅助的卷积网络是在 2015 年的特斯拉 S 车型中。
528 00：53：19,778 --> 00：53：23,882 演讲者 SPEAKER_01：NVIDIA 也投入了大量精力来开发自动驾驶汽车。
529 00：53：24,503 --> 00：53：26,346 演讲者 SPEAKER_01：所以这里面有很多有趣的事情。
530 00:53:26,485 --> 00:53:35,414 说话人 SPEAKER_01：但进步，我不会说慢，但完全自动驾驶是一个难题。
531 00:53:35,434 --> 00:53:37,336 说话人 SPEAKER_01：它不像人们最初想象的那样简单。
532 00:53:38,414 --> 00:53:43,061 说话人 SPEAKER_01：好的，杰夫似乎对强化学习一笔带过。
533 00:53:43,081 --> 00:53:47,507 说话人 SPEAKER_01：但强化学习是很多人非常兴奋的事情，尤其是 DeepMind 的人。
534 00:53:48,789 --> 00:53:53,577 说话人 SPEAKER_01：但是当前强化学习存在一个问题，那就是它非常数据低效。
535 00:53:54,018 --> 00:53:59,646 说话人 SPEAKER_01：如果你想用强化学习训练一个系统做任何事情，它将不得不进行大量的试错。
536 00:53:59,996 --> 00:54:14,635 说话人 SPEAKER_01：例如，要让机器玩 Atari 游戏，经典的 Atari 游戏，达到任何人类在约 15 分钟训练后能达到的水平，机器将不得不玩相当于 80 小时实时游戏。
537 00:54:16,557 --> 00:54:24,148 说话人 SPEAKER_01：要达到超人类水平的围棋，它将不得不玩大约 2000 万场游戏。
538 00:54:24,128 --> 00:54:28,235 说话人 SPEAKER_01：玩星际争霸，这是 DeepMind 最近的一项工作。
539 00:54:29,215 --> 00:54:30,297 说话人 SPEAKER_01：这是一篇博客文章，不是论文。
540 00:54:31,018 --> 00:54:42,998 说话人 SPEAKER_01：AlphaStar 系统相当于 200 年的实时游戏时间，才在单一地图上达到人类水平，针对的是一种单一类型的玩家。
541 00:54:42,978 --> 00:54:49,307 说话人 SPEAKER_01：顺便说一下，所有这些系统都使用了卷积神经网络和其他各种技术，但这确实很有趣。
542 00:54:49,869 --> 00:54:55,797 说话者 SPEAKER_01：强化学习的问题在于，这些模型必须尝试一些方法才能知道它是否可行。
543 00:54:56,259 --> 00:55:04,652 说话者 SPEAKER_01：如果你想在现实世界中训练一个机器人去抓取东西，或者训练一辆车自动驾驶，这实际上并不实用。
544 00:55:04,672 --> 00:55:06,876 说话者 SPEAKER_01：所以，你知道，要弄清楚
545 00:55:08,492 --> 00:55:19,731 说话者 SPEAKER_01：要训练一个系统让汽车不冲下悬崖，它实际上必须多次冲下悬崖，才能弄清楚如何避免这样做。
首先，要弄清楚这是一个坏主意，其次，要弄清楚如何不这样做。
547 00：55：26,422 --> 00：55：27,864 演讲者 SPEAKER_01：因为它没有世界模型。
548 00：55：27,923 --> 00：55：30,588 议长 SPEAKER_01：在发生之前，它无法想象会发生什么。
549 00：55：30,648 --> 00：55：32,831 议长 SPEAKER_01：它必须尝试纠正自己。
550 00:55:33,032 --> 00:55:34,635 说话人 SPEAKER_01：这就是为什么它如此低效。
551 00:55:35,797 --> 00:55:40,610 说话人 SPEAKER_01：这不禁让人思考，人类和动物是如何如此高效、如此快速地学习的？
552 00:55:40,990 --> 00:55:42,034 说话人 SPEAKER_01：我们可以学会开车。
553 00:55:42,074 --> 00:55:46,005 说话人 SPEAKER_01：我们大多数人可以在大约 20 小时的训练后学会开车，而且几乎不会发生事故。
554 00:55:46,847 --> 00:55:47,628 说话人 SPEAKER_01：这是怎么发生的？
555 00:55:48,335 --> 00:56:01,014 说话人 SPEAKER_01：我们不会冲下悬崖，因为我们有一个相当好的直觉物理模型，它告诉我们，如果我正开车靠近悬崖，我向右打方向盘，车就会冲下悬崖，坠落，不会有好结果。
556 00:56:02,516 --> 00:56:04,159 说话人 SPEAKER_01：所以我们有一个内部模型。
557 00:56:04,760 --> 00:56:06,603 说话人 SPEAKER_01：问题是，我们如何学习这个内部模型？
558 00:56:06,983 --> 00:56:10,590 说话人 SPEAKER_01：下一个问题是，我们如何让机器学习像那样的内部模型？
559 00:56:11,451 --> 00:56:12,773 说话人 SPEAKER_01：基本上，就是通过观察。
560 00:56:14,811 --> 00:56:19,601 说话人 SPEAKER_01：所以，在巴黎有一位名叫 Emmanuel Dupou 的先生。
561 00:56:19,681 --> 00:56:21,907 说话人 SPEAKER_01：他是一位发展心理学家。
562 00:56:22,126 --> 00:56:27,878 说话人 SPEAKER_01：他实际上在研究儿童如何学习语言和言语以及类似的事情，还研究其他概念。
563 00:56:27,938 --> 00:56:28,820 说话人 SPEAKER_01：他制作了这个图表。
564 00:56:29,222 --> 00:56:40,398 说话人 SPEAKER_01：关于时间，婴儿在几个月大时学习基本概念，比如区分有生命物体和无生命物体，这通常发生在大约三个月大的时候。
565 00:56:41,599 --> 00:56:51,012 说话人 SPEAKER_01：有些物体是稳定的，有些会掉落，你可以通过观察婴儿对某些物体行为的反应来判断他们是否对此感到惊讶。
566 00:56:52,307 --> 00:56:59,380 说话人 SPEAKER_01：然后婴儿需要大约九个月的时间来弄清楚，不支持的对象会掉落，基本上是重力。
567 00:57:00,503 --> 00:57:13,708 说话人 SPEAKER_01：所以如果你向六个月大的婴儿展示左上角的场景，那里有一辆小车在平台上，你把小车从平台上推下去，小车没有掉落，这是一个骗局。
568 00:57:14,936 --> 00:57:16,760 说话人 SPEAKER_01：六个月大的婴儿甚至不会注意。
569 00:57:16,960 --> 00:57:21,487 说话人 SPEAKER_01：这只是世界向他们抛出的另一件事，他们必须学习。
570 00:57:22,108 --> 00:57:22,467 说话人 SPEAKER_01: 没问题。
571 00:57:23,329 --> 00:57:26,793 说话人 SPEAKER_01: 一个九个月大的婴儿会像左下角的小女孩那样。
572 00:57:28,777 --> 00:57:29,798 说话人 SPEAKER_01: 会非常、非常惊讶。
573 00:57:29,978 --> 00:57:33,123 说话人 SPEAKER_01: 同时，他们已经学会了重力的概念。
574 00:57:34,005 --> 00:57:35,887 说话人 SPEAKER_01：没有人真正告诉他们什么是重力。
575 00:57:35,907 --> 00:57:39,552 说话人 SPEAKER_01：他们只是观察世界，发现没有支撑的物体就会掉落。
576 00:57:39,632 --> 00:57:41,876 说话人 SPEAKER_01：当这种情况没有发生时，他们会感到惊讶。
577 00:57:43,498 --> 00:57:44,320 说话人 SPEAKER_01：这是怎么发生的？
578 00:57:45,244 --> 00:57:46,447 说话人 SPEAKER_01：这不仅仅是人类。
579 00:57:46,467 --> 00:57:47,568 说话人 SPEAKER_01：动物也有那些模型。
580 00:57:47,969 --> 00:57:50,353 说话人 SPEAKER_01：你知道，猫、狗、老鼠。
581 00:57:51,456 --> 00:57:51,936 说话人 SPEAKER_01：或者黑猩猩。
582 00:57:52,376 --> 00:57:53,739 说话人 SPEAKER_01：这里有一个小猩猩。
583 00:57:53,760 --> 00:57:55,061 说话人 SPEAKER_01：它正在被展示一个魔术。
584 00:57:55,643 --> 00:57:56,625 说话人 SPEAKER_01：把一个物体放进杯子里。
585 00:57:58,628 --> 00:58:00,150 说话人 SPEAKER_01：移除物体，但它没有注意到。
586 00:58:01,012 --> 00:58:03,076 说话人 SPEAKER_01: 然后出示杯子。
587 00:58:03,096 --> 00:58:03,516 说话人 SPEAKER_01: 它是空的。
588 00:58:05,119 --> 00:58:06,021 说话人 SPEAKER_01: 它在地板上笑着。
589 00：58：08,802 --> 00：58：12,286 议长 SPEAKER_01：所以他的世界模型被侵犯了，对吧？
590 00：58：12,306 --> 00：58：13,387 议长 SPEAKER_01：他有一个相当不错的世界模型。
591 00：58：13,507 --> 00：58：15,550 演讲者 SPEAKER_01：对象持久性，这是一个非常基本的概念。
592 00：58：15,630 --> 00：58：17,393 发言者 SPEAKER_01：物体不应该就这样消失。
593 00:58:18,655 --> 00:58:26,244 说话人 SPEAKER_01：当你的世界观被违反时，你会注意，因为你将学到一些你不知道的世界知识。
594 00:58:26,286 --> 00:58:31,873 说话人 SPEAKER_01：如果它真的违反了关于世界的非常基本的东西，那很有趣。
595 00:58:33,253 --> 00:58:36,197 说话人 SPEAKER_01：但这也可能很危险，对吧？
596 00:58:36,217 --> 00:58:40,539 说话人 SPEAKER_01：这是可能会要了你的命的东西，因为你没有预测到刚刚发生了什么。
597 00:58:41,601 --> 00:58:42,702 说话人 SPEAKER_01：好吧，那么什么是救赎？
598 00:58:42,742 --> 00:58:45,304 说话人 SPEAKER_01：真的，你知道，我们如何让机器学习这类东西？
599 00:58:46,606 --> 00:58:51,909 说话人 SPEAKER_01：你知道，我们在生命的头几个月里，通过观察就学会了大量关于世界的背景知识。
600 00:58:52,971 --> 00:58:53,871 说话人 SPEAKER_01：动物也会这样做。
601 00:58:54,612 --> 00:59:02,940 说话者 SPEAKER_01：例如，如果我问你，如果我训练自己预测当我稍微向左转动头部时世界会是什么样子。
602 00:59:04,641 --> 00:59:16,384 说话者 SPEAKER_01：由于视差运动，近处的物体和远处的物体相对于我的视角移动的方式不会相同。
603 00:59:17,746 --> 00:59:27,105 说话者 SPEAKER_01：因此，最好的方法是内部表示深度概念，以预测当我移动头部时世界会是什么样子。
604 00:59:28,704 --> 00:59:40,099 说话者 SPEAKER_01：因此，相反地，如果我训练一个系统来预测当它移动相机时世界会是什么样子，也许它会自动学习深度概念。
605 00:59:40,681 --> 00:59:42,202 说话人 SPEAKER_01：一旦有了深度，就有了物体。
606 00:59:42,282 --> 00:59:44,545 说话人 SPEAKER_01：因为物体在别人前面，所以有了遮挡边缘。
607 00:59:45,086 --> 00:59:50,713 说话人 SPEAKER_01：一旦有了物体，就有了可以影响的事物，可以独立于其他事物移动的事物等等。
608 00:59:50,753 --> 00:59:56,501 说话人 SPEAKER_01：因此，概念可以通过预测层层叠加。
609 00:59:57,663 --> 00:59:59,327 说话人 SPEAKER_01：这就是自监督学习的概念。
610 00:59:59,507 --> 01:00:00,949 说话人 SPEAKER_01：它是预测和重建。
611 01:00:01,871 --> 01:00:05,581 说话人 SPEAKER_01：我给机器提供一段数据，比如说一个视频片段。
612 01:00:06,181 --> 01:00:13,478 说话人 SPEAKER_01：我将视频片段的一部分遮挡起来，并要求系统根据它所能观察到的部分预测缺失的部分。
613 01:00:14,268 --> 01:00:16,771 说话人 SPEAKER_01: 好的，那么这就是视频预测，就是预测未来。
614 01:00:18,293 --> 01:00:23,320 说话人 SPEAKER_01: 但是自监督学习的更一般形式是，我事先并不指定要掩码的部分。
615 01:00:24,221 --> 01:00:29,507 说话人 SPEAKER_01: 我只是告诉系统我要掩码一部分，然后被掩码的部分，我要求你重构它。
616 01:00:32,010 --> 01:00:33,833 说话人 SPEAKER_01: 事实上，我甚至可能根本不掩码。
617 01:00:34,353 --> 01:00:40,782 说话人 SPEAKER_01：我将虚拟地屏蔽它，并要求系统在特定约束下重建输入。
618 01:00:40,998 --> 01:00:44,121 说话人 SPEAKER_01：这种自监督学习的优势在于它不依赖于特定任务。
619 01:00:44,202 --> 01:00:47,405 说话人 SPEAKER_01：你让机器了解世界，而不需要为特定任务进行训练。
620 01:00:48,485 --> 01:00:52,231 说话人 SPEAKER_01：因此，它可以通过观察来学习，而无需与世界互动，这要高效得多。
621 01:00:52,590 --> 01:00:55,914 说话人 SPEAKER_01: 但更重要的是，你要求系统预测很多东西。
622 01:00:56,956 --> 01:01:04,844 说话人 SPEAKER_01: 不仅像强化学习中的值函数那样，基本上你只给机器预测一个标量值。
623 01:01:05,364 --> 01:01:11,514 说话人 SPEAKER_01: 而不是监督学习，在监督学习中，你要求系统预测一个标签，这只是一个几个比特的信息。
624 01:01:12,795 --> 01:01:15,800 说话人 SPEAKER_01: 在自监督学习的情况下，你要求机器预测很多东西。
625 01:01:18,342 --> 01:01:28,538 说话人 SPEAKER_01: 因此，这让我想到了一个稍微有点令人讨厌的类比，至少对于从事强化学习的人来说是这样的，那就是如果智能或学习是一块蛋糕的话，
626 01:01:28,686 --> 01:01:33,344 说话人 SPEAKER_01: 这块蛋糕的大部分，我们称之为法国的吉诺斯，实际上是自监督学习。
627 01:01:33,364 --> 01:01:37,802 说话人 SPEAKER_01: 我们学到的很多东西，我们积累的关于世界的知识的大部分，都是通过自监督学习学到的。
628 01:01:38,862 --> 01:01:42,005 说话人 SPEAKER_01: 蛋糕上有一点点糖霜，这就是监督学习。
629 01:01:42,164 --> 01:01:45,467 说话人 SPEAKER_01：我们被展示了一本图画书，并且告诉我们物体的名字。
630 01:01:46,088 --> 01:01:49,311 说话人 SPEAKER_01：仅仅通过几个例子，我们就能知道这些物体是什么。
631 01:01:50,532 --> 01:02:01,481 说话人 SPEAKER_01：我们学习了某些单词的含义，而婴儿和幼儿每天可以学习很多很多新单词。
632 01:02:02,322 --> 01:02:04,184 说话人 SPEAKER_01：然后，蛋糕上的樱桃就是强化学习了。
您请求的机器翻译内容如下： 您要求机器预测的信息量非常小，因此没有办法
634 01：02：08,849 --> 01：02：12,371 演讲者 SPEAKER_01：机器可以纯粹地从这种形式的学习中学习。
635 01：02：12,492 --> 01：02：20,320 演讲者 SPEAKER_01：这得是所有三种学习形式的结合，但主要是自我监督的学习。
636 01：02：20,800 --> 01：02：21,960 议长 SPEAKER_01：这个想法并不新鲜。
637 01:02:22,380 --> 01:02:29,788 众多人主张预测学习、学习模型、预测模型这一观点。
638 01:02:30,608 --> 01:02:34,893 事实上，杰夫就是这样一个人。
639 01:02:35,353 --> 01:02:37,135 这是他的名言。
640 01:02:37,672 --> 01:02:45,222 你知道，这是几年前的事情了，但他至少已经说了40年，比我认识他还要久。
641 01:02:46,423 --> 01:02:47,907 说话人 SPEAKER_01: 它是这样的。
642 01:02:47,987 --> 01:02:54,675 说话人 SPEAKER_01: 大脑大约有 10 的 14 次方个突触，而我们只活大约 10 的 9 次方秒，所以我们有比数据多得多的参数。
643 01:02:54,715 --> 01:03:05,771 说话人 SPEAKER_01: 这促使我们产生这样的想法，我们必须进行大量的无监督学习，或者自监督学习，因为感知输入，包括本体感觉，是我们唯一可以每秒获得 10 的 50 次方约束的地方。
644 01:03:05,751 --> 01:03:21,516 说话人 SPEAKER_01: 如果你被要求预测每时每刻进入你感官的一切，你知道，每一秒的每一部分，你都要学习大量的信息，这可能足以约束我们大脑中所有的突触，以便学习有意义的事物。
645 01:03:23,115 --> 01:03:28,487 说话人 SPEAKER_01：在我看来，深度学习的后续是自监督学习。
646 01:03:28,507 --> 01:03:43,115 说话人 SPEAKER_01：实际上，正如 Jeff 提到的，我们 Yoshua、Jeff 和我从 2000 年代初开始的这种深度学习阴谋，重点是无监督学习，无监督预训练。
647 01:03:43,096 --> 01:03:44,358 说话人 SPEAKER_01：这在一定程度上是成功的。
648 01:03:44,858 --> 01:03:48,965 说话人 SPEAKER_01：但我们把它放在了一边一段时间。
649 01:03:49,286 --> 01:03:50,527 说话人 SPEAKER_01: 它现在又回到了前台。
650 01:03:51,568 --> 01:03:54,052 说话人 SPEAKER_01: 它将引发一场新的革命，至少这是我的预测。
651 01:03:54,994 --> 01:03:57,217 说话人 SPEAKER_01: 下一场革命将不会是监督式的。
652 01:03:58,659 --> 01:04:02,186 说话人 SPEAKER_01: 因此我要感谢 Aljosha Efros 这个口号。
653 01:04:02,306 --> 01:04:03,206 说话人 SPEAKER_01: 他发明了它。
654 01:04:04,750 --> 01:04:06,592 说话人 SPEAKER_01: 当然，他是受到了 Jill Scott Heron 的启发。
655 01:04:06,932 --> 01:04:08,534 说话人 SPEAKER_01: 革命不会在电视上播出。
656 01:04:09,257 --> 01:04:11,500 说话人 SPEAKER_01: 现在甚至可以买到印有这句话的 T 恤。
657 01:04:14,585 --> 01:04:16,047 说话人 SPEAKER_01: 那么自我监督学习究竟是什么呢？
658 01:04:16,367 --> 01:04:17,891 说话人 SPEAKER_01: 自我监督学习就是填补空白。
659 01:04:19,413 --> 01:04:21,717 说话人 SPEAKER_01: 它在自然语言处理方面效果非常好。
660 01:04:22,137 --> 01:04:39,106 说话人 SPEAKER_01: 所以自然语言处理，在过去一年中成为标准的方法，比如 BERT 和其他模型，就是从文本语料库中提取一段长序列的单词，然后删除其中一部分单词，
661 01:04:40,235 --> 01:04:46,682 说话人 SPEAKER_01：您基于这些 Transformer 架构或各种其他架构训练一个非常大的神经网络来预测缺失的单词。
662 01:04:47,443 --> 01:04:58,538 说话人 SPEAKER_01：实际上，它并不能精确地预测缺失的单词，所以您要求它预测整个词汇表在整个词汇分布中每个单词出现在这些位置的概率分布。
663 01:05:00,300 --> 01:05:03,364 说话人 SPEAKER_01：这就是我们所说的掩码自动编码器的一个特例。
664 01:05:04,105 --> 01:05:09,110 说话人 SPEAKER_01：您给它一个输入，要求它重建这部分缺失的输入。
665 01:05:09,309 --> 01:05:12,693 说话人 SPEAKER_01：人们一直在图像识别的背景下尝试做这件事。
666 01:05:12,893 --> 01:05:14,414 说话人 SPEAKER_01：在这方面有各种尝试。
667 01:05:14,474 --> 01:05:22,603 说话人 SPEAKER_01：这是 Pathak 等人几年前的研究成果，其中你将图像的一些部分空白，然后要求系统填充它们。
668 01:05:23,503 --> 01:05:28,568 说话人 SPEAKER_01：它只部分成功，远不如在自然语言处理领域的成功。
669 01:05:28,969 --> 01:05:35,114 说话人 SPEAKER_01：所以自然语言处理，过去一年里使用这些预训练系统进行
670 01:05:35,297 --> 01:05:37,902 说话人 SPEAKER_01：自然语言理解、翻译、各种各样的事情。
671 01:05:38,041 --> 01:05:39,403 说话人 SPEAKER_01：性能惊人。
672 01：05：39,643 --> 01：05：42,608 演讲者 SPEAKER_01：他们是非常非常大的模型，但性能真的很好。
673 01:05:43,248 --> 01:06:00,293 说话者 SPEAKER_01：这种迹象在 Yoshua Bengio 很久以前在 90 年代进行的工作中就已经有所体现，Rolando Colabella 和 Jason Weston 在 2010 年左右使用神经网络进行 NLP 研究时也发现了这一点。
然后是更近期的作品，Word2vec、Fastex 等等，基本上都是利用从上下文中预测单词的这个想法。
675 01：06：06,525 --> 01：06：09,992 演讲者 SPEAKER_01：但实际上，这整个想法完全被打破了。
676 01:06:10,494 --> 01:06:13,440 说话人 SPEAKER_01：那么为什么它在自然语言处理中有效？
677 01:06:13,880 --> 01:06:18,130 说话人 SPEAKER_01：为什么在图像和视觉领域效果不佳？
678 01:06:19,510 --> 01:06:26,717 说话人 SPEAKER_01：我认为这是因为我们如何表示不确定性，或者我们如何不表示不确定性。
679 01:06:27,297 --> 01:06:28,938 说话人 SPEAKER_01：那么假设我们想要进行视频预测。
680 01:06:29,639 --> 01:06:32,902 说话人 SPEAKER_01：我们有包含几个帧的短视频片段。
681 01:06:33,503 --> 01:06:36,005 说话人 SPEAKER_01：在这个例子中，一个小女孩走向生日蛋糕。
682 01:06:36,686 --> 01:06:39,389 说话人 SPEAKER_01：然后我们要求机器预测视频中的下一几个帧。
683 01:06:40,751 --> 01:06:47,036 说话人 SPEAKER_01：如果你训练一个大型神经网络，使用最小二乘误差来预测下一几个帧，
684 01:06:47,556 --> 01:06:49,400 说话人 SPEAKER_01：你得到的是模糊的预测。
685 01:06:50,782 --> 01:06:51,021 说话人 SPEAKER_01：为什么？
686 01:06:51,322 --> 01:06:58,213 说话人 SPEAKER_01：因为系统无法精确预测将要发生什么，所以你能做的最好的事情就是预测所有可能未来的平均值。
687 01:06:59,376 --> 01:07:09,632 说话人 SPEAKER_01：更具体地说，假设所有视频都是由某人把笔放在桌子上然后放手组成，每次重复实验笔都会以不同的方向落下，你根本无法预测它会向哪个方向落下。
688 01:07:10,777 --> 01:07:19,715 说话人 SPEAKER_01：那么如果你预测所有结果的平均值，它将是一个透明笔在所有可能的方向上叠加。
689 01:07:19,835 --> 01:07:23,021 说话人 SPEAKER_01：这不是一个好的预测。
690 01:07:23,041 --> 01:07:25,967 说话人 SPEAKER_01：所以如果你想使一个系统能够
691 01:07:26,385 --> 01:07:30,512 说话人 SPEAKER_01：表示多个预测，它必须具备所谓的潜在变量。
692 01:07:30,652 --> 01:07:32,835 说话人 SPEAKER_01：您已经实现了一个由神经网络实现的函数。
693 01:07:33,356 --> 01:07:37,704 说话人 SPEAKER_01：它接受过去的数据，比如说几个视频帧，并试图预测接下来的几个帧。
694 01:07:38,143 --> 01:07:46,356 说话人 SPEAKER_01：它需要有一个额外的变量，这里称为 z，这样当您改变这个变量时，输出会在一组可能的预测中变化。
695 01:07:47,259 --> 01:07:49,322 说话人 SPEAKER_01：好的，这就是潜在变量模型。
696 01:07:49,302 --> 01:07:59,164 训练这些事物的问题在于，我们基本上只知道两种训练方法，或者说有两种类型的训练系统的方法。
697 01:07:59,563 --> 01:08:08,965 其中一个是来自伊恩·古德费洛（Ian Goodfellow）及其蒙特利尔大学合作者几年前的一个非常酷的想法，称为对抗训练或生成对抗网络。
698 01:08:08,945 --> 01:08:21,573 GANs（对抗网络）的想法是训练第二个神经网络来告诉第一个神经网络其预测是否在这个流形或可能的未来集合上。
699 01:08:21,592 --> 01:08:24,760 你同时训练这两个网络。
700 01:08:26,190 --> 01:08:32,886 说话人 SPEAKER_01：还有一种技术，就是推断出潜在变量的理想值，以便做出良好的预测。
701 01:08:33,868 --> 01:08:44,570 说话人 SPEAKER_01：但是如果你这样做，潜在变量可能会捕获关于预测的所有信息，而实际上不会使用过去的信息来做出预测。
702 01:08:46,356 --> 01:08:48,139 说话人 SPEAKER_01：所以你必须对这个潜在变量进行正则化。
703 01:08:48,859 --> 01:08:55,067 说话人 SPEAKER_01：好的，所以像对抗训练这样的想法效果非常好。
704 01:08:55,207 --> 01:09:01,274 说话人 SPEAKER_01：所以您在这里底部看到的是系统经过这种对抗性训练后的短视频预测。
705 01:09:02,435 --> 01:09:09,903 说话人 SPEAKER_01：进行这些预测的方法有很多，不仅限于像素空间，还包括已经分割的对象空间。
706 01:09:11,305 --> 01:09:14,929 说话人 SPEAKER_01：这些生成对抗网络可以生成
707 01:09:14,908 --> 01:09:19,412 说话人 SPEAKER_01：用于艺术创作的辅助图像。
708 01:09:19,993 --> 01:09:21,854 说话人 SPEAKER_01：这些是非存在的面孔。
709 01:09:21,875 --> 01:09:26,640 说话人 SPEAKER_01：这里有一个系统，经过训练可以生成一个看起来像名人的图像。
710 01:09:27,501 --> 01:09:33,685 说话人 SPEAKER_01：系统训练完成后，给它输入几百个随机数，就会出现一个不存在的面孔。
711 01:09:35,148 --> 01:09:35,807 说话人 SPEAKER_01：它们看起来相当不错。
712 01:09:36,248 --> 01:09:39,631 说话人 SPEAKER_01: 这实际上是今年 NVIDIA 的工作。
713 01:09:39,652 --> 01:09:40,693 说话人 SPEAKER_01: 它今年被展示了。
714 01:09:41,913 --> 01:09:44,376 说话人 SPEAKER_01: 你可以用它来制作各种不同的事物，
715 01:09:46,262 --> 01:09:54,315 说话人 SPEAKER_01: 例如，训练来自著名设计师的服装集合。
716 01:09:55,717 --> 01:10:07,377 说话人 SPEAKER_01：我认为我们需要一些新的方法来表示，或者说在监督学习中对这个问题进行表述，以便我们的系统可以处理预测中的这种不确定性，在连续的高维空间中。
717 01:10:07,356 --> 01:10:09,079 说话人 SPEAKER_01：在自然语言处理中我们没有这个问题，因为表示词语的分布很容易。
718 01:10:09,439 --> 01:10:19,253 说话人 SPEAKER_01：在自然语言处理中我们没有这个问题，因为表示词语的分布很容易。
719 01:10:19,694 --> 01:10:20,856 说话人 SPEAKER_01：它只是一个离散分布。
720 01:10:20,917 --> 01:10:23,921 说话人 SPEAKER_01：这是一个介于 0 和 1 之间的长数字向量，其和为 1。
721 01:10:24,742 --> 01:10:27,947 说话人 SPEAKER_01：但在连续的高维空间中这非常困难。
722 01:10:28,213 --> 01:10:29,475 说话人 SPEAKER_01：因此我们需要新的技术来解决这个问题。
723 01:10:29,536 --> 01:10:37,186 说话人 SPEAKER_01：我提出的一个技术是所谓的基于能量的自监督学习，想象一下你的世界是二维的。
724 01:10:37,247 --> 01:10:39,010 说话人 SPEAKER_01：你只有两个输入变量，两个传感器。
725 01:10:39,831 --> 01:10:46,020 说话人 SPEAKER_01：你的整个世界，你的整个训练集，都是由这些点组成的，这些点位于这个二维空间中。
726 01:10:46,927 --> 01:10:57,247 说话人 SPEAKER_01：你想要训练一个对比函数，我们可以称之为能量，它对数据流形上的点给予低能量，对流形外的点给予高能量。
727 01:10:58,448 --> 01:11:03,417 说话人 SPEAKER_01：在这方面，基本还有很多研究要做，以找到完成这项任务的最佳方法。
728 01:11:03,398 --> 01:11:13,948 说话人 SPEAKER_01：我最喜欢的一种是所谓的正则化潜在变量模型，大约 10 年前，我们在这方面取得了成功，完全无监督地使用这类技术来学习卷积网络的特征。
729 01:11:14,770 --> 01:11:25,461 说话人 SPEAKER_01：您在这里看到的是通过仅用自然图像块进行训练以在稀疏约束下重建这些块来学习基本方向滤波器的系统的动画。
730 01:11:26,521 --> 01:11:31,768 说话人 SPEAKER_01：而您在右侧看到的是使用相同算法学习到的卷积网络的滤波器。
731 01:11:31,747 --> 01:11:34,490 说话人 SPEAKER_01：与不同数量的滤波器。
732 01:11:35,131 --> 01:11:36,393 说话人 SPEAKER_01：这些事情有点用。
733 01:11:37,012 --> 01:11:39,756 说话人 SPEAKER_01：如果你有大量数据，它们不会打败监督学习。
734 01:11:40,136 --> 01:11:44,280 说话人 SPEAKER_01：但希望它能减少必要的标记数据量。
735 01:11:45,703 --> 01:11:57,314 说话人 SPEAKER_01：所以我要以一个例子结束，说明如何将这些结合起来，让机器学习一些有用的东西，比如一个任务，一个运动任务。
736 01:11:57,335 --> 01:12:01,519 说话人 SPEAKER_01：所以，我在谈论的是，我们能否训练一台机器，通过观察其他人驾驶并训练一个关于世界发生什么情况的模型来学习驾驶。
737 01:12:01,717 --> 01:12:09,770 说话人 SPEAKER_01：所以，当你坐在车里，你可以看到周围的车辆，如果你能提前预测周围车辆的行为，那么你就可以进行防御性驾驶。
738 01:12:11,134 --> 01:12:22,932 说话人 SPEAKER_01：所以，你在车里，你可以看到周围的车辆，如果你能提前预测周围车辆将要做什么，那么你就可以进行防御性驾驶。
739 01:12:23,216 --> 01:12:25,940 说话人 SPEAKER_01：你可以决定远离这辆车，因为你看到它在打滑。
740 01:12:26,542 --> 01:12:34,734 说话人 SPEAKER_01: 你可以选择放慢速度，因为前面的车很可能会减速，因为前面还有一辆车正在减速。
741 01:12:35,055 --> 01:12:38,439 说话人 SPEAKER_01: 所以你有了所有那些基本能让你保持安全的预测模型。
742 01:12:38,479 --> 01:12:40,603 说话人 SPEAKER_01: 你已经逐渐学会了整合它们。
743 01:12:40,842 --> 01:12:41,984 说话人 SPEAKER_01: 你甚至都不需要去想。
744 01:12:42,284 --> 01:12:45,609 说话人 SPEAKER_01: 这只是你驾驶时的本能反应。
745 01:12:45,630 --> 01:12:50,877 说话人 SPEAKER_01: 你可以同时说话，并且还能工作。
746 01:12:52,275 --> 01:12:55,421 说话人 SPEAKER_01: 但是训练这样一个系统的方法是，你首先必须训练一个前向模型。
747 01:12:55,480 --> 01:13:02,393 说话人 SPEAKER_01: 因此，前向模型是这样的，这里是时间 t 的世界状态。给我预测一下时间 t+1 的世界状态。
748 01:13:03,694 --> 01:13:06,619 说话人 SPEAKER_01: 当然，这个问题在于世界不是决定性的。
749 01:13:07,381 --> 01:13:08,542 说话人 SPEAKER_01: 可能发生很多事情。
750 01:13:08,743 --> 01:13:10,706 说话人 SPEAKER_01: 这和我之前提到的用笔的问题是一样的。
751 01:13:11,226 --> 01:13:12,028 说话人 SPEAKER_01: 可能发生许多事情。
752 01:13:14,493 --> 01:13:19,060 说话人 SPEAKER_01：但是如果你有一个这样的前向模型，你可以多次运行前向模型。
753 01:13:21,266 --> 01:13:39,135 说话人 SPEAKER_01：然后如果你有一个目标函数，比如你离其他车辆有多远，你是否在车道上，诸如此类，你可以通过整个系统反向传播梯度来训练一个神经网络，以预测长期安全的正确行动方案。
754 01:13:39,975 --> 01:13:41,398 说话人 SPEAKER_01：这可以在你的脑海中完成。
755 01:13:41,779 --> 01:13:45,345 说话人 SPEAKER_01：如果你在脑海中有一个前向模型，你实际上不必亲自驾驶来训练自己驾驶。
756 01:13:45,664 --> 01:13:48,168 说话人 SPEAKER_01: 你可以想象所有这些事情。
757 01:13:51,085 --> 01:13:52,886 说话人 SPEAKER_01: 这是一个具体的例子。
758 01:13:52,988 --> 01:13:56,192 说话人 SPEAKER_01: 所以你放一个摄像头向下看高速公路。
759 01:13:56,872 --> 01:14:01,878 说话人 SPEAKER_01: 它跟随每一辆车，并在底部提取围绕每辆车的矩形。
760 01:14:03,001 --> 01:14:12,212 说话人 SPEAKER_01：你现在正在训练一个卷积网络，以获取围绕特定车辆的几个帧，并预测世界的下一个状态。
761 01:14:13,255 --> 01:14:20,163 说话人 SPEAKER_01：如果你这样做，你会得到，哎呀，对不起。
762 01:14:25,948 --> 01:14:26,971 你得到第二列。
763 01:14:27,113 --> 01:14:35,176 说话人 SPEAKER_01：所以左边的列是现实世界发生的事情，第二列是如果你只用最小二乘法训练卷积网络来预测将要发生的事情。
764 01:14:35,639 --> 01:14:39,250 说话人 SPEAKER_01：它只能预测所有可能未来的平均值，因此预测结果会模糊不清。
765 01:14:40,039 --> 01:14:59,431 说话人 SPEAKER_01：如果你现在转换模型，使其具有一个潜在变量，以便它能考虑到对世界的不确定性，具体如何操作我就不解释了，那么你将得到右侧的预测结果，对于这个潜在变量的每一次绘制，你都会得到不同的预测，但它们是清晰的。
766 01:15:00,560 --> 01:15:15,886 说话人 SPEAKER_01：好的，现在你可以这样做，为了进行我之前提到的训练，你需要采样这个潜在变量，这样你就能得到关于未来可能发生的事情的不同可能场景，然后通过反向传播来训练你的策略网络，使你的系统能够驾驶。
767 01:15:16,667 --> 01:15:17,628 说话人 SPEAKER_01：如果你这样做，是行不通的。
768 01:15:18,631 --> 01:15:25,722 说话人 SPEAKER_01：它不起作用，因为系统进入了状态空间中，其中前向模型非常不准确且非常不确定的区域。
769 01:15:26,328 --> 01:15:34,438 说话人 SPEAKER_01：所以你必须要在目标函数中添加另一个项，以防止系统进入其预测不良的空间部分。
770 01:15:35,519 --> 01:15:40,204 说话人 SPEAKER_01：所以这就像是一个逆向的好奇心约束，如果你愿意的话。
771 01:15:40,225 --> 01:15:41,266 说话人 SPEAKER_01：如果你这样做，它就会起作用。
772 01:15:41,287 --> 01:15:45,311 说话人 SPEAKER_01：这些都是蓝色汽车自动驾驶的例子。
773 01:15:45,351 --> 01:15:48,435 说话人 SPEAKER_01：这个小白点表示它是否加速、是否刹车或是否转向。
774 01:15:48,956 --> 01:15:51,319 说话人 SPEAKER_01：它会在其他车辆附近保持一定的安全距离。
775 01:15:51,679 --> 01:15:52,701 说话人 SPEAKER_01：其他车辆看不到它。
776 01:15:53,081 --> 01:15:54,563 说话人 SPEAKER_01：这里的蓝色汽车是看不见的。
777 01:15:55,234 --> 01:15:56,615 说话人 SPEAKER_01：让我在这里给你展示另一个例子。
778 01:15:58,677 --> 01:16:01,100 说话人 SPEAKER_01：所以在这里，黄色汽车是视频中的实际汽车。
779 01:16:01,119 --> 01:16:04,643 说话人 SPEAKER_01：蓝色汽车是这里训练过的代理所做的事情。
780 01:16:05,104 --> 01:16:08,707 说话人 SPEAKER_01：它被夹在两辆车之间，所以它必须逃脱，因为其他车辆看不到它。
781 01:16:10,368 --> 01:16:11,189 说话人 SPEAKER_01：所以它必须挤出来。
782 01:16:13,690 --> 01:16:14,131 说话人 SPEAKER_01：但是它成功了。
783 01:16:14,431 --> 01:16:15,493 说话人 SPEAKER_01：它工作得相当好。
784 01:16:16,092 --> 01:16:20,457 说话人 SPEAKER_01：基本上，该系统从未与真实世界互动过。
785 01:16:20,556 --> 01:16:24,060 说话人 SPEAKER_01：它只是观察别人开车。
786 01:16:24,817 --> 01:16:29,243 说话人 SPEAKER_01：然后它用这些信息来训练其行动计划，基本上是其策略。
787 01:16:30,145 --> 01:16:35,231 说话人 SPEAKER_01：好的，现在我要稍微谈谈哲学，如果你愿意的话。
788 01：16：35,271 --> 01：16：45,087 演讲者 SPEAKER_01：在整个技术和科学的历史中，一直存在着这种现象，它不是普遍的，但非常频繁，人们发明了一个人工制品
然后从这个物品中推导出一门科学来解释这个物品是如何工作的，或者找出它的局限性。
790 01：16：54,002 --> 01：16：57,108 演讲者 SPEAKER_01：一个很好的例子是 1600 年代望远镜的发明。
791 01：16：57,988 --> 01：17：00,654 演讲者 SPEAKER_01：光学至少在 50 年后才发展起来。
但在此之前，人们已经有了如何建造望远镜的良好直觉。
蒸汽机在17世纪末和18世纪初被发明，而热力学则是在100多年后出现的，主要是为了解释热机的局限性。
794 01:17:19,845 --> 01:17:24,975 说话者 SPEAKER_01：现在热力学是所有科学中最基本的知识体系之一的基础。
795 01:17:26,458 --> 01:17:30,827 说话者 SPEAKER_01：所以它是特意定义来解释一个特定文物的。
796 01:17:31,287 --> 01:17:32,048 说话人 SPEAKER_01：这非常有趣。
797 01:17:33,853 --> 01:17:42,529 说话人 SPEAKER_01：电磁学和电动力学也是一样，有了帆船、飞机和空气动力学。
798 01:17:42,509 --> 01:17:46,099 你知道，化合物的发明和化学的解释等。
799 01:17:46,118 --> 01:17:46,500 说话人 SPEAKER_01：对吧？
800 01:17:46,680 --> 01:17:49,849 说话人 SPEAKER_01：计算机和计算机科学是在计算机发明之后出现的，对吧？
801 01:17:51,132 --> 01:17:58,493 说话人 SPEAKER_01：信息论是在无线电和电传等第一代数字通信发明之后出现的。
802 01:17:59,367 --> 01:18:21,354 说话人 SPEAKER_01：因此，在接下来的几十年里，我们完全有可能拥有通过试错、可能在强大机器上的系统优化、直觉、经验工作、或许一点理论、或许很多理论构建的实证系统，希望如此。
803 01:18:22,917 --> 01:18:27,061 说话人 SPEAKER_01：问题是这会不会导致一个关于智能的完整理论。
804 01:18:28,814 --> 01:18:36,890 说话人 SPEAKER_01：能够构建一个智能的物品的事实可能会导致信息处理和智能的一般理论。
805 01:18:37,792 --> 01:18:39,997 说话人 SPEAKER_01：这算是一个很大的希望。
806 01:18:40,578 --> 01:18:45,168 说话人 SPEAKER_01：我不确定这一点在接下来的几十年内能否实现，但这是一个好的项目。
807 01:18:46,452 --> 01:18:48,055 说话人 SPEAKER_01：有一点要提醒大家。
808 01:18:48,270 --> 01:18:49,512 说话人 SPEAKER_01：关于生物启发。
809 01:18:49,533 --> 01:18:54,338 说话人 SPEAKER_01：所以神经网络是受生物启发的，卷积神经网络也是受生物启发的，但它们只是受到启发，并没有复制。
810 01:18:55,581 --> 01:18:58,645 说话人 SPEAKER_01：让我给你讲一个名叫克莱门特·阿德的人的故事。
811 01:18:59,485 --> 01:19:00,807 说话人 SPEAKER_01：这里有没有法国人？
812 01:19:01,788 --> 01:19:03,091 说话人 SPEAKER_01: 好的，你能举手吗？
813 01:19:03,631 --> 01:19:04,091 说话人 SPEAKER_01: 法国人民？
814 01:19:04,233 --> 01:19:04,792 说话人 SPEAKER_01: 没有法国人？
815 01:19:05,033 --> 01:19:05,854 说话人 SPEAKER_01: 嗯，好的，有几个人。
816 01:19:06,234 --> 01:19:07,256 说话人 SPEAKER_01: 你听说过克莱门特·阿德吗？
817 01:19:09,840 --> 01:19:10,701 说话人 SPEAKER_01: 从来没听说过克莱门特·阿德？
818 01:19:11,221 --> 01:19:12,182 说话人 SPEAKER_01: 是的，你听说过，好吧。
819 01:19:12,844 --> 01:19:15,627 说话人 SPEAKER_01: 有没有哪个非法国人听说过克莱门特·阿德？
820 01:19:17,092 --> 01:19:20,917 说话人 SPEAKER_01: 好的，一个人，两个人，基本上没人。
821 01:19:21,078 --> 01:19:22,279 说话人 SPEAKER_01: 你们不知道他是谁，对吧？
822 01:19:22,880 --> 01:19:29,948 说话人 SPEAKER_01: 好的，这个人于 19 世纪末建造了一架蝙蝠形状的飞机，蒸汽动力。
823 01:19:30,850 --> 01:19:32,011 说话人 SPEAKER_01: 他是一位蒸汽机设计师。
824 01:19:33,153 --> 01:19:44,686 说话人 SPEAKER_01：他的飞机实际上是在自己的动力下起飞的，比莱特兄弟早 13 年，在约 50 厘米的高度飞行了大约 50 米，然后撞到了，着陆了。
825 01:19:45,578 --> 01:19:47,480 说话人 SPEAKER_01：基本上是无法控制的。
826 01:19:48,221 --> 01:19:55,110 说话人 SPEAKER_01：所以这个人基本上是照搬了蝙蝠，并认为因为它的形状像蝙蝠，所以它就能飞，对吧？
827 01:19:55,131 --> 01:19:56,332 说话人 SPEAKER_01：这看起来有点天真。
828 01:19:56,453 --> 01:20:13,475 说话者 SPEAKER_01：这根本不天真，但有点过于接近生物学，有点被它迷住了，没有像莱特兄弟那样建造模型、滑翔机、风筝或风洞。
829 01:20:13,456 --> 01:20:16,238 说话者 SPEAKER_01：所以他有点过于接近生物学。
830 01:20:16,819 --> 01:20:27,350 说话者 SPEAKER_01：另一方面，他有一个很大的遗产，那就是他的第二架飞机叫做“Avion”，这个词在法语、西班牙语和葡萄牙语中都是飞机的意思。
831 01:20:27,371 --> 01:20:28,412 说话者 SPEAKER_01：所以他有一些遗产。
832 01:20:29,932 --> 01:20:31,154 说话人 SPEAKER_01: 他有点儿神秘。
833 01:20:31,175 --> 01:20:33,237 说话人 SPEAKER_01: 你知道，这还是在开源之前。
834 01:20:33,737 --> 01:20:36,220 说话人 SPEAKER_01: 所以你从来没有听说过他。
835 01:20:37,640 --> 01:20:38,282 说话人 SPEAKER_01: 非常感谢你。
836 01:20:46,547 --> 01:20:49,693 说话人 SPEAKER_02: 谢谢。
837 01:20:49,733 --> 01:20:50,453 说话人 SPEAKER_02: 谢谢。
838 01:20:50,474 --> 01:20:51,154 说话人 SPEAKER_02: 谢谢，Jeff。
839 01:20:51,234 --> 01:20:51,935 说话人 SPEAKER_02: 谢谢，Jan。
840 01:20:53,578 --> 01:20:54,980 说话人 SPEAKER_02: 请打开会议室的灯光，好吗？
841 01:20:55,360 --> 01:20:58,605 说话人 SPEAKER_02: 我们有两个麦克风，还有时间问几个问题。
842 01:20:59,667 --> 01:21:00,789 说话人 SPEAKER_02: 请打开会议室的灯光。
843 01:21:02,572 --> 01:21:03,694 说话人 SPEAKER_02: 我知道它们之前已经打开了。
844 01:21:06,158 --> 01:21:06,838 说话人 SPEAKER_02: 是的。
845 01:21:07,819 --> 01:21:12,386 说话人 SPEAKER_02: 首先，让我们为 Jan 和 Jeff 的精彩演讲鼓掌。
846 01:21:21,546 --> 01:21:24,489 说话人 SPEAKER_02: 当有人走上麦克风时，我们先来一个小趣闻。
847 01:21:25,289 --> 01:21:28,432 说话人 SPEAKER_02：艾伦·图灵的生日是 1912 年 6 月 23 日。
848 01:21:29,755 --> 01:21:32,896 说话人 SPEAKER_02：所以今天是我们 107 周年诞辰。
849 01:21:33,417 --> 01:21:37,081 说话人 SPEAKER_02：因此，今天我们举行这次难忘的图灵讲座非常合适。
850 01:21:37,341 --> 01:21:40,885 说话人 SPEAKER_02：好的，提问。
851 01:21:43,167 --> 01:21:43,927 说话人 SPEAKER_06: 嗨，两位，谢谢。
852 01:21:44,849 --> 01:21:48,412 说话人 SPEAKER_06: 我非常感兴趣于理解推理的工作。
853 01:21:48,492 --> 01:21:50,793 说话人 SPEAKER_06: 能否给我们分享一下您的想法？
854 01:21:51,466 --> 01:21:54,609 说话人 SPEAKER_06: 神经网络推理的推理方式。
855 01:21:55,530 --> 01:22:02,859 说话人 SPEAKER_07: 好吧，神经网络在 100 毫秒内并行处理的事情上表现得相当不错。
856 01:22:04,162 --> 01:22:07,666 说话人 SPEAKER_07: 到目前为止，它们在长时间段内处理的事情上并不那么出色。
857 01:22:07,685 --> 01:22:13,453 说话人 SPEAKER_07: 尤其是人们批评神经网络的一点是它们不能进行递归。
858 01:22:14,333 --> 01:22:19,060 说话人 SPEAKER_07: 所以当我们理解一个句子时，我们可以进入一个相对从句
859 01:22:19,394 --> 01:22:20,614 说话人 SPEAKER_07: 理解相对从句。
860 01:22:20,635 --> 01:22:24,979 说话人 SPEAKER_07: 我们投入所有努力去理解那个相对从句，然后再回来。
861 01:22:25,539 --> 01:22:29,404 说话人 SPEAKER_07: 那种事情，我们刚开始能够用神经网络来做。
862 01:22:30,265 --> 01:22:31,987 说话人 SPEAKER_07: 所以 Facebook 的人已经做了很多这方面的工作。
863 01:22:32,046 --> 01:22:33,068 说话人 SPEAKER_07：谷歌的人正在做这件事。
864 01:22:33,188 --> 01:22:38,472 说话人 SPEAKER_07：但要做这样的事情，你需要某种记忆。
865 01:22:38,873 --> 01:22:45,399 说话人 SPEAKER_07：在神经网络中通常使用的方法是，你只是拥有另一组神经元，这些神经元是你已有的神经元的副本。
866 01:22:45,860 --> 01:22:47,341 说话人 SPEAKER_07：但这在生物学上是不合理的。
867 01:22:48,233 --> 01:22:50,497 说话人 SPEAKER_07：所以我总是想要一些在生物学上合理的东西。
868 01:22:51,239 --> 01:22:58,136 说话人 SPEAKER_07：在大脑中，这种记忆似乎不太可能是神经活动的副本。
869 01:22:58,617 --> 01:23:01,524 说话人 SPEAKER_07：它是一种可以重现神经活动的联想记忆。
870 01:23:02,326 --> 01:23:04,891 说话人 SPEAKER_07：但它只是用于临时事物的。
871 01:23:06,408 --> 01:23:13,395 说话人 SPEAKER_01：实际上在这方面有很多工作，就是试图填补神经网络无法进行长链推理的空白。
872 01:23:14,457 --> 01:23:29,512 说话人 SPEAKER_01：所以有一个问题，Jeff 已经长期倡导，那就是如果你有基于经典逻辑的推理，它是离散的，因此与基于梯度的学习不兼容。
873 01:23:29,493 --> 01:23:39,346 说话人 SPEAKER_01：那么如何通过用向量替换符号，用连续函数替换逻辑（基本上是参数化的连续函数）来进行推理。
874 01:23:40,087 --> 01:23:43,612 说话人 SPEAKER_01：然后如果你想要进行长链推理，你需要有一个工作记忆。
875 01:23:43,631 --> 01:23:46,195 说话人 SPEAKER_01：杰夫刚刚提到了一个使用快速权重的想法。
876 01:23:46,657 --> 01:23:48,738 说话人 SPEAKER_01：很多人正在研究所谓的记忆网络。
877 01:23:48,760 --> 01:23:59,314 说话人 SPEAKER_01：所以你基本上有一个循环神经网络，它可以访问一个独立的神经网络，这个神经网络也是可微分的，但它构建了特定的架构，使其成为关联记忆。
878 01:23:59,293 --> 01:24:02,177 说话人 SPEAKER_01：这类方法在简单情况下是有效的。
879 01:24:02,279 --> 01:24:19,345 说话人 SPEAKER_01：它们还没有真正扩展到大规模问题，但关于基本上不直接计算答案的神经网络的研究非常有趣，这些神经网络产生一个专门设计来回答所提问题的神经网络。
880 01:24:19,712 --> 01:24:22,617 说话人 SPEAKER_01：视觉问答是这类问题的典型例子。
881 01:24:22,917 --> 01:24:32,949 说话人 SPEAKER_01：你向系统展示一个复杂图像，然后问它，你知道，这张图片中有没有比两个立方体大的中国球体，对吧？
882 01:24:32,970 --> 01:24:37,836 说话人 SPEAKER_01：然后神经网络会生成另一个神经网络，它具有回答该问题的正确模块。
883 01:24:38,476 --> 01:24:41,220 说话人 SPEAKER_01：你可以用反向传播训练整个系统，它竟然能工作真是太神奇了。
884 01:24:42,462 --> 01:24:42,862 说话人 SPEAKER_01：但是它确实工作了。
885 01:24:42,902 --> 01:24:45,905 说话人 SPEAKER_02：还有一个问题？
886 01:24:47,623 --> 01:24:48,926 说话人 SPEAKER_02：哦，对不起，是的，请继续。
887 01:24:49,967 --> 01:24:51,631 说话人 SPEAKER_04：来自东北大学的 Yifan。
888 01:24:52,032 --> 01:25:00,126 说话人 SPEAKER_04：所以我知道很多人对神经网络有疑问，我们只知道神经网络是有效的，但我们不知道它是如何工作的。
889 01:25:00,546 --> 01:25:03,372 说话人 SPEAKER_04：那么您对这个问题有什么看法？
890 01:25:04,381 --> 01:25:05,143 说话人 SPEAKER_01：并不完全是这样。
891 01:25:05,182 --> 01:25:07,207 说话人 SPEAKER_01：我的意思是，我们当然有一些理解。
892 01:25:07,770 --> 01:25:10,457 说话人 SPEAKER_01：我的意思是，首先，我们有权访问机器内部的一切，对吧？
893 01:25:11,378 --> 01:25:16,894 说话人 SPEAKER_01：我的意思是，显然这些模型有数亿个参数，你知道，内部有成千上万的变量。
894 01:25:16,993 --> 01:25:17,836 说话人 SPEAKER_01：这将会很复杂。
895 01:25:17,916 --> 01:25:21,225 说话人 SPEAKER_01：它必须很复杂，因为我们希望他们解决复杂的问题。
896 01:25:21,204 --> 01:25:27,091 说话人 SPEAKER_01：所以认为你能完全理解每一个细节是徒劳的。
897 01:25:28,453 --> 01:25:43,969 说话人 SPEAKER_01：另一方面，我认为对于例如为什么优化在大网络中似乎有效，为什么系统似乎不会陷入局部最小值，或者学习到的表示类型等，有很多理论上的理解。
898 01:25:44,630 --> 01:25:49,795 说话人 SPEAKER_07：关于这一点，我也有话要说，就是大多数人做的事情，
899 01:25:50,078 --> 01:25:51,279 说话人 SPEAKER_07：我们不知道它们是如何工作的。
900 01:25:51,841 --> 01:25:53,524 说话人 SPEAKER_07：我们根本不知道它们是如何做到的。
901 01:25:54,064 --> 01:25:57,850 说话人 SPEAKER_07：所以如果你用神经网络代替人，你并不比用人更糟。
902 01:25:58,471 --> 01:26:03,761 说话人 SPEAKER_07：实际上，你可能更好，因为你可以用神经网络更好地纠正偏差，而不是用人。
903 01:26:04,362 --> 01:26:12,576 说话人 SPEAKER_07: 但是还有其他任务，可能需要使用数据中的数十万个弱规则来进行预测。
904 01:26:13,449 --> 01:26:15,512 说话人 SPEAKER_07: 没有简单的规则。
905 01:26:15,814 --> 01:26:17,697 说话人 SPEAKER_07: 只有大量的弱规则。
906 01:26:17,737 --> 01:26:26,711 说话人 SPEAKER_07: 而大型神经网络会使用它们全部，然后说，你知道，300,000 个规则说“是”，150,000 个规则说“否”，所以可能是“是”。
907 01:26:27,492 --> 01:26:29,534 说话人 SPEAKER_07：如果我问你，它是怎么做到的？
908 01:26:30,172 --> 01:26:35,059 说话人 SPEAKER_07：如果你期待得到一些可以计算这个的计算机代码，那是不可能的。
909 01:26:35,238 --> 01:26:37,121 说话人 SPEAKER_07：这个神经网络里有十亿个权重。
910 01:26:37,561 --> 01:26:40,024 说话人 SPEAKER_07：它是这样做到的，那十亿个权重有这些值。
911 01:26:40,164 --> 01:26:41,766 说话人 SPEAKER_07: 这可能就是你能得到的最好结果。
912 01:26:42,207 --> 01:26:48,074 说话人 SPEAKER_07: 对于那样的决定，你只能接受人们有直觉，他们的直觉告诉他们该怎么做。
913 01:26:48,636 --> 01:26:50,056 说话人 SPEAKER_07: 而神经网络也有直觉。
914 01:26:50,497 --> 01:26:57,987 说话人 SPEAKER_07: 它们的工作方式与人类相似，通过拥有大量的权重共同作用，来表示这个比那个更有可能。
915 01:27:00,127 --> 01:27:00,769 说话人 SPEAKER_02: 谢谢。
916 01:27:00,948 --> 01:27:04,859 说话人 SPEAKER_02: 我知道你在等待，所以你就先说吧，然后我们再从那里继续。
917 01:27:04,878 --> 01:27:05,961 说话人 SPEAKER_03: 对不起，我有一个简短的问题。
918 01:27:06,122 --> 01:27:11,996 说话人 SPEAKER_03: 在其他人工智能方面，比如进化计算之类的，你有什么看法吗？
919 01:27:12,036 --> 01:27:16,768 说话人 SPEAKER_03: 对不起，我没听清你说什么。
920 01:27:17,271 --> 01:27:19,917 说话人 SPEAKER_03: 例如，像进化计算这样的领域。
921 01:27:20,557 --> 01:27:21,880 说话人 SPEAKER_03: 你对这些有什么看法吗？
922 01:27:21,920 --> 01:27:23,863 说话人 SPEAKER_03: 因为你说得好像只有符号和神经网络。
923 01:27:24,163 --> 01:27:25,206 说话人 SPEAKER_03：你说的是进化吗？
924 01:27:25,787 --> 01:27:27,309 说话人 SPEAKER_03：就像遗传编程，这类事情。
925 01:27:27,630 --> 01:27:28,912 说话人 SPEAKER_07：哦，是的。
926 01:27:29,613 --> 01:27:31,516 说话人 SPEAKER_07：我认为这对设置超参数很有帮助。
927 01:27:31,537 --> 01:27:40,412 说话人 SPEAKER_07：也就是说，如果你处于一个高维空间并且想要改进，如果你能获得梯度，你将比那些不能获得梯度的人做得更好。
928 01:27:40,431 --> 01:27:42,756 说话人 SPEAKER_07：我认为大脑是一种获取梯度的设备。
929 01:27:43,680 --> 01:27:51,572 说话人 SPEAKER_07：进化无法获得梯度，因为决定基因型和表型之间关系的大部分因素都在你的控制之外。
930 01:27:51,591 --> 01:27:52,393 说话人 SPEAKER_07：这是环境。
931 01:27:53,094 --> 01:27:58,261 说话人 SPEAKER_07：所以进化必须使用诸如突变、随机变化和重组等技术。
932 01:27:59,542 --> 01:28:00,744 说话人 SPEAKER_07：但我们并不局限于这些。
933 01:28:00,824 --> 01:28:02,667 说话人 SPEAKER_07：我们可以制造出能够获取梯度的设备。
934 01:28:03,349 --> 01:28:06,313 说话人 SPEAKER_07：显然，如果你能够获取梯度，
935 01:28:06,917 --> 01:28:09,180 说话人 SPEAKER_07：您也可以用进化来让那个设备变得更好。
936 01:28:09,881 --> 01:28:21,878 说话人 SPEAKER_07：现在看看神经网络中发生的事情，您使用梯度来训练神经网络，但现在您使用更类似于进化技术的手段来调整超参数。
937 01:28:21,899 --> 01:28:25,264 说话人 SPEAKER_02：我想我们还有时间回答那边的一个问题。
938 01:28:26,408 --> 01:28:26,828 说话人 SPEAKER_05：谢谢。
939 01:28:27,170 --> 01:28:38,961 说话人 SPEAKER_05：所以杨谈到了在自动驾驶汽车中应用 CN 或其它类型的神经网络进行感知，听起来不是很积极。
940 01:28:39,001 --> 01:28:41,127 说话人 SPEAKER_05：那么你能对此发表更多评论吗？
941 01:28:41,849 --> 01:28:52,265 说话人 SPEAKER_01：嗯，已经有很多人宣称，可能更多的是营销导向而非科学导向，完全自动驾驶就在眼前。
942 01:28:53,207 --> 01:28:57,835 说话人 SPEAKER_01：而这比大多数人想象的要困难得多。
943 01：28：58,074 --> 01：29：02,743 演讲者 SPEAKER_01：当然，很多业内人士都知道这很困难，而且不仅仅是指日可待。
我认为在人工智能的许多领域以及人工智能整体上，都存在一个类似的故事，许多人对何时达到人类水平的人工智能抱有非常乐观的期望，例如。
945 01：29：17,740 --> 01：29：19,685 议长 SPEAKER_01：在我看来，这不仅仅是指日可待。
946 01：29：19,666 --> 01：29：27,255 演讲者 SPEAKER_01：当然，在这种情况发生之前，需要弄清楚一些事情，比如如何正确地进行自我监督。
947 01:29:27,695 --> 01:29:29,578 说话人 SPEAKER_01: 但这并非唯一的障碍。
948 01:29:29,677 --> 01:29:31,740 说话人 SPEAKER_01: 这只是我们看到的第一个山峰。
949 01:29:32,081 --> 01:29:34,743 说话人 SPEAKER_01: 而可能还有一大堆我们尚未弄清楚的山峰。
950 01:29:35,145 --> 01:29:39,289 说话人 SPEAKER_01: 所以我认为对于自动驾驶来说，情况也大致如此。
951 01:29:39,550 --> 01:29:47,579 说话人 SPEAKER_01：自动驾驶，很容易在早期获得令人印象深刻的成果，一辆车似乎可以很好地自动驾驶大约半小时。
952 01:29:47,560 --> 01:29:54,872 说话人 SPEAKER_01：但要达到与人类相同水平的可靠性，即每行驶 100 英里或每行驶 1 亿英里发生一次致命事故，我感到抱歉。
953 01:30:01,443 --> 01:30:04,167 说话人 SPEAKER_01：你知道，10 的 6 次方在法国之间是什么？
954 01:30:06,612 --> 01:30:09,355 说话人 SPEAKER_01：那么达到那个水平真的很困难。
955 01:30:09,516 --> 01:30:18,511 说话人 SPEAKER_01：如果你尝试通过观察数据量增加时性能如何提高来推断你需要多少数据才能达到那个水平，这基本上是不切实际的。
956 01:30:18,591 --> 01:30:21,095 说话人 SPEAKER_01：所以我们必须找到训练这些系统的新方法。
957 01:30:21,114 --> 01:30:22,997 说话人 SPEAKER_01：我认为自监督学习是部分答案。
958 01:30:24,560 --> 01:30:24,920 说话人 SPEAKER_01：我们拭目以待。
959 01:30:26,682 --> 01:30:28,185 说话人 SPEAKER_01：这是一个难题。
960 01:30:28,206 --> 01:30:29,768 说话人 SPEAKER_01：你可能会过度设计。
961 01:30:29,747 --> 01:30:32,850 说话人 SPEAKER_01：你可以添加使处理更简单的传感器。
962 01:30:33,011 --> 01:30:35,274 说话人 SPEAKER_01：你可以做详细的地图。
963 01:30:35,514 --> 01:30:38,457 说话人 SPEAKER_01: 你可以在某些条件下做各种事情，使其变得实用。
964 01:30:39,759 --> 01:30:44,104 说话人 SPEAKER_01: 但完全的五级自动驾驶是困难的。
965 01:30:44,123 --> 01:30:44,743 说话人 SPEAKER_05: 非常感谢。
966 01:30:44,804 --> 01:30:46,046 说话人 SPEAKER_02: 好的。
967 01:30:46,065 --> 01:30:48,908 说话人 SPEAKER_02：这样，我知道你们中的许多人都有其他会议活动要参加。
968 01:30:48,948 --> 01:30:50,409 说话人 SPEAKER_02：现在我们已经完成了最后一个问题。
969 01:30:50,831 --> 01:30:57,137 说话人 SPEAKER_02：所以，我再次非常感谢 Jan 和 Jeff 为我们带来一场难忘的图灵讲座。
970 01:30:57,158 --> 01:30:57,358 说话人 SPEAKER_02：谢谢。
971 01:31:05,623 --> 01:31:10,106 说话人 SPEAKER_02：享受剩下的会议，包括今晚的活动。
972 01:31:11,837 --> 01:31:14,047 说话人 SPEAKER_02：谢谢。
