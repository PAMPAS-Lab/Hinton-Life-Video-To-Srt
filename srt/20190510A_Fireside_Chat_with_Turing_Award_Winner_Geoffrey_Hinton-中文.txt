1 00:00:06,275 --> 00:00:07,517 说话人 SPEAKER_01: 你好，我是尼古拉斯·汤普森。
2 00:00:07,597 --> 00:00:09,038 说话人 SPEAKER_01: 我是《连线》杂志的编辑。
3 00:00:09,359 --> 00:00:13,544 说话人 SPEAKER_01: 今天能有机会采访杰弗里·辛顿，我感到非常荣幸。
4 00:00:13,564 --> 00:00:18,289 说话人 SPEAKER_01: 他有很多优点，嗯，我想在介绍中只提两点。
5 00:00:19,111 --> 00:00:21,152 说话人 SPEAKER_01：首先是他坚持不懈。
6 00:00:21,213 --> 00:00:28,242 说话人 SPEAKER_01：他有一个真正相信的想法，其他人说这个想法不好，但他一直坚持。
7 00:00:28,742 --> 00:00:32,146 说话人 SPEAKER_01：这给了所有持有不良想法的人，包括我自己，很大的信心。
8 00:00:32,228 --> 00:00:36,774 说话人 SPEAKER_01：然后第二个人，他把自己的一半时间花在作为管理者裁决职位名称上。
9 00:00:37,494 --> 00:00:43,301 说话人 SPEAKER_01：在介绍之前，我看了他的职位名称，这是历史上最不虚荣的职位名称。
10 00:00:43,362 --> 00:00:47,188 说话人 SPEAKER_01：所以请欢迎杰弗里·辛顿，谷歌的工程研究员。
11 00:00:55,978 --> 00:00:56,298 说话人 SPEAKER_01：欢迎。
12 00:00:56,840 --> 00:00:57,740 说话人 SPEAKER_01：很高兴和你们在这里。
13 00:00:58,281 --> 00:01:02,067 说话人 SPEAKER_01: 好的，那么让我们回到 20 年前。
14 00:01:02,570 --> 00:01:12,870 说话人 SPEAKER_01: 当你写下你早期的一些非常有影响力的论文时，每个人都开始说，这是个好主意，但我们实际上无法用这种方式设计计算机。
15 00:01:13,751 --> 00:01:18,941 说话人 SPEAKER_01: 解释一下你为什么坚持下来，为什么你对找到的东西如此自信。
16 00:01:19,799 --> 00:01:22,283 说话人 SPEAKER_00: 实际上是 40 年前。
17 00:01:23,825 --> 00:01:27,209 说话人 SPEAKER_00：在我看来，大脑似乎没有其他工作方式。
18 00:01:27,349 --> 00:01:30,433 说话人 SPEAKER_00：它必须通过学习连接的优势来工作。
19 00:01:31,555 --> 00:01:35,221 说话人 SPEAKER_00：如果你想让一个设备做些智能的事情，你有两种选择。
20 00:01:35,260 --> 00:01:36,722 说话人 SPEAKER_00：你可以编程它，或者让它学习。
21 00:01:37,103 --> 00:01:40,929 说话人 SPEAKER_00：我们当然没有被编程，所以我们必须学习。
22 00:01:41,010 --> 00:01:42,751 说话人 SPEAKER_00：所以这一定是正确的方向。
23 00:01:43,052 --> 00:01:45,376 说话人 SPEAKER_01：那么，请解释一下，嗯，让我们这么做。
24 00:01:45,736 --> 00:01:46,938 说话人 SPEAKER_01：解释一下神经网络是什么。
25 00:01:46,978 --> 00:01:52,546 这里的大部分人可能都很熟悉，但请解释一下最初的洞察力以及它在您心中的发展过程。
26 00:01:53,429 --> 00:01:57,674 所以你们有相对简单的处理元素，这些元素非常松散地模拟了神经元。
27 00:01:58,656 --> 00:02:00,058 它们有传入的连接。
28 00:02:00,498 --> 00:02:01,820 每个连接都有一个权重。
29 00:02:02,542 --> 00:02:04,504 说话人 SPEAKER_00：那个权重可以改变以进行学习。
30 00:02:05,325 --> 00:02:11,034 说话人 SPEAKER_00：神经元的作用是计算连接上的活动乘以权重，然后将它们全部加起来，
31 00:02:11,014 --> 00:02:13,078 说话人 SPEAKER_00：然后决定是否发送输出。
32 00:02:13,998 --> 00:02:15,901 说话人 SPEAKER_00：如果总和足够大，它就会发送输出。
33 00:02:16,522 --> 00:02:18,504 说话人 SPEAKER_00：如果总和是负数，则不发送任何内容。
34 00:02:19,306 --> 00:02:19,806 说话人 SPEAKER_00：就这么多。
35 00:02:20,908 --> 00:02:30,122 说话人 SPEAKER_00：你只需要用无数个这样的（权重）平方，然后找出如何改变权重，它就能做任何事情。
36 00:02:30,481 --> 00:02:31,764 说话人 SPEAKER_00：这只是个如何改变权重的问题。
37 00:02:32,846 --> 00:02:39,655 说话人 SPEAKER_01：那么你是何时意识到这只是一个近似的大脑工作方式的表示？
38 00:02:40,342 --> 00:02:41,765 说话人 SPEAKER_00：哦，它一直都是这样设计的。
39 00:02:42,467 --> 00:02:44,312 说话人 SPEAKER_00：它被设计成类似于大脑的工作方式。
40 00:02:44,331 --> 00:02:45,413 说话人 SPEAKER_01：但让我问你这个问题。
41 00:02:45,433 --> 00:02:48,319 说话人 SPEAKER_01：在您的职业生涯中，您会在某个时刻开始理解大脑是如何工作的。
42 00:02:48,360 --> 00:02:49,362 说话人 SPEAKER_01：也许是在您 12 岁的时候。
43 00:02:49,423 --> 00:02:50,305 说话人 SPEAKER_01：也许是在您 25 岁的时候。
44 00:02:50,485 --> 00:02:55,094 说话人 SPEAKER_01：您是什么时候决定尝试将计算机建模为大脑的呢？
45 00:02:55,800 --> 00:02:57,862 说话人 SPEAKER_00: 大概就是从那时起，这就是它的全部意义。
46 00:02:59,243 --> 00:03:05,610 说话人 SPEAKER_00: 整个想法是制造一个学习设备，它像大脑一样学习，就像人们认为大脑学习的那样，通过改变连接强度。
47 00:03:06,009 --> 00:03:07,211 说话人 SPEAKER_00: 这不是我的想法。
48 00:03:07,270 --> 00:03:08,793 说话人 SPEAKER_00: 图灵也有同样的想法。
49 00:03:09,092 --> 00:03:18,420 说话人 SPEAKER_00: 图灵，尽管他发明了标准计算机科学的基础，但他认为大脑是一个无组织的设备，带有随机的权重。
50 00:03:19,062 --> 00:03:22,564 说话人 SPEAKER_00: 它将使用强化学习来改变连接。
51 00:03:23,086 --> 00:03:23,925 说话人 SPEAKER_00: 它将学习一切。
52 00:03:24,127 --> 00:03:25,807 说话人 SPEAKER_00: 他认为这是通往智能的最佳途径。
53 00:03:25,788 --> 00:03:31,597 说话人 SPEAKER_01：因此，您遵循图灵的想法，最好的制造机器的方法是模仿人脑。
54 00:03:31,918 --> 00:03:34,260 说话人 SPEAKER_01：这就是人脑的工作方式，所以让我们制造出这样的机器。
55 00:03:34,401 --> 00:03:35,502 说话人 SPEAKER_00：是的，这不仅仅是图灵的想法。
56 00:03:35,563 --> 00:03:36,784 说话人 SPEAKER_00：当时很多人都有这样的想法。
57 00:03:36,806 --> 00:03:37,787 说话人 SPEAKER_01：好吧，所以你有了这个想法。
58 00:03:37,847 --> 00:03:38,989 说话人 SPEAKER_01：很多人都有这个想法。
59 00:03:39,049 --> 00:03:42,995 说话人 SPEAKER_01：你在 80 年代末获得了很多赞誉。
60 00:03:43,034 --> 00:03:45,419 说话人 SPEAKER_01：你的作品发表后开始成名。
61 00:03:45,438 --> 00:03:46,120 说话人 SPEAKER_01：这是正确的吗？
62 00:03:46,139 --> 00:03:46,580 说话人 SPEAKER_00：是的。
63 00:03:46,561 --> 00:03:48,366 说话人 SPEAKER_01：最黑暗的时刻是什么时候？
64 00:03:48,385 --> 00:03:56,486 说话人 SPEAKER_01：是什么时候，其他人开始对这个图灵的想法表示怀疑，并开始退缩，而你却继续前进？
65 00:03:58,474 --> 00:04:02,320 说话人 SPEAKER_00：总有一群人一直相信它，尤其是在心理学领域。
66 00:04:02,983 --> 00:04:11,556 说话人 SPEAKER_00：但在计算机科学家中，我想在 90 年代，发生的事情是数据集相当小，计算机速度也不快。
67 00:04:12,377 --> 00:04:18,288 说话人 SPEAKER_00：在小数据集上，其他方法，比如所谓的支持向量机，效果稍微好一些。
68 00:04:18,949 --> 00:04:21,293 说话人 SPEAKER_00：它们不会因为噪声而混淆得那么严重。
69 00:04:21,273 --> 00:04:24,819 说话人 说话人_00: 这非常令人沮丧，因为我们80年代开发了反向传播算法。
70 00:04:25,321 --> 00:04:26,483 说话人 说话人_00: 我们以为它能解决一切问题。
71 00:04:27,004 --> 00:04:29,307 说话人 说话人_00: 我们对此有些困惑，为什么它不能解决一切问题。
72 00:04:30,269 --> 00:04:34,237 说话人 说话人_00: 这只是规模问题，但我们当时并不真正了解这一点。
73 00:04:34,257 --> 00:04:36,362 说话人 SPEAKER_01：那么为什么你认为它不起作用呢？
74 00:04:37,404 --> 00:04:40,208 说话人 SPEAKER_00：我们认为它不起作用是因为我们没有完全正确的算法。
75 00:04:40,228 --> 00:04:41,990 说话人 SPEAKER_00：我们没有完全正确的目标函数。
76 00:04:42,331 --> 00:04:47,336 说话人 SPEAKER_00：我长时间认为是因为我们试图进行监督学习，而监督学习需要标注数据。
77 00:04:47,637 --> 00:04:51,141 说话人 SPEAKER_00：我们本应该进行无监督学习，即从无标签的数据中进行学习。
78 00:04:52,002 --> 00:04:54,745 说话人 SPEAKER_00：结果证明这主要是一个规模问题。
79 00:04:54,766 --> 00:04:55,466 说话人 SPEAKER_01：哦，这很有趣。
80 00:04:55,487 --> 00:04:58,110 说话人 SPEAKER_01：所以问题是你的数据不够。
81 00:04:58,170 --> 00:05:00,894 说话者 SPEAKER_01: 你以为你有了正确数量的数据，但你并没有正确标注。
82 00:05:00,913 --> 00:05:02,855 说话者 SPEAKER_01: 所以你是误判了问题？
83 00:05:03,173 --> 00:05:06,178 说话者 SPEAKER_00: 我认为使用标签本身就是个错误。
84 00:05:06,199 --> 00:05:11,129 说话者 SPEAKER_00: 你应该尽量在没有任何标签的情况下学习，只是通过尝试模拟数据中的结构。
85 00:05:11,529 --> 00:05:12,732 说话人 SPEAKER_00: 我实际上仍然相信这一点。
86 00:05:12,752 --> 00:05:20,206 说话人 SPEAKER_00: 我认为随着计算机速度的提高，对于任何给定大小的数据集，如果你能让计算机足够快，那么进行无监督学习会更好。
87 00:05:21,209 --> 00:05:25,317 说话人 SPEAKER_00: 一旦你完成了无监督学习，你将能够从更少的标签中学习。
88 00:05:25,533 --> 00:05:27,857 说话人 SPEAKER_01: 所以在 20 世纪 90 年代，你继续进行你的研究。
89 00:05:27,877 --> 00:05:28,718 说话人 SPEAKER_01：你在学术界。
90 00:05:28,798 --> 00:05:31,682 说话人 SPEAKER_01：你还在发表文章，但并未获得赞誉。
91 00:05:31,702 --> 00:05:33,064 说话人 SPEAKER_01：你并没有解决大问题。
92 00:05:33,545 --> 00:05:34,307 说话人 SPEAKER_01：你什么时候开始？
93 00:05:35,387 --> 00:05:38,312 说话人 SPEAKER_01：嗯，实际上，有没有那么一刻，你知道的？
94 00:05:39,514 --> 00:05:40,136 说话人 SPEAKER_01：够了。
95 00:05:40,276 --> 00:05:41,959 说话人 SPEAKER_01：我要去尝试其他的事情。
96 00:05:42,879 --> 00:05:46,987 说话人 SPEAKER_01：不是我要去卖汉堡，而是我要找出另一种做这件事的方式。
97 00:05:47,007 --> 00:05:49,110 说话人 SPEAKER_01：你刚刚说我们要继续做深度学习。
98 00:05:49,192 --> 00:05:50,836 说话人 SPEAKER_00：是的，类似这样的方法必须有效。
99 00:05:50,896 --> 00:05:52,821 说话人 SPEAKER_00：我的意思是，大脑中的连接以某种方式在学习。
100 00:05:53,523 --> 00:05:54,625 说话人 SPEAKER_00：我们只需要找出答案。
101 00:05:55,406 --> 00:05:59,276 说话人 SPEAKER_00: 很可能，有几种不同的方法来学习连接强度。
102 00:05:59,416 --> 00:06:00,379 说话人 SPEAKER_00: 大脑正在使用其中一种。
103 00:06:00,720 --> 00:06:01,843 说话人 SPEAKER_00: 可能还有其他方法来做这件事。
104 00:06:02,283 --> 00:06:04,870 说话人 SPEAKER_00: 但肯定的是，你需要有能够学习这些连接强度的事物。
105 00:06:05,793 --> 00:06:07,115 说话人 SPEAKER_00：我从未怀疑过。
106 00:06:07,096 --> 00:06:08,497 说话人 SPEAKER_01：好的，所以你从未怀疑过。
107 00:06:08,877 --> 00:06:12,202 说话人 SPEAKER_01：它第一次开始像是在工作是什么时候？
108 00:06:12,262 --> 00:06:13,824 说话人 SPEAKER_01：好的，我们有了这个。
109 00:06:14,324 --> 00:06:15,206 说话人 SPEAKER_01：我相信这个想法。
110 00:06:15,225 --> 00:06:18,170 说话人 SPEAKER_01：实际上，如果你眯着眼睛看，你会发现它在起作用。
111 00:06:18,250 --> 00:06:19,232 说话人 SPEAKER_01：那是什么时候发生的？
112 00:06:19,492 --> 00:06:26,940 说话人 SPEAKER_00：好的，所以 80 年代的一个大失望是，如果你制作了很多隐藏层的网络，你无法训练它们。
113 00:06:26,961 --> 00:06:36,072 说话人 SPEAKER_00: 这并不完全正确，因为 Yann LeCun 设计的卷积网络可以用于训练一些相对简单的任务，比如识别手写体。
114 00:06:36,052 --> 00:06:40,778 说话人 SPEAKER_00: 但对于大多数深度网络，我们不知道如何训练它们。
115 00:06:40,798 --> 00:06:47,286 说话人 SPEAKER_00: 大约在 2005 年，我想出了一种进行深度网络无监督训练的方法。
116 00:06:48,086 --> 00:06:55,894 说话人 SPEAKER_00: 因此，你会取你的输入，比如说像素，然后你会学习一些特征检测器，它们擅长解释为什么像素会表现出那样的行为。
117 00:06:56,295 --> 00:07:04,524 说话者 SPEAKER_00: 然后你会把那些特征检测器当作数据，然后你会学习另一组能够解释为什么那些特征检测器有那些相关性的特征检测器。
118 00:07:04,504 --> 00:07:06,067 说话者 SPEAKER_00: 你会不断地学习层与层。
119 00:07:06,788 --> 00:07:17,988 说话者 SPEAKER_00: 而有趣的是，你可以做一些数学证明，每次你学习另一层时，你并不一定有一个更好的数据模型，但你有一个关于你的模型有多好的界限。
120 00:07:18,430 --> 00:07:20,834 说话者 SPEAKER_00: 而且每次你添加另一层时，你都可以得到一个更好的界限。
121 00:07:20,853 --> 00:07:23,137 说话人 SPEAKER_01：你说的模型的好坏限制是什么意思？
122 00:07:23,269 --> 00:07:29,350 说话人 SPEAKER_00：好的，那么在你有了模型之后，你可以问，模型对这个数据有多惊讶？
123 00:07:29,389 --> 00:07:32,519 说话人 SPEAKER_00：你给它一些数据，然后你说，这是你相信的那种类型吗，还是说这很惊讶？
124 00:07:33,161 --> 00:07:36,874 说话人 SPEAKER_00：你可以测量出某种表示这种惊讶程度的东西。
125 00:07:36,971 --> 00:07:38,613 说话人 SPEAKER_00: 你想要的是一个模型。
126 00:07:38,774 --> 00:07:41,637 说话人 SPEAKER_00: 一个好的模型是能够观察数据并说，是的，我知道。
127 00:07:41,798 --> 00:07:42,557 说话人 SPEAKER_00: 这并不令人惊讶。
128 00:07:44,139 --> 00:07:48,985 说话人 SPEAKER_00: 而且通常很难精确计算这个模型认为数据有多令人惊讶。
129 00:07:49,466 --> 00:07:51,088 说话人 SPEAKER_00: 但你可以计算一个界限。
130 00:07:51,108 --> 00:07:55,994 说话人 SPEAKER_00: 你可以说，这个模型认为这些数据比这些更不令人惊讶。
131 00:07:56,735 --> 00:07:59,637 说话人 SPEAKER_00: 你可以证明这一点。
132 00:08:00,098 --> 00:08:03,822 说话人 SPEAKER_00: 随着添加额外的特征检测器层，你得到一个模型。
133 00:08:03,988 --> 00:08:06,716 说话人 说话人_00：每次添加一层，它都会找到数据。
134 00:08:06,995 --> 00:08:09,281 说话人 说话人_00：它发现数据时的惊讶程度限制变得更好。
135 00:08:09,843 --> 00:08:10,283 说话人 说话人_01：哦，我明白了。
136 00:08:10,343 --> 00:08:11,125 说话人 说话人_01：好的，这样就有道理了。
137 00:08:11,146 --> 00:08:15,617 说话人 SPEAKER_01：你在进行观察，它们并不正确，但你清楚它们越来越接近正确。
138 00:08:15,656 --> 00:08:16,579 说话人 SPEAKER_01：我在观察观众。
139 00:08:16,598 --> 00:08:17,841 说话人 SPEAKER_01：我在做一些概括。
140 00:08:18,142 --> 00:08:20,749 说话人 SPEAKER_01：这并不正确，但我越来越擅长它了。
141 00：08：21,134 --> 00：08：21,555 议长 SPEAKER_01：大概？
142 00：08：21,855 --> 00：08：22,216 议长 SPEAKER_00：大概。
143 00：08：22,315 --> 00：08：22,555 议长 SPEAKER_01：好的。
144 00：08：22,877 --> 00：08：26,242 演讲者 SPEAKER_01：大概是 2005 年，你提出了数学上的突破。
145 00:08:26,422 --> 00:08:26,843 说话人 SPEAKER_01: 嗯。
146 00:08:26,862 --> 00:08:29,047 说话人 SPEAKER_01: 你什么时候开始得到正确的答案？
147 00:08:29,307 --> 00:08:30,348 说话人 SPEAKER_01: 你正在处理什么数据？
148 00:08:30,949 --> 00:08:32,652 说话人 SPEAKER_01: 这是语音数据，你在这里首先取得突破。
149 00:08:32,672 --> 00:08:35,476 说话人 SPEAKER_00: 这只是手写的数字，非常简单的数据。
150 00:08:35,876 --> 00:08:39,623 说话人 SPEAKER_00: 然后，在大约同一时间，他们开始开发 GPU。
151 00:08:40,384 --> 00:08:45,673 说话人 SPEAKER_00: 大约在 2007 年，做神经网络的人们开始使用 GPU。
152 00:08:47,458 --> 00:08:54,187 说话人 SPEAKER_00: 我有一个非常优秀的学生叫 Vlad Mni，他开始使用 GPU 在航空图像中寻找道路。
153 00:08:55,269 --> 00:09:03,099 说话人 说话人_00: 他编写了一些代码，然后其他学生使用这些代码利用 GPU 识别语音中的音素。
154 00:09:04,019 --> 00:09:06,504 说话人 说话人_00: 因此他们使用了预训练的想法。
155 00:09:06,543 --> 00:09:12,711 说话人 说话人_00: 在完成所有预训练后，只需在上面贴上标签，然后使用反向传播。
156 00:09:12,731 --> 00:09:16,115 说话人 说话人_00: 结果证明，你可以有一个非常深的网络。
157 00:09:16,096 --> 00:09:21,368 说话人 SPEAKER_00: 这样进行预训练，然后可以使用反向传播，实际上效果很好。
158 00:09:21,388 --> 00:09:24,235 说话人 SPEAKER_00: 它在某种程度上击败了语音识别的基准。
159 00:09:24,655 --> 00:09:29,005 说话人 SPEAKER_01: 初始时，只是略微超过了最好的商用语音识别。
160 00:09:29,046 --> 00:09:31,471 说话人 SPEAKER_01: 它击败了语音识别领域最好的学术成果。
161 00:09:32,278 --> 00:09:35,125 说话人 SPEAKER_00：在一个相对较小的数据集 Timit 上。
162 00:09:35,145 --> 00:09:37,510 说话人 SPEAKER_00：它的表现略好于最佳学术成果。
163 00:09:38,833 --> 00:09:40,357 说话人 SPEAKER_00：同时也在 IBM 工作过。
164 00:09:43,004 --> 00:09:48,616 说话人 SPEAKER_00：很快，人们就意识到这件事。
165 00:09:48,596 --> 00:09:55,003 说话人 SPEAKER_00：因为它打败了那些需要 30 年才能开发的标准模型，再稍加发展，就能做得非常好。
166 00:09:55,703 --> 00:10:01,490 说话人 SPEAKER_00：因此，我的研究生们去了微软、IBM 和谷歌。
167 00:10:01,509 --> 00:10:04,993 说话人 SPEAKER_00：谷歌是最快将其转化为生产级语音识别器的。
168 00:10:05,394 --> 00:10:11,940 说话人 SPEAKER_00：到 2012 年，2009 年开始的那项工作在安卓系统中发布。
169 00:10:12,421 --> 00:10:14,503 说话人 SPEAKER_00：安卓语音识别突然变得更好了。
170 00:10:14,482 --> 00:10:24,591 说话人 SPEAKER_01：那么，请告诉我那个你构思了 40 年、发表了 20 年，最终比同事做得更好的想法。
171 00:10:24,610 --> 00:10:25,894 说话人 SPEAKER_01：那是什么感觉？
172 00:10:26,160 --> 00:10:28,144 说话人 SPEAKER_00：当时，我的想法才构思了 30 年。
173 00:10:28,924 --> 00:10:29,164 说话人 SPEAKER_01: 正确。
174 00:10:29,184 --> 00:10:29,645 说话人 SPEAKER_01: 正确。
175 00:10:29,666 --> 00:10:29,885 说话人 SPEAKER_01: 抱歉。
176 00:10:30,927 --> 00:10:31,808 说话人 SPEAKER_01: 所以有一个新想法。
177 00:10:31,849 --> 00:10:32,870 说话人 SPEAKER_01: 很新鲜。
178 00:10:33,171 --> 00:10:37,738 说话人 SPEAKER_00: 它最终在真实问题上达到了最先进的状态，感觉真的很好。
179 00:10:37,878 --> 00:10:42,323 说话人 SPEAKER_01: 你还记得你第一次得到启示性数据时你在哪里吗？
180 00:10:42,985 --> 00:10:44,147 说话人 SPEAKER_00: 不记得了。
181 00:10:44,167 --> 00:10:44,606 说话人 SPEAKER_01: 不。
182 00:10:44,626 --> 00:10:44,768 说话人 SPEAKER_01: 不。
183 00:10:44,827 --> 00:10:45,248 说话人 SPEAKER_01: 好的。
184 00:10:45,268 --> 00:10:45,609 说话人 SPEAKER_01: 好吧。
185 00:10:45,629 --> 00:10:48,852 说话人 SPEAKER_01：所以你意识到它在语音识别上有效。
186 00:10:49,453 --> 00:10:52,118 说话人 SPEAKER_01：你什么时候开始将其应用于其他问题？
187 00:10:52,232 --> 00:10:54,434 说话人 SPEAKER_00：然后我们开始将其应用于各种其他问题。
188 00:10:54,895 --> 00:11:02,903 说话人 SPEAKER_00：所以乔治·达尔（George Dahl），他是进行原始语音识别工作的人之一，将这种方法应用于，我给你很多分子的描述符。
189 00:11:03,585 --> 00:11:08,129 说话人 SPEAKER_00：你想预测这个分子是否会与某种物质结合，从而成为一款好药。
190 00:11:09,070 --> 00:11:10,370 说话人 SPEAKER_00：在 Cargill 举行了一场竞赛。
191 00:11:11,032 --> 00:11:16,817 说话人 SPEAKER_00：他只是将我们为语音识别设计的标准技术应用于预测药物活性。
192 00:11:17,339 --> 00:11:18,779 说话人 SPEAKER_00：并且赢得了竞赛。
193 00:11:18,759 --> 00:11:21,303 说话人 SPEAKER_00：这就是一个迹象，表明这些东西相当普遍。
194 00:11:21,865 --> 00:11:29,796 说话人 SPEAKER_00：然后我有一个学生叫伊利亚·苏特科娃，他说，杰夫，这些方法对图像识别也会有效。
195 00:11:30,157 --> 00:11:32,841 说话人 SPEAKER_00：而李飞飞已经为它创建了正确的数据集。
196 00:11:32,880 --> 00:11:34,864 说话人 SPEAKER_00：并且有一个公开的比赛。
197 00:11:34,903 --> 00:11:36,886 说话人 SPEAKER_00: 我们必须这么做。
198 00:11:36,866 --> 00:11:41,799 说话人 SPEAKER_00: 因此我们采用了最初由 Yann LeCun 开发的方案。
199 00:11:44,246 --> 00:11:51,687 说话人 SPEAKER_00: 一个名叫 Alex Krashevsky 的学生，他是一位真正的巫师，能够让 GPU 做任何事情，编程能力非常强。
200 00:11:51,885 --> 00:11:56,913 说话人 SPEAKER_00: 我们得到了比标准计算机视觉更好的结果。
201 00:11:56,932 --> 00:11:58,034 说话人 SPEAKER_00: 那是 2012 年。
202 00:11:58,434 --> 00:12:02,301 说话人 SPEAKER_00: 我认为这是一个巧合，因为安卓系统推出了语音识别。
203 00:12:02,341 --> 00:12:04,423 说话人 SPEAKER_00: 所以你知道这些技术可以解决生产问题。
204 00:12:05,566 --> 00:12:10,952 说话人 SPEAKER_00: 2012 年在视觉领域，它已经比标准计算机视觉做得更好了。
205 00:12:11,433 --> 00:12:13,317 说话人 SPEAKER_01：那么这是它成功的三个领域。
206 00:12:13,397 --> 00:12:16,541 说话人 SPEAKER_01：建模化学、语音、声音。
207 00:12:16,881 --> 00:12:17,842 说话人 SPEAKER_01：它在哪些方面失败了？
208 00:12:19,628 --> 00:12:21,431 说话人 SPEAKER_00：失败只是暂时的，你明白。
209 00:12:23,673 --> 00:12:24,375 说话人 SPEAKER_00: 它在哪里失败？
210 00:12:26,157 --> 00:12:30,624 说话人 SPEAKER_00: 对于像机器翻译这样的任务，我认为我们还需要很长时间才能做到。
211 00:12:31,485 --> 00:12:36,692 说话人 SPEAKER_00: 因为机器翻译，你有一个符号串输入，然后输出一个符号串。
212 00:12:37,033 --> 00:12:43,662 说话人 SPEAKER_00: 在这之间，你可以在符号串上进行操作，这正是传统人工智能所做的事情。
213 00:12:43,642 --> 00:12:45,485 说话人 SPEAKER_00：实际上，它并不是这样工作的。
214 00:12:45,865 --> 00:12:46,908 说话人 SPEAKER_00：符号串就出现了。
215 00:12:46,967 --> 00:12:49,312 说话人 SPEAKER_00：你把它们转换成大脑中的巨大向量。
216 00:12:49,352 --> 00:12:50,816 说话人 SPEAKER_00：这些向量相互作用。
217 00:12:51,115 --> 00:12:53,782 说话人 SPEAKER_00: 然后将它转换回符号字符串输出。
218 00:12:54,984 --> 00:13:06,426 说话人 SPEAKER_00: 如果你在 2012 年告诉我，在接下来的五年里，我们只需使用同样的技术就能在许多语言之间进行翻译，
219 00:13:06,405 --> 00:13:12,816 说话人 SPEAKER_00: 循环神经网络，但只是从随机初始权重开始的随机梯度下降。
220 00:13:12,836 --> 00:13:13,657 说话人 SPEAKER_00: 我是不会相信你的。
221 00:13:13,817 --> 00:13:15,399 说话人 说话人_00: 发生得比预期的要快得多。
222 00:13:16,000 --> 00:13:24,133 说话人 说话人_01: 但是什么区分了它工作得最快和需要更多时间的地方？
223 00:13:24,552 --> 00:13:34,427 说话人 说话人_01: 看起来视觉处理、语音识别，这些是我们通过感官感知做的核心人类事情，似乎是第一个需要克服的障碍。
224 00:13:34,648 --> 00:13:35,669 说话人 说话人_01: 这样说对吗？
225 00:13:35,649 --> 00:13:38,373 说话人 SPEAKER_00: 是的，不是的，因为我们还做其他事情，比如电机控制。
226 00:13:38,413 --> 00:13:39,654 说话人 SPEAKER_00: 我们在电机控制方面非常出色。
227 00:13:39,695 --> 00:13:41,136 说话人 SPEAKER_00: 我们的大脑显然是为这个目的而设计的。
228 00:13:41,798 --> 00:13:48,306 说话人 SPEAKER_00: 而且现在神经网络才刚刚开始与最好的其他技术竞争。
229 00:13:48,326 --> 00:13:51,129 说话人 SPEAKER_00: 他们最终会赢，但现在他们才刚刚开始赢。
230 00:13:51,931 --> 00:13:59,880 说话人 SPEAKER_00: 我认为像推理、抽象推理这样的东西将是最后我们学会做的事情。
231 00:14:00,581 --> 00:14:03,345 说话人 SPEAKER_00: 我认为它们将是这些神经网络最后学会做的事情之一。
232 00:14:03,562 --> 00:14:09,436 说话人 SPEAKER_01: 所以你一直说神经网络最终会在所有事情上获胜。
233 00:14:09,756 --> 00:14:11,039 说话人 说话人_00：嗯，我们是神经网络，对吧？
234 00:14:11,120 --> 00:14:12,243 说话人 说话人_00：我们能做的，它们都能做。
235 00:14:12,583 --> 00:14:14,347 说话人 说话人_01：没错，但仅仅因为人类
236 00:14:15,356 --> 00:14:20,903 说话人 说话人_01：人脑并不一定是迄今为止最有效的计算机器。
237 00:14:21,443 --> 00:14:23,125 说话人 SPEAKER_01：那么为什么不能有呢？
238 00:14:23,145 --> 00:14:24,366 说话人 SPEAKER_01：当然不是我的大脑。
239 00:14:24,888 --> 00:14:29,113 说话人 SPEAKER_01：难道就没有一种比人脑更高效的方式来模拟机器吗？
240 00:14:29,472 --> 00:14:33,899 说话人 SPEAKER_00：从哲学上讲，我对存在某种完全不同的方法来完成这一切的想法没有异议。
241 00:14:34,119 --> 00:14:41,246 说话人 SPEAKER_00：也许如果你从逻辑开始，尝试自动化逻辑，并制作一些非常复杂的定理证明器，
242 00:14:41,226 --> 00:14:43,870 说话人 SPEAKER_00：然后进行推理。
243 00:14:44,230 --> 00:14:46,975 说话人 SPEAKER_00：然后你决定通过推理来进行视觉感知。
244 00:14:47,655 --> 00:14:49,097 说话人 SPEAKER_00：这种做法可能会获胜。
245 00:14:49,278 --> 00:14:50,219 说话人 说话人_00：结果证明并没有。
246 00:14:50,779 --> 00:14:52,783 说话人 说话人_00：但我对它获奖没有哲学上的反对意见。
247 00:14:53,464 --> 00:14:55,486 说话人 说话人_00：只是我们知道大脑可以做到这一点。
248 00:14:56,989 --> 00:14:57,208 说话人 说话人_01：没错。
249 00:14:57,769 --> 00:15:01,895 说话人 SPEAKER_01：但是也有一些事情，我们的大脑做不好。
250 00:15:02,115 --> 00:15:05,039 说话人 SPEAKER_01：这些事情神经网络也不太可能做得好？
251 00:15:06,320 --> 00:15:07,741 说话人 SPEAKER_01：很可能，是的。
252 00:15:07,761 --> 00:15:13,148 说话人 SPEAKER_01：然后还有一个问题，就是我们并不完全清楚这些事情是如何工作的。
253 00:15:13,368 --> 00:15:14,809 说话人 SPEAKER_00: 不，我们真的不知道它们是如何工作的。
254 00:15:14,830 --> 00:15:19,335 说话人 SPEAKER_01: 我们不明白自上而下的神经网络是如何工作的。
255 00:15:19,355 --> 00:15:23,078 说话人 SPEAKER_01: 甚至连神经网络工作的核心元素我们都不理解。
256 00:15:23,419 --> 00:15:28,304 说话人 SPEAKER_01: 好吧，解释一下，然后让我问一个明显的后续问题，那就是，我们不知道这些是如何工作的。
257 00:15:28,325 --> 00:15:29,125 说话人 SPEAKER_01: 这些东西是如何工作的？
258 00:15:29,306 --> 00:15:31,668 说话人 SPEAKER_01: 好的。
259 00:15:31,688 --> 00:15:32,951 说话人 SPEAKER_00: 你问我解释完之后。
260 00:15:33,211 --> 00:15:34,993 说话人 SPEAKER_00: 是的。
261 00:15:37,201 --> 00:15:41,730 说话人 SPEAKER_00：如果你看看当前的计算机视觉系统，它们大多数基本上都是前馈的。
262 00:15:42,451 --> 00:15:44,033 说话人 SPEAKER_00：它们不使用反馈连接。
263 00:15:44,676 --> 00:15:48,964 说话人 SPEAKER_00：关于当前计算机视觉系统还有一点，那就是它们非常容易受到对抗性样本的影响。
264 00:15:49,705 --> 00:15:53,572 说话人 SPEAKER_00：你只需稍微改变几个像素。
265 00:15:54,024 --> 00:16:00,219 说话人 SPEAKER_00: 然后有一张熊猫的图片，在你看来它仍然像一只熊猫，突然说那是鸵鸟。
266 00:16:01,140 --> 00:16:05,171 说话人 SPEAKER_00: 显然，改变像素的方式设计得很巧妙，足以让它误以为是鸵鸟。
267 00:16:06,934 --> 00:16:09,620 说话人 SPEAKER_00: 但关键是，它在你看来仍然和熊猫一模一样。
268 00:16:09,600 --> 00:16:12,065 说话人 SPEAKER_00: 起初，我们认为这些方法效果非常好。
269 00:16:12,184 --> 00:16:18,054 说话者 说话者_00：但是，当他们面对一个事实，即看到一只熊猫却确信它是鸵鸟时，你会感到有些担忧。
270 00:16:18,836 --> 00:16:24,745 说话者 说话者_00：我认为那里的问题部分在于他们没有尝试从高级表示中重建。
271 00:16:25,326 --> 00:16:28,692 说话者 说话者_00：他们试图进行判别性学习，即只是学习特征检测器层。
272 00:16:29,274 --> 00:16:35,845 说话者 说话者_00：整个目标就是改变权重，以便你能够更好地得到正确答案。
273 00:16:36,009 --> 00:16:44,722 说话人 SPEAKER_00：他们并没有在每个特征检测器级别上检查是否可以从这些特征检测器的活动中重建下一层的原始数据。
274 00:16:45,544 --> 00:16:57,783 说话人 SPEAKER_00：最近在多伦多，我们发现，或者尼克·弗罗斯特（Nick Frost）发现，如果你引入重建，那么它可以帮助你更好地抵抗对抗攻击。
275 00:16:57,803 --> 00:17:00,027 说话人 SPEAKER_00：所以我认为在人类的视觉中，
276 00:17:00,006 --> 00:17:08,460 说话人 SPEAKER_00：为了进行学习，我们在进行重建，而且因为我们通过重建进行了大量的学习，所以我们更能抵抗对抗攻击。
277 00:17:08,480 --> 00:17:18,654 说话者 SPEAKER_01：但你认为神经网络中的自上而下的通信是您如何测试、如何重建、如何测试并确保它是一只熊猫而不是鸵鸟的方式吗？
278 00:17:18,674 --> 00:17:23,803 说话者 SPEAKER_01：我认为这是至关重要的，是的，因为我认为如果您……但是脑科学家对此并不完全一致，对吗？
279 00:17:25,436 --> 00:17:35,385 说话者 SPEAKER_00：脑科学家都同意这样的观点，如果在感知通路中的两个皮层区域之间有连接，那么总会有反向连接。
280 00:17:35,886 --> 00:17:39,176 说话者 SPEAKER_00：不一定是一对一的，但总会有一个反向通路。
281 00:17:39,595 --> 00:17:41,156 说话人 SPEAKER_00: 他们还没有达成一致意见，这究竟是为了什么。
282 00:17:41,576 --> 00:17:43,479 说话人 SPEAKER_00: 可能是为了引起注意。
283 00:17:43,499 --> 00:17:45,080 说话人 SPEAKER_00: 可能是为了学习。
284 00:17:45,101 --> 00:17:46,442 说话人 SPEAKER_00: 或者可能是为了重建。
285 00:17:47,042 --> 00:17:47,963 说话人 SPEAKER_00：或者可能是三者都适用。
286 00:17:48,084 --> 00:17:51,647 说话人 SPEAKER_01：所以我们不知道反向通信是什么。
287 00:17:52,567 --> 00:18:01,958 说话人 SPEAKER_01：你在构建新的神经网络时是基于这样的假设，或者你在构建反向通信，这种通信是为了重建而加入到你的神经网络中，尽管我们不确定大脑就是这样工作的。
288 00:18:02,278 --> 00:18:02,439 说话人 SPEAKER_00：是的。
289 00:18:02,699 --> 00:18:03,380 说话人 SPEAKER_01: 这不是作弊吗？
290 00:18:03,400 --> 00:18:08,505 说话人 SPEAKER_01: 我是说，如果你试图让它像大脑一样，你做了一些我们不确定是否像大脑的事情。
291 00:18:08,484 --> 00:18:09,205 说话人 SPEAKER_00: 完全不是。
292 00:18:11,671 --> 00:18:13,394 说话人 SPEAKER_00: 我不是在做计算神经科学。
293 00:18:13,433 --> 00:18:15,857 说话人 SPEAKER_00：也就是说，我并不是试图建立一个如何大脑工作的模型。
294 00:18:16,238 --> 00:18:19,703 说话人 SPEAKER_00：我是在观察大脑，并说，这东西是有效的。
295 00:18:20,285 --> 00:18:24,532 说话人 SPEAKER_00：如果我们想制造出其他有效的东西，我们应该从中寻找灵感。
296 00:18:24,893 --> 00:18:27,538 说话人 SPEAKER_00：所以这是神经启发的，而不是一个神经网络模型。
297 00:18:27,959 --> 00:18:33,327 说话人 SPEAKER_00：我们使用的神经元，它们受到这样一个事实的启发，即神经元有很多连接，并且会改变连接的强度。
298 00:18:33,307 --> 00:18:33,929 说话人 SPEAKER_01：这很有趣。
299 00:18:33,969 --> 00:18:49,487 说话人 SPEAKER_01：如果我是计算机科学领域的人，并且我在研究神经网络，并且我想打败杰夫·辛顿，我可以做的一件事是，我可以构建自上而下的通信，并基于其他脑科学模型，基于学习而不是重建。
300 00:18:49,507 --> 00:18:51,909 说话人 SPEAKER_00：如果它们是更好的模型，那么你就会赢，是的。
301 00:18:52,150 --> 00:18:53,611 说话人 SPEAKER_01：这非常、非常有趣。
302 00:18:53,651 --> 00:18:56,835 说话人 SPEAKER_01：好吧，那么让我们转向一个更普遍的话题。
303 00:18:57,135 --> 00:18:59,199 说话人 SPEAKER_01：神经网络将能够解决各种问题。
304 00:18:59,660 --> 00:19:06,109 说话人 SPEAKER_01：人类大脑中有没有神经网络无法捕捉或无法解决的奥秘？
305 00：19：06,269 --> 00：19：08,532 议长 SPEAKER_01：比如说，情绪可以吗？
306 00:19:08,594 --> 00:19:09,234 说话者 SPEAKER_01：不。
307 00:19:09,255 --> 00:19:09,795 说话者 SPEAKER_01：不。
308 00：19：09,815 --> 00：19：12,058 演讲者 SPEAKER_01：所以爱可以通过神经网络重建。
309 00:19:12,439 --> 00:19:13,842 说话人 SPEAKER_01：意识是可以构建的。
310 00:19:14,342 --> 00:19:14,883 说话人 SPEAKER_00：当然。
311 00:19:14,942 --> 00:19:19,329 说话人 SPEAKER_00：一旦你弄清楚这些事物的含义，我们就变成了神经网络，对吧？
312 00:19:20,541 --> 00:19:22,934 说话人 SPEAKER_00：现在，我对意识特别感兴趣。
313 00:19:22,954 --> 00:19:27,378 说话人 说话人_00：没有它我也能过得去。
314 00:19:29,823 --> 00:19:32,007 说话人 说话人_00：人们实际上并不真正知道它的意思。
315 00:19:32,047 --> 00:19:33,509 说话人 说话人_00：有各种各样的定义。
316 00:19:33,890 --> 00:19:35,551 说话人 说话人_00：我认为这是一个前科学术语。
317 00:19:35,972 --> 00:19:40,421 说话人 说话人_00：100年前，如果你问人们，什么是生命？
318 00:19:41,422 --> 00:19:43,486 说话人 说话人_00：他们会说，嗯，生物有生命力。
319 00:19:43,526 --> 00:19:45,107 说话人 说话人_00：而它们死亡时，生命力就会消失。
320 00:19:45,548 --> 00:19:51,038 说话人 说话人_00：这就是生与死的区别，是否有生命力。
321 00:19:51,018 --> 00:19:54,741 说话人 SPEAKER_00: 现在我们不认为我们没有生命力。
322 00:19:55,102 --> 00:19:57,044 说话人 SPEAKER_00: 我们只是认为它是一个前科学概念。
323 00:19:57,384 --> 00:20:02,328 说话者 SPEAKER_00：一旦你理解了一些生物化学和分子生物学，你就不需要生命力了。
324 00:20:02,529 --> 00:20:03,810 说话者 SPEAKER_00：你理解了它实际上是如何运作的。
325 00:20:04,431 --> 00:20:05,913 说话者 SPEAKER_00：我认为意识也会是这样。
326 00:20:05,952 --> 00:20:12,159 说话者 SPEAKER_00：我认为意识是试图用某种特殊本质来解释心理现象的一种尝试。
327 00:20:13,039 --> 00:20:15,122 说话者 SPEAKER_00: 这特殊精华，你不需要它。
328 00:20:15,201 --> 00:20:16,923 说话者 SPEAKER_00: 一旦你真的能解释清楚，
329 00:20:16,903 --> 00:20:28,419 说话者 SPEAKER_00: 那你就将解释我们如何做那些让人认为我们有意识的事情，你将解释所有这些关于意识的不同含义，而不需要某种特殊的意识精华。
330 00:20:29,961 --> 00:20:43,417 说话者 SPEAKER_01: 对，没有一种情感不能被创造，没有一种思想不能被创造，没有人类心智能做到的事情不能在理论上通过一个完全运作的神经网络被重新创造，一旦我们真正理解了大脑是如何工作的。
331 00:20:43,499 --> 00:20:48,865 说话人 SPEAKER_00：约翰·列侬的歌曲中有一段听起来非常像你刚才说的。
332 00:20:48,885 --> 00:20:50,387 说话人 SPEAKER_00：你对此有 100%的信心吗？
333 00:20:51,930 --> 00:20:54,472 说话人 SPEAKER_00：不，我是一个贝叶斯主义者，所以我有 99.9%的信心。
334 00:20:57,136 --> 00:20:57,416 说话人 SPEAKER_01：好的。
335 00:20:57,738 --> 00:20:58,479 说话者 SPEAKER_01：那么第一点是什么？
336 00:20:59,440 --> 00:21:05,146 说话者 SPEAKER_00：比如说，我们可能都参与了一个大型的模拟。
337 00:21:05,166 --> 00:21:05,346 说话者 SPEAKER_01：确实。
338 00:21:05,508 --> 00:21:05,867 说话者 SPEAKER_01：公平。
339 00:21:05,968 --> 00:21:07,329 说话人 SPEAKER_01: 好的。
340 00:21:15,528 --> 00:21:17,674 说话人 SPEAKER_01: 这实际上让我觉得我们更有可能是。
341 00:21:19,359 --> 00:21:19,621 说话人 SPEAKER_01: 好的。
342 00:21:19,922 --> 00:21:23,934 说话人 SPEAKER_01: 那么我们在做这件事和研读大脑以改进计算机的过程中，我们学到了什么？
343 00:21:24,798 --> 00:21:25,660 说话人 SPEAKER_01：反向操作是如何工作的？
344 00:21:25,700 --> 00:21:28,710 说话人 SPEAKER_01：我们从工作计算机中学到了关于大脑的哪些知识？
345 00:21:29,432 --> 00:21:50,039 说话人 SPEAKER_00：所以我认为在过去的 10 年里，我们学到的是，如果你有一个拥有数十亿参数的系统，并在某个目标函数中进行随机梯度下降，目标函数可能是获取正确的标签，或者是在一串单词中填补空缺，或者任何旧的目标函数，
346 00:21:50,019 --> 00:21:53,786 说话人 SPEAKER_00：它表现得比它应有的要好得多。
347 00:21:53,806 --> 00:21:55,348 说话人 SPEAKER_00: 它的工作效果比您预期的要好得多。
348 00:21:56,130 --> 00:22:07,208 说话人 SPEAKER_00: 您会认为，而且大多数传统人工智能领域的人都会认为，从一个拥有十亿参数的系统开始，用随机值初始化，测量目标函数的梯度。
349 00:21:07,268 --> 00:21:13,699 说话人 SPEAKER_00: 也就是说，对于每个参数，找出如果稍微改变该参数，目标函数会如何变化。
350 00:21:14,522 --> 00:21:21,272 说话人 SPEAKER_00: 然后按照改善目标函数的方向改变它，您会认为这会是一种无望的算法，会导致严重退化。
351 00:22:21,953 --> 00:22:27,301 说话人 SPEAKER_00: 结果证明这是一个非常好的算法，而且规模越大，效果越好。
352 00:22:28,002 --> 00:22:30,086 说话人 SPEAKER_00: 这实际上是一个经验发现。
353 00:22:30,606 --> 00:22:33,290 说话人 SPEAKER_00: 现在有一些理论正在出现，但基本上还是一个经验发现。
354 00:22:33,270 --> 00:22:45,478 说话人 SPEAKER_00: 现在，因为我们已经发现了这一点，所以大脑在计算某个目标函数的梯度并更新突触强度的权重以跟随该梯度的可能性就大得多。
355 00:22:45,498 --> 00:22:48,765 说话人 SPEAKER_00: 我们必须弄清楚它是如何获取梯度和目标函数的。
356 00:22:48,796 --> 00:22:50,897 说话人 SPEAKER_01: 但我们并不了解大脑这方面。
357 00:22:50,938 --> 00:22:52,179 说话人 SPEAKER_01: 我们并不了解突触的重加权。
358 00:22:52,199 --> 00:22:52,839 说话人 SPEAKER_00: 这是一种理论。
359 00:22:52,900 --> 00:22:55,863 说话人 SPEAKER_00: 我的意思是，很久以前，人们认为这是可能的。
360 00:22:56,624 --> 00:23:07,934 说话人 SPEAKER_00: 但在幕后，总有那种传统的计算机科学家说，是的，但是这个一切随机的想法，你只是通过梯度下降来学习，对于十亿个参数来说，这永远不会行得通。
361 00:23:08,076 --> 00:23:09,616 说话人 SPEAKER_00: 你必须植入很多知识。
362 00:23:10,038 --> 00:23:11,759 说话人 SPEAKER_00: 而我们现在知道这是错误的。
363 00:23:11,878 --> 00:23:14,382 说话人 SPEAKER_00: 你可以随意输入参数，然后学习所有内容。
364 00:23:14,547 --> 00:23:15,608 说话人 SPEAKER_01: 那么让我们扩展一下。
365 00:23:15,628 --> 00:23:23,940 说话人 SPEAKER_01: 随着我们不断学习，我们可能会继续更多地了解人类大脑的功能，因为我们对这些基于我们认为其功能的方式运行的模型进行大规模测试。
366 00:23:25,102 --> 00:23:35,135 说话人 SPEAKER_01: 一旦我们更好地理解了它，是否有一个点，我们可以基本上重新连接我们的大脑，使其更像最有效的机器，或者改变我们的思维方式？
367 00:23:36,617 --> 00:23:39,221 说话人 SPEAKER_01：如果这是一个模拟，那应该很容易，但不是在模拟中。
368 00:23:39,336 --> 00:23:46,229 说话人 SPEAKER_00：你可能会认为，如果我们真正理解了正在发生的事情，我们应该能够使教育等工作做得更好。
369 00:23:46,349 --> 00:23:47,491 说话人 SPEAKER_00：是的。
370 00:23:47,692 --> 00:23:48,353 说话人 SPEAKER_00：我认为我们会。
371 00:23:48,953 --> 00:23:49,255 Speaker SPEAKER_01: 我们会的。
372 00:23:49,494 --> 00:23:49,695 Speaker SPEAKER_00: 嗯。
373 00:23:50,175 --> 00:23:58,932 Speaker SPEAKER_00: 如果你能最终理解你的大脑是如何学习和运作的，却不能适应环境以更好地学习，那就非常奇怪了。
374 00:23:59,079 --> 00:24:01,042 Speaker SPEAKER_01: 好的，我不想把话题扯得太远。
375 00:24:01,103 --> 00:24:07,894 说话人 SPEAKER_01：但再过几年，你认为我们会如何利用我们对大脑的了解以及深度学习的工作原理来改变教育的运作方式？
376 00:24:07,913 --> 00:24:09,375 说话人 SPEAKER_01：你将如何改变课堂？
377 00:24:09,797 --> 00:24:12,580 说话人 SPEAKER_00：再过几年，我不确定我们会学到多少。
378 00:24:13,461 --> 00:24:16,145 说话人 SPEAKER_00：我认为改变教育将会是一个漫长的过程。
379 00:24:16,186 --> 00:24:19,932 说话人 SPEAKER_00: 但如果你看看，助手现在变得越来越聪明了。
380 00:24:20,333 --> 00:24:27,483 说话人 SPEAKER_00: 一旦助手能够真正理解对话，它们就可以与孩子进行对话并教育他们。
381 00:24:27,463 --> 00:24:34,814 说话人 SPEAKER_00: 我认为我获得的大部分新知识都来自于我思考，我好奇，然后在谷歌上打字，谷歌告诉我。
382 00:24:35,013 --> 00:24:36,997 说话人 SPEAKER_00: 如果我能进行对话，我就能更好地获取知识。
383 00:24:37,497 --> 00:24:55,902 说话人 SPEAKER_01：从理论上讲，随着我们对大脑了解的加深，以及我们将孩子们放在助手面前，现在是我的助手，几乎肯定基于纽约的时间，正在对 Alexa 大喊播放 Spotify 上的歌曲，可能是《小黄鱼》，你们将编程助手与孩子们进行更好的对话，基于我们知道他们将如何学习。
384 00:24:56,167 --> 00:24:57,851 说话人 SPEAKER_00：我并没有真正考虑过这个问题。
385 00:24:57,931 --> 00:24:58,672 说话人 SPEAKER_00：这不是我做的事情。
386 00:24:59,113 --> 00:25:01,276 说话人 SPEAKER_00：但这在我看来似乎是相当合理的。
387 00:25:02,538 --> 00:25:05,461 Speaker SPEAKER_01: 我们能否理解梦境是如何运作的？
388 00:25:05,883 --> 00:25:06,844 Speaker SPEAKER_01: 这是一大谜团。
389 00:25:07,045 --> 00:25:08,467 Speaker SPEAKER_00: 是的，我对梦境非常感兴趣。
390 00:25:09,147 --> 00:25:10,068 Speaker SPEAKER_00: 我非常感兴趣。
391 00:25:10,088 --> 00:25:11,932 说话人 SPEAKER_00: 我至少有四种关于梦的理论。
392 00:25:12,113 --> 00:25:12,854 说话人 SPEAKER_00: 让我们听听它们都是什么。
393 00:25:13,013 --> 00:25:13,755 说话人 SPEAKER_02: 一、二、三、四。
394 00:25:15,135 --> 00:25:19,041 说话人 SPEAKER_00: 所以很久以前，有 Hopfield 网络。
395 00:25:19,682 --> 00:25:22,547 说话者 SPEAKER_00: 他们会将记忆作为局部吸引子来学习。
396 00:25:23,828 --> 00:25:28,174 说话者 SPEAKER_00: 而 Hopfield 发现，如果你试图放入太多的记忆，它们会变得混乱。
397 00:25:29,136 --> 00:25:32,642 说话者 SPEAKER_00: 它们会将两个局部吸引子合并成一个位于中间的吸引子。
398 00:25:32,682 --> 00:25:39,050 说话者 SPEAKER_00: 然后，Francis Crick 和 Graham Mitchison 出现了，他们说，
399 00:25:39,587 --> 00:25:42,332 说话人 SPEAKER_00: 我们可以通过反向学习来消除这些假极小值。
400 00:25:43,333 --> 00:25:45,375 说话人 SPEAKER_00: 因此我们关闭了输入。
401 00:25:45,915 --> 00:25:47,959 说话人 SPEAKER_00: 我们将神经网络置于随机状态。
402 00:25:48,500 --> 00:25:49,500 说话人 SPEAKER_00: 我们让它稳定下来。
403 00:25:49,942 --> 00:25:51,022 说话者 SPEAKER_00: 我们说，这是不好的。
404 00:25:51,584 --> 00:25:54,227 说话者 SPEAKER_00: 改变连接，以免陷入那种状态。
405 00:25:54,247 --> 00:25:59,855 说话者 SPEAKER_00: 如果你这样做一点，它将能够存储更多的记忆。
406 00:26:00,675 --> 00:26:08,987 说话者 SPEAKER_00: 然后，Terry Sanofsky 和我来了，我们说，看，如果我们不仅有存储记忆的神经元，还有许多其他的神经元，
407 00:26:09,321 --> 00:26:13,393 说话人 SPEAKER_00: 我们能否找到一个算法，利用这些其他神经元来帮助你存储记忆？
408 00:26:14,134 --> 00:26:17,242 说话人 SPEAKER_00: 结果，最后我们提出了玻尔兹曼机学习算法。
409 00:26:17,262 --> 00:26:21,976 说话人 SPEAKER_00: 玻尔兹曼机学习算法有一个非常有趣的特性，就是，我向你展示数据。
410 00:26:22,215 --> 00:26:25,203 说话人 SPEAKER_00: 也就是说，我固定了可观察单元的状态。
411 00:26:25,183 --> 00:26:30,270 说话者 SPEAKER_00：它会在其他单元中摇摆不定，直到达到一个相对满意的状态。
412 00:26:30,932 --> 00:26:38,462 说话者 SPEAKER_00：一旦完成这个动作，它会根据两个单元是否都处于活跃状态来增加所有连接的强度。
413 00:26:38,482 --> 00:26:40,586 说话者 SPEAKER_00：这被称为赫布学习。
414 00:26:40,605 --> 00:26:43,028 说话者 SPEAKER_00：但如果你只是这样做，连接强度会越来越大。
415 00:26:44,391 --> 00:26:47,174 说话者 SPEAKER_00: 你还得有一个阶段，让它从输入中分离出来。
416 00:26:48,251 --> 00:26:50,617 说话者 SPEAKER_00: 你让它来回摇晃，直到它满意的状态。
417 00:26:50,979 --> 00:26:52,202 说话者 SPEAKER_00: 所以现在它正在做白日梦。
418 00:26:53,405 --> 00:27:00,726 说话者 SPEAKER_00: 一旦它完成了白日梦，你就说，取所有活跃的神经元对，并减少它们之间的连接强度。
419 00:27:01,786 --> 00:27:04,772 说话者 SPEAKER_00：所以我正在向您解释这个算法，就像一个过程一样。
420 00:27:05,334 --> 00:27:19,086 说话者 SPEAKER_00：但实际上，这个算法是进行了一些数学运算，并提出了如何改变这些连接字符串，以便这个包含所有隐藏单元的神经网络能够发现数据并不令人惊讶？
421 00:27:19,066 --> 00:27:21,429 说话者 SPEAKER_00：并且它必须有一个这个阶段。
422 00:27:21,509 --> 00:27:25,272 说话者 SPEAKER_00：它必须有一个我们称之为负相的阶段，当它没有输入时运行。
423 00:27:25,773 --> 00:27:27,015 说话者 说话者_00: 正在相互抵消。
424 00:27:27,615 --> 00:27:30,018 说话者 说话者_00: 它正在忘记它所进入的任何状态。
425 00:27:30,538 --> 00:27:35,444 说话者 说话者_00: 现在，克里克关于梦境所指出的，我们知道每个人每晚都会梦很多小时。
426 00:27:36,125 --> 00:27:41,090 说话者 说话者_00: 如果我随机叫醒你，你可以告诉我你刚才在做什么梦，因为那还在你的短期记忆中。
427 00:27:41,746 --> 00:27:42,907 说话人 SPEAKER_00: 所以我们知道你梦了几个小时。
428 00:27:42,948 --> 00:27:44,009 说话人 SPEAKER_00: 但早上醒来时。
429 00:27:44,549 --> 00:27:48,955 说话人 SPEAKER_00: 你可以记得最后一个梦，但记不起其他的梦，这很幸运，因为你可能会把它们误认为是现实。
430 00:27:51,599 --> 00:27:53,663 说话人 SPEAKER_00: 那为什么我们完全不记得我们的梦呢？
431 00:27:54,104 --> 00:27:59,090 说话者 SPEAKER_00: 克里克的观点是，做梦的整个目的就是忘记那些东西。
432 00:27:59,511 --> 00:28:00,953 说话者 SPEAKER_00: 所以你将学习世界倒过来。
433 00:28:01,674 --> 00:28:07,663 说话者 SPEAKER_00: 而我和 Terry Stanofsky 证明了这实际上是对玻尔兹曼机的一种最大似然学习过程。
434 00:28:07,943 --> 00:28:09,306 说话者 SPEAKER_00: 所以这是关于做梦的一个理论。
435 00:28:09,286 --> 00:28:10,568 说话人 SPEAKER_00: 你在理论上证明了这一点吗？
436 00:28:10,608 --> 00:28:21,657 说话人 SPEAKER_00: 是的，我们在理论上证明了如果你想要改变权重，使你的大型神经网络对观测到的数据感到不那么惊讶，这是正确的做法。
437 00:28:22,414 --> 00:28:23,617 说话人 SPEAKER_01：我想听听你的其他理论。
438 00:28:23,637 --> 00:28:29,029 说话人 SPEAKER_01：但在我们失去这个线索之前，你已经证明它是有效的。
439 00:28:29,049 --> 00:28:33,500 说话人 SPEAKER_01：你实际上有没有将你的深度学习算法设置为本质上像人类一样做梦？
440 00:28:34,001 --> 00:28:35,965 说话人 SPEAKER_01：研究这个图像数据集一段时间。
441 00:28:36,667 --> 00:28:37,148 说话人 SPEAKER_01：重新考虑。
442 00:28:37,189 --> 00:28:37,951 说话人 SPEAKER_01：再次研究它。
443 00:28:37,971 --> 00:28:40,676 主持人 SPEAKER_01：度假村与持续运行的机器相比。
444 00:28:40,656 --> 00:28:43,019 主持人 SPEAKER_00：是的，我们有过机器学习算法。
445 00:28:43,079 --> 00:28:48,727 主持人 SPEAKER_00：其中一些最早能够学习如何使用隐藏单元的算法是玻尔兹曼机。
446 00:28:49,528 --> 00:28:51,371 主持人 SPEAKER_00：它们非常低效。
447 00:28:51,391 --> 00:28:56,237 说话人 SPEAKER_00: 但是后来，我发现了一种使它们近似于它们的方法，这种方法是高效的。
448 00:28:56,257 --> 00:29:00,221 说话人 SPEAKER_00: 这实际上成为了深度学习再次兴起的关键。
449 00:29:00,682 --> 00:29:03,506 说话人 SPEAKER_00: 这些是逐层学习特征检测器的东西。
450 00:29:04,728 --> 00:29:08,132 说话人 SPEAKER_00: 这是一种高效的受限玻尔兹曼机形式。
451 00:29:08,112 --> 00:29:10,738 说话者 SPEAKER_00: 因此它正在做这种类型的遗忘学习。
452 00:29:11,419 --> 00:29:17,712 说话者 SPEAKER_00: 但那个人并不是去睡觉，而是在每个数据点之后幻想一会儿。
453 00:29:18,094 --> 00:29:19,897 说话者 SPEAKER_01: 所以机器人也会梦见电子羊。
454 00:29:19,938 --> 00:29:22,584 说话者 SPEAKER_01: 那么让我们看看理论二、三和四。
455 00:29:23,445 --> 00:29:23,926 说话人 SPEAKER_00: 好的。
456 00:29:24,852 --> 00:29:27,075 说话人 SPEAKER_00: 理论二被称为唤醒-睡眠算法。
457 00:29:28,196 --> 00:29:31,182 说话人 SPEAKER_00: 你想要学习一个生成模型。
458 00:29:31,803 --> 00:29:35,468 说话人 SPEAKER_00: 所以你有一个想法，你将有一个可以生成数据的模型。
459 00:29:36,229 --> 00:29:37,771 说话人 SPEAKER_00：它有特征检测器的层级。
460 00:29:38,172 --> 00:29:42,137 说话人 SPEAKER_00：并且激活高级和低级等，直到激活像素。
461 00:29:42,699 --> 00:29:43,380 说话人 SPEAKER_00：那是一张图片。
462 00:29:44,161 --> 00:29:45,303 说话人 SPEAKER_00：你还要学习另一种方式。
463 00:29:45,323 --> 00:29:46,845 说话人 SPEAKER_00: 你想学习识别数据。
464 00:29:48,007 --> 00:29:49,829 说话人 SPEAKER_00: 因此你将有一个算法
465 00:29:50,198 --> 00:29:52,344 说话人 SPEAKER_00: 该算法分为两个阶段。
466 00:29:53,026 --> 00:29:55,532 说话人 SPEAKER_00: 在跟踪阶段，数据进入。
467 00:29:55,553 --> 00:29:57,699 说话人 SPEAKER_00: 它试图识别它。
468 00:29:58,461 --> 00:30:03,314 说话人 SPEAKER_00: 而不是学习用于识别的连接，它正在学习生成连接。
469 00:30:03,734 --> 00:30:05,118 说话人 SPEAKER_00: 所以数据来了。
470 00:30:05,825 --> 00:30:10,794 说话人 SPEAKER_00: 我激活隐藏单元，然后我学习让这些隐藏单元擅长重建这些数据。
471 00:30:11,154 --> 00:30:13,940 说话人 SPEAKER_00：所以它正在学习在每个层重建。
472 00:30:13,960 --> 00:30:15,884 说话人 SPEAKER_00：但问题是，你是如何学习正向连接的？
473 00:30:15,923 --> 00:30:21,775 说话人 SPEAKER_00：所以想法是，如果你知道了正向连接，你就可以学习反向连接，因为你能够学习重建。
474 00:30:23,375 --> 00:30:27,204 说话人 SPEAKER_00：现在，也发现如果你知道了反向连接，你就可以学习正向连接。
475 00:30:27,224 --> 00:30:29,832 说话人 SPEAKER_00: 因为你可以从顶部开始生成一些数据。
476 00:30:30,594 --> 00:30:35,086 说话人 SPEAKER_00: 由于你生成了数据，你就会知道所有隐藏层的状态。
477 00:30:35,807 --> 00:30:39,577 说话人 SPEAKER_00: 因此你可以学习正向连接来恢复这些状态。
478 00:30:40,282 --> 00:30:42,946 说话人 SPEAKER_00: 那将是睡眠阶段。
479 00:30:43,587 --> 00:30:47,834 说话人 SPEAKER_00：当您关闭输入时，您就生成数据。
480 00:30:48,255 --> 00:30:51,961 说话人 SPEAKER_00：然后您尝试重建生成数据的隐藏单元。
481 00:30:52,381 --> 00:30:57,409 说话人 SPEAKER_00：因此，如果您知道自上而下的连接，您就会学习自下而上的连接。
482 00:30:57,429 --> 00:30:59,372 说话人 SPEAKER_00：如果您知道自下而上的连接，您就可以学习自上而下的连接。
483 00:30:59,952 --> 00:31:04,559 说话人 SPEAKER_00：那么，如果你从随机连接开始，尝试交替两种学习方式，会发生什么？
484 00:31:04,720 --> 00:31:05,201 说话人 SPEAKER_00：它奏效了。
485 00:31:05,902 --> 00:31:08,425 说话人 说话人_00：为了让它工作得更好，你必须做各种各样的变体。
486 00:31:08,445 --> 00:31:09,227 说话人 说话人_00：但是它有效。
487 00:31:09,982 --> 00:31:12,425 说话人 SPEAKER_01：好吧，你想讨论其他两个理论吗？
488 00:31:12,445 --> 00:31:13,326 说话人 SPEAKER_01：我们只剩下八分钟了。
489 00:31:13,346 --> 00:31:15,890 说话人 SPEAKER_01：我认为我们应该跳过一些其他问题。
490 00:31:16,711 --> 00:31:20,234 说话人 SPEAKER_00：如果你再给我一个小时，我可以讨论其他两个理论。
491 00:31:20,255 --> 00:31:21,675 说话人 SPEAKER_01: 好的，那么，2020 年谷歌 I/O 大会。
492 00:31:22,116 --> 00:31:24,720 说话人 SPEAKER_01: 那么接下来我们要讨论什么？
493 00:31:25,039 --> 00:31:26,842 说话人 SPEAKER_01: 你们的研究方向在哪里？
494 00:31:26,902 --> 00:31:28,324 说话人 SPEAKER_01: 你现在正在尝试解决什么问题？
495 00:31:30,385 --> 00:31:34,911 说话人 说话人_00：我试图解决的主要问题，我已经做了好几年了，
496 00:31:36,680 --> 00:31:38,482 说话人 说话人_00：实际上，我想起了一位足球解说员。
497 00:31:38,502 --> 00:31:45,452 说话人 SPEAKER_00: 你可能会注意到足球解说员，他们总是说一些像“他们做得很好”这样的话，但最后总是传球失误。
498 00:31:46,034 --> 00:31:48,837 说话人 SPEAKER_00: 他们似乎从未注意到这一点很有趣。
499 00:31:49,558 --> 00:31:50,980 说话人 SPEAKER_00: 有点循环。
500 00:31:51,642 --> 00:31:56,148 说话人 SPEAKER_00: 所以我正在工作，最终，你将会开始做一件你无法完成的事情。
501 00:31:56,710 --> 00:31:59,153 说话人 SPEAKER_00: 我想我可能一直在做一件我永远无法完成的事情。
502 00:31:59,233 --> 00:32:03,480 说话人 SPEAKER_00: 但它被称为胶囊，这是一种理论，
503 00:32:03,460 --> 00:32:11,375 说话人 SPEAKER_00: 如何使用重建进行视觉感知，以及如何将信息路由到正确的位置。
504 00:32:12,518 --> 00:32:22,257 说话人 SPEAKER_00: 两个主要动机因素是，在标准神经网络中，某一层的活动会自动流向某个地方。
505 00:32:22,538 --> 00:32:24,642 说话人 SPEAKER_00: 你不会决定把它发送到哪儿。
506 00:32:25,229 --> 00:32:28,211 说话人 SPEAKER_00: 提出胶囊的概念是为了决定信息该发送到哪儿。
507 00:32:29,173 --> 00:32:35,961 说话人 SPEAKER_00: 现在，自从我开始研究胶囊以来，谷歌的一些非常聪明的人发明了转换器，它们正在做同样的事情。
508 00:32:35,980 --> 00:32:37,501 说话人 SPEAKER_00: 它们在决定信息该路由到哪儿。
509 00:32:38,083 --> 00:32:38,884 说话人 说话人_00: 这是一大胜利。
510 00:32:40,244 --> 00:32:44,869 说话人 说话人_00: 另一个促使胶囊结构产生的原因是坐标系。
511 00:32:44,890 --> 00:32:48,614 说话人 说话人_00: 所以当人类进行视觉处理时，他们总是使用坐标系。
512 00:32:49,194 --> 00:32:55,101 说话人 说话人_00: 如果他们给物体施加了错误的坐标系，甚至都无法识别这个物体。
513 00:32:55,080 --> 00:32:57,305 说话人 SPEAKER_00: 我给你一个小任务。
514 00:32:57,685 --> 00:32:59,449 说话人 SPEAKER_00: 想象一个四面体。
515 00:32:59,469 --> 00:33:01,593 说话人 SPEAKER_00: 它有一个三角形的底面和三个三角形面。
516 00:33:01,613 --> 00:33:02,734 说话人 SPEAKER_00: 它们都是等边三角形。
517 00:33:03,154 --> 00:33:04,076 说话人 说话人_00：想象一下，对吧？
518 00:33:06,621 --> 00:33:10,648 说话人 说话人_00：现在想象用平面去切割，得到一个正方形横截面。
519 00:33:12,250 --> 00:33:13,653 说话人 说话人_00：这并不容易，对吧？
520 00:33:14,315 --> 00:33:15,837 说话人 说话人_00：每次切割都会得到一个三角形。
521 00:33:16,638 --> 00:33:18,221 说话人 说话人_00：显然不知道如何得到一个正方形。
522 00:33:18,281 --> 00:33:19,384 说话人 说话人_00：一点也不明显。
523 00:33:20,208 --> 00:33:24,453 说话人 说话人_00：好吧，但我将以不同的方式描述相同的形状。
524 00:33:25,476 --> 00:33:26,096 说话人 说话人_00：我需要你的笔。
525 00:33:26,696 --> 00:33:36,090 讲者 SPEAKER_00：想象一下，如果你拿一支笔像这样，再拿另一支笔垂直于这个方向，并将这支笔上的所有点与那支笔上的所有点连接起来，你会得到什么形状。
526 00:33:37,573 --> 00:33:40,356 讲者 SPEAKER_00：那是一个实心四面体。
527 00:33:40,376 --> 00:33:40,698 讲者 SPEAKER_00：好吗？
528 00:33:42,019 --> 00:33:44,442 说话人 SPEAKER_00: 你是相对于不同的坐标系来看的。
529 00:33:45,976 --> 00:33:50,200 说话人 SPEAKER_00: 其中四面体的边缘，这两条线与坐标系对齐。
530 00:33:51,260 --> 00:33:57,865 说话人 SPEAKER_00: 对于这一点，如果你这样想四面体，那么很明显，在顶部，你会得到一个这样的长方形。
531 00:33:58,166 --> 00:33:59,988 说话人 SPEAKER_00: 在底部，你会得到一个这样的长方形。
532 00:34:00,969 --> 00:34:03,611 说话人 SPEAKER_00: 有个叫魏尔斯特拉斯的人说，你得在中间放一个正方形。
533 00:34:05,272 --> 00:34:08,094 说话人 SPEAKER_00: 所以很明显，你可以这样切割来得到一个正方形。
534 00:34:08,235 --> 00:34:11,097 说话人 SPEAKER_00: 但只有当你用那个坐标系来想的时候，这才会很明显。
535 00:34:11,117 --> 00:34:15,882 说话人 SPEAKER_00: 所以对人类来说，坐标系对于感知非常重要。
536 00:34:15,862 --> 00:34:18,367 Speaker SPEAKER_00: 它们对卷积神经网络来说根本不重要。
537 00:34:18,387 --> 00:34:27,025 Speaker SPEAKER_00: 对于卷积神经网络来说，如果我给你展示一个倾斜的正方形和一个直立的长方形，实际上它们是同一件事，卷积神经网络会认为它们看起来是一样的。
538 00:34:27,626 --> 00:34:30,731 Speaker SPEAKER_00: 它没有两种描述同一事物的不同方式。
539 00:34:30,965 --> 00:34:40,494 Speaker SPEAKER_01: 将坐标系添加到你的模型中，这与你在 90 年代犯的错误有什么不同，当时你试图将规则放入系统中，而不是让系统无监督地运行？
540 00:34:40,755 --> 00:34:41,996 说话人 SPEAKER_00: 这正是那个错误。
541 00:34:42,838 --> 00:34:47,623 说话人 SPEAKER_00: 因为我如此坚决地认为那是一个糟糕的错误，所以我被允许做一点。
542 00:34:48,603 --> 00:34:50,585 说话人 SPEAKER_00: 这有点像尼克松与中国谈判。
543 00:34:51,907 --> 00:34:55,831 说话人 SPEAKER_00: 实际上，这让我处于一个糟糕的角色。
544 00:34:55,851 --> 00:34:58,795 说话者 SPEAKER_00: 总之。
545 00:35:00,478 --> 00:35:05,644 说话者 SPEAKER_00: 如果你看看卷积神经网络，它们只是加入了少量知识的神经网络。
546 00:35:05,965 --> 00:35:09,568 说话者 SPEAKER_00: 你加入的知识是，如果在这里的特征检测器很好，那么在那里也很好。
547 00:35:10,971 --> 00:35:14,914 说话者 SPEAKER_00: 人们都希望加入更多关于尺度和平面的知识。
548 00:35:15,775 --> 00:35:20,340 说话人 SPEAKER_00: 但如果你用 4D 网格代替 2D 网格这种明显的方式来做，整个事情就会在你面前崩溃。
549 00:35:21,461 --> 00:35:28,409 说话人 SPEAKER_00: 但是你可以获取关于视角如何影响图像的知识。
550 00:35:28,626 --> 00:35:31,612 说话人 SPEAKER_00: 通过使用与图形中相同的方式使用坐标系。
551 00:35:32,413 --> 00:35:35,077 说话人 SPEAKER_00: 因此现在你在一层中有了这种表示。
552 00:35:35,418 --> 00:35:48,918 讲者 SPEAKER_00：当你尝试在下一层重建物体的各个部分时，当你进行这个重建时，你可以将整个物体的坐标系乘以部分与整体的关系，以得到部分坐标系。
553 00:35:49,739 --> 00:35:51,342 说话人 说话人_00：您可以将它连接到网络中。
554 00:35:51,362 --> 00:35:55,309 说话人 说话人_00：您可以将执行这些坐标变换的能力连接到网络中。
555 00:35:55,289 --> 00:35:57,557 说话人 说话人_00：这将使它更加通用，非常好。
556 00:35:57,579 --> 00:36:01,594 说话人 SPEAKER_00：这意味着网络很容易处理视角。
557 00:36:02,056 --> 00:36:05,873 说话人 SPEAKER_00：当前的神经网络除了翻译之外，很难处理视角。
558 00:36:06,358 --> 00:36:14,090 说话人 SPEAKER_01：所以你现在的任务是否仅限于视觉识别，或者是否是通过制定坐标系的规则集来提高的更一般的方法？
559 00:36:14,349 --> 00:36:16,092 说话人 SPEAKER_00：好的，它可以用于其他事情。
560 00:36:16,172 --> 00:36:20,197 说话人 SPEAKER_00: 我真的很感兴趣视觉识别的应用。
561 00:36:20,518 --> 00:36:21,340 说话人 SPEAKER_01: 好的，最后一个问题。
562 00:36:21,380 --> 00:36:23,983 说话人 SPEAKER_01: 我听了你前几天播客。
563 00:36:24,023 --> 00:36:31,753 说话人 SPEAKER_01: 在其中，你说你最看重想法的人是进入你实验室的年轻研究生，因为他们没有陷入旧观念的束缚。
564 00:36:31,835 --> 00:36:32,856 说话人 SPEAKER_01: 他们有新想法。
565 00:36:33,436 --> 00:36:34,998 说话人 SPEAKER_01: 而且他们还知道很多。
566 00:36:35,434 --> 00:36:43,757 说话人 SPEAKER_01: 你是否觉得自己可能陷入了某种思维定式，而一个新来的研究生或者这个房间里来和你一起工作的人可能会打破这种定式？
567 00:36:44,277 --> 00:36:45,539 说话人 SPEAKER_00: 是的，我所说的每一件事。
568 00:36:45,559 --> 00:36:47,201 说话人 SPEAKER_01：你说的一切。
569 00:36:47,221 --> 00:36:48,483 说话人 SPEAKER_01：把这些坐标单位取出来。
570 00:36:49,103 --> 00:36:50,827 说话人 SPEAKER_01：处理第三个功能，处理第四个功能。
571 00:36:50,847 --> 00:36:52,148 说话人 SPEAKER_01：我将问你一个单独的问题。
572 00:36:52,710 --> 00:36:55,112 说话人 SPEAKER_01：深度学习曾经是一件独特的事情。
573 00:36:55,132 --> 00:36:58,958 说话人 SPEAKER_01：然后它变成了与 AI 这个短语同义。
574 00:36:59,460 --> 00:37:04,126 说话人 SPEAKER_01：现在 AI 已经变成了一个营销术语，基本上意味着以任何方式使用机器。
575 00:37:04,427 --> 00:37:07,652 说话人 SPEAKER_01：作为帮助创造这一术语的人，你对这个术语有什么看法？
576 00:37:07,766 --> 00:37:15,001 说话人 SPEAKER_00: 但当有 AI 的时候，我更快乐，这意味着你的逻辑受到启发，并在符号字符串上进行操作。
577 00:37:15,623 --> 00:37:19,871 说话人 SPEAKER_00: 而且还有神经网络，这意味着你想要在神经网络中进行学习。
578 00:37:20,010 --> 00:37:26,625 说话人 SPEAKER_00: 它们是完全不同的企业，实际上并没有很好地相处，并且为了资金而争斗。
579 00:37:27,646 --> 00:37:29,369 说话人 SPEAKER_00: 我就是这样成长的。
580 00:37:30,059 --> 00:37:36,393 说话人 SPEAKER_00: 现在我看到那些多年来一直说神经网络是胡说的人，我说，我是人工智能教授，所以我需要钱。
581 00:37:37,094 --> 00:37:38,557 说话人 SPEAKER_00: 真是让人烦恼。
582 00:37:38,577 --> 00:37:46,195 说话人 SPEAKER_01: 所以你的领域成功了，某种程度上吞噬了其他领域，这使得他们有优势去申请资金，这很令人沮丧。
583 00:37:46,175 --> 00:37:49,018 说话人 SPEAKER_00: 是的，现在并不完全公平，因为他们中的许多人实际上已经转变了。
584 00:37:49,197 --> 00:37:50,619 说话人 SPEAKER_01: 好的，好吧，太棒了。
585 00:37:50,900 --> 00:37:52,420 说话人 SPEAKER_01: 那么，我还有时间再问一个问题。
586 00:37:52,820 --> 00:38:02,811 说话人 SPEAKER_01: 所以在那次采访中，你谈到 AI，你说，想想看，就像一台挖掘机，一台可以挖洞的挖掘机，如果建造不当，可能会把你摧毁。
587 00:38:03,351 --> 00:38:08,797 说话人 SPEAKER_01: 关键在于，当你修理你的挖掘机时，要设计得最好，以便它挖洞而不是敲你的头。
588 00:38:09,237 --> 00:38:11,760 说话人 SPEAKER_01：在你思考你的工作时，你做出了哪些这样的选择？
589 00:38:16,195 --> 00:38:24,244 说话人 SPEAKER_00：嗯，我想我绝不会故意去制作武器。
590 00:38:25,405 --> 00:38:28,829 说话人 SPEAKER_00：我的意思是，你可以设计一种能够很好地敲掉人们头部的蝙蝠，对吧？
591 00:38:28,849 --> 00:38:33,215 说话人 SPEAKER_00：我认为这是蝙蝠的糟糕用途，我不会去做的。
592 00:38:33,235 --> 00:38:33,434 说话人 SPEAKER_01: 好吧。
593 00:38:33,454 --> 00:38:36,277 说话人 SPEAKER_01: 嗯，杰弗里·辛顿，非常棒的采访，各种信息。
594 00:38:36,298 --> 00:38:39,541 说话人 SPEAKER_01: 我们明年再来谈谈第三、第四季度的梦想。
595 00:38:39,561 --> 00:38:41,204 说话人 SPEAKER_01: 真是太好玩了。
596 00：38：41,224 --> 00：38：41,864 议长 SPEAKER_01：谢谢。
