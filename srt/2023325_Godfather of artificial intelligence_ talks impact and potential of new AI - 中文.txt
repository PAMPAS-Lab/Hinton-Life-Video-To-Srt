1 00:00:00,031 --> 00:00:04,716 说话人 SPEAKER_00: 这周，谷歌加入了人工智能竞赛，推出了 BARD。
2 00:00:05,158 --> 00:00:10,564 说话人 SPEAKER_00: 这个聊天机器人将与由微软资助的 OpenAI 的 ChatGBT 竞争。
3 00:00:10,685 --> 00:00:21,038 说话人 SPEAKER_00: 在短短几个月内，这些聊天机器人凭借回答复杂问题、撰写电子邮件和演讲稿、规划定制假期等功能，赢得了用户的惊叹。
4 00:00:21,457 --> 00:00:29,228 说话人 SPEAKER_00: 但随着技术的进步，这项技术带来了巨大的希望和，有些人认为，重大的、甚至生存的威胁。
5 00:00:29,207 --> 00:00:36,719 说话人 SPEAKER_00: 布鲁克·席尔瓦·布拉加前往多伦多，这是人工智能领先的研究中心之一，去见一些正在构建这个勇敢新世界的人。
6 00:00:37,578 --> 00:00:43,604 说话人 SPEAKER_04: 嗯，这是我们在我们的生成语言模型支持下开发的一个聊天机器人实验预览。
7 00:00:43,784 --> 00:00:44,466 说话人 SPEAKER_02: 好的。
8 00:00:44,485 --> 00:00:47,228 说话人 SPEAKER_02: 尼克·弗罗斯特是 Cohere 的联合创始人。
9 00:00:47,710 --> 00:00:56,841 说话人 SPEAKER_02：像谷歌和 OpenAI 一样，这家多伦多初创公司用数万亿个单词训练了强大的计算机，并让它们回答。
10 00:00:57,201 --> 00:01:00,564 说话人 SPEAKER_02：它能写，叫它写一篇书评。
11 00:01:00,545 --> 00:01:02,366 说话人 SPEAKER_02：关于《战争与和平》。
12 00:01:03,167 --> 00:01:03,848 说话人 SPEAKER_02：好的，它能。
13 00:01:04,308 --> 00:01:07,733 说话人 SPEAKER_02：战争与和平是俄国作家列夫·托尔斯泰的历史小说。
14 00:01:07,972 --> 00:01:15,281 说话人 SPEAKER_02：在计算领域的一次重大飞跃中，这些模型可以理解和创造自然语言。
15 00:01:15,301 --> 00:01:15,981 说话人 SPEAKER_02：它刚刚写了这个。
16 00:01:16,102 --> 00:01:18,525 说话人 SPEAKER_02：是的，但它基于它所看到的一切。
17 00:01:18,924 --> 00:01:21,628 说话人 SPEAKER_02：这项技术已在研究实验室中研究了多年。
18 00:01:22,168 --> 00:01:26,834 说话人 SPEAKER_02：去年秋天 ChatGPT 的发布... 奶酪，哦奶酪，如此美味而大胆。
19 00:01:26,853 --> 00:01:29,016 说话人 SPEAKER_02：...把它带到了一个毫无准备的大众面前。
20 00:01:28,995 --> 00:01:31,278 说话人 SPEAKER_02：它正在为我写一首关于奶酪的诗。
21 00:01:31,319 --> 00:01:32,801 说话人 SPEAKER_04：相当不错！
22 00:01:32,861 --> 00:01:37,987 说话人 SPEAKER_04：在老式编程中，我们会编写代码来告诉计算机该做什么。
23 00:01:38,528 --> 00:01:39,069 说话人 SPEAKER_04：我们仍然在做这件事。
24 00:01:39,209 --> 00:01:39,930 说话人 SPEAKER_04：很多人还在做这件事。
25 00:01:39,990 --> 00:01:44,337 说话人 SPEAKER_04：但我们现在还做的一件事是编写代码告诉计算机如何学习该做什么。
26 00:01:44,897 --> 00:01:48,742 说话人 SPEAKER_04：它是通过展示许多它应该做的例子来学习的。
27 00:01:48,722 --> 00:01:57,632 说话人 SPEAKER_04：所以在大型语言模型的背景下，这种方法是这样的：我们获取大量文本，然后展示给它几个单词，让它预测下一个单词。
28 00:01:58,052 --> 00:02:02,158 说话人 SPEAKER_04：这种简单的技术最终会给你带来非常有用且强大的东西。
29 00:02:03,099 --> 00:02:11,608 说话人 SPEAKER_02：如此强大，以至于 OpenAI 的新 GPT-4 在律师资格考试上的表现比 90%的法学实习生都要好。
30 00:02:11,587 --> 00:02:19,215 说话人 SPEAKER_02：这些模型能在几秒钟内编写计算机代码，并迅速产出任何 AI 程序员未禁止主题的博客文章。
31 00:02:19,655 --> 00:02:23,057 说话人 SPEAKER_02：它们正成为最新界限思想的仲裁者。
32 00:02:23,578 --> 00:02:26,700 说话人 SPEAKER_02：尽管聊天应用目前很流行，但其他形式的 AI。
33 00:02:27,241 --> 00:02:30,283 说话人 SPEAKER_04：现在您可以用文字生成视频。
34 00:02:30,663 --> 00:02:31,945 说话人 SPEAKER_02：将做得多得多。
35 00:02:32,265 --> 00:02:35,268 说话人 SPEAKER_02：这是自以来的最大技术进步。
36 00:02:35,808 --> 00:02:40,633 说话人 SPEAKER_05：我认为它在规模上可以与工业革命或电力相提并论。
37 00:02:40,883 --> 00:02:41,489 说话人 SPEAKER_02：电力。
38 00:02:41,508 --> 00:02:42,195 说话人 SPEAKER_05：或者可能是轮子。
39 00:02:42,962 --> 00:02:44,598 说话人 SPEAKER_02：或者可能是轮子。
40 00:02:45,305 --> 00:02:46,326 说话人 SPEAKER_02：是的。
41 00:02:46,347 --> 00:02:50,633 说话人 SPEAKER_02：杰弗里·辛顿被誉为人工智能之父。
42 00:02:50,653 --> 00:03:01,931 说话人 SPEAKER_02：在过去 10 年里，他帮助谷歌创建人工智能，并指导行业的新星，包括 OpenAI 的首席科学家伊利亚·西斯科娃和 Cohere 的尼克·弗罗斯特。
43 00:03:02,453 --> 00:03:12,408 说话人 SPEAKER_02：事实上，多伦多今天成为全球人工智能中心，在很大程度上是因为 40 年前辛顿在加拿大政府同意资助他不同寻常的研究时搬到了这里。
44 00:03:12,389 --> 00:03:15,633 说话人 SPEAKER_05：我有点奇怪，因为其他人认为这些事情都是胡说八道，我却做了这些。
45 00:03:15,652 --> 00:03:24,283 说话人 SPEAKER_02：当其他人追求人工智能时试图将逻辑和推理编程到计算机中，Hinton 认为让他们自己解决问题更好。
46 00:03:24,844 --> 00:03:26,687 说话人 SPEAKER_02：想法是模仿大脑。
47 00:03:27,068 --> 00:03:34,616 说话人 SPEAKER_02：通过大量练习，这些虚拟神经网络，如图所示，将建立正确的连接以解决给定任务。
48 00:03:35,120 --> 00:03:35,901 说话人 SPEAKER_02：当时有人怀疑。
49 00:03:36,361 --> 00:03:43,090 说话人 SPEAKER_05：主要问题在于，你能期待一个仅仅通过改变连接强度来学习的庞大神经网络吗？
50 00:03:43,730 --> 00:03:49,919 说话人 SPEAKER_05：你能期待它只看数据，没有任何先验知识，就能学会如何做事吗？
51 00:03:50,299 --> 00:03:53,743 说话人 SPEAKER_05：主流人工智能领域的人认为这完全荒谬。
52 00:03:53,764 --> 00:03:55,164 说话人 SPEAKER_05：这听起来有点荒谬。
53 00:03:55,526 --> 00:03:57,709 说话人 SPEAKER_05：这有点荒谬，但管用。
54 00:03:58,669 --> 00:04:01,092 说话人 SPEAKER_02：这一切都是真实的。
55 00:04:02,997 --> 00:04:08,764 说话人 SPEAKER_02：只是在过去十年左右，计算机的强大才足以证明 Hinton 是对的。
56 00:04:09,264 --> 00:04:15,073 说话人 SPEAKER_02：他的机器学习理念现在应用于不同类型的训练数据，可以创造出各种输出。
57 00:04:15,593 --> 00:04:19,619 说话人 SPEAKER_02：当然，这不是汤姆·克鲁斯，而是一个模仿他的深度伪造。
58 00:04:19,778 --> 00:04:22,802 说话人 SPEAKER_04：我去了办公室，因为他们正在制作我的机器人。
59 00:04:22,822 --> 00:04:29,291 说话人 SPEAKER_02：这不是最近 Netflix 纪录片中安迪·沃霍尔的嗓音，而是一个由 Resemble AI 生成的克隆体。
60 00:04:29,271 --> 00:04:31,915 说话人 SPEAKER_02：点击录音，然后大声朗读句子。
61 00:04:32,416 --> 00:04:40,529 说话人 SPEAKER_02：阅读训练文本几分钟之后，创始人 Zohab Ahmed 已经克隆了我的声音。
62 00:04:40,750 --> 00:04:45,317 说话人 SPEAKER_02： Habitat for Humanity，这个组织帮助房主和志愿者一起建造家园。
63 00:04:45,658 --> 00:04:47,279 说话人 SPEAKER_02： 是的，我确实在录音中听到了自己的声音。
64 00:04:47,259 --> 00:04:48,682 说话人 SPEAKER_02：对着镜头微笑。
65 00:04:48,701 --> 00:04:53,028 主持人 SPEAKER_02：一家名为 Synthesia 的公司让我在绿幕前朗读剧本。
66 00:04:53,048 --> 00:04:55,973 主持人 SPEAKER_02：他们用这段视频制作出了我的数字版本。
67 00:04:56,473 --> 00:05:01,040 主持人 SPEAKER_02：我们将它与 Resemble 的声音搭配，创造了一个可以说出你输入任何内容的电视记者。
68 00:05:01,821 --> 00:05:04,644 主持人 SPEAKER_02：这项技术在未来几年只会变得更好。
使用这项技术来传播虚假信息似乎是不可避免的。
70 00：05：08,790 --> 00：05：11,394 议长 SPEAKER_02：这是我来到新冠代理的第一天。
71 00：05：11,375 --> 00：05：18,144 演讲者 SPEAKER_02：用它来取代记者、律师、会计师、放射科医生、小说家、词曲作者和画家。
72 00：05：18,906 --> 00：05：19,826 演讲者 SPEAKER_02：嗯，那也可能发生。
73 00:05:20,206 --> 00:05:21,750 说话人 SPEAKER_02：但这将需要大量的工作。
74 00:05:22,370 --> 00:05:29,079 说话人 SPEAKER_04：我认为这将使许多工作变得更简单，许多工作变得更快捷。
75 00:05:29,430 --> 00:05:30,754 说话人 SPEAKER_02：我以两种方式理解你的回答。
76 00:05:30,973 --> 00:05:33,738 说话人 SPEAKER_02：一方面，如果结果真的如此，那就太好了。
77 00:05:34,220 --> 00:05:42,014 说话人 SPEAKER_02：二，如果制作这项技术的人还没有意识到它可能带来的潜在崩溃，那可能有点可怕。
78 00:05:42,435 --> 00:05:47,305 说话人 SPEAKER_04：是的，我认为我们尽力去思考这项技术的真正影响。
79 00:05:47,622 --> 00:05:52,468 说话人 SPEAKER_02：而这些进步的真正影响，正是目前一场高风险辩论的主题。
80 00:05:53,129 --> 00:06:00,581 说话人 SPEAKER_02：人工智能是否会迅速超越人类能力，成为人们所认为的人工通用智能（AGI）？
上个月，OpenAI 的 CEO 山姆·奥特曼写道，风险可能非常巨大。
一个错位的、超级智能的 AGI 可能会对世界造成严重伤害。
但 Frost 和其他人表示，终结者式的担忧被夸大了。
84 00：06：15,541 --> 00：06：20,348 说话者 SPEAKER_02：大型语言模型只是编写一些听起来很聪明的单词的算法。
85 00:06:20,869 --> 00:06:23,192 说话人 SPEAKER_02：他们甚至不理解基本真理。
86 00:06:23,612 --> 00:06:24,434 说话人 SPEAKER_02：今天是星期几？
87 00:06:24,494 --> 00:06:25,274 说话人 SPEAKER_02：今天是星期一。
88 00:06:25,555 --> 00:06:26,036 说话人 SPEAKER_02：今天是星期一。
89 00:06:26,115 --> 00:06:26,697 说话者 SPEAKER_04：它只是猜的吗？
90 00:06:26,836 --> 00:06:27,497 说话者 SPEAKER_04：是的，它只是猜的。
91 00:06:27,918 --> 00:06:33,204 说话者 SPEAKER_04：我认为我们今天正在构建的技术不会自然地导致通用人工智能。
92 00:06:33,225 --> 00:06:34,187 说话者 SPEAKER_04：我认为我们离那个目标还远着呢。
93 00:06:34,927 --> 00:06:37,490 说话人 SPEAKER_05：他的导师以前总是同意。
94 00:06:37,471 --> 00:06:43,641 说话人 SPEAKER_05：直到最近，我还认为我们可能要再过 20 到 50 年才能拥有通用人工智能。
95 00:06:44,083 --> 00:06:46,767 说话人 SPEAKER_05：现在我认为可能只需要 20 年或更少。
96 00:06:47,209 --> 00:06:48,971 说话人 SPEAKER_02：有些人认为可能只需要 5 年。
97 00:06:49,392 --> 00:06:51,476 说话人 SPEAKER_05：我现在不会完全排除这种可能性。
98 00:06:51,596 --> 00:06:54,281 说话人 SPEAKER_05：而几年前我可能会说绝对不可能。
99 00:06:54,362 --> 00:06:57,726 说话人 SPEAKER_02：我们离计算机自己提出改进自己的想法还有多远？
100 00:06:58,067 --> 00:06:58,747 说话人 SPEAKER_05：是的，可能快了。
101 00:06:59,028 --> 00:07:00,829 说话人 SPEAKER_02：然后它就可以快速进行。
102 00:07:01,190 --> 00:07:02,232 说话人 SPEAKER_05：这是个问题，对吧。
103 00:07:02,291 --> 00:07:04,855 说话人 SPEAKER_05：我们必须认真思考如何控制它。
104 00:07:05,175 --> 00:07:05,454 说话人 SPEAKER_02：是的。
105 00:07:05,675 --> 00:07:06,016 说话人 SPEAKER_05: 我们可以吗？
106 00:07:06,456 --> 00:07:06,916 说话人 SPEAKER_05: 我们不知道。
107 00:07:06,937 --> 00:07:08,519 说话人 SPEAKER_05: 我们还没有去过，但我们可以试试。
108 00:07:08,559 --> 00:07:09,519 说话人 SPEAKER_02: 好的。
109 00:07:09,620 --> 00:07:10,880 说话人 SPEAKER_02：这似乎有点令人担忧。
110 00:07:12,223 --> 00:07:12,442 说话人 SPEAKER_02：是的。
111 00:07:13,384 --> 00:07:17,468 说话人 SPEAKER_02：你认为 AI 灭绝人类的可能性有多大？
112 00:07:18,269 --> 00:07:19,271 说话人 SPEAKER_05：这并非不可想象。
113 00:07:19,790 --> 00:07:20,112 说话人 SPEAKER_02: 好的。
114 00:07:20,291 --> 00:07:21,432 说话人 SPEAKER_02: 就说这么多。
115 00:07:21,817 --> 00:07:29,910 讲者 SPEAKER_02：Hinton 想知道，我们如何管理一项可能让少数公司或政府拥有如此巨大权力的技术？
116 00:07:30,310 --> 00:07:36,399 讲者 SPEAKER_05：因此，我认为人们现在担心这些问题是非常合理的，尽管这些事情不会在明年或后年发生。
117 00:07:36,899 --> 00:07:39,302 讲者 SPEAKER_05：人们应该思考这些问题。
118 00:07:39,322 --> 00:07:45,312 讲者 SPEAKER_02：为哥伦比亚广播公司周六晨间节目撰稿，目前仍由 Brooke Silva-Braga 自己撰写，多伦多。
119 00:07:47,029 --> 00:07:48,252 说话人 SPEAKER_02：你做得好，布鲁克。
120 00:07:48,291 --> 00:07:49,012 说话人 SPEAKER_01：是的，是的，没错。
121 00:07:49,033 --> 00:07:52,538 说话人 SPEAKER_01：但是有两个问题，比如，你为什么要建造它，第一个问题？
122 00:07:52,978 --> 00:07:56,463 说话人 SPEAKER_01：第二个问题，你为什么没有考虑可能的后果？
123 00:07:56,543 --> 00:08:01,872 说话人 SPEAKER_01：这是一个大问号，我们其他人必须去面对它。
124 00:08:01,892 --> 00:08:03,214 说话人 SPEAKER_01：建造它，试图让生活更轻松。
125 00:08:03,235 --> 00:08:12,649 说话人 SPEAKER_03：我认为更大的问题是，当 Brooke 问，你认为 AI 消灭人类的可能性如何时，那个人说，这并不... 并不难以想象，是的。
126 00:08:12,629 --> 00:08:13,947 说话人 SPEAKER_00：我同意。
127 00:08:14,130 --> 00:08:15,327 说话人 说话人_00：我的观点正是如此。
128 00:08:15,591 --> 00:08:17,255 说话人 说话人_00：我认为我们不可能在10秒内回答这个问题。