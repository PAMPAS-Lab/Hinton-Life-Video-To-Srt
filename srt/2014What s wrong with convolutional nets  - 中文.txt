1
00:00:00,031 --> 00:00:09,367
发言人 SPEAKER_00: 他是人工神经网络和机器学习领域的创始人之一，也是该领域的核心人物。

2
00:00:09,426 --> 00:00:12,492
发言人 SPEAKER_00: 他来到MIT，所以这算是个大事件。

3
00:00:12,512 --> 00:00:19,204
发言人 SPEAKER_00: 昨天在CSAIL的讲座有500多人参加，甚至有人无法入场。

4
00:00:19,184 --> 00:00:24,655
发言人 SPEAKER_00: 今天我们从四点开始，因为我相信情况会类似。

5
00:00:25,716 --> 00:00:36,618
发言人 SPEAKER_00: 六点还有一个由Tommy组织的专题讨论会，Jeff也会参加，讨论的主题是“通向智能的路径”，地点就在这个房间。

6
00:00:37,307 --> 00:00:44,158
发言人 SPEAKER_00: 所以，我不再多说了，因为我们都是来听他的。

7
00:00:44,598 --> 00:00:52,991
发言人 SPEAKER_00: 成功的代价可能是你在他的网页上看到的内容，上面写着：“致未来的学生：我将不再接收新的研究生、访问学生、暑期学生或访客，因此请不要申请与我合作。”

8
00:00:53,512 --> 00:01:02,246
发言人 SPEAKER_00: 我不会再接收任何新的研究生、访问学生、暑期学生或访客，所以请不要申请与我合作。

9
00:01:02,725 --> 00:01:03,146
发言人 SPEAKER_00: Jeff？

10
00:01:09,674 --> 00:01:10,355
发言人 SPEAKER_01: 非常感谢。

11
00:01:10,575 --> 00:01:12,878
发言人 SPEAKER_01: 不过，如果你想要一份在谷歌的工作，那是另一回事。

12
00:01:17,444 --> 00:01:20,769
发言人 SPEAKER_01: 我们目前使用的神经网络有很多问题。

13
00:01:22,131 --> 00:01:26,316
发言人 SPEAKER_01: 它们在语音识别和物体识别方面非常成功，尤其是最近。

14
00:01:27,158 --> 00:01:33,706
发言人 SPEAKER_01: 但它们与大脑的工作方式有很大不同，我认为这限制了它们的表现。

15
00:01:34,412 --> 00:01:40,444
发言人 SPEAKER_01: 一个复杂工程系统应该具有多层次的结构，而神经网络的层次结构非常少。

16
00:01:40,465 --> 00:01:42,469
发言人 SPEAKER_01: 神经网络只有神经元、神经元层（与大脑皮层完全不同）和整个神经网络，这就是大多数神经网络的全部结构。

17
00:01:43,171 --> 00:01:51,948
发言人 SPEAKER_01: 这些神经网络缺少的一个关键点是，它们没有明确的“实体”概念。

18
00:01:54,037 --> 00:01:59,188
发言人 SPEAKER_01: 对于在场的先天论者，我愿意承认，可能值得在神经网络中引入与“实体”相关的概念。

19
00:02:00,010 --> 00:02:05,441
发言人 SPEAKER_01: 我想将这种概念构建到网络架构中。

20
00:02:05,921 --> 00:02:08,486
发言人 SPEAKER_01: 这就是本次演讲的主要内容。

21
00:02:08,837 --> 00:02:11,222
发言人 SPEAKER_01: 我想做的是将我们称为“层”中的神经元分组为子集，并让这些子集中的神经元活动表示同一实体的不同属性。

22
00:02:11,241 --> 00:02:12,383
发言人 SPEAKER_01: 我希望神经网络能够决定实体是什么以及它们如何相互作用，但我希望网络内置“实体”这一属性。

23
00:02:13,104 --> 00:02:23,241
发言人 SPEAKER_01: 这就是我对先天论者的全部让步。

24
00:02:23,701 --> 00:02:31,234
发言人 SPEAKER_01: 我还想推动一个观点，即“微柱”（mini-column）是表示实体的地方。

25
00:02:32,800 --> 00:02:34,824
发言人 SPEAKER_01: 每个微柱表示一个实体。

26
00:02:36,348 --> 00:02:40,741
发言人 SPEAKER_01: 我将在人工网络中称这种东西为“胶囊”（capsule）。

27
00:02:42,365 --> 00:02:43,467
发言人 SPEAKER_01: 胶囊将有两种实例化参数。

28
00:02:44,747 --> 00:02:48,110
发言人 SPEAKER_01: 一个参数表示实体是否存在（我主要讨论图像，所以指的是当前输入图像中是否存在该实体）。

29
00:02:48,792 --> 00:02:52,836
发言人 SPEAKER_01: 另一个参数描述该实体的属性。

30
00:02:53,437 --> 00:02:58,921
发言人 SPEAKER_01: 如果实体不存在，你可以随意描述其属性，但这无关紧要。

31
00:02:59,763 --> 00:03:04,487
发言人 SPEAKER_01: 但如果实体存在，那么你需要知道它的属性。

32
00:03:05,028 --> 00:03:07,790
发言人 SPEAKER_01: 这些属性包括方向、大小、速度、颜色、变形等。

33
00:03:08,171 --> 00:03:11,294
发言人 SPEAKER_01: 胶囊输出的是实体存在的概率以及实体的广义位姿（在视觉中通常是物体或物体的一部分）。

34
00:03:11,377 --> 00:03:18,146
发言人 SPEAKER_01: 广义位姿包括各种参数。

35
00:03:19,288 --> 00:03:31,426
发言人 SPEAKER_01: 胶囊所做的计算与普通神经网络不同，它们的基本计算是：接收来自下层胶囊的预测（关于它们的广义位姿的多维向量），并寻找高度一致的预测。

36
00:03:32,528 --> 00:03:36,033
发言人 SPEAKER_01: 它们不关心是否存在大量离群预测。

37
00:03:39,001 --> 00:04:05,228
发言人 SPEAKER_01: 它们关心的是是否存在一小部分高度一致的预测。

38
00:04:06,203 --> 00:04:08,747
发言人 SPEAKER_01: 如果你在计算机视觉的早期阶段工作过，这类似于RANSAC和Hough变换。

39
00:04:09,248 --> 00:04:13,094
发言人 SPEAKER_01: 所以，胶囊有一个高维位姿空间，可能是20维或50维。

40
00:04:14,538 --> 00:04:20,369
发言人 SPEAKER_01: 这是一个关于该空间的图示。

41
00:04:21,992 --> 00:04:23,875
发言人 SPEAKER_01: 假设它是一个20维空间。

42
00:04:24,225 --> 00:04:28,632
发言人 SPEAKER_01: 来自下层胶囊的预测会进入这个空间。

43
00:04:29,432 --> 00:04:30,875
发言人 SPEAKER_01: 这些是预测的向量。

44
00:04:31,956 --> 00:04:33,879
发言人 SPEAKER_01: 我们希望找到这个聚类。

45
00:04:34,540 --> 00:04:36,843
发言人 SPEAKER_01: 它将输出一个概率，表示“我真的存在，因为这不是偶然发生的”。

46
00:04:36,862 --> 00:04:38,625
发言人 SPEAKER_01: 我有很多证据证明我的存在。

47
00:04:38,725 --> 00:04:42,831
发言人 SPEAKER_01: 我可以输出该聚类的重心，并忽略其他所有预测。

48
00:04:43,411 --> 00:04:45,615
发言人 SPEAKER_01: 现有的神经网络并不擅长做这种事情。

49
00:04:46,636 --> 00:04:49,660
发言人 SPEAKER_01: 它们可能以某种方式模拟这一点，但它们并不是为这种任务设计的。

50
00:04:49,841 --> 00:04:55,151
发言人 SPEAKER_01: 高维空间中的偶然一致性极低。

51
00:04:55,411 --> 00:04:56,153
发言人 SPEAKER_01: 即使是一个六维的物体，如果有两个六维向量在每个维度上都一致到10%的误差范围内，那么这种情况的概率是百万分之一。

52
00:04:56,514 --> 00:04:58,036
发言人 SPEAKER_01: 所以，如果你看到几个高度一致的预测，这不太可能是偶然的。

53
00:04:59,038 --> 00:05:02,024
发言人 SPEAKER_01: 这就像情报过滤中的情况：如果你看到很多对话提到“纽约”或“九月”，这并不意味着什么。

54
00:05:03,206 --> 00:05:05,451
发言人 SPEAKER_01: 但如果你看到多个对话提到“纽约，9月11日”，你应该高度怀疑，因为这是一个高维的偶然一致性。

55
00:05:05,790 --> 00:05:09,538
发言人 SPEAKER_01: 即使有很多其他对话提到“芝加哥”等无关内容，高维的偶然一致性应该让你意识到有真实的事情发生。

56
00:05:10,531 --> 00:05:13,735
发言人 SPEAKER_01: 我将从Marr的角度出发，认为要理解大脑，我们需要弄清楚它在计算什么。

57
00:05:14,755 --> 00:05:25,290
发言人 SPEAKER_01: 我将给出一个理由，说明为什么大脑需要进行这种计算，然后我会说，这就是微柱在做的事情。

58
00:05:26,851 --> 00:05:34,502
发言人 SPEAKER_01: 这是大胆的推测，但至少是基于计算的推测，因为它源于需要完成的计算任务。

59
00:05:35,963 --> 00:05:37,685
发言人 SPEAKER_01: 好的，现在我来解释当前神经网络如何进行物体识别，并且做得相当不错。

60
00:05:38,391 --> 00:05:49,326
发言人 SPEAKER_01: 这主要归功于Yann LeCun，他自1987年以来一直在使用反向传播来实现这一点，并极大地推动了技术的发展。

61
00:05:49,505 --> 00:05:59,639
发言人 SPEAKER_01: 他称之为“卷积网络”（ConvNets）。

62
00:06:00,399 --> 00:06:07,267
发言人 SPEAKER_01: 它们使用多层学习到的特征检测器。

63
00:06:08,564 --> 00:06:25,326
发言人 SPEAKER_01: 特征检测器是局部的，随着层级的上升，它们的感受野逐渐变大。

64
00:06:25,947 --> 00:06:33,778
发言人 SPEAKER_01: 特征提取层与池化层（如最大池化或平均池化）交替出现。

65
00:06:36,374 --> 00:06:44,985
发言人 SPEAKER_01: 池化层的作用是查看附近神经元的激活情况，并通常选择最活跃的神经元。

66
00:06:46,326 --> 00:06:52,894
发言人 SPEAKER_01: 这提供了一定程度的平移不变性，并减少了下一层的神经元数量。

67
00:06:54,437 --> 00:06:55,499
发言人 SPEAKER_01: 但我不相信池化操作。

68
00:06:56,259 --> 00:07:00,245
发言人 SPEAKER_01: 我认为它与形状感知的心理学不符。

69
00:07:01,146 --> 00:07:02,728
发言人 SPEAKER_01: 我们并不希望神经活动对视角不变，至少在最高层之前不应该如此。

70
00:07:02,747 --> 00:07:04,389
发言人 SPEAKER_01: 我们希望的是知识对视角不变，而不是神经活动对视角不变。

71
00:07:05,146 --> 00:07:08,269
发言人 SPEAKER_01: 卷积网络未能利用线性流形，而计算机图形学通过仿射变换实现高效视角泛化。

72
00:07:08,290 --> 00:07:13,276
发言人 SPEAKER_01: 池化是一种非常原始的路由方式。

73
00:07:15,658 --> 00:07:16,079
发言人 SPEAKER_01: 在视觉中，视角的变化会导致信息在不同像素之间跳跃。

74
00:07:19,803 --> 00:07:23,427
发言人 SPEAKER_01: 我们需要将像素中的信息正确地路由到知道如何处理这些信息的神经元。

75
00:07:24,730 --> 00:07:31,398
发言人 SPEAKER_01: 大多数神经网络研究者还没有真正面对这个路由问题。

76
00:07:31,418 --> 00:07:34,562
发言人 SPEAKER_01: 我将从形状感知的心理学角度开始，说明卷积网络的不合理性。

77
00:07:34,997 --> 00:07:44,208
发言人 SPEAKER_01: 当人们进行形状感知时，他们会将矩形坐标系强加在物体上。

78
00:07:45,189 --> 00:07:48,733
发言人 SPEAKER_01: 如果你对同一个物体施加不同的坐标系，你甚至不会意识到它们是同一个物体。

79
00:07:49,273 --> 00:07:52,976
发言人 SPEAKER_01: 这是一个巨大的效应，而卷积网络无法解释这一点。

80
00:07:54,098 --> 00:08:04,870
发言人 SPEAKER_01: 卷积网络无法解释为什么相同的像素会根据坐标系的不同而被完全不同的方式处理，因为它们没有显式的坐标系概念。

81
00:08:05,980 --> 00:08:07,221
发言人 SPEAKER_01: 我将通过一个演示来说明坐标系的力量。

82
00:08:08,062 --> 00:08:10,204
发言人 SPEAKER_01: 这是一个简单的物体，比如一个四面体。

83
00:08:12,127 --> 00:08:16,413
发言人 SPEAKER_01: 如果你将四面体切成两半，然后让一个聪明的人将这两半重新组合成四面体，他们可能无法做到。

84
00:08:18,555 --> 00:08:19,716
发言人 SPEAKER_01: 这个谜题之所以难，是因为人们自然施加的坐标系与四面体的坐标系不一致。

85
00:08:21,778 --> 00:08:28,747
发言人 SPEAKER_01: 这个演示表明，坐标系对形状感知的影响是巨大的，而卷积网络无法解释这一点。

86
00:08:28,930 --> 00:08:33,840
发言人 SPEAKER_01: 卷积网络无法解释为什么相同的像素会根据坐标系的不同而被完全不同的方式处理。

87
00:08:34,140 --> 00:08:37,368
发言人 SPEAKER_01: 我将继续讨论卷积网络的另一个问题：它们未能利用线性流形。

88
00:08:38,429 --> 00:08:45,183
发言人 SPEAKER_01: 线性流形是计算机图形学中用于处理视角变化的关键工具。

89
00:08:49,147 --> 00:09:00,097
发言人 SPEAKER_01: 卷积网络未能利用线性流形，这使得它们在处理视角变化时效率低下。

90
00:09:00,717 --> 00:09:05,442
发言人 SPEAKER_01: 我将继续讨论卷积网络的最后一个问题：池化是一种非常原始的路由方式。

91
00:09:05,503 --> 00:09:07,605
发言人 SPEAKER_01: 在视觉中，视角的变化会导致信息在不同像素之间跳跃。

92
00:09:09,287 --> 00:09:12,990
发言人 SPEAKER_01: 我们需要将像素中的信息正确地路由到知道如何处理这些信息的神经元。

93
00:09:13,871 --> 00:09:14,993
发言人 SPEAKER_01: 大多数神经网络研究者还没有真正面对这个路由问题。

94
00:09:15,352 --> 00:09:17,414
发言人 SPEAKER_01: 我将通过一个演示来说明如何通过一致性进行路由。

95
00:09:17,513 --> 00:09:21,860
发言人 SPEAKER_01: 假设我们有一个低层胶囊，它检测到一个圆形。

96
00:09:21,879 --> 00:09:26,966
发言人 SPEAKER_01: 这个圆形可能是脸部的左眼、右眼，或者是汽车的前轮或后轮。

97
00:09:27,869 --> 00:09:30,451
发言人 SPEAKER_01: 低层胶囊会将这个圆形的位姿发送到所有可能的高层胶囊，并附上一个权重，表示它认为这个圆形属于每个高层胶囊的概率。

98
00:09:30,552 --> 00:09:36,822
发言人 SPEAKER_01: 高层胶囊会查看所有传入的预测，并寻找一致性最高的预测。