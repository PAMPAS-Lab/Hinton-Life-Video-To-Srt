1 00:00:23,301 --> 00:00:33,036 说话人 SPEAKER_08：很高兴向大家介绍杰弗里·辛顿，他是机器学习、神经网络以及最近深度架构的先驱。
2 00:00:33,136 --> 00:00:35,198 主持人 SPEAKER_08：我认为这将是今天的话题。
3 00:00:35,899 --> 00:00:37,642 主持人 SPEAKER_08：那么，杰弗里，请您发言。
4 00:00:38,362 --> 00:00:38,643 主持人 SPEAKER_01：好的。
5 00:00:39,405 --> 00:00:41,046 说话人 SPEAKER_01：我在这里几年前做过一次演讲。
6 00:00:41,087 --> 00:00:45,654 说话人 SPEAKER_01：前 10 分钟或左右将是对我那时所说内容的概述。
7 00:00:46,173 --> 00:00:48,718 说话人 SPEAKER_01：然后我会谈论新内容。
8 00:00:51,600 --> 00:01:02,622 说话人 SPEAKER_01：新内容包括一个更好的学习模块，我会向你展示它在各种不同的事情上学习得更好，比如学习图像如何变换，学习人们如何行走，以及学习物体识别。
9 00:01:06,569 --> 00:01:13,317 说话人 SPEAKER_01：所以基本学习模块由一些代表像素等事物的变量组成，这些变量目前是二进制的。
10 00:01:13,998 --> 00:01:17,843 说话人 SPEAKER_01：一些代表，这些是潜在变量，它们也将是二进制的。
11 00:01:18,846 --> 00:01:22,751 说话人 SPEAKER_01：并且存在二分连通性，所以这些变量不会相互连接。
12 00:01:23,352 --> 00:01:29,521 说话人 SPEAKER_01：这使得如果给你可见变量的状态，推断隐藏变量的状态变得非常容易。
13 00:01:30,040 --> 00:01:34,246 说话人 SPEAKER_01：由于是无向图，所以所有变量都是独立的。
14 00:01:34,227 --> 00:01:44,647 说话人 SPEAKER_01：推理过程只是说，给定可见向量 V，激活隐藏单元 Hj 的概率是来自可见单元的总输入的逻辑函数。
15 00:01:45,347 --> 00:01:46,891 说话人 SPEAKER_01：因此，推断隐藏变量非常简单。
16 00:01:48,033 --> 00:01:51,459 说话人 SPEAKER_01：有了隐藏变量，我们也可以非常简单地推断出可见变量。
17 00:01:51,692 --> 00:02:04,090 说话人 SPEAKER_01：如果我们想的话，如果我们给连接加上权重，并想知道这个模型相信什么，我们就可以前后推理，并行推断所有隐藏变量，然后是所有可见变量，这样长时间做下去，你就能看到它喜欢相信的一些例子。
18 00:02:04,751 --> 00:02:08,858 说话人 SPEAKER_01：学习的目标就是让它喜欢相信那些实际上发生的事情。
19 00:02:12,313 --> 00:02:16,278 说话人 SPEAKER_01：所以这个模型是由一个能量函数控制的，该函数给出了连接的权重。
20 00:02:16,438 --> 00:02:25,811 说话人 SPEAKER_01：可见向量和隐藏向量的能量是所有连接的权重之和，如果可见单元和隐藏单元都处于激活状态。
21 00:02:26,312 --> 00:02:28,935 说话人 SPEAKER_01：所以当一个像素和特征检测器处于激活状态时，你会加上权重。
22 00:02:29,575 --> 00:02:31,717 说话人 SPEAKER_01：如果这是一个很大的正权重，那么它表示低能量，这是好的。
23 00:02:31,919 --> 00:02:32,819 说话人 SPEAKER_01：所以这是一个快乐的网络。
24 00:02:33,841 --> 00:02:34,942 说话人 SPEAKER_01：这个有很好的导数。
25 00:02:35,002 --> 00:02:39,367 说话人 SPEAKER_01：如果你对权重进行微分，你会得到可见和隐藏活动的乘积。
26 00:02:39,348 --> 00:02:46,724 说话人 SPEAKER_01：因此，这个导数将在学习过程中频繁出现，因为这个导数是改变可见和隐藏单元组合配置能量的方式。
27 00:02:51,228 --> 00:02:58,795 说话人 SPEAKER_01：给定能量函数，一个组合配置的概率是指数函数减去该组合配置的能量除以配分函数归一化后的能量。
28 00:02:59,576 --> 00:03:07,365 说话人 SPEAKER_01：如果你想知道特定可见向量的概率，你必须对所有可能与之相关的隐藏向量进行求和，这就是可见向量的概率。
29 00:03:07,925 --> 00:03:20,138 说话人 SPEAKER_01：如果你想通过改变权重来提高这个概率，显然需要降低那些想要与之匹配的可见向量和隐藏向量组合的能量，并提高所有其他组合的能量
30 00:03:20,117 --> 00:03:21,378 说话人 SPEAKER_01：因此你减少了竞争。
31 00:03:25,423 --> 00:03:42,457 说话人 SPEAKER_01：正确的最大似然学习规则，也就是说，如果我想通过改变权重来增加网络在幻想它喜欢相信的事物时生成向量 V 的对数概率，那么它有一个简单的形式。
32 00:03:42,937 --> 00:03:44,599 说话人 SPEAKER_01：它只是两个相关性的差值。
33 00:03:45,199 --> 00:03:49,264 说话人 SPEAKER_01：尽管它依赖于所有其他权重，但仍然表现为这种相关性的差异。
34 00:03:50,391 --> 00:03:57,842 说话人 SPEAKER_01：你所做的是，取你的数据，激活隐藏单元，随机二进制单元。
35 00:03:57,861 --> 00:03:59,784 说话人 SPEAKER_01：然后重建，激活，重建，激活。
36 00:03:59,805 --> 00:04:01,006 说话人 SPEAKER_01：这是一个马尔可夫链。
37 00:04:01,387 --> 00:04:03,389 说话人 SPEAKER_01：你运行它很长时间，直到你忘记了开始的地方。
38 00:04:04,150 --> 00:04:07,335 说话人 SPEAKER_01：然后你测量那里的相关性，与这里的相关性进行比较。
39 00:04:08,075 --> 00:04:17,427 说话人 SPEAKER_01：而你真正做的是，通过按比例改变权重，我降低了这个可见向量与它所显示的任何隐藏向量的能量。
40 00:04:18,050 --> 00:04:22,939 说话人 SPEAKER_01：而在这里做相反的操作，我提高了我所幻想的事物的能量。
41 00:04:23,740 --> 00:04:27,908 说话人 SPEAKER_01：所以我试图相信数据，而不是相信模型所相信的。
42 00:04:29,209 --> 00:04:34,860 说话人 SPEAKER_01：最终，这种相关性将与那个相同，那时将不会发生任何事情，因为它将相信数据，希望如此。
43 00:04:37,456 --> 00:04:43,464 说话人 SPEAKER_01：结果发现，你可以得到一个更快的学习算法，你只需要上下移动，然后再向上移动，你只需要取这些相关性的差值。
44 00:04:45,266 --> 00:04:49,994 说话人 SPEAKER_01：证明这一点很难，但主要的证明是它有效且快速。
45 00:04:54,281 --> 00:04:58,586 发言人 SPEAKER_01：这些模块之所以有趣，主要原因是你可以将它们堆叠起来。
46 00:04:59,360 --> 00:05:01,807 发言人 SPEAKER_01：原因很复杂，我就不多说了。
47 00:05:01,827 --> 00:05:09,673 发言人 SPEAKER_01：训练一个模块，然后采取特征检测器的活动，将它们视为
48 00:05:10,074 --> 00:05:11,677 发言人 SPEAKER_01：然后在此基础上训练另一个模块。
49 00:05:12,579 --> 00:05:17,204 说话人 SPEAKER_01：所以第一个模块试图通过使用这些特征检测器来模拟像素中的情况。
50 00:05:17,745 --> 00:05:19,588 说话人 SPEAKER_01：特征检测器往往会高度相关。
51 00:05:20,250 --> 00:05:23,675 说话人 SPEAKER_01：第二个模型试图模拟特征检测器之间的相关性。
52 00:05:24,334 --> 00:05:29,603 说话人 SPEAKER_01：你可以保证，如果你这样做是正确的，每次你上升一个层次，你都会得到一个更好的数据模型。
53 00:05:29,887 --> 00:05:32,108 说话人 SPEAKER_01：实际上，你可以保证第一次你升到下一个级别。
54 00:05:32,810 --> 00:05:37,875 说话人 SPEAKER_01：对于更高的级别，你能保证的只是你的数据模型有多好有一个界限。
55 00:05:38,636 --> 00:05:42,740 说话人 SPEAKER_01：每次你增加一个级别，如果你正确地增加，这个界限就会提高。
56 00:05:43,701 --> 00:05:55,894 说话人 SPEAKER_01：在得到这样的保证，即随着级别的增加，总会有好事发生之后，我们就违反了所有数学条件，以某种随意的方式增加更多级别，因为我们知道好事会发生，然后我们用好事确实发生了这一事实来证明它是合理的。
57 00:06:01,122 --> 00:06:06,668 说话人 SPEAKER_01：这使得我们能够完全无监督地学习许多层特征检测器，仅为了建模数据中的结构。
58 00:06:07,449 --> 00:06:14,177 说话人 SPEAKER_01：一旦我们做到了这一点，你无法在机器学习会议上得到认可，因为你要做区分才能在机器学习会议上得到认可。
59 00:06:14,577 --> 00:06:23,990 说话人 SPEAKER_01：所以一旦你做到了这一点，你就在顶部添加一些决策单元，并学习特征顶层和决策单元之间的连接性。
60 00:06:24,569 --> 00:06:28,394 说话人 SPEAKER_01：然后，如果你想的话，你可以使用反向传播来微调所有的连接。
61 00:06:29,235 --> 00:06:35,766 讲者 SPEAKER_01：这克服了反向传播的局限性，因为标签中的信息不多，它只能从标记数据中学习。
62 00:06:36,327 --> 00:06:38,911 讲者 SPEAKER_01：这些可以学习大量未标记的数据。
63 00:06:39,733 --> 00:06:49,810 讲者 SPEAKER_01：它们学习完毕后，你就可以在顶部添加这些单元，并从少量标记数据中进行反向传播，这不再是设计特征检测器了。
64 00:06:50,312 --> 00:06:54,276 讲者 SPEAKER_01：正如你可能知道的，在谷歌，设计特征检测器是一门艺术。
65 00:06:54,817 --> 00:07:00,584 说话人 SPEAKER_01：您希望根据数据中的内容设计特征检测器，而不是基于需要产生标记数据。
66 00:07:01,245 --> 00:07:04,988 说话人 SPEAKER_01：所以反向传播的想法是设计您的特征检测器，以便您能够得到正确的答案。
67 00:07:05,550 --> 00:07:09,995 说话人 SPEAKER_01：这里的想法是设计您的特征检测器，使其擅长模拟数据中的任何情况。
68 00:07:10,956 --> 00:07:15,161 说话人 SPEAKER_01：一旦完成，就稍微调整一下，以便您能更好地得到正确的答案。
69 00:07:15,420 --> 00:07:18,244 说话人 SPEAKER_01：但不要试图用答案来设计特征检测器。
70 00:07:21,059 --> 00:07:31,836 说话人 SPEAKER_01：Yoshua Bengio 的实验室已经做了大量工作，表明这比仅仅进行反向传播能得到更好的最小值，而且是在空间中完全不同部分的最小值。
71 00:07:36,403 --> 00:07:46,880 说话人 SPEAKER_01：所以简要总结这一部分，我认为这是演讲中最重要的一页，因为它指出了近几年来几乎所有机器学习存在的问题。
72 00:07:47,317 --> 00:07:51,141 说话人 SPEAKER_01：机器学习领域的人通常会尝试学习从图像到标签的映射。
73 00:07:51,963 --> 00:07:56,369 说话人 SPEAKER_01：如果你们认为图像和标签是这样产生的，那当然是一件好事。
74 00:07:57,129 --> 00:08:00,954 东西产生了图像，然后图像产生了标签。
75 00:08:01,375 --> 00:08:03,478 给定图像，标签并不依赖于东西。
76 00:08:04,459 --> 00:08:05,641 但你们并不真的相信这一点。
77 00:08:05,721 --> 00:08:08,985 说话人 SPEAKER_01：你只相信如果标签是图像像素奇偶性的话。
78 00:08:09,886 --> 00:08:16,615 说话人 SPEAKER_01：你真正相信的是那些产生图像的东西，以及与图像一起的标签是因为那些东西，而不是因为图像。
79 00:08:17,168 --> 00:08:19,153 说话人 SPEAKER_01：所以，有一只牛在田野里，你说它是牛。
80 00:08:20,194 --> 00:08:26,911 说话人 SPEAKER_01：现在，如果我只对你说“牛”，你不知道这只牛是棕色还是黑色，是站立还是死亡，是远还是近。
81 00:08:26,932 --> 00:08:30,079 说话人 SPEAKER_01：如果我给你看一张牛的图片，你就会知道所有这些事情。
82 00:08:31,000 --> 00:08:32,605 说话人 SPEAKER_01：这是一个非常高的带宽路径。
83 00:08:32,966 --> 00:08:34,570 说话人 SPEAKER_01：这是一个非常低的带宽路径。
84 00:08:35,326 --> 00:08:40,732 说话人 SPEAKER_01：将标签与图像关联的正确方法首先是要学会逆转这条高带宽路径。
85 00:08:41,072 --> 00:08:43,697 说话人 SPEAKER_01：我们可以清楚地做到这一点，因为视觉基本上是可行的。
86 00:08:43,716 --> 00:08:45,359 说话人 SPEAKER_01：首先，你向外看，你看到一些东西。
87 00:08:45,759 --> 00:08:49,303 说话人 SPEAKER_01：它不像是一头牛，可能是一头大象，也可能是一个演讲厅。
88 00:08:49,965 --> 00:08:51,527 说话人 SPEAKER_01：基本上，你几乎总是能做对。
89 00:08:52,888 --> 00:08:54,389 说话人 SPEAKER_01：因此，我们可以逆转这个途径。
90 00:08:54,691 --> 00:08:57,153 说话人 SPEAKER_01：学会了这样做之后，我们就可以学习事物的名称了。
91 00:08:58,556 --> 00:09:03,662 说话人 SPEAKER_01：但你不是从名字上理解牛的概念，而是从观察世界中的事物来理解。
92 00:09:04,013 --> 00:09:06,514 说话人 SPEAKER_01：这正是我们在做的事情，然后稍后关联标签。
93 00:09:11,049 --> 00:09:17,677 说话人 SPEAKER_01：现在，我需要对基本模块进行一点小的修改，就是我之前使用的是二进制单元作为可观察量。
94 00:09:18,119 --> 00:09:21,163 说话人 SPEAKER_01：现在，我们希望使用带有高斯噪声的线性单元。
95 00:09:21,783 --> 00:09:23,385 说话人 SPEAKER_01：所以我们只是稍微改变了能量函数。
96 00:09:23,926 --> 00:09:27,691 说话人 SPEAKER_01：现在的能量函数呈现一种抛物线形的约束。
97 00:09:28,072 --> 00:09:31,716 说话人 SPEAKER_01：这些线性可见单元每个都有一个偏置，就像它的均值一样。
98 00:09:31,975 --> 00:09:33,217 说话人 SPEAKER_01：它希望坐在这里。
99 00:09:33,639 --> 00:09:35,660 说话人 SPEAKER_01：远离这一点会消耗能量。
100 00:09:36,241 --> 00:09:38,745 说话人 SPEAKER_01：抛物线是高斯函数的负对数。
101 00:09:38,725 --> 00:09:39,527 说话人 SPEAKER_01：所以这会消耗能量。
102 00:09:40,008 --> 00:09:49,669 说话人 SPEAKER_01：然后来自隐藏单元的输入，这仅仅是 VI，HJ，WIJ，但 Vs 必须按高斯的标准差进行缩放。
103 00:09:52,135 --> 00:09:56,986 说话人 SPEAKER_01：如果我问，如果我对一个可见活动进行微分，
104 00:09:57,135 --> 00:10:02,846 说话人 SPEAKER_01：那么我得到的是 HJWIJ 除以 sigma I。这就像是一个能量梯度。
105 00:10:03,586 --> 00:10:12,081 说话人 SPEAKER_01：当您重建时，可见单元所做的是，它试图在想要坐在这里和想要满足这个能量梯度之间取得妥协。
106 00:10:12,482 --> 00:10:14,927 说话人 SPEAKER_01：所以它移动到这两个梯度相等且方向相反的位置。
107 00:10:15,528 --> 00:10:19,195 说话人 SPEAKER_01：这就是最有可能的值，然后你周围有高斯噪声。
108 00:10:20,102 --> 00:10:29,422 说话人 SPEAKER_01：所以，经过这样小的修改，我们现在可以处理具有二进制潜在变量的实值数据，并且有一个高效的近似最大似然学习算法。
109 00:10:30,403 --> 00:10:33,650 说话人 SPEAKER_01：因此，我们可以将其应用于某些事物。
110 00:10:33,671 --> 00:10:37,317 说话人 SPEAKER_01：所以，有一个由语音专家精心组织的很好的语音识别任务。
111 00:10:37,923 --> 00:10:40,467 说话人 SPEAKER_01：有一个名为 Timit 的旧数据库。
112 00:10:41,210 --> 00:10:47,581 说话人 SPEAKER_01：它有一个非常明确的语音识别任务，你需要做的是给定一个短语音窗口。
113 00:10:48,202 --> 00:10:55,037 说话人 SPEAKER_01：你必须预测各种不同音素的中心帧的概率分布。
114 00:10:55,017 --> 00:10:59,464 说话人 SPEAKER_01：实际上，每个音素都是由一个三状态 HMM 模型来表示的，即开始、中间和结束。
115 00:11:00,085 --> 00:11:05,674 说话人 SPEAKER_01：所以你必须预测每个帧，它是否是每个可能的音素的开始、中间还是结束？
116 00:11:06,115 --> 00:11:07,498 说话人 SPEAKER_01：有 183 个这样的东西。
117 00:11:08,158 --> 00:11:16,873 说话人 SPEAKER_01：如果你给它一个良好的分布，这样就能集中关注正确的事情，那么所有后处理都会告诉你音素边界在哪里以及你的音素错误率是多少。
118 00:11:17,157 --> 00:11:20,363 说话人 SPEAKER_01：音素边界应该在哪里以及你的音素错误率是多少。
119 00:11:20,703 --> 00:11:21,664 说话人 SPEAKER_01：这都很标准。
120 00:11:22,225 --> 00:11:23,528 说话人 SPEAKER_01：有些人使用三元音模型。
121 00:11:24,850 --> 00:11:26,975 说话人 SPEAKER_01：我们使用的是二元音模型，这并不那么强大。
122 00:11:29,219 --> 00:11:33,466 说话人 SPEAKER_01：现在我们可以测试我们在提取 11 帧语音方面的能力有多好。
123 00:11:34,187 --> 00:11:40,600 说话人 SPEAKER_01：每帧 10 毫秒，但每帧都在观察大约 25 毫秒的语音，并预测中间帧的音素。
124 00:11:42,115 --> 00:11:45,567 说话人 SPEAKER_01：我们使用标准的语音表示，即梅尔胶囊系数。
125 00:11:46,049 --> 00:11:48,659 说话人 SPEAKER_01：有 13 个这样的系数，以及它们之间的差异和差异。
126 00:11:50,245 --> 00:11:52,615 说话人 SPEAKER_01：然后我们将它们输入到这些深度网络之一中。
127 00:11:54,350 --> 00:11:59,638 说话人 SPEAKER_01：那么，这是你的输入，39 个系数的 11 帧。
128 00:11:59,658 --> 00:12:04,245 说话人 SPEAKER_01：然后，当学生这样做的时候我不在，他实际上相信了我所说的话。
129 00:12:04,304 --> 00:12:06,548 说话人 SPEAKER_01：所以他认为添加很多很多隐藏层是个好主意。
130 00:12:06,769 --> 00:12:07,529 说话人 SPEAKER_01：我会停在两层。
131 00:12:07,890 --> 00:12:11,154 说话人 SPEAKER_01：但他添加了很多隐藏层，全部是无监督的。
132 00:12:11,615 --> 00:12:16,583 说话人 SPEAKER_01：所以所有这些绿色连接都是通过无标签学习得到的。
133 00:12:18,426 --> 00:12:22,753 说话人 SPEAKER_01：他在那里使用了一个瓶颈，所以红色连接的数量相对较小。
134 00:12:24,657 --> 00:12:28,068 说话人 SPEAKER_01：这些必须使用判别信息来学习。
135 00:12:28,976 --> 00:12:41,349 讲者 SPEAKER_01：现在你可以在 GPU 板上用一天或核心上用一个月的时间，将正确的答案反向传播整个网络，效果非常好。
136 00:12:41,769 --> 00:12:55,744 讲者 SPEAKER_01：这是你得到的最好的电话错误率，为 23%，但重要的是无论你使用什么配置，有多少隐藏层，只要足够多，无论宽度如何，是否使用这个瓶颈，它都在 23%到 24%之间。
137 00:12:55,724 --> 00:12:59,932 讲者 SPEAKER_01：所以，它对层数和宽度等具体细节非常稳健。
138 00:13:00,673 --> 00:13:08,687 讲者 SPEAKER_01：Timit 上之前最好的结果，对于没有使用说话人自适应的模型，是 24.4%，这是将许多模型平均在一起的结果。
139 00:13:09,870 --> 00:13:17,445 说话人 SPEAKER_03：嗯，这很好。
140 00:13:17,898 --> 00:13:22,744 说话人 SPEAKER_01：所以，我们只训练了一、二、三、一、二、三。
141 00:13:23,205 --> 00:13:25,168 说话人 SPEAKER_01：你知道，我们在训练大约两千万个权重。
142 00:13:26,089 --> 00:13:33,798 说话人 SPEAKER_01：两千万个权重大约是立方毫米皮层的百分之二。
143 00:13:35,020 --> 00:13:35,341 说话人 SPEAKER_01: 好的。
144 00:13:35,380 --> 00:13:36,643 说话人 SPEAKER_01: 所以，这是一个微型大脑。
145 00:13:36,964 --> 00:13:38,826 说话人 SPEAKER_01: 嗯，这可能就是进行音素识别所需要的全部。
146 00:13:40,730 --> 00:13:48,989 说话人 SPEAKER_02: 如果你想让它自己学习做这件事，那么 MFCC 的差异和双差异呢？
147 00:13:49,009 --> 00:13:51,333 讲者 SPEAKER_01：这是一个非常好的问题，你能再问一遍吗？
148 00:13:51,816 --> 00:13:58,991 讲者 SPEAKER_01：这是一个极其好的问题，因为他们之所以要放差异和二阶差异，是为了能够用对角协方差来建模数据。
149 00:13:58,971 --> 00:14:01,075 讲者 SPEAKER_01：矩阵，对角协方差模型。
150 00:14:01,956 --> 00:14:12,409 讲者 SPEAKER_01：而且，除非你实际上将差异放入数据中并直接对差异进行建模，否则你无法通过建模协方差来模拟随着时间的推移，两件事物往往非常相似的事实。
151 00:14:12,711 --> 00:14:15,354 说话人 SPEAKER_01：这使得您可以使用无法处理协方差性的模型。
152 00:14:16,315 --> 00:14:27,190 说话人 SPEAKER_01：稍后我们将向您展示一个可以处理协方差的模型，然后我们将做迪克·莱昂斯（Dick Lyons）一直说您应该做的事情，即丢弃不良的表示，使用更好的语音表示。
153 00:14:28,384 --> 00:14:28,705 说话人 SPEAKER_01：是的。
154 00:14:28,985 --> 00:14:30,167 说话人 SPEAKER_01：上次我拜访时您对我说过这句话。
155 00:14:34,953 --> 00:14:35,173 说话人 SPEAKER_01：聪明人。
156 00:14:35,193 --> 00:14:35,333 说话人 SPEAKER_01：好的。
157 00:14:36,235 --> 00:14:38,658 说话人 SPEAKER_01：所以，新的想法是使用更好的一种模块。
158 00:14:39,320 --> 00:14:41,001 说话人 SPEAKER_01：这个模块已经工作得相当好了，对吧？
159 00:14:41,602 --> 00:14:43,125 说话人 SPEAKER_01：你知道，它在音素识别方面做得很好。
160 00:14:43,144 --> 00:14:44,125 说话人 SPEAKER_01：它在很多其他事情上都做得很好。
161 00:14:45,148 --> 00:14:47,431 说话人 SPEAKER_01：它不能很好地模拟乘性交互。
162 00:14:48,032 --> 00:14:53,298 说话人 SPEAKER_01：只要有足够的训练数据，它可以模拟任何事物，但它不喜欢模拟乘数。
163 00:14:53,339 --> 00:14:56,383 说话人 SPEAKER_01：而乘数无处不在。
164 00:14:57,932 --> 00:15:00,034 说话人 SPEAKER_01：我将向您展示一些需要乘法的地方。
165 00:15:03,418 --> 00:15:05,822 说话人 SPEAKER_01：这就是为什么你需要乘法的主要例子。
166 00:15:06,602 --> 00:15:15,873 说话人 SPEAKER_01：假设我想从对物体的整体描述中获取信息，比如形状的名称和姿态、大小、位置、方向。
167 00:15:16,212 --> 00:15:21,139 说话人 SPEAKER_01：假设我想生成物体的各个部分，并希望它们之间正确关联。
168 00:15:22,789 --> 00:15:30,639 说话人 SPEAKER_01：我需要一个非常精确的从上到下的模型，知道这些平方和后置参数，我就能精确地生成每一块。
169 00:15:31,061 --> 00:15:32,302 说话人 SPEAKER_01：这需要很高的带宽。
170 00:15:33,163 --> 00:15:39,250 说话人 SPEAKER_01：或者我可以马虎一点，可以说，我要生成这一边，而那只是这一边可能分布的一种表示。
171 00:15:40,131 --> 00:15:43,416 说话人 SPEAKER_01：然后我会生成角落和其他边，它们都有点马虎。
如果我从每个分布中挑选一个东西，它们组合起来不会形成一个漂亮的正方形。
173 00:15:48,523 --> 00:15:52,628 说话人 SPEAKER_01：但我也可以自上而下地指定这些事物应该如何拼接在一起。
174 00:15:53,366 --> 00:15:56,714 说话人 SPEAKER_01：实际上，我可以指定一个马尔可夫随机场，说明什么与什么相匹配。
175 00:15:57,515 --> 00:16:02,567 说话人 SPEAKER_01：然后我可以利用这些分布来清理这些信息，并选择一个像那样的正方形。
176 00:16:03,168 --> 00:16:11,004 说话人 SPEAKER_01：当然，有时我可能会选择一个稍微不同方向或大小的正方形，但因为它我知道事物是如何组合的，所以它将是一个整洁的正方形。
177 00:16:11,726 --> 00:16:16,134 说话者 SPEAKER_01：因此这是一种更强大的生成模型，这正是我们想要学习的。
178 00:16:16,897 --> 00:16:26,095 说话者 SPEAKER_01：因此我们需要在这里添加隐藏单元来指定可见单元之间的交互，而不是仅仅指定输入到可见单元。
179 00:16:28,259 --> 00:16:34,730 说话者 SPEAKER_01：这里有一个类比，比如我是一个军官，有一群士兵，我想让他们站成一个方阵，
180 00:16:34,929 --> 00:16:40,422 说话者 SPEAKER_01：我可以拿出我的 GPS，对士兵一号说，站在这些 GPS 坐标上。
181 00:16:40,501 --> 00:16:42,787 说话人 SPEAKER_01：士兵二号，站在这些 GPS 坐标上。
182 00:16:43,347 --> 00:16:45,874 说话人 SPEAKER_01：如果我用足够的数字，就能得到一个整洁的矩形。
183 00:16:46,775 --> 00:16:48,840 说话人 SPEAKER_01：或者我可以这么说，士兵一号，大致站在这里。
184 00:16:48,879 --> 00:16:55,234 说话人 SPEAKER_01：然后士兵二号，伸出你的手臂，与士兵一号保持这个距离。
185 00:16:55,990 --> 00:16:58,215 说话人 SPEAKER_01：这确实是一个制作整齐矩形的更好方法。
186 00:16:58,335 --> 00:16:59,898 说话人 SPEAKER_01：这需要远少的沟通。
187 00:17:00,359 --> 00:17:05,470 说话人 SPEAKER_01：所以你正在做的是大致下载人们应该站立的位置以及他们应该如何相互关联。
188 00:17:06,050 --> 00:17:08,777 说话人 SPEAKER_01：但你必须指定关系，而不仅仅是他们应该在哪里。
189 00:17:10,380 --> 00:17:13,846 说话人 SPEAKER_01：这就是我们想要的强大分层生成模型。
190 00:17:17,928 --> 00:17:27,400 说话人 SPEAKER_01：因此，我们的目标是让某一层的单元能够描述在生成过程中，下面的层级的单元如何进行横向交互。
191 00:17:29,462 --> 00:17:34,269 说话人 SPEAKER_01：实际上，在识别过程中，你不需要担心这些横向交互，但在生成过程中，你需要。
192 00:17:36,833 --> 00:17:41,538 说话人 SPEAKER_01：为了做到这一点，我们需要所谓的三阶玻尔兹曼机，它们具有三方交互。
193 00:17:44,319 --> 00:17:52,752 讲者 SPEAKER_01：所以，Terry Sinofsky 很久以前就指出，我们有一个这样的能量函数，其中这个是 V，这个是 H，但这些都是二元变量。
194 00:17:53,634 --> 00:17:57,901 讲者 SPEAKER_01：我们可能可以写下这样一个能量函数，其中三个因素相互作用，我们有一个三向权重。
195 00:17:58,961 --> 00:18:03,808 讲者 SPEAKER_01：如果你现在考虑这三个因素，K 的状态就像一个开关。
196 00:18:04,009 --> 00:18:10,159 讲者 SPEAKER_01：当 K 打开时，你实际上在 I 和 J 之间有一个这样的权重。当 K 关闭时，这个权重消失。
197 00:18:11,944 --> 00:18:14,127 说话人 SPEAKER_01：它以各种方式发生，因为它是对称的。
198 00:18:15,390 --> 00:18:21,018 说话人 SPEAKER_01：所以使用这样的能量函数，我们可以允许一个事物指定两个其他事物应该如何相互作用。
199 00:18:22,519 --> 00:18:26,145 说话人 SPEAKER_01：所以每个隐藏单元可以指定一个整个像素的马尔可夫随机场，如果您愿意的话。
200 00:18:27,146 --> 00:18:30,612 说话人 SPEAKER_01：但这样可能会让你感到担忧，因为马尔可夫随机场有很多参数。
201 00:18:31,472 --> 00:18:39,505 说话人 SPEAKER_01：如果您从这里开始计数索引，如果有 N 个这样的，N 个那样的，N 个那样的，那么这些参数的立方就是 N 立方，相当多。
202 00:18:42,421 --> 00:18:46,106 说话人 SPEAKER_01：如果您愿意使用 NQ 参数，现在可以构建出这样的网络。
203 00:18:46,607 --> 00:18:50,535 说话人 SPEAKER_01：假设我有两张图片，我想模拟图片随时间的变化。
204 00:18:51,777 --> 00:18:54,281 说话人 SPEAKER_01：假设我只是把随机点移动来移动去。
205 00:18:54,301 --> 00:18:57,247 说话人 SPEAKER_01：我有一个随机的点模式，我将其进行翻译。
206 00:18:57,267 --> 00:19:03,196 说话人 SPEAKER_01：嗯，如果我看到那个点和看到那个点，这可以作为特定翻译的证据。
207 00:19:04,290 --> 00:19:13,240 说话人 SPEAKER_01：因此，如果我在那里放一个很大的正权重，这个三角形表示的就是那个大的三重权重，那么当这两个都开启时，它们会说有这个人真是太好了。
208 00:19:13,881 --> 00:19:15,623 说话人 SPEAKER_01：那将是一个很低的能量状态。
209 00:19:15,643 --> 00:19:20,807 说话人 SPEAKER_01：如果我也看到这对点，我会给这个人更多投票，我会把这个人的灯打开。
210 00:19:22,650 --> 00:19:27,915 说话人 SPEAKER_01：然而，如果这个像素移动到那里，我会给这个人投票，如果这个像素也移动到那里，我也会给这个人投票。
211 00:19:27,935 --> 00:19:32,019 说话人 SPEAKER_01：所以这些人将代表图像的连贯翻译。
212 00:19:32,624 --> 00:19:40,294 说话人 SPEAKER_01：它将能够使用这三个权重来提取两个图像的隐藏单元，这些单元代表连贯的翻译。
213 00:19:40,755 --> 00:19:46,722 说话人 SPEAKER_01：它还能根据预图像和翻译来计算哪些像素应该在这里。
214 00:19:51,269 --> 00:19:53,551 说话人 SPEAKER_01：现在，我们要做的是采用这个基本模型
215 00:19:53,818 --> 00:19:54,861 说话人 SPEAKER_01：然后我们将对其进行分解。
216 00:19:54,921 --> 00:19:58,827 说话人 SPEAKER_01：我们将说，我有这些三维权重，但我有太多这样的权重了。
217 00:19:59,368 --> 00:20:05,079 说话人 SPEAKER_01：所以我将每个三向权重表示为三个双向量的乘积。
218 00:20:06,903 --> 00:20:12,232 说话人 SPEAKER_01：我将介绍这些因子，每个因子都会有这些
219 00:20:13,106 --> 00:20:20,182 说话人 SPEAKER_01：这么多参数，每个因子就是线性数量的参数。
220 00:20:20,803 --> 00:20:25,712 说话人 SPEAKER_01：如果我大约有 N 个因子，最终我只会有 N 平方个这样的权重。
221 00:20:27,215 --> 00:20:31,625 说话人 SPEAKER_01：如果你思考一下图像中像素的变化，它们并不是随机排列。
222 00:20:31,726 --> 00:20:33,849 说话人 SPEAKER_01：并不是这个像素去那里，那个像素去这里。
223 00:20:34,673 --> 00:20:36,255 说话人 SPEAKER_01：像素做的是一种相对一致的事情。
224 00:20:36,454 --> 00:20:43,201 说话人 SPEAKER_01：所以我实际上不需要 NQ 参数，因为我只是试图模拟这些相对一致的变化，这些变化是有限的。
225 00:20:43,541 --> 00:20:45,242 说话人 SPEAKER_01：我应该能够用更少的参数来完成它。
226 00:20:45,884 --> 00:20:46,904 说话人 SPEAKER_01：这就是实现它的方法。
227 00:20:47,986 --> 00:20:51,930 说话人 SPEAKER_01：所以这将成为我们的新能量函数，省略了偏置项。
228 00:20:56,954 --> 00:21:02,200 说话人 SPEAKER_01：关于我如何建模权重的思考方式之一是，我想有一个三维的张量。
229 00:21:03,849 --> 00:21:08,134 发言人 SPEAKER_01：如果我像这样对两个向量进行外积，我会得到一个秩为一的矩阵。
230 00:21:08,756 --> 00:21:12,000 发言人 SPEAKER_01：如果我取三向外积，我会得到一个秩为一的张量。
如果我现在把很多这样的张量加起来，那么现在每个因子，每个 F，都指定了一个一阶张量。
通过将它们加在一起，如果使用 N 平方因子，我可以用它们来模拟任何我想要的张量。
233 00:21:24,776 --> 00:21:31,765 说话人 SPEAKER_01：如果我只用 N 个因素，我可以建模漂亮的正则张量，但我不能建模任意排列，这正是我们想要的。
234 00:21:36,013 --> 00:21:37,696 说话人 SPEAKER_01：那么现在推理是如何工作的呢？
235 00:21:38,077 --> 00:21:39,941 说话人 SPEAKER_01：在这个模型中，推理仍然非常简单。
236 00:21:40,622 --> 00:21:41,463 说话人 SPEAKER_01：所以这里有一个因素。
237 00:21:42,786 --> 00:21:45,431 说话人 SPEAKER_01：这是连接到预图像的权重。
238 00:21:45,451 --> 00:21:47,273 说话人 SPEAKER_01：这是连接到后图像的权重。
239 00:21:47,974 --> 00:21:49,858 说话人 SPEAKER_01：这是连接到隐藏单元的权重。
240 00:21:51,240 --> 00:21:52,943 说话人 SPEAKER_01：要进行推理，我会这样做。
241 00:21:53,826 --> 00:21:55,167 说话人 SPEAKER_01：假设我只考虑这一个因素。
242 00:21:56,269 --> 00:21:59,035 说话人 SPEAKER_01：我会将这些权重乘以像素。
243 00:21:59,707 --> 00:22:03,272 说话人 SPEAKER_01：将它们加起来，这样在这个顶点处得到一个总和。
244 00:22:03,733 --> 00:22:06,057 说话人 SPEAKER_01：这里我也这样做，我在这个顶点处得到一个总和。
245 00:22:06,077 --> 00:22:10,224 说话人 SPEAKER_01：然后我将这两个和相乘，得到要发送给隐藏单元的消息。
246 00:22:10,925 --> 00:22:15,133 说话人 SPEAKER_01：当这个消息传到隐藏单元时，我会将它乘以那个连接上的权重。
247 00:22:15,721 --> 00:22:26,994 说话人 SPEAKER_01：因此，隐藏单元将看到的是这个权重乘以这两个和的乘积，这是能量相对于隐藏单元状态的导数，这是它需要知道的是否开启或关闭。
248 00:22:27,816 --> 00:22:30,358 说话人 SPEAKER_01：它希望进入任何可以降低能量的状态。
249 00:22:30,378 --> 00:22:34,203 说话人 SPEAKER_01：即使现在有了这些乘数，所有的隐藏单元仍然保持独立。
250 00:22:35,526 --> 00:22:38,670 说话人 SPEAKER_01：这样比在这里加入另一个随机二进制单元要好得多。
251 00:22:39,191 --> 00:22:44,277 说话人 SPEAKER_01：如果我在这里加入一个随机二进制单元，隐藏单元将不再独立，推理将变得困难。
252 00:22:44,813 --> 00:22:49,559 说话人 SPEAKER_01：但这种方式，通过一个确定性的因子来计算这两个和的乘积，推理仍然简单。
253 00:22:53,164 --> 00:22:54,567 说话人 SPEAKER_01：学习过程也保持简单。
254 00:22:55,848 --> 00:23:08,086 说话人 SPEAKER_01：所以这是从因子 F 到隐藏单元 H 的消息。这个消息是我们在两个较低顶点得到的产品，即你在前像和后像上计算的求和的乘积。
255 00:23:09,265 --> 00:23:27,949 说话人 SPEAKER_01：你通过改变从因子 F 到隐藏单元 H 的连接权重来学习权重，以便在观察数据时降低能量，在从模型构造事物或仅从数据得到的隐藏单元中重建事物时提高能量。
256 00:23:28,942 --> 00:23:31,105 讲者 SPEAKER_01：这些能量导数看起来就是这样。
257 00:23:31,164 --> 00:23:36,391 讲者 SPEAKER_01：它们仅仅是隐藏单元的状态以及当您查看数据时传递给它的消息的乘积。
258 00:23:36,810 --> 00:23:41,175 讲者 SPEAKER_01：当您查看模型样本或重建时，隐藏单元的状态以及传递给它的消息。
259 00:23:42,076 --> 00:23:43,699 讲者 SPEAKER_01：所以，它仍然是一个很好的成对学习规则。
260 00:23:44,119 --> 00:23:45,582 说话人 SPEAKER_01：所以，一切仍然是一对一。
261 00:23:49,046 --> 00:23:50,227 说话人 SPEAKER_01：所以，你可能把它装进你的大脑里。
262 00:23:52,509 --> 00:23:58,797 说话人 SPEAKER_01：现在，如果我们看看这些因素中的一个在展示随机的点图案时
263 00:23:59,417 --> 00:24:03,122 说话人 SPEAKER_01：然后我们可以看看连接到前图像的权重。
264 00:24:04,123 --> 00:24:07,807 说话人 SPEAKER_01：这就是一种权重模式，白色代表大的正权重，黑色代表大的负权重。
265 00:24:08,548 --> 00:24:10,931 说话人 SPEAKER_01：因此，它学会了将预图像与之连接的条纹。
266 00:24:11,550 --> 00:24:13,753 说话人 SPEAKER_01：这将学会将后图像与之连接的条纹。
267 00:24:14,413 --> 00:24:16,876 说话人 SPEAKER_01：有了 100 个因子，我将向您展示罗兰学到的东西。
268 00:24:20,820 --> 00:24:23,644 说话人 SPEAKER_01：这就是那一百个连接因素。
269 00:24:25,365 --> 00:24:27,888 说话人 SPEAKER_01：这些是预像中因素的感受野。
270 00:24:29,269 --> 00:24:30,912 说话人 SPEAKER_01：记住，这是在翻译点。
271 00:24:32,212 --> 00:24:34,875 说话人 SPEAKER_01：这些是后像中的因素。
272 00:24:36,238 --> 00:24:40,522 说话人 SPEAKER_01：你看，它基本上学会了傅里叶基，并且学会了通过大约 90 度来转换事物。
273 00:24:41,584 --> 00:24:43,226 说话人 SPEAKER_01：这是一种处理翻译的非常好的方法。
274 00:24:44,366 --> 00:24:48,971 说话人 SPEAKER_01：数学家们会说，傅里叶基是建模翻译的自然基。
275 00:24:49,813 --> 00:24:52,896 说话人 SPEAKER_01：我并不真正知道这是什么意思，但是它学会了傅里叶基，所以我很高兴。
276 00:24:55,400 --> 00:24:57,521 说话人 SPEAKER_01：如果你给它旋转，它会学习不同的基。
277 00:24:58,700 --> 00:25:00,382 说话人 SPEAKER_01：所以这是它学习到的旋转的基。
278 00:25:02,065 --> 00:25:03,767 说话人 SPEAKER_01：你看到它在这里学习了阴阳。
279 00:25:05,970 --> 00:25:07,471 说话人 SPEAKER_01：哎呀。
280 00:25:07,491 --> 00:25:10,675 说话人 SPEAKER_01: 好吧。
281 00:25:10,695 --> 00:25:11,798 说话人 SPEAKER_01: 这是旋转的基础。
282 00:25:15,682 --> 00:25:24,555 说话人 SPEAKER_01: 另一件事是，你可以只训练它在连贯方式下平移的单点模式，然后测试它。
283 00:25:24,721 --> 00:25:28,776 说话人 SPEAKER_01: 在两个不同方向平移的叠加点模式上。
284 00:25:29,357 --> 00:25:30,422 说话人 SPEAKER_01：这种情况以前从未见过。
285 00:25:30,442 --> 00:25:36,282 说话人 SPEAKER_01：它只接受过连贯运动的训练，但我们将要测试它对透明运动的处理。
286 00:25:37,646 --> 00:25:41,192 说话人 SPEAKER_01：为了了解它的想法，记住我们正在进行无监督训练。
287 00:25:41,212 --> 00:25:42,174 说话人 SPEAKER_01：没有任何标签。
288 00:25:42,255 --> 00:25:43,557 说话人 SPEAKER_01：我们从不告诉它动作是什么。
289 00:25:44,078 --> 00:25:45,601 说话人 SPEAKER_01：我们需要一种方法来观察它在想什么。
290 00:25:46,282 --> 00:25:52,252 说话人 SPEAKER_01：所以我们增加一个第二隐藏层，该层查看代表变换的隐藏单元，并且它相当稀疏。
291 00:25:52,894 --> 00:25:57,563 说话人 SPEAKER_01：因此，第二隐藏层中的单元将被调整到特定的运动方向。
292 00:25:57,796 --> 00:26:07,287 说话者 SPEAKER_01：然后为了了解它的想法，我们根据这些单元的活跃程度加权它们的方向，这将告诉你它认为它看到的方向。
293 00:26:08,387 --> 00:26:19,020 说话者 SPEAKER_01：现在，当你展示透明运动并观察第二隐藏层中的这些单元时，如果两种运动在约 30 度范围内，它就会看到一个平均方向的单个运动。
294 00:26:19,701 --> 00:26:24,326 说话者 SPEAKER_01：如果它们超过约 30 度，它就会看到两个不同的运动，而且更有甚者，它们彼此排斥。
295 00:26:24,863 --> 00:26:28,807 说话者 SPEAKER_01：这正是人类所发生的情况，这正是大脑的工作方式。
296 00:26:32,513 --> 00:26:32,673 说话人 SPEAKER_01: 好吧。
297 00:26:35,096 --> 00:26:39,824 说话人 SPEAKER_01: 在这次演讲中会有很多这样的推理。
298 00:26:39,844 --> 00:26:41,486 说话人 SPEAKER_01: 现在我将转到时间序列模型。
299 00:26:42,507 --> 00:26:46,252 说话人 SPEAKER_01: 所以我们希望不仅仅对静态图像进行建模。
300 00:26:46,272 --> 00:26:47,173 说话人 SPEAKER_01：我们想对视频进行建模。
301 00:26:47,574 --> 00:26:49,257 说话人 SPEAKER_01：首先，我们要尝试一些稍微简单一点的东西。
302 00:26:51,460 --> 00:26:53,082 说话人 SPEAKER_01：当人们做时间序列模型时，
303 00:26:54,174 --> 00:26:59,028 说话人 SPEAKER_01：你几乎总是希望有一个分布式的非线性表示，但这很难学习。
304 00:26:59,971 --> 00:27:09,298 说话人 SPEAKER_01：所以人们倾向于做一些愚蠢的事情，比如隐马尔可夫模型或线性动态系统，这些要么放弃分布式，要么放弃非线性，但易于进行推理。
305 00:27:09,463 --> 00:27:12,169 说话人 SPEAKER_01：我们将提出的是既有分布式和非线性，又易于推理的东西，但学习算法并不完全正确，但已经足够好了。
306 00:27:13,010 --> 00:27:21,386 说话人 SPEAKER_01：我们将提出的是既有分布式和非线性，又易于推理的东西，但学习算法并不完全正确，但已经足够好了。
307 00:27:21,727 --> 00:27:23,490 说话人 SPEAKER_01：这只是对最大似然的一个近似。
308 00:27:24,192 --> 00:27:27,979 说话人 SPEAKER_01：并且推理也忽略了未来，只是基于过去。
309 00:27:32,616 --> 00:27:36,962 说话人 SPEAKER_01：这里有一个基本模块，这是双向交互的。
310 00:27:37,865 --> 00:27:41,048 说话人 SPEAKER_01：这是具有可见单元和隐藏单元的受限螺栓机。
311 00:27:42,090 --> 00:27:45,455 说话人 SPEAKER_01：这里显示了之前的可见帧。
312 00:27:46,376 --> 00:27:47,838 说话人 SPEAKER_01：这些都是线性单元。
313 00:27:48,779 --> 00:27:56,912 说话人 SPEAKER_01：因此，这些蓝色连接以线性方式对当前可见值进行条件化，基于之前观察到的值。
314 00:27:57,353 --> 00:27:58,994 说话人 SPEAKER_01：这就叫做自回归模型。
315 00:28:01,304 --> 00:28:03,727 说话人 SPEAKER_01：这里的隐藏单元将是二进制隐藏单元。
316 00:28:04,027 --> 00:28:06,069 说话人 SPEAKER_01：它们还依赖于之前的可见帧。
317 00:28:07,451 --> 00:28:09,133 说话人 SPEAKER_01：在这个模型中学习很容易。
318 00:28:09,713 --> 00:28:18,423 说话人 SPEAKER_01：你所做的是，将你的观测数据与当前可见帧以及之前的可见帧结合起来，为隐藏单元提供输入。
319 00:28:18,765 --> 00:28:24,431 说话人 SPEAKER_01：根据数据，它们都是独立的，因此你可以分别决定它们应该处于何种状态。
320 00:28:25,152 --> 00:28:28,476 说话人 SPEAKER_01：一旦为它们固定了状态，你现在就可以重建
321 00:28:28,642 --> 00:28:35,950 说话人 SPEAKER_01：当前帧，使用从之前帧获得的输入，以及从隐藏单元获得的自上而下的输入。
322 00:28:35,970 --> 00:28:44,078 说话人 SPEAKER_01：重建后，然后再次激活隐藏单元，您将这里的数据和这里的重建之间的成对统计差异用于学习这些权重。
323 00:28:44,778 --> 00:28:52,587 说话人 SPEAKER_01：您将这组人的活动和数据以及重建之间的差异用于获取一个可以用来学习这些权重或这些权重的信号。
324 00:28:53,608 --> 00:28:57,432 说话人 SPEAKER_01：因此，学习过程很简单，它只取决于差异。
325 00:28:58,897 --> 00:29:00,078 说话人 SPEAKER_01：您可以学习这样的模型。
326 00:29:00,278 --> 00:29:09,287 说话人 SPEAKER_01：学完后，你可以通过取一些之前的帧来从模型中生成。
327 00:29:11,048 --> 00:29:17,433 说话人 SPEAKER_01：这些输入，即条件输入，实际上固定了这些输入的偏差，使其依赖于之前的帧。
328 00:29:17,473 --> 00:29:18,815 说话人 SPEAKER_01：所以这是一种动态偏差。
329 00:29:19,375 --> 00:29:27,082 说话人 SPEAKER_01：然后，偏差固定后，你就可以前后移动一段时间，然后从中选择一个帧，那就是你生成的下一个帧。
330 00:29:27,122 --> 00:29:28,482 说话人 SPEAKER_01：然后你继续。
331 00:29:28,817 --> 00:29:31,724 说话人 SPEAKER_01：所以一旦模型学会了，我们就可以从模型中生成，看看它相信什么。
332 00:29:37,380 --> 00:29:37,621 说话人 SPEAKER_01：对不起？
333 00:29:38,021 --> 00:29:42,512 说话人 SPEAKER_00：不，我们要回到更早的时间点。
334 00:29:43,455 --> 00:29:45,560 说话人 SPEAKER_01：我最近对 PowerPoint 有点懒散了。
335 00:29:50,991 --> 00:29:54,176 说话人 SPEAKER_01：现在，我们可以从这里出发的一个方向是做更高层次的模型。
336 00:29:54,758 --> 00:30:03,393 说话人 SPEAKER_01：也就是说，这个模型已经学会了，其中这些隐藏单元在给定数据的情况下都是独立的，我们可以这么说，我已经将可见帧转换成了隐藏帧。
337 00:30:04,394 --> 00:30:12,949 说话人 SPEAKER_01：结果发现，如果你用这些隐藏帧来建模这里发生的事情，并在隐藏帧之间建立条件连接，你就可以得到一个更好的模型。
338 00:30:13,215 --> 00:30:18,468 说话人 SPEAKER_01：并且还有更多没有条件连接的隐藏单元，它们不与其他隐藏单元交互，你学习这个模型。
339 00:30:19,048 --> 00:30:27,406 说话人 SPEAKER_01：你可以证明，如果你这样做是正确的，那么你会得到一个更好的原始序列模型，或者你会提高原始序列模型的一个界限。
340 00:30:28,229 --> 00:30:29,412 说话人 SPEAKER_01：所以你可以学习很多这样的层。
341 00:30:29,612 --> 00:30:31,236 说话人 SPEAKER_01：当你有更多层时，它生成的效果更好。
342 00:30:31,717 --> 00:30:33,299 说话人 SPEAKER_01：但我将走向不同的方向
343 00:30:36,367 --> 00:30:39,111 说话人 SPEAKER_01：我将向您展示如何使用三方连接来完成。
344 00:30:39,771 --> 00:30:42,536 说话人 SPEAKER_01：我们将将其应用于动作捕捉数据。
345 00:30:42,556 --> 00:30:44,617 说话人 SPEAKER_01：所以您需要在关节处放置反光标记。
346 00:30:44,637 --> 00:30:46,019 说话人 SPEAKER_01：你有很多红外摄像头。
347 00:30:46,059 --> 00:30:47,481 说话人 SPEAKER_01：你找出空间中关节的位置。
348 00:30:48,002 --> 00:30:50,987 说话人 SPEAKER_01：你知道身体的形状，所以你可以从那里反向推算出关节角度。
349 00:30:51,788 --> 00:31:01,599 说话人 SPEAKER_01：然后一个数据帧将包含大约 50 个数字，大约 50 个数字，这些是关节角度和脊柱基部的平移和旋转。
350 00:31:03,013 --> 00:31:06,857 说话人 SPEAKER_01: 好的，想象一下我们在艺术商店橱窗里看到的那种模特。
351 00:31:07,337 --> 00:31:14,705 说话人 SPEAKER_01: 我们在他的脊椎底部钉了一根钉子，我们可以用这根钉子移动他并旋转他，他还可以扭动他的腿和手臂。
352 00:31:15,507 --> 00:31:15,866 说话人 SPEAKER_01: 好吧？
353 00:31:16,768 --> 00:31:24,015 说话人 SPEAKER_01: 我们希望他在移动时，能够扭动他的腿和手臂，使他的脚看起来像是静止在地面上的，而他看起来像是在走路。
354 00:31:24,675 --> 00:31:29,780 说话人 SPEAKER_01：他在我们翻译他的骨盆时，最好恰当地扭动他的腿，否则他的脚看起来会在地面上打滑。
355 00:31:33,557 --> 00:31:34,558 说话人 SPEAKER_01：我们将对他进行建模。
356 00:31:35,820 --> 00:31:42,371 说话人 SPEAKER_01：我们可以做一个像刚才给你展示的分层模型，或者我们可以做一个三向模型，就像这样，我们基于六个更早的帧进行条件建模。
357 00:31:43,532 --> 00:31:44,693 说话人 SPEAKER_01：这是当前可见的帧。
358 00:31:44,713 --> 00:31:49,101 说话人 SPEAKER_01：这是你的基本玻尔兹曼机，但现在它是一种三向事物，这些是因素。
359 00:31:50,142 --> 00:31:52,065 说话人 SPEAKER_01：我们有一个 N 种风格的变量。
360 00:31:52,486 --> 00:31:54,788 说话人 SPEAKER_01：所以我们有数据，我们在训练时告诉它风格。
361 00:31:55,289 --> 00:31:57,472 说话人 SPEAKER_01：这就算是半监督了。
362 00:31:59,056 --> 00:32:03,642 说话人 SPEAKER_01：它学会了将一个 N 维表示转换为一组实值特征。
363 00:32:04,001 --> 00:32:08,126 说话人 SPEAKER_01：然后它将这些实值特征作为因子输入之一。
364 00:32:08,928 --> 00:32:21,284 说话人 SPEAKER_01：这些因子实际上是在说，这些实值特征在调节你用于条件化的权重矩阵，以及你在非线性模型中使用的权重矩阵。
365 00:32:22,345 --> 00:32:25,088 说话人 SPEAKER_01：所以，这些正在调节自回归模型。
366 00:32:25,308 --> 00:32:26,750 说话人 SPEAKER_01：这与切换自回归模型非常不同。
367 00:32:27,490 --> 00:32:29,133 说话人 SPEAKER_01：它要强大得多。
368 00:32:29,192 --> 00:32:29,954 说话人 SPEAKER_01：它更加强大。
369 00:32:30,275 --> 00:32:31,798 说话人 SPEAKER_04: 嗯。
370 00:32:32,199 --> 00:32:35,806 说话人 SPEAKER_01: 所以，我们将有关于某人以不同风格行走的数据。
371 00:32:36,125 --> 00:32:39,311 说话人 SPEAKER_01: 行走风格。
372 00:32:39,373 --> 00:32:46,967 说话人 SPEAKER_04: 嗯。
373 00:32:48,230 --> 00:32:49,011 说话人 SPEAKER_04: 是的。
374 00:32:49,112 --> 00:32:51,576 说话人 SPEAKER_04: 模型中有什么是关注这个相对的吗？
375 00:32:51,596 --> 00:32:52,779 说话人 SPEAKER_01: 是的，是的。
376 00:32:52,799 --> 00:32:56,688 说话人 SPEAKER_01: 连接上的权重会告诉你它来自哪个帧，对吧？
377 00:32:56,748 --> 00:32:59,053 说话人 SPEAKER_01：在早期模型中，有两个蓝色线条。
378 00:32:59,313 --> 00:33:03,663 说话人 SPEAKER_01：它们是不同的矩阵，并且它们上面有不同的权重。
379 00:33:03,682 --> 00:33:05,226 说话人 SPEAKER_04：从两步之前到一步之前，没有东西，对吧？
380 00:33:05,246 --> 00:33:05,928 说话人 SPEAKER_04：它直接跳过去了？
381 00:33:05,948 --> 00:33:06,890 说话人 SPEAKER_01: 它直接跳过去了，对吧。
382 00:33:07,210 --> 00:33:08,532 说话人 SPEAKER_04: 它只是... 这会一直发生吗？
383 00:33:09,019 --> 00:33:09,319 说话人 SPEAKER_01: 是的。
384 00:33:10,261 --> 00:33:17,652 说话人 SPEAKER_01: 换句话说，从所有六个前帧到当前帧都有直接连接，用于确定当前帧。
385 00:33:17,711 --> 00:33:23,199 说话人 SPEAKER_04：第六帧没有链接到第五帧，或者更早的第四帧吗？
386 00:33:23,219 --> 00:33:26,723 说话人 SPEAKER_01：嗯，当你在计算第五帧是什么的时候，对吧？
387 00:33:27,243 --> 00:33:29,948 说话人 SPEAKER_01：但是当我们计算这个帧时，我们有直接从它连接过来。
388 00:33:31,462 --> 00:33:31,844 说话人 SPEAKER_01：好的。
389 00:33:32,305 --> 00:33:34,268 说话人 SPEAKER_01：我们现在开始训练这个模型。
390 00:33:34,808 --> 00:33:37,773 说话人 SPEAKER_01：训练起来相对容易，尤其是在 GPU 板上。
391 00:33:37,794 --> 00:33:40,960 说话人 SPEAKER_01：然后我们将从中生成内容，以便我们可以看到它学到了什么。
392 00:33:42,442 --> 00:33:51,057 说话人 SPEAKER_01：我们可以通过观察脚是否在地面打滑来判断它是否训练得很好。
393 00:34:06,461 --> 00:34:15,282 说话人 SPEAKER_05：我们会到达那里。
394 00:34:18,150 --> 00:34:19,353 说话人 SPEAKER_01：这是一个正常的散步。
395 00:34:22,780 --> 00:34:23,121 说话人 SPEAKER_01：也许吧。
396 00:34:23,443 --> 00:34:24,284 说话人 SPEAKER_01：维斯塔·威尔林。
397 00:34:26,661 --> 00:34:27,443 说话人 SPEAKER_01: 好吧。
398 00:34:27,463 --> 00:34:28,985 说话人 SPEAKER_01: 这是由模型生成的。
399 00:34:29,025 --> 00:34:38,298 说话人 SPEAKER_01: 他正在决定转向哪个方向，还有，你知道的，他需要让外侧腿比内侧腿迈得更远等等。
400 00:34:40,842 --> 00:34:53,579 说话人 SPEAKER_01: 如果我们有一个模型，如果我们把风格标签翻转为“笨拙的青少年”，他肯定看起来很笨拙，对吧？
401 00:34:53,599 --> 00:34:55,402 说话人 SPEAKER_01: 我们都经历过这种情况。
402 00:34:58,132 --> 00:34:59,934 说话人 SPEAKER_01: 我认为这是一个计算机科学学生。
403 00:35:01,077 --> 00:35:07,264 说话人 SPEAKER_01: 我主要这么想的理由是，如果你让他做一个优雅的走步，看起来就像这样。
404 00:35:07,324 --> 00:35:09,987 说话人 SPEAKER_01: 那肯定是 C3PO。
405 00:35:11,449 --> 00:35:20,260 说话人 SPEAKER_01：现在，我认为这是一个学生，不是一个演员，但他非常出色。
406 00:35:21,400 --> 00:35:23,163 说话人 SPEAKER_01：你可以让他像猫一样轻轻地走。
407 00:35:24,724 --> 00:35:26,266 说话人 SPEAKER_01：我们现在正在询问模型，对吧？
408 00:35:28,541 --> 00:35:30,485 说话人 SPEAKER_01：模型看起来几乎和真实数据一样。
409 00:35:30,505 --> 00:35:32,547 说话人 SPEAKER_01：显然，真实数据中脚的着地更好。
410 00:35:33,088 --> 00:35:36,391 说话人 SPEAKER_01：但请注意他可以减速然后再加速。
411 00:35:37,193 --> 00:35:38,974 说话人 SPEAKER_01：自回归模型无法做到这一点。
412 00:35:39,356 --> 00:35:46,724 说话人 SPEAKER_01：自回归模型的最大特征值要么大于 1，在这种情况下会爆炸，要么小于 1，在这种情况下会死亡。
413 00:35:47,186 --> 00:35:51,492 说话人 SPEAKER_01：保持它们存活的方式就是不断地注入随机噪声，这样它们才能保持活力。
414 00:35:51,952 --> 00:35:54,996 说话人 SPEAKER_01：这就像用死马摇动来让马走路一样。
415 00:35:55,155 --> 00:35:58,059 说话人 SPEAKER_01：这有点，不太好。
416 00:36:03,322 --> 00:36:05,485 说话人 SPEAKER_01：现在，他没有物理模型的任何概念。
417 00:36:06,085 --> 00:36:09,690 说话人 SPEAKER_01：所以，为了做这些类似的失误，数据中必须有类似的失误。
418 00:36:10,570 --> 00:36:14,034 说话人 SPEAKER_01：但是当他停下来以及何时失误，他完全决定。
419 00:36:19,121 --> 00:36:21,744 说话人 SPEAKER_01：我们可以让他走性感步，但你可能对那不感兴趣。
420 00:36:24,648 --> 00:36:25,710 说话人 SPEAKER_01：你想要恐龙变鸡吗？
421 00:36:26,911 --> 00:36:27,932 说话人 SPEAKER_01：恐龙在哪里去鸡了？
422 00:36:29,715 --> 00:36:31,297 说话人 SPEAKER_01：哦，不，那是恐龙和鸡。
423 00:36:31,797 --> 00:36:32,838 说话人 SPEAKER_01：那是混合体。
424 00:36:39,367 --> 00:36:40,429 说话人 SPEAKER_01：嗯，也许是个转换。
425 00:36:45,400 --> 00:36:47,543 说话人 SPEAKER_01：他在那里有很多脚部空间，所以可能是一种混合。
426 00:36:49,789 --> 00:36:54,157 说话人 SPEAKER_01：它正在做一个性感的走步，然后你把标签翻转到正常，然后再翻转到性感。
427 00:36:54,818 --> 00:36:58,927 说话人 SPEAKER_01：它从未见过任何过渡，但因为它是同一个模型，它可以做到合理的过渡。
428 00:37:10,331 --> 00:37:12,735 说话人 SPEAKER_02：变量。
429 00:37:13,394 --> 00:37:18,159 说话人 SPEAKER_02：你能将这些与一个事件风格分离出来，然后通过这些来创造新的风格吗？
430 00:37:18,179 --> 00:37:19,400 说话人 SPEAKER_01：是的。
431 00:37:19,420 --> 00:37:19,501 说话人 SPEAKER_01：是的。
432 00:37:19,521 --> 00:37:22,063 说话人 SPEAKER_01：现在，你还可以在训练时给它添加更多的标签。
433 00:37:22,083 --> 00:37:26,268 说话人 SPEAKER_01：你可以给它速度、步长等，然后你可以很好地控制它。
434 00:37:30,532 --> 00:37:30,632 说话人 SPEAKER_01：是的。
435 00:37:30,652 --> 00:37:31,594 说话人 SPEAKER_01：好的。
436 00:37:31,614 --> 00:37:34,237 说话人 SPEAKER_01：所以，我们可以学习至少 50 维数据的时间序列。
437 00:37:34,797 --> 00:37:37,199 说话人 SPEAKER_01：显然，我们想要将其应用于视频。
438 00:37:37,822 --> 00:37:41,027 说话人 SPEAKER_01：但我们还没有这样做，除了少数简单的情况。
439 00:37:50,440 --> 00:37:53,565 说话人 SPEAKER_01：我要展示的最后一件事是这三个模型中最复杂的应用。
440 00:37:56,110 --> 00:38:04,302 说话人 SPEAKER_01：一种思考方式是让它与之前的用法相似，即我们取一张图片并制作两个副本，但它们必须相同。
441 00:38:04,956 --> 00:38:11,304 说话人 SPEAKER_01：然后我们坚持从因子到这个副本的权重与从因子到这个副本的权重相同。
442 00:38:11,324 --> 00:38:14,086 说话人 SPEAKER_01：所以如果 I 等于 J，那么 WIF 等于 WJF。
443 00:38:16,489 --> 00:38:17,630 说话人 SPEAKER_01：推理仍然简单。
444 00:38:18,210 --> 00:38:27,920 说话人 SPEAKER_01：实际上，这里的推理将包括，你将这些像素乘以这些权重得到加权总和，然后平方它，因为这将是一个相同的加权总和。
445 00:38:27,940 --> 00:38:34,507 说话人 SPEAKER_01：所以推理包括取一个线性滤波器，平方其输出，并通过这些权重发送到隐藏单元。
446 00:38:35,128 --> 00:38:41,577 说话人 SPEAKER_01：这正是所谓的定向能量模型，如果你使用正确的线性滤波器的话。
447 00:38:42,239 --> 00:38:49,668 说话人 SPEAKER_01：所以它很早就被视觉研究人员 Adelson 和 Bergen 以及神经科学家提出，早在 80 年代。
448 00:38:50,349 --> 00:38:59,001 说话人 SPEAKER_01：所以神经科学家试图观察简单细胞，我指得不是很明确，看看它们的输入输出是什么多项式。
449 00:38:59,682 --> 00:39:03,128 伯克利大学的杨丹表示，这个数字在1.7到2.3之间。
450 00:39:04,018 --> 00:39:06,882 这就意味着两个，对吧。
451 00:39:09,005 --> 00:39:17,115 所以，这看起来很像为了完全不同的原因而提出的模型，它只是从三向能量模型中分解出来的。
452 00:39:18,057 --> 00:39:22,983 我们的优势在于，我们现在有一个用于所有这些权重的学习算法，并且有一个生成模型。
453 00:39:30,775 --> 00:39:33,418 说话人 SPEAKER_01：那么，现在我们可以对像素之间的协方差进行建模。
454 00:39:33,871 --> 00:39:36,824 说话人 SPEAKER_01：这样做的好处是，嗯，这里有一个好处。
455 00:39:37,909 --> 00:39:41,164 说话人 SPEAKER_01：假设我让你定义一条垂直边缘。
456 00:39:41,565 --> 00:39:45,110 说话人 SPEAKER_01：大多数人会说，嗯，垂直边缘是这一侧亮而另一侧暗的东西。
457 00:39:45,610 --> 00:39:48,152 说话人 SPEAKER_01：嗯，可能这边亮那边暗，但你知道。
458 00:39:48,594 --> 00:39:51,476 说话人 SPEAKER_01：嗯，可能上面亮下面暗，也可能上面暗下面亮。
459 00:39:51,536 --> 00:39:51,817 说话人 SPEAKER_01：好的。
460 00:39:52,177 --> 00:39:53,958 说话人 SPEAKER_01：或者可能是纹理边缘。
461 00:39:54,579 --> 00:39:55,039 说话人 SPEAKER_01：它就要来了。
462 00:39:55,059 --> 00:39:58,003 说话人 SPEAKER_01：或者实际上可能是一个差异边缘。
463 00:39:58,143 --> 00:40:00,565 说话人 SPEAKER_01：嗯，这边可能有运动，而那边没有运动。
464 00:40:00,585 --> 00:40:01,547 说话人 SPEAKER_01：那也是一个垂直边缘。
465 00:40:02,327 --> 00:40:04,250 Speaker SPEAKER_01: 垂直边缘是一个包含许多事物的集合。
466 00:40:05,030 --> 00:40:11,438 Speaker SPEAKER_01: 所有这些陈述的共同点在于，垂直边缘是一个你不应该进行水平插值的地方。
467 00:40:11,873 --> 00:40:14,900 Speaker SPEAKER_01: 通常情况下，在图像中，水平插值效果非常好。
468 00:40:15,440 --> 00:40:20,070 Speaker SPEAKER_01: 像素几乎总是非常准确地是其左右邻居的平均值。
469 00:40:20,090 --> 00:40:22,956 说话人 SPEAKER_01：偶尔会出现故障，而故障发生的地方就是有垂直边缘的地方。
470 00:40:23,818 --> 00:40:29,510 说话人 SPEAKER_01：所以，垂直边缘的真实抽象定义就是水平插值的分解。
471 00:40:30,487 --> 00:40:31,909 说话人 SPEAKER_01：这正是我们的模型将要做的。
472 00:40:31,949 --> 00:40:39,336 说话人 SPEAKER_01：隐藏单元将进行插值，并将其关闭，所以这是一种逆向逻辑。
473 00:40:39,697 --> 00:40:41,539 说话人 SPEAKER_01：当它崩溃时，它就会关闭。
474 00:40:42,360 --> 00:40:43,521 说话人 SPEAKER_01：所以看待它的一个方式是这一点。
475 00:40:45,884 --> 00:40:57,396 说话人 SPEAKER_01：如果这里的隐藏单元是开启的，它会在像素 I 和像素 J 之间输入一个权重，这个权重等于这个权重乘以这个权重乘以这个权重。
476 00:41:00,039 --> 00:41:00,139 未知说话人：好的。
477 00:41:00,557 --> 00:41:04,190 说话人 SPEAKER_01：既然这样，好吧，足够了。
478 00:41:07,360 --> 00:41:12,576 说话人 SPEAKER_01：所以这些可以有效地控制像素之间的马尔可夫随机场，我们可以很好地建模协方差。
479 00:41:18,614 --> 00:41:25,163 说话人 SPEAKER_01：因为隐藏单元正在创建可见单元之间的相关性，因此重建现在变得更加困难。
480 00:41:25,664 --> 00:41:28,628 说话人 SPEAKER_01：我们可以像处理运动一样，根据另一张图像重建一张图像。
481 00:41:29,208 --> 00:41:32,974 说话人 SPEAKER_01：但是如果你想要重建它们并且使它们相同，那就更难了。
482 00:41:33,454 --> 00:41:35,737 说话人 SPEAKER_01：所以我们必须使用一种不同的方法，称为混合蒙特卡洛。
483 00:41:36,039 --> 00:41:41,786 说话人 SPEAKER_01：本质上，你从数据所在的位置开始，让它从那里游走，但保持两张图片相同。
484 00:41:41,766 --> 00:41:45,010 说话人 SPEAKER_01：我不会详细介绍混合蒙特卡洛，但它非常适合进行学习。
485 00:41:45,692 --> 00:41:48,074 说话人 SPEAKER_01：混合蒙特卡洛方法仅用于获取重建结果。
486 00:41:48,635 --> 00:41:50,317 说话人 SPEAKER_01：学习算法与之前相同。
487 00:41:54,021 --> 00:42:01,190 说话人 SPEAKER_01：我们将使用一些隐藏单元，这些隐藏单元利用三种交互来建模像素之间的协方差。
488 00:42:01,650 --> 00:42:03,492 说话人 SPEAKER_01：其他隐藏单元仅用于建模均值。
489 00:42:04,313 --> 00:42:08,179 说话人 SPEAKER_01：因此我们呼吁意义相关性，我们称之为 Maccabi M。
490 00:42:11,364 --> 00:42:15,710 说话人 SPEAKER_01：这是在黑白图像上学习后的一个例子。
491 00:42:16,431 --> 00:42:17,333 说话人 SPEAKER_01：这是一个图像块。
492 00:42:18,715 --> 00:42:25,726 说话人 SPEAKER_01：如果不添加噪声，这是图像块的重建，非常好，来自均值和协方差隐藏单元。
493 00:42:26,467 --> 00:42:28,831 说话人 SPEAKER_01：这是随机重建，效果也不错。
494 00:42:30,492 --> 00:42:31,755 说话人 SPEAKER_01：但现在我们要做一些有趣的事情。
495 00:42:31,795 --> 00:42:38,605 说话人 SPEAKER_01：我们将取协方差单元的激活，这些单元是用来建模哪些像素与哪些其他像素相同的。
496 00:42:39,530 --> 00:42:40,452 说话人 SPEAKER_01：并且我们将保留这些。
497 00:42:41,313 --> 00:42:47,463 说话人 SPEAKER_01：我们将取均值单元的激活，所以我们会把它们扔掉，假装像素的均值看起来像这样。
498 00:42:48,605 --> 00:42:49,487 说话人 SPEAKER_01：好吧，我们先拿这个来。
499 00:42:49,847 --> 00:42:53,934 说话人 SPEAKER_01：我们告诉它所有像素都有相同的值，除了这些非常暗的像素。
500 00:42:53,954 --> 00:43:02,449 说话人 SPEAKER_01：现在它试图使关于均值的信息与关于协方差的信息相匹配，即这些信息应该是相同的，但与这些信息非常不同。
501 00:43:03,626 --> 00:43:11,639 说话人 SPEAKER_01：因此，它提出了一个看起来像这样的重建，你可以看到它正在将这块深色的东西模糊地扩展到这个区域。
502 00:43:11,659 --> 00:43:19,931 说话人 SPEAKER_01：如果我们只给它四个点像那样，以及我们从那里得到的协方差矩阵，它就会将这些点模糊化，形成一个看起来相当像的那个图像。
503 00:43:20,704 --> 00:43:33,929 说话人 SPEAKER_01：所以这非常类似于所谓的图像水彩模型，你知道边界在哪里，你只是大致勾勒出区域的颜色，对我们来说看起来都很正常，因为我们把颜色边界与实际的边缘对齐。
504 00:43:36,434 --> 00:43:42,324 说话人 SPEAKER_01：如果你将这些颜色反转，就会得到一个反向的图像，因为协方差根本不在乎事物的符号。
505 00:43:45,561 --> 00:43:53,253 说话人 SPEAKER_01：如果你看看它学习的过滤器，用于覆盖区域的均值单元，会学习这些模糊的过滤器。
506 00:43:53,335 --> 00:43:58,222 说话人 SPEAKER_01：通过组合几十个这样的单元，你几乎可以制作出你喜欢的任何颜色的图像。
507 00:43:59,364 --> 00:44:00,266 说话人 SPEAKER_01：所以，它们非常模糊。
508 00:44:00,286 --> 00:44:03,050 说话人 SPEAKER_01：它们很光滑、模糊且多彩。
509 00:44:03,771 --> 00:44:05,554 说话人 SPEAKER_01：并且你可以大致调出正确的颜色。
510 00:44:06,496 --> 00:44:08,760 说话人 SPEAKER_01：协方差单位学习到了完全不同的事物。
511 00:44:09,541 --> 00:44:10,842 说话人 SPEAKER_01：所以，这就是过滤器学习到的内容。
512 00:44:12,898 --> 00:44:17,923 说话人 SPEAKER_01：你会发现这些因素，它们学习高频黑白边缘。
513 00:44:20,266 --> 00:44:26,492 说话人 SPEAKER_01：然后其中一小部分变成了低频的红、绿、黄、蓝颜色边缘。
514 00:44:27,373 --> 00:44:37,902 说话人 SPEAKER_01：更有甚者，当你使用我将在下一页描述的技术从地形图制作出来时，你会得到这个颜色块，这个低频颜色块与低频黑白滤镜混合在一起。
515 00:44:38,784 --> 00:44:40,746 说话人 SPEAKER_01：这就是你在猴子的脑中看到的东西。
516 00:44:41,266 --> 00:44:41,706 说话人 SPEAKER_01: 会很。
517 00:44:41,726 --> 00:44:47,876 说话人 SPEAKER_01: 如果你进入猴子的脑中，你会看到这些随着你沿着皮层切向移动而方向变化平滑的高频滤波器。
518 00:44:48,579 --> 00:44:50,702 说话人 SPEAKER_01: 你还会看到这些低频颜色块。
519 00:44:51,884 --> 00:44:54,789 说话人 SPEAKER_01: 大多数神经科学家认为这至少是先天的。
520 00:44:55,530 --> 00:45:02,583 说话人 SPEAKER_01：这说的意思是，不，仅仅图像的结构和形成地形图的想法就足够了。
521 00:45:03,284 --> 00:45:04,385 说话人 SPEAKER_01：这并不意味着它是天生的。
522 00:45:04,465 --> 00:45:05,788 说话人 SPEAKER_01：只是意味着它不需要。
523 00:45:07,911 --> 00:45:17,947 说话人 SPEAKER_01：所以，我们获取地形图的方式是通过像素到因子的全局连通性。
524 00:45:18,509 --> 00:45:20,512 说话人 SPEAKER_01：所以这些因素实际上是在学习局部滤波器。
525 00:45:20,773 --> 00:45:24,097 说话人 SPEAKER_01：局部滤波器一开始是有颜色的，然后逐渐学会变成纯黑白色。
526 00:45:26,186 --> 00:45:29,873 说话人 SPEAKER_01：然后因素和隐藏单元之间存在局部连接性。
527 00:45:30,375 --> 00:45:36,666 说话人 SPEAKER_01：所以这些隐藏单元中的一个将连接到一个小因素的正方形，这在这里诱导出地形。
528 00:45:37,349 --> 00:45:44,802 说话人 SPEAKER_01：能量函数是这样的，当你关闭其中一个隐藏单元，比如说平滑性不再适用时，
529 00:45:45,813 --> 00:45:46,994 说话人 SPEAKER_01：你会付出一定的代价。
530 00:45:48,275 --> 00:45:50,358 说话人 SPEAKER_01：你宁愿只付出一次代价。
531 00:45:50,538 --> 00:45:55,603 说话人 SPEAKER_01：所以如果两个因素要同时启动，最好将它们连接到同一个隐藏单元。
532 00:45:55,623 --> 00:45:56,844 说话人 SPEAKER_01：你只需支付一次罚款。
533 00:45:57,606 --> 00:46:06,094 说话人 SPEAKER_01：因此，这些类似因素会进入这里类似的位置，我们得到一幅地形图。
534 00:46:06,114 --> 00:46:08,918 说话人 SPEAKER_01：对于了解图像建模的人来说，
535 00:46:09,487 --> 00:46:14,195 说话人 SPEAKER_01：据我所知，到目前为止，还没有人制作出好的彩色图像块模型。
536 00:46:14,797 --> 00:46:17,621 说话人 SPEAKER_01：这是一个生成模型，可以生成看起来像真实数据的玩意儿。
537 00:46:19,085 --> 00:46:22,971 说话人 SPEAKER_01：这是一个在伯克利数据库的 16x16 彩色图像上学习到的模型。
538 00:46:23,592 --> 00:46:26,376 说话人 SPEAKER_01：这是模型生成的图像。
539 00:46:26,396 --> 00:46:27,498 说话人 SPEAKER_01：它们看起来很相似。
540 00:46:28,260 --> 00:46:29,362 说话人 SPEAKER_01：现在，这有一部分是技巧。
541 00:46:29,422 --> 00:46:33,048 说话人 SPEAKER_01：这里的色彩平衡就像色彩平衡，这让你觉得它们相似。
542 00:46:33,451 --> 00:46:34,793 说话人 SPEAKER_01：但有一部分是真实的。
543 00:46:34,972 --> 00:46:39,719 说话人 SPEAKER_01：我的意思是，这些大多数都是颜色大致均匀的平滑区域，这些也是如此。
544 00:46:40,320 --> 00:46:42,282 说话人 SPEAKER_01：还有一些比那些更平滑的。
545 00:46:43,164 --> 00:46:45,987 说话人 SPEAKER_01：但你也会遇到这些有相当锐利边缘的东西。
546 00:46:46,608 --> 00:46:50,432 说话人 SPEAKER_01：所以你会先有平滑，然后是锐利的边缘，然后又是平滑，就像在真实数据中那样。
547 00:46:51,014 --> 00:46:52,775 说话人 SPEAKER_01：这里甚至有角落。
548 00:46:53,126 --> 00:46:56,614 说话人 SPEAKER_01：我们还没有完全达到那里，但这是目前最好的图像块颜色图像模型。
549 00:46:57,255 --> 00:47:05,190 说话人 SPEAKER_01：这是因为它同时建模协方差和均值，所以它能够说出什么是相同的，以及强度是多少。
550 00:47:07,434 --> 00:47:09,177 说话人 SPEAKER_01：你可以用它来进行识别。
551 00:47:10,525 --> 00:47:22,184 说话人 SPEAKER_01：这是一个困难的物体识别任务，有 8000 万未标记的训练图像，不是所有类别，但收集了成千上万的类别，这些类别是由麻省理工学院的人收集的。
552 00:47:22,405 --> 00:47:23,907 说话人 SPEAKER_01：它被称为 Tiny Images 数据库。
553 00:47:24,288 --> 00:47:26,251 说话人 SPEAKER_01：它们是 32x32 彩色图像。
554 00:47:26,871 --> 00:47:29,657 说话人 SPEAKER_01：但令人惊讶的是，你可以在 32x32 彩色图像中看到什么。
555 00:47:30,617 --> 00:47:31,739 说话人 SPEAKER_01：既然
556 00:47:31,889 --> 00:47:34,833 说话人 SPEAKER_01：我们将使用的最大模型大约有 1 亿个连接。
557 00:47:35,253 --> 00:47:39,300 说话人 SPEAKER_01：这大约是立方毫米皮质中参数数量的 0.1。
558 00:47:40,101 --> 00:47:45,809 说话人 SPEAKER_01：因此，我们必须以某种方式让我们的计算机模型跟上拥有更多硬件的大脑。
559 00:47:46,090 --> 00:47:47,932 说话人 SPEAKER_01：所以我们通过提供一个非常小的视网膜来完成它。
560 00:47:48,293 --> 00:47:53,661 说话人 SPEAKER_01：我们假设输入只有 32x32，也许我们实际上可以在这里做一些合理的事情。
561 00:47:55,987 --> 00:47:57,789 说话人 SPEAKER_01：所以正如您将看到的，这里有很多变化。
562 00:47:57,829 --> 00:48:00,032 说话人 SPEAKER_01：如果您看鸟，这是鸵鸟的特写。
563 00:48:00,472 --> 00:48:02,215 说话人 SPEAKER_01：这是一张典型的鸟类图片。
564 00:48:03,536 --> 00:48:10,405 说话人 SPEAKER_01：在这十个类别中很难区分，尤其是像鹿和马这样的东西。
565 00:48:10,485 --> 00:48:16,492 说话人 SPEAKER_01：我们故意选择了非常相似的一些类别，比如卡车和汽车，鹿和马。
566 00:48:18,987 --> 00:48:19,907 说话人 SPEAKER_01：人们在这方面做得相当不错。
567 00:48:19,967 --> 00:48:21,409 说话人 SPEAKER_01：人们不会犯很多错误。
568 00:48:21,871 --> 00:48:23,934 说话人 SPEAKER_01：这主要是因为这些数据是人工标注的。
569 00:48:25,695 --> 00:48:28,460 说话人 SPEAKER_01：所以，即使是人们也会犯一些错误。
570 00:48:30,161 --> 00:48:36,490 说话人 SPEAKER_01：我们只有 50,000 个训练样本，每个类别 5,000 个，以及 10,000 个测试样本，因为我们必须人工标注它们。
571 00:48:37,050 --> 00:48:39,034 说话人 SPEAKER_01：但我们有很多未训练、未标记的数据。
572 00:48:39,353 --> 00:48:42,057 说话人 SPEAKER_01：因此我们可以在大量未标记的数据上进行所有这些预训练。
573 00:48:42,780 --> 00:48:54,376 说话人 SPEAKER_01：然后取我们的协方差单元和均值单元，在上面尝试进行多项式逻辑回归，或者可能添加另一个隐藏层在上面进行。
574 00:48:56,010 --> 00:49:06,764 说话人 SPEAKER_01：实际上，Marco Iliaranzato 在 Jan Lekans 实验室工作期间所做的是，他实际上取了更小的块，学习了一个模型，然后在图像上跨步移动并复制它们。
575 00:49:07,286 --> 00:49:08,507 说话人 SPEAKER_01：所以它有点半卷积。
576 00:49:09,068 --> 00:49:18,922 说话人 SPEAKER_01：然后取了所有这些小块中的隐藏单元，并将它们连接起来，形成了一个包含 11,000 个隐藏单元的大向量，这些隐藏单元既是均值也是协方差。
577 00:49:20,103 --> 00:49:23,588 说话人 SPEAKER_01：然后我们将用它作为我们的特征，看看我们做得怎么样。
578 00:49:27,043 --> 00:49:30,128 说话人 SPEAKER_01：我们将将其与各种其他方法进行比较。
579 00:49:32,992 --> 00:49:39,059 说话人 SPEAKER_01：那么，第一次比较就是直接对像素进行逻辑回归，以决定十个类别。
580 00:49:39,579 --> 00:49:41,021 说话人 SPEAKER_01：你得到 36%的正确率。
581 00:49:42,224 --> 00:49:50,875 说话人 SPEAKER_01：如果你使用由 Toralbo 和麻省理工学院的人开发的 gist 特征，这些特征旨在很好地捕捉图像中的内容，但它们的维度相对较低。
582 00:49:50,972 --> 00:49:53,876 说话人 SPEAKER_01：你得到 54%，所以它们比像素要好得多。
如果你使用一个正常的 RBM，它具有具有高斯噪声的线性输入单元和二进制隐藏单元，然后使用这些二进制隐藏单元进行分类，你将得到 60%的准确率。
如果你使用这些 RBM 中的任何一个，同时使用这些单元进行均值计算，然后使用这些具有三方交互的单元来建模协方差，
你将得到69%的准确率，只要你使用大量的这些因素。
然后，如果你再学习一个包含8,000个单元的额外隐藏层，请注意，这相当于1亿个额外的连接，你将在那里学习到。
587 00:50:29,744 --> 00:50:33,110 说话人 SPEAKER_01：但这没关系，因为它是无监督的，你只需要在大量数据上学习。
588 00:50:34,873 --> 00:50:38,398 说话人 SPEAKER_01：你可以达到 72%，这是该数据库迄今为止的最佳结果。
589 00:50:39,378 --> 00:50:40,521 说话人 SPEAKER_01：最后还有一件事。
590 00:50:44,737 --> 00:50:57,514 说话人 SPEAKER_01：你可以使用这个为图像块开发的模型，那位做音素识别的学生只是将那段代码应用到对数频谱图上，这更接近迪克希望看到的样子。
591 00:50:57,554 --> 00:51:04,605 说话人 SPEAKER_01：你没有使用这些设计用来丢弃你认为不需要的东西并消除大量相关性的恶意胶囊。
592 00:51:05,045 --> 00:51:09,731 说话人 SPEAKER_01：相反，你将使用包含大量相关性的数据，但我们现在有一个可以处理这些数据的模型。
593 00:51:10,538 --> 00:51:29,003 说话人 SPEAKER_01：2 月 20 日，乔治尝试的第一件事是在这之上添加了四层一千个隐藏单元，正确率达到了 22.7%，这是在 Timit 数据库上电话识别的记录，你不需要为每个说话人定制模型。
594 00:51:29,827 --> 00:51:34,751 说话人 SPEAKER_01：然后，一周后当他稍微调整了一下并使用了更多的帧时，正确率下降到了 21.6%。
595 00:51:35,632 --> 00:51:38,034 说话人 SPEAKER_01：所以，所有这些设计都是为了做视觉。
596 00:51:38,096 --> 00:51:39,396 说话人 SPEAKER_01：它并不是为了做音素。
597 00:51:40,237 --> 00:51:51,028 说话人 SPEAKER_01：如果我们把音素识别当作是对对数频谱图上的视觉问题处理，我们就可以在小型词汇量上击败语音专家。
598 00:51:51,048 --> 00:51:54,972 说话人 SPEAKER_01：现在还有一位学生在微软尝试看这种方法是否也能在大词汇量上生效。
599 00:51:57,518 --> 00:51:57,777 说话人 SPEAKER_01: 是的。
600 00:51:58,159 --> 00:52:00,884 说话人 SPEAKER_01: 当然，没错。
601 00:52:00,903 --> 00:52:02,346 说话人 SPEAKER_03: 我们，当然，没错。
602 00:52:02,365 --> 00:52:03,849 说话人 SPEAKER_03: 我们可以给他们提供更好的新工具。
603 00:52:04,068 --> 00:52:05,452 说话人 SPEAKER_01：我们可以给他们提供新的更好的工具。
604 00:52:07,054 --> 00:52:08,878 说话人 SPEAKER_01：所以，这是多年来语音单元识别的情况。
605 00:52:10,039 --> 00:52:13,005 说话人 SPEAKER_01：80 年代的后处理得到了 26.1%的正确率。
606 00:52:13,826 --> 00:52:20,277 说话人 SPEAKER_01：接下来的 20 年左右，他们通过非神经启发的方法将正确率降低到 24.4%。
607 00:52:20,717 --> 00:52:22,581 说话人 SPEAKER_01：所以，我把它们称为人工的。
608 00:52:24,012 --> 00:52:25,494 说话人 SPEAKER_01：我们现在已经下降到 21.6%。
609 00:52:26,016 --> 00:52:27,981 说话人 SPEAKER_01：人类性能的估计大约是 15%。
610 00:52:28,922 --> 00:52:31,909 说话人 SPEAKER_01：恐怕我对他们是如何进行这个估计的并不了解。
611 00:52:32,329 --> 00:52:34,835 说话人 SPEAKER_01：但我们已经接近从人工到真实的近三分之一了。
612 00:52:35,858 --> 00:52:37,701 说话人 SPEAKER_01：所以，我们还需要两个想法，我们就成功了。
613 00:52:39,485 --> 00:52:40,226 说话人 SPEAKER_01：好的，我完成了。
614 00:52:43,594 --> 00:52:43,994 说话人 SPEAKER_01：我完成了。
615 00:52:54,572 --> 00:52:55,954 说话人 SPEAKER_03: 嗯。
616 00:52:55,974 --> 00:53:15,804 说话人 SPEAKER_03: 您的仪器最近宣布您和学生们在 MNIST 数据集上打破了世界纪录，您只是使用了一个经过反向传播训练的七层前馈网络进行识别，但这是在 GPU 上进行的，使用了大量的周期。
617 00:53:15,987 --> 00:53:17,548 说话人 SPEAKER_01: 是的，他确实宣布了这一点。
618 00:53:18,170 --> 00:53:22,637 说话人 SPEAKER_01: 他没有宣布的是，他取得了惊人的成果。
619 00:53:22,657 --> 00:53:24,159 说话人 SPEAKER_01：他减少到 35 个错误。
620 00:53:25,920 --> 00:53:29,425 说话人 SPEAKER_01：他没有宣布的是，涉及两个技巧。
621 00:53:30,347 --> 00:53:34,753 说话人 SPEAKER_01：一个技巧是使用具有许多层的庞大网络和 GPU 板。
622 00:53:35,434 --> 00:53:37,858 说话人 SPEAKER_01：这个技巧本身并不能给你带来 35 个错误。
623 00:53:38,219 --> 00:53:39,800 说话人 SPEAKER_01：还有一个技巧。
624 00:53:39,780 --> 00:53:51,021 说话人 SPEAKER_01：实际上，这个技巧是由微软的人开创的，即投入大量工作来产生数据的扭曲，以便拥有大量标记数据。
625 00:53:52,063 --> 00:53:58,353 说话人 SPEAKER_01：所以你拿一张标注好的“二”的图片，然后用巧妙的方式对其进行扭曲，使其仍然看起来像“二”，但进行了翻译。
626 00:53:58,994 --> 00:54:01,619 说话人 SPEAKER_01：人们可以将错误率降低到大约 40 个。
627 00:54:03,253 --> 00:54:03,474 说话人 SPEAKER_01：好。
628 00:54:03,715 --> 00:54:05,521 说话人 SPEAKER_01：所以迪克已经申请了这项专利。
629 00:54:05,541 --> 00:54:09,514 说话人 SPEAKER_01：这样你可以通过这些扭曲将错误率降低到大约 40 个。
630 00:54:09,855 --> 00:54:16,655 说话人 SPEAKER_01：他甚至做了更好的扭曲，更多，以及更大的网络和 GPU，错误率从 40 降低到 35。
631 00:54:17,632 --> 00:54:20,414 说话人 SPEAKER_01：这很令人印象深刻，因为在那里取得任何进展都很困难。
632 00:54:20,434 --> 00:54:22,896 说话人 SPEAKER_01：但是如果没有大量标记数据，这是不会起作用的。
633 00:54:23,536 --> 00:54:26,920 说话人 SPEAKER_01：而且被隐藏的东西就是他们投入了哪些工作。
634 00:54:26,960 --> 00:54:29,181 说话人 SPEAKER_01：如果你看论文，一切都是非常直接的。
635 00:54:29,202 --> 00:54:35,226 说话人 SPEAKER_01：这只是反向传播，除非你到了他们生成所有额外标记数据的部分，那里有非常细致的工作。
636 00:54:35,246 --> 00:54:39,351 说话人 SPEAKER_01：比如如果是 1 或 7，它们只旋转一定的角度。
637 00:54:39,411 --> 00:54:41,032 说话人 SPEAKER_01：但如果不是这样，他们就会旋转更多度数。
638 00:54:41,733 --> 00:54:44,295 说话人 SPEAKER_01：我实际上是这篇论文的评审人，但我并不介意他知道这一点。
639 00:54:44,876 --> 00:54:47,318 说话人 SPEAKER_01：我认为这是一项非常重要的工作。
640 00:54:47,297 --> 00:54:54,793 说话人 SPEAKER_01：但他应该强调他们必须要有标记数据来做这件事，并且他们必须投入精力去处理扭曲。
641 00:54:55,534 --> 00:54:59,704 讲者 SPEAKER_01：对我来说，那篇论文的教训是，在我们拥有小型计算机的时候
642 00:55:00,577 --> 00:55:07,989 讲者 SPEAKER_01：你应该把精力投入到像权重约束这样的东西上，这样你就不会有太多的参数，因为你只有一台小电脑。
643 00:55:08,010 --> 00:55:28,981 讲者 SPEAKER_01：随着计算机变得更大更快，你可以把精力从像 Yam 在早期那样捆绑权重转移到生成更多的扭曲上，这样你就可以以扭曲的形式注入你的先验知识，这会更耗费计算资源，但有了大电脑就没事了，而且更灵活。
644 00:55:29,452 --> 00:55:31,054 说话人 SPEAKER_01：我认为这就是那篇论文的教训。
645 00:55:33,496 --> 00:55:41,344 说话人 SPEAKER_03：我甚至都没问问题，你就回答了。
646 00:55:41,364 --> 00:55:41,563 说话人 SPEAKER_08：谢谢。
647 00:55:41,684 --> 00:55:44,246 说话人 SPEAKER_08：还有其他非问题吗？
648 00:55:44,266 --> 00:55:52,215 说话人 SPEAKER_02：所以看起来你发明了一种具有预期特性的“大脑皮层”，如果它做视觉，它也会做声音。
649 00:55:53,295 --> 00:55:53,456 说话人 SPEAKER_02：是的。
650 00:55:54,356 --> 00:55:55,998 说话人 SPEAKER_02：你打算将它应用到哪些其他问题上？
651 00:55:56,688 --> 00:56:03,996 说话人 SPEAKER_01：也许我们应该先说说我们不打算应用的问题。
652 00:56:04,016 --> 00:56:04,737 说话人 SPEAKER_01：我想不出任何。
653 00:56:08,641 --> 00:56:13,266 说话人 SPEAKER_01：我的意思是，好吧，让我来说说这个在视觉上的主要局限性。
654 00:56:14,768 --> 00:56:18,492 说话人 SPEAKER_01：我们至少有 100 亿个神经元用于视觉处理。
655 00:56:19,773 --> 00:56:21,775 说话人 SPEAKER_01：嗯，至少有十亿，可能有一百亿。
656 00:56:22,715 --> 00:56:32,847 说话人 SPEAKER_01：尽管我们有了那么多神经元和大约 10 的 13 次方个连接来处理视觉，但我们仍然有一个视网膜，其黄斑区的大小只有我的拇指指尖那么大，距离手臂长度。
657 00:56:33,989 --> 00:56:37,032 说话人 SPEAKER_01：所以我们仍然几乎看一切，但不去看它。
658 00:56:37,132 --> 00:56:40,818 说话人 SPEAKER_01：视觉的本质不是聪明地看几乎一切。
659 00:56:42,079 --> 00:56:46,083 说话人 SPEAKER_01：这就是为什么你会看到这些有趣的错觉，你看不见东西。
660 00:56:47,025 --> 00:56:48,489 说话人 SPEAKER_01：我们必须在这些模型中这样做。
661 00:56:48,548 --> 00:57:01,070 说话人 SPEAKER_01：这些模型完全疯狂，几乎所有计算机视觉都是疯狂的，因为它们使用统一分辨率的图像，相当大，比如一千乘一千，然后它们试图一次性用过滤器处理整个图像。
662 00:57:01,753 --> 00:57:07,583 说话人 SPEAKER_01：如果它们要进行选择，它们要么在到处运行它们的面部检测器。
663 00:57:07,815 --> 00:57:13,541 说话人 SPEAKER_01：或者它们在没有任何智能的情况下运行脸部检测器，或者它们在非常低级别上进行某种兴趣点检测，以决定关注什么。
664 00:57:13,561 --> 00:57:23,431 说话人 SPEAKER_01：我们所做的是在某处固定目光，然后根据我们的视网膜提供的边缘大像素和中间小像素，我们决定我们看到的是什么，以及下一步看向哪里。
665 00:57:23,771 --> 00:57:29,657 说话人 SPEAKER_01：到了第二次或第三次注视时，我们就会非常智能地注视，其本质是视觉采样。
666 00:57:30,938 --> 00:57:35,123 说话人 SPEAKER_01：它并不是处理所有事物，这一点我在之前的说法中完全忽略了。
667 00:57:35,896 --> 00:57:41,230 说话人 SPEAKER_01：现在，为了做到这一点，你必须能够将你所看到的和你看到的地方结合起来，这就是乘法。
668 00:57:41,871 --> 00:57:46,222 说话人 SPEAKER_01：所以这个能够进行乘法的模块非常擅长将“什么”和“在哪里”结合起来，以整合时间上的信息。
669 00:57:46,844 --> 00:57:49,190 说话人 SPEAKER_01：这正是我们现在正在努力解决的问题之一。
670 00:57:49,210 --> 00:57:50,574 说话人 SPEAKER_01：但也许是最大的缺失。
671 00:57:50,594 --> 00:57:52,639 说话人 SPEAKER_01：但这只是一个例子，
672 00:57:52,619 --> 00:57:56,585 说话人 SPEAKER_01：拥有一个模块相当不错，但现在永远不够好。
673 00:57:56,706 --> 00:57:59,110 说话人 SPEAKER_01：所以你必须随着时间的推移将其组合起来并多次使用。
674 00:57:59,731 --> 00:58:01,695 说话人 SPEAKER_01：这就是顺序推理以及所有这些内容。
675 00:58:02,416 --> 00:58:07,023 说话人 SPEAKER_01：所以，基本上，一旦人们变得连续，我们就根本不对其进行建模。
676 00:58:07,304 --> 00:58:09,608 说话人 SPEAKER_01：我们建模的是在 100 毫秒内你能做什么。
677 00:58:10,990 --> 00:58:12,112 说话人 SPEAKER_01：这就是所缺失的部分。
678 00:58:12,885 --> 00:58:17,875 说话人 SPEAKER_01：但我相信要建模这种连续性，我们需要理解什么是序列。
679 00:58:17,954 --> 00:58:20,139 说话人 SPEAKER_01：这是这些非常强大的操作的序列。
680 00:58:21,001 --> 00:58:26,110 说话人 SPEAKER_01：现在我们比不知道原始操作是什么的情况下，更有条件去尝试建模序列 AI。
681 00:58:26,371 --> 00:58:33,222 说话人 SPEAKER_01：如果我们认为原始操作仅仅是判断两个符号是否相同，那么在理解人们如何进行序列操作方面，我们将陷入困境。
682 00:58:36,577 --> 00:58:37,458 说话人 SPEAKER_01：嗯？
683 00:58:37,478 --> 00:58:51,920 说话人 SPEAKER_03：这其实不是一个公平的问题，但你既然说要用这些网络做所有的事情，你是怎么处理一阶逻辑的，比如存在一只狗，每个女孩都有一个男孩喜欢？
684 00:58:51,940 --> 00:58:53,163 说话人 SPEAKER_01：等等，我还在处理这个问题。
685 00:58:54,945 --> 00:58:58,670 说话人 SPEAKER_01：我想说的是，人们觉得量词相当难。
686 00:58:58,954 --> 00:59:00,797 说话人 SPEAKER_03：如果你能处理到三个量词。
687 00:59:00,818 --> 00:59:01,838 说话人 SPEAKER_01: 我很愿意这么做。
688 00:59:01,978 --> 00:59:03,862 说话人 SPEAKER_01：我根本不知道怎么做到这一点。
689 00:59:04,161 --> 00:59:10,771 说话人 SPEAKER_01：你会注意到，在传统的 AI 中，你曾经用它来指出神经网络，但你无法处理量词，所以别想了。
690 00:59:11,512 --> 00:59:16,759 说话人 SPEAKER_01：如今，当他们都做图模型时，他们不再提这件事了，因为他们的图模型也难以处理。
691 00:59:17,019 --> 00:59:18,101 有些人确实如此。
692 00:59:18,121 --> 00:59:18,963 斯图尔特·罗素和一些人确实如此。
693 00:59:19,943 --> 00:59:20,063 对。
694 00:59:20,083 --> 00:59:20,724 是的，有些人确实如此。
695 00:59:20,925 --> 00:59:24,670 说话人 SPEAKER_01：但像五年前的大多数图形模型也无法处理量词。
696 00:59:25,492 --> 00:59:28,775 说话人 SPEAKER_01：所以一个相当好的分界线是，
697 00:59:30,427 --> 00:59:33,449 说话人 SPEAKER_01：你可以在不处理那样真正复杂的问题的情况下做到。
698 00:59:33,931 --> 00:59:35,932 说话人 SPEAKER_01：我很想知道我们如何处理这个问题，但我不知道。
699 00:59:37,014 --> 00:59:38,514 说话人 SPEAKER_01：嗯，我现在就放弃那个了。
700 00:59:42,880 --> 00:59:46,182 说话人 SPEAKER_07：是的。
701 00:59:49,085 --> 00:59:51,068 说话人 SPEAKER_01：是的。
702 00:59:51,547 --> 00:59:52,588 说话人 SPEAKER_01：在 Timit 中，我们就是这样做的。
703 00:59:52,628 --> 00:59:55,152 说话人 SPEAKER_01: 在 Timit 中，我们所有的例子都有标签。
704 00:59:55,637 --> 00:59:57,599 说话人 SPEAKER_01：进行预训练仍然是一个巨大的胜利。
705 01:00:02,947 --> 01:00:08,114 说话人 SPEAKER_01：嗯，Jürgen Schmidhuber 并没有尝试用他所有的扭曲进行预训练。
706 01:00:08,134 --> 01:00:12,278 说话人 SPEAKER_01：现在，我有一个学生叫 Vinod Nair，他刚刚完成了一篇论文，其中尝试了类似的事情。
707 01:00:12,338 --> 01:00:24,514 说话人 SPEAKER_01：他在一个 amnest 上尝试扭曲，并使用他自己的特殊扭曲，事实上，扭曲有很大帮助，但如果进行预训练，那也会有所帮助。
708 01:00:24,494 --> 01:00:32,101 说话人 SPEAKER_01：Bengio 的结果，Yoshua Bengio 的结果表明，即使你有所有这些标签数据，预训练也会让你到达空间中的不同部分。
所以很明显，需要做的一件事就是尝试将这些标签与预训练相结合。
710 01:00:37,967 --> 01:00:40,351 Speaker SPEAKER_01: 你不必有预训练，但我敢打赌它仍然有帮助。
711 01:00:43,293 --> 01:00:45,076 Speaker SPEAKER_01: 我敢打赌它还更有效率。
712 01:00:45,476 --> 01:00:48,099 说话人 SPEAKER_01：它更快，因为预训练相对较快。
713 01:00:48,139 --> 01:00:49,300 说话人 SPEAKER_01：你不需要学习一个非常好的模型。
714 01:00:49,559 --> 01:00:51,041 说话人 SPEAKER_01：你将获得许多丰富的特征。
715 01:00:51,628 --> 01:00:57,577 说话人 SPEAKER_01：从这里开始，我认为你会比仅仅从随机开始做得更好，而且更快。
716 01:00:58,778 --> 01:01:00,041 说话人 SPEAKER_01：那只是一个预测。
717 01:01:00,061 --> 01:01:01,764 说话人 SPEAKER_01：你可能甚至能降低到 34 个错误。
718 01:01:04,608 --> 01:01:08,032 说话人 SPEAKER_01：MNIST 的问题在于错误率太低，你无法得到显著性。
719 01:01:08,112 --> 01:01:09,233 Speaker SPEAKER_01: 害羞真的很讨人喜欢。
720 01:01:09,273 --> 01:01:21,552 Speaker SPEAKER_06: 他们设计得很好，所以你可以得到更高的错误率，这样你就能看到差异。
721 01:01:22,054 --> 01:01:31,164 Speaker SPEAKER_06: 你是否会得到超出你使用的时间窗口大小的推断或观察？
722 01:01:32,664 --> 01:01:33,905 Speaker SPEAKER_01: 抱歉，我没有听懂这个问题。
723 01:01:35,648 --> 01:01:37,409 说话人 SPEAKER_06：我们有一个有限的时间窗口。
724 01:01:37,429 --> 01:01:42,875 说话人 SPEAKER_06：我们有一个有限的时间窗口。
725 01:01:42,894 --> 01:01:45,898 说话人 SPEAKER_06：训练后，模型中有没有什么捕捉到的？
726 01:01:46,838 --> 01:01:47,099 说话人 SPEAKER_01：没有。
727 01:01:47,418 --> 01:01:47,760 说话人 SPEAKER_06: 没什么。
728 01:01:48,019 --> 01:01:48,860 说话人 SPEAKER_01: 没什么。
729 01:01:48,880 --> 01:01:51,083 说话人 SPEAKER_01: 它无法处理。
730 01:01:51,434 --> 01:01:56,250 说话人 SPEAKER_01: 它无法建模如何... 对。
731 01:01:56,369 --> 01:02:02,489 说话人 SPEAKER_01: 但是如果 15 个时间步之前发生的事情真的能告诉你现在应该发生什么。
732 01:02:02,943 --> 01:02:04,425 说话人 SPEAKER_01: 它只能告诉你现在应该发生什么。
733 01:02:04,445 --> 01:02:06,971 说话人 SPEAKER_01: 它不能告诉你中间 14 个时间步应该发生什么。
734 01:02:07,291 --> 01:02:11,860 说话人 SPEAKER_01: 它只包含 15 个时间步的信息，而没有在更小的时间尺度上具有特征。
735 01:02:12,641 --> 01:02:13,483 说话人 SPEAKER_01: 你听不出来。
736 01:02:14,045 --> 01:02:16,208 说话人 SPEAKER_01: 因为它没有隐藏的前向-后向算法。
737 01:02:16,389 --> 01:02:25,085 说话人 SPEAKER_01: 前向-后向算法理论上可以听出来，但实际上不行。
738 01:02:25,927 --> 01:02:30,972 说话人 SPEAKER_06: 规则在盒子里，从另一边出来，你就听不出来了。
739 01:02:30,992 --> 01:02:34,056 说话人 SPEAKER_01：不是在很长时间尺度上，不，不。
740 01:02:34,077 --> 01:02:37,960 说话人 SPEAKER_01：除非你说这里涉及到记忆，你会回到之前的时间。
741 01:02:37,981 --> 01:02:40,704 说话人 SPEAKER_01：这会变得更复杂，对吧？
742 01:02:40,724 --> 01:02:45,230 说话人 SPEAKER_01：现在，当你构建多级结构时，无论是使用双向连接还是三向连接都可以做到这一点，这是真的。
743 01:02:45,690 --> 01:02:51,157 说话人 SPEAKER_01：在每一个级别，你都能获得更长的时距，因为你的时间窗口更宽，所以每个级别都更深入到过去。
744 01:02:51,797 --> 01:02:53,739 说话人 SPEAKER_01：所以你会有点像那样，但这只是线性的。
745 01:02:56,706 --> 01:03:05,670 说话人 SPEAKER_05：你能说，对于不同级别，你训练时需要多少未标记的数据，以及这会如何变化吗？
746 01:03:06,157 --> 01:03:10,903 说话人 SPEAKER_05：比如，它是与权重的数量线性相关吗？还是随着级别的提高，情况会发生变化？
747 01:03:10,923 --> 01:03:11,083 说话人 SPEAKER_01: 好吧。
748 01:03:11,103 --> 01:03:28,248 说话人 SPEAKER_01: 关于这一点，我想说一件很重要的事情，那就是如果你正在对高维数据进行建模，并且试图构建数据的无监督模型，你所需要的训练样本比如果你习惯了判别学习所想象的要少得多。
749 01:03:28,228 --> 01:03:34,375 说话人 SPEAKER_01: 你在进行判别学习时，通常每个训练案例的约束参数非常少。
750 01:03:34,815 --> 01:03:42,463 说话人 SPEAKER_01: 对于训练案例的参数约束量，是确定答案所需的位数，而不是确定输入所需的位数。
751 01:03:42,923 --> 01:03:45,226 说话者 SPEAKER_01：所以，对于 MNIST，每个案例有 3.3 比特。
752 01:03:46,108 --> 01:03:53,054 说话人 SPEAKER_01：如果你在建模图像，每个案例的比特数就是指定图像所需的比特数，大约是一百比特。
753 01:03:54,047 --> 01:03:57,295 说话人 SPEAKER_01：所以每个参数需要的案例要少得多。
754 01:03:57,795 --> 01:04:03,586 说话人 SPEAKER_01：另一种说法是，你在建模更丰富的事物，因此每个案例都能提供更多的信息。
755 01:04:04,289 --> 01:04:08,056 说话人 SPEAKER_01: 实际上，我们通常可以建模的参数比我们拥有的训练案例要多得多。
756 01:04:08,938 --> 01:04:10,922 说话人 SPEAKER_01: 而有歧视心的人并不习惯这样。
757 01:04:11,923 --> 01:04:15,751 说话人 SPEAKER_01：参数比我们有的像素少得多，比训练案例多得多。
758 01:04:16,626 --> 01:04:21,835 说话人 SPEAKER_01：实际上，他只用了大约两百万个案例来做图像处理，但这还不够。
759 01:04:21,894 --> 01:04:22,576 说话人 SPEAKER_01：这是过拟合了。
760 01:04:22,896 --> 01:04:23,838 说话人 SPEAKER_01：他应该使用更多。
761 01:04:26,420 --> 01:04:31,548 说话人 SPEAKER_01: 但他正在调整一千万个参数或者类似的东西，所以。
762 01:04:31,568 --> 01:04:44,068 说话人 SPEAKER_01: 但是，基本上，唯一的一个经验法则是，参数数量要比训练数据中的总像素数少很多，但通常可以比训练案例的数量使用更多的参数。
763 01:04:44,088 --> 01:04:46,431 说话人 SPEAKER_01: 而这是不能用正常的判别性学习来做到的。
764 01:04:46,833 --> 01:04:53,545 说话人 SPEAKER_01: 现在，如果你这样做，当你开始判别性训练时，它会迅速提高效果，然后很快就会过拟合。
765 01:04:53,565 --> 01:04:54,686 说话人 SPEAKER_01: 所以，你得早点停止。
766 01:05:04,885 --> 01:05:06,748 说话人 SPEAKER_08: 好的。
